shnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:14:23 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:14:23 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:14:23 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:14:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 16:14:23 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 16:14:23 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:14:23 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1132178964
16/03/16 16:14:23 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1079.7 MB)
16/03/16 16:14:23 INFO MemoryStore: ensureFreeSpace(4141) called with curMem=6568, maxMem=1132178964
16/03/16 16:14:23 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1079.7 MB)
16/03/16 16:14:23 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:47333 (size: 4.0 KB, free: 1079.7 MB)
16/03/16 16:14:23 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 16:14:23 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:14:23 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 16:14:23 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 16:14:23 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 16:14:23 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125063094
16/03/16 16:14:23 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-29676747-1513-4814-9fb6-9739cb19a9c3/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: area
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: issue
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: planning
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: permission
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: economy
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: composition
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: agency
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 16:14:31 INFO PythonRunner: Times: total = 7757, boot = 455, init = 353, finish = 6949
16/03/16 16:14:31 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 16:14:31 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 16:14:31 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 16:14:31 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7842 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: set
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): adding to parents: syn =  Synset('set.n.01') ; keyword:  belong  in syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: bend
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: giant
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: astatine
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: present
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: area
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
16/03/16 16:14:31 INFO PythonRunner: Times: total = 267, boot = 169, init = 0, finish = 98
16/03/16 16:14:31 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 16:14:31 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.130 s
16/03/16 16:14:31 INFO DAGScheduler: looking for newly runnable stages
16/03/16 16:14:31 INFO DAGScheduler: running: Set()
16/03/16 16:14:31 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 16:14:31 INFO DAGScheduler: failed: Set()
16/03/16 16:14:31 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 16:14:31 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 16:14:31 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10709, maxMem=1132178964
16/03/16 16:14:31 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1079.7 MB)
16/03/16 16:14:31 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15693, maxMem=1132178964
16/03/16 16:14:31 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1079.7 MB)
16/03/16 16:14:31 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 299 ms on localhost (2/2)
16/03/16 16:14:31 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 16:14:31 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:47333 (size: 3.0 KB, free: 1079.7 MB)
16/03/16 16:14:31 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 16:14:31 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:14:31 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 16:14:31 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:14:31 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 16:14:31 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:14:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 16:14:31 INFO PythonRunner: Times: total = 170, boot = 169, init = 1, finish = 0
16/03/16 16:14:31 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 16:14:31 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:14:31 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 16:14:31 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:14:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/16 16:14:31 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 200 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'set']
16/03/16 16:14:31 INFO PythonRunner: Times: total = 177, boot = 176, init = 0, finish = 1
16/03/16 16:14:31 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1229 bytes result sent to driver
16/03/16 16:14:31 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 229 ms on localhost (2/2)
16/03/16 16:14:31 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 16:14:31 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.404 s
16/03/16 16:14:31 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.565030 s
16/03/16 16:14:31 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:14:31 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:14:31 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:14:31 INFO DAGScheduler: Parents of final stage: List()
16/03/16 16:14:31 INFO DAGScheduler: Missing parents: List()
16/03/16 16:14:31 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:14:31 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18741, maxMem=1132178964
16/03/16 16:14:31 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1079.7 MB)
16/03/16 16:14:31 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24557, maxMem=1132178964
16/03/16 16:14:31 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1079.7 MB)
16/03/16 16:14:31 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:47333 (size: 3.3 KB, free: 1079.7 MB)
16/03/16 16:14:31 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 16:14:31 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:14:31 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 16:14:31 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 16:14:31 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 16:14:32 INFO PythonRunner: Times: total = 19, boot = 1, init = 18, finish = 0
16/03/16 16:14:32 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 16:14:32 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2259 bytes)
16/03/16 16:14:32 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 44 ms on localhost (1/2)
16/03/16 16:14:32 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 16:14:32 INFO PythonRunner: Times: total = 164, boot = 164, init = 0, finish = 0
16/03/16 16:14:32 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1295 bytes result sent to driver
16/03/16 16:14:32 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.225 s
16/03/16 16:14:32 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.286528 s
16/03/16 16:14:32 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 201 ms on localhost (2/2)
16/03/16 16:14:32 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 16:14:32 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 16:14:32 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 16:14:32 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 16:14:32 INFO MemoryStore: MemoryStore cleared
16/03/16 16:14:32 INFO BlockManager: BlockManager stopped
16/03/16 16:14:32 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 16:14:32 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 16:14:32 INFO SparkContext: Successfully stopped SparkContext
16/03/16 16:14:32 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 16:14:32 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 16:14:32 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'set']
16/03/16 16:14:33 INFO SparkContext: Running Spark version 1.5.2
16/03/16 16:14:33 INFO SecurityManager: Changing view acls to: root
16/03/16 16:14:33 INFO SecurityManager: Changing modify acls to: root
16/03/16 16:14:33 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 16:14:33 INFO Slf4jLogger: Slf4jLogger started
16/03/16 16:14:33 INFO Remoting: Starting remoting
16/03/16 16:14:33 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:49896]
16/03/16 16:14:33 INFO Utils: Successfully started service 'sparkDriver' on port 49896.
16/03/16 16:14:33 INFO SparkEnv: Registering MapOutputTracker
16/03/16 16:14:33 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 16:14:33 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-94241a97-6af5-406f-9904-da2dad1a6855
16/03/16 16:14:33 INFO MemoryStore: MemoryStore started with capacity 1079.7 MB
16/03/16 16:14:33 INFO HttpFileServer: HTTP File server directory is /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/httpd-f5aeeb1e-9c5e-4de8-8a59-27f9ad55674a
16/03/16 16:14:33 INFO HttpServer: Starting HTTP Server
16/03/16 16:14:33 INFO Utils: Successfully started service 'HTTP file server' on port 57280.
16/03/16 16:14:33 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 16:14:33 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 16:14:33 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 16:14:33 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-137ef2eb-8ce5-41c0-a58f-f2956c1d038b/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 16:14:33 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125073507
16/03/16 16:14:33 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 16:14:33 INFO Executor: Starting executor ID driver on host localhost
16/03/16 16:14:33 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42892.
16/03/16 16:14:33 INFO NettyBlockTransferService: Server created on 42892
16/03/16 16:14:33 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 16:14:33 INFO BlockManagerMasterEndpoint: Registering block manager localhost:42892 with 1079.7 MB RAM, BlockManagerId(driver, localhost, 42892)
16/03/16 16:14:33 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): uranium
16/03/16 16:14:33 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:14:33 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:14:33 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:14:33 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:14:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 16:14:33 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 16:14:33 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:14:33 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1132178964
16/03/16 16:14:33 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1079.7 MB)
16/03/16 16:14:33 INFO MemoryStore: ensureFreeSpace(4141) called with curMem=6568, maxMem=1132178964
16/03/16 16:14:33 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1079.7 MB)
16/03/16 16:14:33 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:42892 (size: 4.0 KB, free: 1079.7 MB)
16/03/16 16:14:33 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 16:14:33 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:14:33 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 16:14:33 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 16:14:33 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 16:14:33 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125073507
16/03/16 16:14:33 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-137ef2eb-8ce5-41c0-a58f-f2956c1d038b/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: area
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: issue
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: planning
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: permission
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: economy
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: composition
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: agency
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 16:14:41 INFO PythonRunner: Times: total = 7833, boot = 471, init = 358, finish = 7004
16/03/16 16:14:41 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 16:14:41 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 16:14:41 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 16:14:41 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7921 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: set
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: bend
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: giant
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: astatine
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('astatine.n.01') ; keyword:  uranium  in syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= [u'astatine']
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: present
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: area
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
16/03/16 16:14:41 INFO PythonRunner: Times: total = 248, boot = 145, init = 1, finish = 102
16/03/16 16:14:41 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 16:14:41 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 282 ms on localhost (2/2)
16/03/16 16:14:41 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 16:14:41 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.200 s
16/03/16 16:14:41 INFO DAGScheduler: looking for newly runnable stages
16/03/16 16:14:41 INFO DAGScheduler: running: Set()
16/03/16 16:14:41 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 16:14:41 INFO DAGScheduler: failed: Set()
16/03/16 16:14:41 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 16:14:41 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 16:14:41 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10709, maxMem=1132178964
16/03/16 16:14:41 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1079.7 MB)
16/03/16 16:14:41 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15693, maxMem=1132178964
16/03/16 16:14:41 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1079.7 MB)
16/03/16 16:14:41 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:42892 (size: 3.0 KB, free: 1079.7 MB)
16/03/16 16:14:41 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 16:14:41 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:14:41 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 16:14:41 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:14:41 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 16:14:41 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:14:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
16/03/16 16:14:42 INFO PythonRunner: Times: total = 120, boot = 119, init = 1, finish = 0
16/03/16 16:14:42 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 16:14:42 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:14:42 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 16:14:42 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:14:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/16 16:14:42 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 163 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'astatine']
16/03/16 16:14:42 INFO PythonRunner: Times: total = 161, boot = 160, init = 0, finish = 1
16/03/16 16:14:42 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1242 bytes result sent to driver
16/03/16 16:14:42 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.315 s
16/03/16 16:14:42 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.562453 s
16/03/16 16:14:42 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 188 ms on localhost (2/2)
16/03/16 16:14:42 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 16:14:42 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:14:42 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:14:42 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:14:42 INFO DAGScheduler: Parents of final stage: List()
16/03/16 16:14:42 INFO DAGScheduler: Missing parents: List()
16/03/16 16:14:42 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:14:42 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18741, maxMem=1132178964
16/03/16 16:14:42 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1079.7 MB)
16/03/16 16:14:42 INFO MemoryStore: ensureFreeSpace(3373) called with curMem=24557, maxMem=1132178964
16/03/16 16:14:42 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1079.7 MB)
16/03/16 16:14:42 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:42892 (size: 3.3 KB, free: 1079.7 MB)
16/03/16 16:14:42 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 16:14:42 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:14:42 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 16:14:42 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 16:14:42 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 16:14:42 INFO PythonRunner: Times: total = 36, boot = 26, init = 10, finish = 0
16/03/16 16:14:42 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 16:14:42 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2272 bytes)
16/03/16 16:14:42 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 72 ms on localhost (1/2)
16/03/16 16:14:42 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 16:14:42 INFO PythonRunner: Times: total = 163, boot = 163, init = 0, finish = 0
16/03/16 16:14:42 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1311 bytes result sent to driver
16/03/16 16:14:42 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 194 ms on localhost (2/2)
16/03/16 16:14:42 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 16:14:42 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.252 s
16/03/16 16:14:42 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.301512 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 16:14:42 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 16:14:42 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 16:14:42 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 16:14:42 INFO MemoryStore: MemoryStore cleared
16/03/16 16:14:42 INFO BlockManager: BlockManager stopped
16/03/16 16:14:42 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 16:14:42 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 16:14:42 INFO SparkContext: Successfully stopped SparkContext
16/03/16 16:14:42 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 16:14:42 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 16:14:42 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'astatine']
16/03/16 16:14:43 INFO SparkContext: Running Spark version 1.5.2
16/03/16 16:14:43 INFO SecurityManager: Changing view acls to: root
16/03/16 16:14:43 INFO SecurityManager: Changing modify acls to: root
16/03/16 16:14:43 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 16:14:43 INFO Slf4jLogger: Slf4jLogger started
16/03/16 16:14:43 INFO Remoting: Starting remoting
16/03/16 16:14:43 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:42940]
16/03/16 16:14:43 INFO Utils: Successfully started service 'sparkDriver' on port 42940.
16/03/16 16:14:43 INFO SparkEnv: Registering MapOutputTracker
16/03/16 16:14:43 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 16:14:43 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-a1e10303-0ca7-4511-88f8-b4cc00fb5cd9
16/03/16 16:14:43 INFO MemoryStore: MemoryStore started with capacity 1079.7 MB
16/03/16 16:14:43 INFO HttpFileServer: HTTP File server directory is /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/httpd-152fdf45-1df2-431f-a92c-b89f8666cc76
16/03/16 16:14:43 INFO HttpServer: Starting HTTP Server
16/03/16 16:14:43 INFO Utils: Successfully started service 'HTTP file server' on port 42898.
16/03/16 16:14:43 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 16:14:43 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 16:14:43 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 16:14:43 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-25fe8f54-b95b-4a49-b248-388497d2f5d3/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 16:14:43 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125083924
16/03/16 16:14:43 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 16:14:43 INFO Executor: Starting executor ID driver on host localhost
16/03/16 16:14:44 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45035.
16/03/16 16:14:44 INFO NettyBlockTransferService: Server created on 45035
16/03/16 16:14:44 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 16:14:44 INFO BlockManagerMasterEndpoint: Registering block manager localhost:45035 with 1079.7 MB RAM, BlockManagerId(driver, localhost, 45035)
16/03/16 16:14:44 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): arrangement
16/03/16 16:14:44 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:14:44 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:14:44 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:14:44 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:14:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 16:14:44 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 16:14:44 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:14:44 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1132178964
16/03/16 16:14:44 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1079.7 MB)
16/03/16 16:14:44 INFO MemoryStore: ensureFreeSpace(4141) called with curMem=6568, maxMem=1132178964
16/03/16 16:14:44 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1079.7 MB)
16/03/16 16:14:44 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:45035 (size: 4.0 KB, free: 1079.7 MB)
16/03/16 16:14:44 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 16:14:44 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:14:44 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 16:14:44 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 16:14:44 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 16:14:44 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125083924
16/03/16 16:14:44 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-25fe8f54-b95b-4a49-b248-388497d2f5d3/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: area
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: issue
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: planning
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: permission
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: economy
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: composition
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): adding to parents: syn =  Synset('composition.n.01') ; keyword:  arrangement  in syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= [u'composition']
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: agency
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
16/03/16 16:14:51 INFO PythonRunner: Times: total = 7843, boot = 463, init = 354, finish = 7026
16/03/16 16:14:52 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 16:14:52 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 16:14:52 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 16:14:52 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7917 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: set
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: bend
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: giant
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: astatine
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: present
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: area
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 16:14:52 INFO PythonRunner: Times: total = 284, boot = 179, init = 1, finish = 104
16/03/16 16:14:52 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 16:14:52 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 326 ms on localhost (2/2)
16/03/16 16:14:52 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.244 s
16/03/16 16:14:52 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 16:14:52 INFO DAGScheduler: looking for newly runnable stages
16/03/16 16:14:52 INFO DAGScheduler: running: Set()
16/03/16 16:14:52 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 16:14:52 INFO DAGScheduler: failed: Set()
16/03/16 16:14:52 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 16:14:52 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 16:14:52 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10709, maxMem=1132178964
16/03/16 16:14:52 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1079.7 MB)
16/03/16 16:14:52 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15693, maxMem=1132178964
16/03/16 16:14:52 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1079.7 MB)
16/03/16 16:14:52 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:45035 (size: 3.0 KB, free: 1079.7 MB)
16/03/16 16:14:52 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 16:14:52 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:14:52 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 16:14:52 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:14:52 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 16:14:52 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:14:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/16 16:14:52 INFO PythonRunner: Times: total = 140, boot = 140, init = 0, finish = 0
16/03/16 16:14:52 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 16:14:52 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:14:52 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 16:14:52 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:14:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
16/03/16 16:14:52 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 157 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'composition', 'None']
16/03/16 16:14:52 INFO PythonRunner: Times: total = 165, boot = 164, init = 1, finish = 0
16/03/16 16:14:52 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1245 bytes result sent to driver
16/03/16 16:14:52 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 184 ms on localhost (2/2)
16/03/16 16:14:52 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 16:14:52 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.336 s
16/03/16 16:14:52 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.612768 s
16/03/16 16:14:52 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:14:52 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:14:52 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:14:52 INFO DAGScheduler: Parents of final stage: List()
16/03/16 16:14:52 INFO DAGScheduler: Missing parents: List()
16/03/16 16:14:52 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:14:52 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18741, maxMem=1132178964
16/03/16 16:14:52 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1079.7 MB)
16/03/16 16:14:52 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24557, maxMem=1132178964
16/03/16 16:14:52 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1079.7 MB)
16/03/16 16:14:52 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:45035 (size: 3.3 KB, free: 1079.7 MB)
16/03/16 16:14:52 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 16:14:52 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:14:52 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 16:14:52 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 16:14:52 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 16:14:52 INFO PythonRunner: Times: total = 59, boot = 58, init = 0, finish = 1
16/03/16 16:14:52 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 16:14:52 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2275 bytes)
16/03/16 16:14:52 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 74 ms on localhost (1/2)
16/03/16 16:14:52 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 16:14:53 INFO PythonRunner: Times: total = 177, boot = 177, init = 0, finish = 0
16/03/16 16:14:53 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1314 bytes result sent to driver
16/03/16 16:14:53 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 192 ms on localhost (2/2)
16/03/16 16:14:53 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 16:14:53 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.262 s
16/03/16 16:14:53 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.291863 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 16:14:53 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 16:14:53 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 16:14:53 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 16:14:53 INFO MemoryStore: MemoryStore cleared
16/03/16 16:14:53 INFO BlockManager: BlockManager stopped
16/03/16 16:14:53 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 16:14:53 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 16:14:53 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 16:14:53 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 16:14:53 INFO SparkContext: Successfully stopped SparkContext
16/03/16 16:14:53 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'composition', u'None']
16/03/16 16:14:54 INFO SparkContext: Running Spark version 1.5.2
16/03/16 16:14:54 INFO SecurityManager: Changing view acls to: root
16/03/16 16:14:54 INFO SecurityManager: Changing modify acls to: root
16/03/16 16:14:54 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 16:14:54 INFO Slf4jLogger: Slf4jLogger started
16/03/16 16:14:54 INFO Remoting: Starting remoting
16/03/16 16:14:54 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:33857]
16/03/16 16:14:54 INFO Utils: Successfully started service 'sparkDriver' on port 33857.
16/03/16 16:14:54 INFO SparkEnv: Registering MapOutputTracker
16/03/16 16:14:54 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 16:14:54 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-cfb77262-dc7d-4cbe-8534-1c915734a444
16/03/16 16:14:54 INFO MemoryStore: MemoryStore started with capacity 1079.7 MB
16/03/16 16:14:54 INFO HttpFileServer: HTTP File server directory is /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/httpd-ec4c8179-4358-4e5a-b5cd-7d7f67dc1220
16/03/16 16:14:54 INFO HttpServer: Starting HTTP Server
16/03/16 16:14:54 INFO Utils: Successfully started service 'HTTP file server' on port 53844.
16/03/16 16:14:54 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 16:14:54 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 16:14:54 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 16:14:54 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-1c553bd8-144c-467e-a6c8-3ecc5bae484e/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 16:14:54 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125094342
16/03/16 16:14:54 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 16:14:54 INFO Executor: Starting executor ID driver on host localhost
16/03/16 16:14:54 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37401.
16/03/16 16:14:54 INFO NettyBlockTransferService: Server created on 37401
16/03/16 16:14:54 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 16:14:54 INFO BlockManagerMasterEndpoint: Registering block manager localhost:37401 with 1079.7 MB RAM, BlockManagerId(driver, localhost, 37401)
16/03/16 16:14:54 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): parts
16/03/16 16:14:54 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:14:54 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:14:54 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:14:54 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:14:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 16:14:54 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 16:14:54 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:14:54 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1132178964
16/03/16 16:14:54 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1079.7 MB)
16/03/16 16:14:54 INFO MemoryStore: ensureFreeSpace(4141) called with curMem=6568, maxMem=1132178964
16/03/16 16:14:54 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1079.7 MB)
16/03/16 16:14:54 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:37401 (size: 4.0 KB, free: 1079.7 MB)
16/03/16 16:14:54 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 16:14:54 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:14:54 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 16:14:54 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 16:14:54 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 16:14:54 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125094342
16/03/16 16:14:54 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-1c553bd8-144c-467e-a6c8-3ecc5bae484e/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: area
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: issue
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: planning
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: permission
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: economy
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: composition
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): adding to parents: syn =  Synset('composition.n.01') ; keyword:  parts  in syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= [u'composition']
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: agency
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
16/03/16 16:15:04 INFO PythonRunner: Times: total = 9445, boot = 457, init = 358, finish = 8630
16/03/16 16:15:04 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 16:15:04 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 16:15:04 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 16:15:04 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9547 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: set
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: bend
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: giant
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: astatine
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: present
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: area
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 16:15:04 INFO PythonRunner: Times: total = 408, boot = 243, init = 2, finish = 163
16/03/16 16:15:04 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 16:15:04 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 9.990 s
16/03/16 16:15:04 INFO DAGScheduler: looking for newly runnable stages
16/03/16 16:15:04 INFO DAGScheduler: running: Set()
16/03/16 16:15:04 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 16:15:04 INFO DAGScheduler: failed: Set()
16/03/16 16:15:04 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 16:15:04 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 16:15:04 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 453 ms on localhost (2/2)
16/03/16 16:15:04 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 16:15:04 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10709, maxMem=1132178964
16/03/16 16:15:04 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1079.7 MB)
16/03/16 16:15:04 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15693, maxMem=1132178964
16/03/16 16:15:04 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1079.7 MB)
16/03/16 16:15:04 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:37401 (size: 3.0 KB, free: 1079.7 MB)
16/03/16 16:15:04 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 16:15:04 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:15:04 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 16:15:04 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:15:04 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 16:15:04 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:15:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 16:15:04 INFO PythonRunner: Times: total = 14, boot = -117, init = 130, finish = 1
16/03/16 16:15:04 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 16:15:05 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:15:05 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 16:15:05 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 63 ms on localhost (1/2)
16/03/16 16:15:05 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:15:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
reduceFunction_Parents(): returns= ['None', u'composition', 'None']
16/03/16 16:15:05 INFO PythonRunner: Times: total = 192, boot = 189, init = 0, finish = 3
16/03/16 16:15:05 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1245 bytes result sent to driver
16/03/16 16:15:05 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.287 s
16/03/16 16:15:05 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 232 ms on localhost (2/2)
16/03/16 16:15:05 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 16:15:05 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 10.765643 s
16/03/16 16:15:05 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:15:05 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:15:05 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:15:05 INFO DAGScheduler: Parents of final stage: List()
16/03/16 16:15:05 INFO DAGScheduler: Missing parents: List()
16/03/16 16:15:05 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:15:05 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18741, maxMem=1132178964
16/03/16 16:15:05 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1079.7 MB)
16/03/16 16:15:05 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24557, maxMem=1132178964
16/03/16 16:15:05 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1079.7 MB)
16/03/16 16:15:05 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:37401 (size: 3.3 KB, free: 1079.7 MB)
16/03/16 16:15:05 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 16:15:05 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:15:05 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 16:15:05 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 16:15:05 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 16:15:05 INFO PythonRunner: Times: total = 113, boot = 113, init = 0, finish = 0
16/03/16 16:15:05 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 16:15:05 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2275 bytes)
16/03/16 16:15:05 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 132 ms on localhost (1/2)
16/03/16 16:15:05 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 16:15:05 INFO PythonRunner: Times: total = 213, boot = 213, init = 0, finish = 0
16/03/16 16:15:05 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1314 bytes result sent to driver
16/03/16 16:15:05 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 228 ms on localhost (2/2)
16/03/16 16:15:05 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 16:15:05 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.355 s
16/03/16 16:15:05 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.372806 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 16:15:05 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 16:15:05 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 16:15:05 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 16:15:05 INFO MemoryStore: MemoryStore cleared
16/03/16 16:15:05 INFO BlockManager: BlockManager stopped
16/03/16 16:15:05 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 16:15:05 INFO SparkContext: Successfully stopped SparkContext
16/03/16 16:15:05 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 16:15:05 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 16:15:05 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 16:15:05 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'composition', u'None']
16/03/16 16:15:06 INFO SparkContext: Running Spark version 1.5.2
16/03/16 16:15:06 INFO SecurityManager: Changing view acls to: root
16/03/16 16:15:06 INFO SecurityManager: Changing modify acls to: root
16/03/16 16:15:06 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 16:15:06 INFO Slf4jLogger: Slf4jLogger started
16/03/16 16:15:06 INFO Remoting: Starting remoting
16/03/16 16:15:06 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:47745]
16/03/16 16:15:06 INFO Utils: Successfully started service 'sparkDriver' on port 47745.
16/03/16 16:15:06 INFO SparkEnv: Registering MapOutputTracker
16/03/16 16:15:06 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 16:15:06 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-c4cf4363-95a8-42ef-97cd-e73baee3f8ce
16/03/16 16:15:06 INFO MemoryStore: MemoryStore started with capacity 1081.1 MB
16/03/16 16:15:06 INFO HttpFileServer: HTTP File server directory is /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/httpd-ffbf2c79-b371-4dd2-8412-2064d9cd10ce
16/03/16 16:15:06 INFO HttpServer: Starting HTTP Server
16/03/16 16:15:07 INFO Utils: Successfully started service 'HTTP file server' on port 52943.
16/03/16 16:15:07 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 16:15:07 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 16:15:07 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 16:15:07 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-d7592fe7-b9af-44d5-afa0-fe8956d6b995/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 16:15:07 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125107181
16/03/16 16:15:07 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 16:15:07 INFO Executor: Starting executor ID driver on host localhost
16/03/16 16:15:07 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37559.
16/03/16 16:15:07 INFO NettyBlockTransferService: Server created on 37559
16/03/16 16:15:07 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 16:15:07 INFO BlockManagerMasterEndpoint: Registering block manager localhost:37559 with 1081.1 MB RAM, BlockManagerId(driver, localhost, 37559)
16/03/16 16:15:07 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): speech
16/03/16 16:15:07 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:15:07 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:15:07 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:15:07 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:15:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 16:15:07 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 16:15:07 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:15:07 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1133594542
16/03/16 16:15:07 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1081.1 MB)
16/03/16 16:15:07 INFO MemoryStore: ensureFreeSpace(4142) called with curMem=6568, maxMem=1133594542
16/03/16 16:15:07 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1081.1 MB)
16/03/16 16:15:07 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:37559 (size: 4.0 KB, free: 1081.1 MB)
16/03/16 16:15:07 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 16:15:07 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:15:07 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 16:15:07 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 16:15:07 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 16:15:07 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125107181
16/03/16 16:15:07 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-d7592fe7-b9af-44d5-afa0-fe8956d6b995/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: area
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: issue
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: planning
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: permission
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: economy
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: composition
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: agency
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 16:15:16 INFO PythonRunner: Times: total = 9263, boot = 494, init = 433, finish = 8336
16/03/16 16:15:16 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 16:15:16 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 16:15:16 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 16:15:16 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9382 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: set
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: bend
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: giant
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: astatine
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: present
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('present.n.01') ; keyword:  speech  in syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= [u'present']
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: area
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
16/03/16 16:15:17 INFO PythonRunner: Times: total = 329, boot = 218, init = 1, finish = 110
16/03/16 16:15:17 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 16:15:17 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 372 ms on localhost (2/2)
16/03/16 16:15:17 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 9.736 s
16/03/16 16:15:17 INFO DAGScheduler: looking for newly runnable stages
16/03/16 16:15:17 INFO DAGScheduler: running: Set()
16/03/16 16:15:17 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 16:15:17 INFO DAGScheduler: failed: Set()
16/03/16 16:15:17 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 16:15:17 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 16:15:17 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10710, maxMem=1133594542
16/03/16 16:15:17 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1081.1 MB)
16/03/16 16:15:17 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 16:15:17 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15694, maxMem=1133594542
16/03/16 16:15:17 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1081.1 MB)
16/03/16 16:15:17 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:37559 (size: 3.0 KB, free: 1081.1 MB)
16/03/16 16:15:17 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 16:15:17 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:15:17 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 16:15:17 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:15:17 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 16:15:17 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:15:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/16 16:15:17 INFO PythonRunner: Times: total = 204, boot = 204, init = 0, finish = 0
16/03/16 16:15:17 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 16:15:17 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:15:17 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 16:15:17 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:15:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/16 16:15:17 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 232 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'present']
16/03/16 16:15:17 INFO PythonRunner: Times: total = 207, boot = 205, init = 0, finish = 2
16/03/16 16:15:17 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1241 bytes result sent to driver
16/03/16 16:15:17 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.447 s
16/03/16 16:15:17 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 10.237558 s
16/03/16 16:15:17 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 227 ms on localhost (2/2)
16/03/16 16:15:17 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 16:15:17 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:15:17 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:15:17 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:15:17 INFO DAGScheduler: Parents of final stage: List()
16/03/16 16:15:17 INFO DAGScheduler: Missing parents: List()
16/03/16 16:15:17 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:15:17 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18742, maxMem=1133594542
16/03/16 16:15:17 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1081.1 MB)
16/03/16 16:15:17 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24558, maxMem=1133594542
16/03/16 16:15:17 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1081.1 MB)
16/03/16 16:15:17 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:37559 (size: 3.3 KB, free: 1081.1 MB)
16/03/16 16:15:17 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 16:15:17 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:15:17 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 16:15:17 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 16:15:17 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 16:15:17 INFO PythonRunner: Times: total = 64, boot = 64, init = 0, finish = 0
16/03/16 16:15:17 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 16:15:17 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2271 bytes)
16/03/16 16:15:17 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 16:15:17 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 79 ms on localhost (1/2)
16/03/16 16:15:18 INFO PythonRunner: Times: total = 222, boot = 221, init = 0, finish = 1
16/03/16 16:15:18 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1310 bytes result sent to driver
16/03/16 16:15:18 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 238 ms on localhost (2/2)
16/03/16 16:15:18 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 16:15:18 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.306 s
16/03/16 16:15:18 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.333293 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 16:15:18 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 16:15:18 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 16:15:18 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 16:15:18 INFO MemoryStore: MemoryStore cleared
16/03/16 16:15:18 INFO BlockManager: BlockManager stopped
16/03/16 16:15:18 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 16:15:18 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 16:15:18 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 16:15:18 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 16:15:18 INFO SparkContext: Successfully stopped SparkContext
16/03/16 16:15:18 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'present']
16/03/16 16:15:19 INFO SparkContext: Running Spark version 1.5.2
16/03/16 16:15:19 INFO SecurityManager: Changing view acls to: root
16/03/16 16:15:19 INFO SecurityManager: Changing modify acls to: root
16/03/16 16:15:19 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 16:15:19 INFO Slf4jLogger: Slf4jLogger started
16/03/16 16:15:19 INFO Remoting: Starting remoting
16/03/16 16:15:19 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:51207]
16/03/16 16:15:19 INFO Utils: Successfully started service 'sparkDriver' on port 51207.
16/03/16 16:15:19 INFO SparkEnv: Registering MapOutputTracker
16/03/16 16:15:19 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 16:15:19 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-1fc0e949-c34a-434b-ac2e-1cf4e1e9ce86
16/03/16 16:15:19 INFO MemoryStore: MemoryStore started with capacity 1081.1 MB
16/03/16 16:15:19 INFO HttpFileServer: HTTP File server directory is /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/httpd-992de2c7-6e60-4f66-93c9-9933514b30c6
16/03/16 16:15:19 INFO HttpServer: Starting HTTP Server
16/03/16 16:15:19 INFO Utils: Successfully started service 'HTTP file server' on port 46478.
16/03/16 16:15:19 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 16:15:19 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 16:15:19 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 16:15:19 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-ac11c308-74a0-46d5-98cb-3544f0280afc/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 16:15:19 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125119558
16/03/16 16:15:19 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 16:15:19 INFO Executor: Starting executor ID driver on host localhost
16/03/16 16:15:19 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49958.
16/03/16 16:15:19 INFO NettyBlockTransferService: Server created on 49958
16/03/16 16:15:19 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 16:15:19 INFO BlockManagerMasterEndpoint: Registering block manager localhost:49958 with 1081.1 MB RAM, BlockManagerId(driver, localhost, 49958)
16/03/16 16:15:19 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): geographical
16/03/16 16:15:19 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:15:19 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:15:19 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:15:19 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:15:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 16:15:19 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 16:15:19 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:15:19 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1133594542
16/03/16 16:15:19 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1081.1 MB)
16/03/16 16:15:19 INFO MemoryStore: ensureFreeSpace(4141) called with curMem=6568, maxMem=1133594542
16/03/16 16:15:19 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1081.1 MB)
16/03/16 16:15:19 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:49958 (size: 4.0 KB, free: 1081.1 MB)
16/03/16 16:15:19 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 16:15:19 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:15:19 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 16:15:19 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 16:15:19 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 16:15:19 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125119558
16/03/16 16:15:19 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-ac11c308-74a0-46d5-98cb-3544f0280afc/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: area
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  geographical  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: issue
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: planning
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: permission
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: economy
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: composition
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: agency
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
16/03/16 16:15:30 INFO PythonRunner: Times: total = 10452, boot = 511, init = 398, finish = 9543
16/03/16 16:15:30 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 16:15:30 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 16:15:30 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 16:15:30 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 10564 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: set
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: bend
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: giant
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: astatine
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: present
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: area
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  geographical  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
16/03/16 16:15:30 INFO PythonRunner: Times: total = 291, boot = 187, init = 1, finish = 103
16/03/16 16:15:30 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 16:15:30 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 327 ms on localhost (2/2)
16/03/16 16:15:30 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 16:15:30 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 10.898 s
16/03/16 16:15:30 INFO DAGScheduler: looking for newly runnable stages
16/03/16 16:15:30 INFO DAGScheduler: running: Set()
16/03/16 16:15:30 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 16:15:30 INFO DAGScheduler: failed: Set()
16/03/16 16:15:30 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 16:15:30 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 16:15:30 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10709, maxMem=1133594542
16/03/16 16:15:30 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1081.1 MB)
16/03/16 16:15:30 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15693, maxMem=1133594542
16/03/16 16:15:30 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1081.1 MB)
16/03/16 16:15:30 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:49958 (size: 3.0 KB, free: 1081.1 MB)
16/03/16 16:15:30 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 16:15:30 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:15:30 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 16:15:30 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:15:30 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 16:15:30 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:15:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 16:15:30 INFO PythonRunner: Times: total = 149, boot = 149, init = 0, finish = 0
16/03/16 16:15:30 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 16:15:30 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:15:30 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 16:15:30 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:15:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 16:15:30 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 178 ms on localhost (1/2)
reduceFunction_Parents(): returns= [u'area', 'None', u'area']
16/03/16 16:15:31 INFO PythonRunner: Times: total = 324, boot = 323, init = 1, finish = 0
16/03/16 16:15:31 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1241 bytes result sent to driver
16/03/16 16:15:31 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.518 s
16/03/16 16:15:31 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 11.447292 s
16/03/16 16:15:31 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 350 ms on localhost (2/2)
16/03/16 16:15:31 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 16:15:31 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:15:31 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:15:31 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:15:31 INFO DAGScheduler: Parents of final stage: List()
16/03/16 16:15:31 INFO DAGScheduler: Missing parents: List()
16/03/16 16:15:31 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:15:31 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18741, maxMem=1133594542
16/03/16 16:15:31 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1081.1 MB)
16/03/16 16:15:31 INFO MemoryStore: ensureFreeSpace(3374) called with curMem=24557, maxMem=1133594542
16/03/16 16:15:31 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1081.1 MB)
16/03/16 16:15:31 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:49958 (size: 3.3 KB, free: 1081.1 MB)
16/03/16 16:15:31 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 16:15:31 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:15:31 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 16:15:31 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 16:15:31 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 16:15:31 INFO PythonRunner: Times: total = 214, boot = 214, init = 0, finish = 0
16/03/16 16:15:31 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 16:15:31 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2271 bytes)
16/03/16 16:15:31 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 243 ms on localhost (1/2)
16/03/16 16:15:31 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 16:15:31 INFO PythonRunner: Times: total = 234, boot = 233, init = 0, finish = 1
16/03/16 16:15:31 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1307 bytes result sent to driver
16/03/16 16:15:31 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 275 ms on localhost (2/2)
16/03/16 16:15:31 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.490 s
16/03/16 16:15:31 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.566703 s
16/03/16 16:15:31 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 16:15:32 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 16:15:32 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 16:15:32 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 16:15:32 INFO MemoryStore: MemoryStore cleared
16/03/16 16:15:32 INFO BlockManager: BlockManager stopped
16/03/16 16:15:32 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 16:15:32 INFO SparkContext: Successfully stopped SparkContext
16/03/16 16:15:32 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 16:15:32 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 16:15:32 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 16:15:32 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'area', u'None', u'area']
16/03/16 16:15:32 INFO SparkContext: Running Spark version 1.5.2
16/03/16 16:15:32 INFO SecurityManager: Changing view acls to: root
16/03/16 16:15:32 INFO SecurityManager: Changing modify acls to: root
16/03/16 16:15:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 16:15:33 INFO Slf4jLogger: Slf4jLogger started
16/03/16 16:15:33 INFO Remoting: Starting remoting
16/03/16 16:15:33 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:53136]
16/03/16 16:15:33 INFO Utils: Successfully started service 'sparkDriver' on port 53136.
16/03/16 16:15:33 INFO SparkEnv: Registering MapOutputTracker
16/03/16 16:15:33 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 16:15:33 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-afb83dc9-daca-428f-9199-9bfb43cb23e3
16/03/16 16:15:33 INFO MemoryStore: MemoryStore started with capacity 1081.1 MB
16/03/16 16:15:33 INFO HttpFileServer: HTTP File server directory is /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/httpd-1060c6cf-dcac-4ff3-bcc1-5bf86f33f8e4
16/03/16 16:15:33 INFO HttpServer: Starting HTTP Server
16/03/16 16:15:33 INFO Utils: Successfully started service 'HTTP file server' on port 59462.
16/03/16 16:15:33 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 16:15:33 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 16:15:33 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 16:15:33 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-248b61d3-6c1a-43fc-9831-6aaaa87fc188/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 16:15:33 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125133241
16/03/16 16:15:33 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 16:15:33 INFO Executor: Starting executor ID driver on host localhost
16/03/16 16:15:33 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34850.
16/03/16 16:15:33 INFO NettyBlockTransferService: Server created on 34850
16/03/16 16:15:33 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 16:15:33 INFO BlockManagerMasterEndpoint: Registering block manager localhost:34850 with 1081.1 MB RAM, BlockManagerId(driver, localhost, 34850)
16/03/16 16:15:33 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): spatial
16/03/16 16:15:33 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:15:33 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:15:33 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:15:33 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:15:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 16:15:33 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 16:15:33 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:15:33 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1133594542
16/03/16 16:15:33 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1081.1 MB)
16/03/16 16:15:33 INFO MemoryStore: ensureFreeSpace(4141) called with curMem=6568, maxMem=1133594542
16/03/16 16:15:33 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1081.1 MB)
16/03/16 16:15:33 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:34850 (size: 4.0 KB, free: 1081.1 MB)
16/03/16 16:15:33 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 16:15:33 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:15:33 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 16:15:33 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 16:15:33 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 16:15:33 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125133241
16/03/16 16:15:33 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-248b61d3-6c1a-43fc-9831-6aaaa87fc188/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: area
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: issue
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: planning
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: permission
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: economy
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: composition
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): adding to parents: syn =  Synset('composition.n.01') ; keyword:  spatial  in syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= [u'composition']
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: agency
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
16/03/16 16:15:41 INFO PythonRunner: Times: total = 7870, boot = 471, init = 412, finish = 6987
16/03/16 16:15:41 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 16:15:41 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 16:15:41 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 16:15:41 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7984 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: set
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: bend
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: giant
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: astatine
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: present
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: area
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 16:15:41 INFO PythonRunner: Times: total = 226, boot = 122, init = 1, finish = 103
16/03/16 16:15:41 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 16:15:41 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 293 ms on localhost (2/2)
16/03/16 16:15:41 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 16:15:41 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.255 s
16/03/16 16:15:41 INFO DAGScheduler: looking for newly runnable stages
16/03/16 16:15:41 INFO DAGScheduler: running: Set()
16/03/16 16:15:41 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 16:15:41 INFO DAGScheduler: failed: Set()
16/03/16 16:15:41 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 16:15:41 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 16:15:41 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10709, maxMem=1133594542
16/03/16 16:15:41 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1081.1 MB)
16/03/16 16:15:41 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15693, maxMem=1133594542
16/03/16 16:15:41 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1081.1 MB)
16/03/16 16:15:41 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:34850 (size: 3.0 KB, free: 1081.1 MB)
16/03/16 16:15:41 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 16:15:41 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:15:41 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 16:15:41 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:15:41 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 16:15:41 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:15:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 16:15:41 INFO PythonRunner: Times: total = 171, boot = 170, init = 1, finish = 0
16/03/16 16:15:41 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 16:15:41 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:15:41 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 16:15:41 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 185 ms on localhost (1/2)
16/03/16 16:15:41 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:15:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
reduceFunction_Parents(): returns= ['None', u'composition', 'None']
16/03/16 16:15:42 INFO PythonRunner: Times: total = 181, boot = 180, init = 1, finish = 0
16/03/16 16:15:42 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1245 bytes result sent to driver
16/03/16 16:15:42 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.378 s
16/03/16 16:15:42 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.674815 s
16/03/16 16:15:42 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 204 ms on localhost (2/2)
16/03/16 16:15:42 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 16:15:42 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:15:42 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:15:42 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:15:42 INFO DAGScheduler: Parents of final stage: List()
16/03/16 16:15:42 INFO DAGScheduler: Missing parents: List()
16/03/16 16:15:42 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:15:42 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18741, maxMem=1133594542
16/03/16 16:15:42 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1081.1 MB)
16/03/16 16:15:42 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24557, maxMem=1133594542
16/03/16 16:15:42 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1081.1 MB)
16/03/16 16:15:42 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:34850 (size: 3.3 KB, free: 1081.1 MB)
16/03/16 16:15:42 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 16:15:42 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:15:42 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 16:15:42 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 16:15:42 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 16:15:42 INFO PythonRunner: Times: total = 123, boot = 122, init = 1, finish = 0
16/03/16 16:15:42 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 16:15:42 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2275 bytes)
16/03/16 16:15:42 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 140 ms on localhost (1/2)
16/03/16 16:15:42 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 16:15:42 INFO PythonRunner: Times: total = 154, boot = 154, init = 0, finish = 0
16/03/16 16:15:42 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1314 bytes result sent to driver
16/03/16 16:15:42 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 176 ms on localhost (2/2)
16/03/16 16:15:42 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 16:15:42 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.311 s
16/03/16 16:15:42 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.351052 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 16:15:42 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 16:15:42 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 16:15:42 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 16:15:42 INFO MemoryStore: MemoryStore cleared
16/03/16 16:15:42 INFO BlockManager: BlockManager stopped
16/03/16 16:15:42 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 16:15:42 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 16:15:42 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 16:15:42 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 16:15:42 INFO SparkContext: Successfully stopped SparkContext
16/03/16 16:15:42 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'composition', u'None']
16/03/16 16:15:43 INFO SparkContext: Running Spark version 1.5.2
16/03/16 16:15:43 INFO SecurityManager: Changing view acls to: root
16/03/16 16:15:43 INFO SecurityManager: Changing modify acls to: root
16/03/16 16:15:43 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 16:15:43 INFO Slf4jLogger: Slf4jLogger started
16/03/16 16:15:43 INFO Remoting: Starting remoting
16/03/16 16:15:43 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:41294]
16/03/16 16:15:43 INFO Utils: Successfully started service 'sparkDriver' on port 41294.
16/03/16 16:15:43 INFO SparkEnv: Registering MapOutputTracker
16/03/16 16:15:43 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 16:15:43 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-d865a035-50d0-4f42-83a1-4120ec59fe7e
16/03/16 16:15:43 INFO MemoryStore: MemoryStore started with capacity 1081.1 MB
16/03/16 16:15:43 INFO HttpFileServer: HTTP File server directory is /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/httpd-06ed5def-23d1-45be-a461-5361868d7d54
16/03/16 16:15:43 INFO HttpServer: Starting HTTP Server
16/03/16 16:15:43 INFO Utils: Successfully started service 'HTTP file server' on port 41455.
16/03/16 16:15:43 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 16:15:43 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 16:15:43 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 16:15:43 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-7a5b5357-a5b6-4562-a35b-a06b88222738/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 16:15:43 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125143786
16/03/16 16:15:43 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 16:15:43 INFO Executor: Starting executor ID driver on host localhost
16/03/16 16:15:43 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57797.
16/03/16 16:15:43 INFO NettyBlockTransferService: Server created on 57797
16/03/16 16:15:43 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 16:15:43 INFO BlockManagerMasterEndpoint: Registering block manager localhost:57797 with 1081.1 MB RAM, BlockManagerId(driver, localhost, 57797)
16/03/16 16:15:43 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): Nadu
16/03/16 16:15:43 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:15:43 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:15:43 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:15:43 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:15:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 16:15:43 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 16:15:43 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:15:43 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1133594542
16/03/16 16:15:43 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1081.1 MB)
16/03/16 16:15:43 INFO MemoryStore: ensureFreeSpace(4140) called with curMem=6568, maxMem=1133594542
16/03/16 16:15:43 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1081.1 MB)
16/03/16 16:15:43 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:57797 (size: 4.0 KB, free: 1081.1 MB)
16/03/16 16:15:43 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 16:15:43 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:15:43 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 16:15:43 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 16:15:43 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 16:15:43 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125143786
16/03/16 16:15:43 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-7a5b5357-a5b6-4562-a35b-a06b88222738/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: area
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: issue
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: planning
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: permission
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: economy
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: composition
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: agency
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): adding to parents: syn =  Synset('chennai.n.01') ; keyword:  Nadu  in syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= [u'Chennai']
reduceFunction_Parents(): returns= ['None', u'Chennai']
16/03/16 16:15:51 INFO PythonRunner: Times: total = 7784, boot = 467, init = 363, finish = 6954
16/03/16 16:15:51 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 16:15:51 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 16:15:51 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 16:15:51 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7873 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: set
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: bend
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: giant
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: astatine
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: present
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): adding to parents: syn =  Synset('chennai.n.01') ; keyword:  Nadu  in syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= [u'Chennai']
reduceFunction_Parents(): returns= ['None', u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: area
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'Chennai']
16/03/16 16:15:52 INFO PythonRunner: Times: total = 303, boot = 185, init = 1, finish = 117
16/03/16 16:15:52 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 16:15:52 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.180 s
16/03/16 16:15:52 INFO DAGScheduler: looking for newly runnable stages
16/03/16 16:15:52 INFO DAGScheduler: running: Set()
16/03/16 16:15:52 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 16:15:52 INFO DAGScheduler: failed: Set()
16/03/16 16:15:52 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 16:15:52 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 16:15:52 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10708, maxMem=1133594542
16/03/16 16:15:52 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1081.1 MB)
16/03/16 16:15:52 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 332 ms on localhost (2/2)
16/03/16 16:15:52 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 16:15:52 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15692, maxMem=1133594542
16/03/16 16:15:52 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1081.1 MB)
16/03/16 16:15:52 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:57797 (size: 3.0 KB, free: 1081.1 MB)
16/03/16 16:15:52 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 16:15:52 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:15:52 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 16:15:52 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:15:52 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 16:15:52 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:15:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/16 16:15:52 INFO PythonRunner: Times: total = 142, boot = 141, init = 1, finish = 0
16/03/16 16:15:52 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 16:15:52 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:15:52 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 16:15:52 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:15:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/16 16:15:52 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 180 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'Chennai', 'None', u'Chennai']
16/03/16 16:15:52 INFO PythonRunner: Times: total = 170, boot = 169, init = 0, finish = 1
16/03/16 16:15:52 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1255 bytes result sent to driver
16/03/16 16:15:52 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 186 ms on localhost (2/2)
16/03/16 16:15:52 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.338 s
16/03/16 16:15:52 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.552292 s
16/03/16 16:15:52 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 16:15:52 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:15:52 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:15:52 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:15:52 INFO DAGScheduler: Parents of final stage: List()
16/03/16 16:15:52 INFO DAGScheduler: Missing parents: List()
16/03/16 16:15:52 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:15:52 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18740, maxMem=1133594542
16/03/16 16:15:52 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1081.1 MB)
16/03/16 16:15:52 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24556, maxMem=1133594542
16/03/16 16:15:52 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1081.1 MB)
16/03/16 16:15:52 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:57797 (size: 3.3 KB, free: 1081.1 MB)
16/03/16 16:15:52 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 16:15:52 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:15:52 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 16:15:52 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 16:15:52 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 16:15:52 INFO PythonRunner: Times: total = 164, boot = 164, init = 0, finish = 0
16/03/16 16:15:52 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 16:15:52 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2285 bytes)
16/03/16 16:15:52 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 182 ms on localhost (1/2)
16/03/16 16:15:52 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 16:15:52 INFO PythonRunner: Times: total = 172, boot = 172, init = 0, finish = 0
16/03/16 16:15:52 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1324 bytes result sent to driver
16/03/16 16:15:52 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 188 ms on localhost (2/2)
16/03/16 16:15:52 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 16:15:52 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.356 s
16/03/16 16:15:52 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.377130 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 16:15:53 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 16:15:53 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 16:15:53 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 16:15:53 INFO MemoryStore: MemoryStore cleared
16/03/16 16:15:53 INFO BlockManager: BlockManager stopped
16/03/16 16:15:53 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 16:15:53 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 16:15:53 INFO SparkContext: Successfully stopped SparkContext
16/03/16 16:15:53 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 16:15:53 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 16:15:53 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'Chennai', u'None', u'Chennai']
16/03/16 16:15:53 INFO SparkContext: Running Spark version 1.5.2
16/03/16 16:15:53 INFO SecurityManager: Changing view acls to: root
16/03/16 16:15:53 INFO SecurityManager: Changing modify acls to: root
16/03/16 16:15:53 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 16:15:54 INFO Slf4jLogger: Slf4jLogger started
16/03/16 16:15:54 INFO Remoting: Starting remoting
16/03/16 16:15:54 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:60966]
16/03/16 16:15:54 INFO Utils: Successfully started service 'sparkDriver' on port 60966.
16/03/16 16:15:54 INFO SparkEnv: Registering MapOutputTracker
16/03/16 16:15:54 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 16:15:54 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-facc572d-5cf6-4412-9758-cfed6686a47b
16/03/16 16:15:54 INFO MemoryStore: MemoryStore started with capacity 1081.1 MB
16/03/16 16:15:54 INFO HttpFileServer: HTTP File server directory is /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/httpd-e79a16ca-b242-4206-9d5e-5cd6936a1637
16/03/16 16:15:54 INFO HttpServer: Starting HTTP Server
16/03/16 16:15:54 INFO Utils: Successfully started service 'HTTP file server' on port 38293.
16/03/16 16:15:54 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 16:15:54 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 16:15:54 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 16:15:54 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-1d0eb567-32d0-4b98-b41c-c8925cead094/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 16:15:54 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125154254
16/03/16 16:15:54 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 16:15:54 INFO Executor: Starting executor ID driver on host localhost
16/03/16 16:15:54 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37498.
16/03/16 16:15:54 INFO NettyBlockTransferService: Server created on 37498
16/03/16 16:15:54 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 16:15:54 INFO BlockManagerMasterEndpoint: Registering block manager localhost:37498 with 1081.1 MB RAM, BlockManagerId(driver, localhost, 37498)
16/03/16 16:15:54 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): circular
16/03/16 16:15:54 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:15:54 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:15:54 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:15:54 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:15:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 16:15:54 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 16:15:54 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:15:54 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1133594542
16/03/16 16:15:54 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1081.1 MB)
16/03/16 16:15:54 INFO MemoryStore: ensureFreeSpace(4141) called with curMem=6568, maxMem=1133594542
16/03/16 16:15:54 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1081.1 MB)
16/03/16 16:15:54 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:37498 (size: 4.0 KB, free: 1081.1 MB)
16/03/16 16:15:54 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 16:15:54 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:15:54 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 16:15:54 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 16:15:54 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 16:15:54 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125154254
16/03/16 16:15:54 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-1d0eb567-32d0-4b98-b41c-c8925cead094/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: area
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: issue
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: planning
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: permission
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: economy
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: composition
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: agency
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 16:16:02 INFO PythonRunner: Times: total = 8032, boot = 460, init = 362, finish = 7210
16/03/16 16:16:02 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 16:16:02 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 16:16:02 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 16:16:02 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8160 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: set
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: bend
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): adding to parents: syn =  Synset('bend.n.01') ; keyword:  circular  in syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= [u'bend']
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: giant
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: astatine
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: present
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: area
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
16/03/16 16:16:02 INFO PythonRunner: Times: total = 220, boot = 115, init = 0, finish = 105
16/03/16 16:16:02 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 16:16:02 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.459 s
16/03/16 16:16:02 INFO DAGScheduler: looking for newly runnable stages
16/03/16 16:16:02 INFO DAGScheduler: running: Set()
16/03/16 16:16:02 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 16:16:02 INFO DAGScheduler: failed: Set()
16/03/16 16:16:02 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 16:16:02 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 16:16:02 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10709, maxMem=1133594542
16/03/16 16:16:02 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 302 ms on localhost (2/2)
16/03/16 16:16:02 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 16:16:02 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1081.1 MB)
16/03/16 16:16:02 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15693, maxMem=1133594542
16/03/16 16:16:02 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1081.1 MB)
16/03/16 16:16:02 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:37498 (size: 3.0 KB, free: 1081.1 MB)
16/03/16 16:16:02 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 16:16:02 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:02 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 16:16:02 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:16:02 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 16:16:02 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:16:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 16:16:03 INFO PythonRunner: Times: total = 128, boot = 127, init = 0, finish = 1
16/03/16 16:16:03 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 16:16:03 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:16:03 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 16:16:03 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:16:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 16:16:03 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 163 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'bend']
16/03/16 16:16:03 INFO PythonRunner: Times: total = 174, boot = 173, init = 1, finish = 0
16/03/16 16:16:03 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1230 bytes result sent to driver
16/03/16 16:16:03 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 193 ms on localhost (2/2)
16/03/16 16:16:03 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.342 s
16/03/16 16:16:03 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 16:16:03 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.847244 s
16/03/16 16:16:03 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:16:03 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:16:03 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:03 INFO DAGScheduler: Parents of final stage: List()
16/03/16 16:16:03 INFO DAGScheduler: Missing parents: List()
16/03/16 16:16:03 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:16:03 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18741, maxMem=1133594542
16/03/16 16:16:03 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1081.1 MB)
16/03/16 16:16:03 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24557, maxMem=1133594542
16/03/16 16:16:03 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1081.1 MB)
16/03/16 16:16:03 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:37498 (size: 3.3 KB, free: 1081.1 MB)
16/03/16 16:16:03 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 16:16:03 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:03 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 16:16:03 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 16:16:03 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 16:16:03 INFO PythonRunner: Times: total = 143, boot = 142, init = 1, finish = 0
16/03/16 16:16:03 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 16:16:03 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2260 bytes)
16/03/16 16:16:03 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 16:16:03 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 161 ms on localhost (1/2)
16/03/16 16:16:03 INFO PythonRunner: Times: total = 181, boot = 181, init = 0, finish = 0
16/03/16 16:16:03 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1296 bytes result sent to driver
16/03/16 16:16:03 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.343 s
16/03/16 16:16:03 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.393127 s
16/03/16 16:16:03 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 196 ms on localhost (2/2)
16/03/16 16:16:03 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 16:16:03 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 16:16:03 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 16:16:03 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 16:16:04 INFO MemoryStore: MemoryStore cleared
16/03/16 16:16:04 INFO BlockManager: BlockManager stopped
16/03/16 16:16:04 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 16:16:04 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 16:16:04 INFO SparkContext: Successfully stopped SparkContext
16/03/16 16:16:04 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 16:16:04 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 16:16:04 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'bend']
16/03/16 16:16:04 INFO SparkContext: Running Spark version 1.5.2
16/03/16 16:16:04 INFO SecurityManager: Changing view acls to: root
16/03/16 16:16:04 INFO SecurityManager: Changing modify acls to: root
16/03/16 16:16:04 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 16:16:04 INFO Slf4jLogger: Slf4jLogger started
16/03/16 16:16:04 INFO Remoting: Starting remoting
16/03/16 16:16:05 INFO Utils: Successfully started service 'sparkDriver' on port 33700.
16/03/16 16:16:05 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:33700]
16/03/16 16:16:05 INFO SparkEnv: Registering MapOutputTracker
16/03/16 16:16:05 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 16:16:05 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-d6160ab7-d8d8-43df-bc9b-b3b306488a62
16/03/16 16:16:05 INFO MemoryStore: MemoryStore started with capacity 1081.1 MB
16/03/16 16:16:05 INFO HttpFileServer: HTTP File server directory is /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/httpd-fbb79736-b72a-4612-8d7f-b377b93bd35b
16/03/16 16:16:05 INFO HttpServer: Starting HTTP Server
16/03/16 16:16:05 INFO Utils: Successfully started service 'HTTP file server' on port 33294.
16/03/16 16:16:05 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 16:16:05 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 16:16:05 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 16:16:05 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-630e0a33-d554-4d32-9945-94dac89170d6/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 16:16:05 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125165339
16/03/16 16:16:05 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 16:16:05 INFO Executor: Starting executor ID driver on host localhost
16/03/16 16:16:05 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 47991.
16/03/16 16:16:05 INFO NettyBlockTransferService: Server created on 47991
16/03/16 16:16:05 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 16:16:05 INFO BlockManagerMasterEndpoint: Registering block manager localhost:47991 with 1081.1 MB RAM, BlockManagerId(driver, localhost, 47991)
16/03/16 16:16:05 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): product
16/03/16 16:16:05 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:16:05 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:05 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:16:05 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 16:16:05 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 16:16:05 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:16:05 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1133594542
16/03/16 16:16:05 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1081.1 MB)
16/03/16 16:16:05 INFO MemoryStore: ensureFreeSpace(4141) called with curMem=6568, maxMem=1133594542
16/03/16 16:16:05 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1081.1 MB)
16/03/16 16:16:05 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:47991 (size: 4.0 KB, free: 1081.1 MB)
16/03/16 16:16:05 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 16:16:05 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:05 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 16:16:05 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 16:16:05 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 16:16:05 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125165339
16/03/16 16:16:05 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-630e0a33-d554-4d32-9945-94dac89170d6/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: area
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: issue
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: planning
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: permission
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: economy
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: composition
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: agency
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 16:16:14 INFO PythonRunner: Times: total = 8807, boot = 483, init = 355, finish = 7969
16/03/16 16:16:14 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 16:16:14 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 16:16:14 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 16:16:14 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8934 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: set
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: bend
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: giant
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: astatine
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('astatine.n.01') ; keyword:  product  in syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= [u'astatine']
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: present
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: area
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
16/03/16 16:16:14 INFO PythonRunner: Times: total = 370, boot = 244, init = 0, finish = 126
16/03/16 16:16:14 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 16:16:14 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 9.326 s
16/03/16 16:16:14 INFO DAGScheduler: looking for newly runnable stages
16/03/16 16:16:14 INFO DAGScheduler: running: Set()
16/03/16 16:16:14 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 16:16:14 INFO DAGScheduler: failed: Set()
16/03/16 16:16:14 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 16:16:14 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 16:16:14 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10709, maxMem=1133594542
16/03/16 16:16:14 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1081.1 MB)
16/03/16 16:16:14 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15693, maxMem=1133594542
16/03/16 16:16:14 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1081.1 MB)
16/03/16 16:16:14 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 410 ms on localhost (2/2)
16/03/16 16:16:14 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 16:16:14 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:47991 (size: 3.0 KB, free: 1081.1 MB)
16/03/16 16:16:14 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 16:16:14 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:14 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 16:16:14 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:16:14 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 16:16:14 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:16:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 16:16:15 INFO PythonRunner: Times: total = 229, boot = 228, init = 0, finish = 1
16/03/16 16:16:15 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 16:16:15 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:16:15 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 16:16:15 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:16:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 16:16:15 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 251 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'astatine']
16/03/16 16:16:15 INFO PythonRunner: Times: total = 494, boot = 263, init = 231, finish = 0
16/03/16 16:16:15 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1242 bytes result sent to driver
16/03/16 16:16:15 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:47991 in memory (size: 4.0 KB, free: 1081.1 MB)
16/03/16 16:16:15 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 563 ms on localhost (2/2)
16/03/16 16:16:15 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 16:16:15 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.833 s
16/03/16 16:16:15 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 10.185098 s
16/03/16 16:16:15 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:16:15 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:16:15 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:15 INFO DAGScheduler: Parents of final stage: List()
16/03/16 16:16:15 INFO DAGScheduler: Missing parents: List()
16/03/16 16:16:15 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:16:15 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=8032, maxMem=1133594542
16/03/16 16:16:15 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1081.1 MB)
16/03/16 16:16:15 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=13848, maxMem=1133594542
16/03/16 16:16:15 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1081.1 MB)
16/03/16 16:16:15 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:47991 (size: 3.3 KB, free: 1081.1 MB)
16/03/16 16:16:15 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 16:16:15 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:15 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 16:16:15 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 16:16:15 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 16:16:15 INFO PythonRunner: Times: total = 77, boot = 34, init = 43, finish = 0
16/03/16 16:16:15 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 16:16:15 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2272 bytes)
16/03/16 16:16:15 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 95 ms on localhost (1/2)
16/03/16 16:16:15 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 16:16:16 INFO PythonRunner: Times: total = 177, boot = 177, init = 0, finish = 0
16/03/16 16:16:16 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1311 bytes result sent to driver
16/03/16 16:16:16 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 200 ms on localhost (2/2)
16/03/16 16:16:16 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 16:16:16 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.288 s
16/03/16 16:16:16 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.302754 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 16:16:16 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 16:16:16 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 16:16:16 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 16:16:16 INFO MemoryStore: MemoryStore cleared
16/03/16 16:16:16 INFO BlockManager: BlockManager stopped
16/03/16 16:16:16 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 16:16:16 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 16:16:16 INFO SparkContext: Successfully stopped SparkContext
16/03/16 16:16:16 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 16:16:16 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'astatine']
16/03/16 16:16:17 INFO SparkContext: Running Spark version 1.5.2
16/03/16 16:16:17 INFO SecurityManager: Changing view acls to: root
16/03/16 16:16:17 INFO SecurityManager: Changing modify acls to: root
16/03/16 16:16:17 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 16:16:17 INFO Slf4jLogger: Slf4jLogger started
16/03/16 16:16:17 INFO Remoting: Starting remoting
16/03/16 16:16:17 INFO Utils: Successfully started service 'sparkDriver' on port 38799.
16/03/16 16:16:17 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:38799]
16/03/16 16:16:17 INFO SparkEnv: Registering MapOutputTracker
16/03/16 16:16:17 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 16:16:17 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-44861a3a-8cba-4e10-94da-f12899feaefe
16/03/16 16:16:17 INFO MemoryStore: MemoryStore started with capacity 1072.2 MB
16/03/16 16:16:17 INFO HttpFileServer: HTTP File server directory is /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/httpd-aa62f867-74f4-40b0-b183-6c5c2141b959
16/03/16 16:16:17 INFO HttpServer: Starting HTTP Server
16/03/16 16:16:17 INFO Utils: Successfully started service 'HTTP file server' on port 56213.
16/03/16 16:16:17 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 16:16:17 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 16:16:17 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 16:16:17 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-1c2fe6d3-c1b8-4f0f-9edf-9b3c170738ce/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 16:16:17 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125177425
16/03/16 16:16:17 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 16:16:17 INFO Executor: Starting executor ID driver on host localhost
16/03/16 16:16:17 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52513.
16/03/16 16:16:17 INFO NettyBlockTransferService: Server created on 52513
16/03/16 16:16:17 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 16:16:17 INFO BlockManagerMasterEndpoint: Registering block manager localhost:52513 with 1072.2 MB RAM, BlockManagerId(driver, localhost, 52513)
16/03/16 16:16:17 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): used
16/03/16 16:16:17 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:16:17 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:17 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:16:17 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 16:16:17 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 16:16:17 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:16:17 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1124251729
16/03/16 16:16:17 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1072.2 MB)
16/03/16 16:16:17 INFO MemoryStore: ensureFreeSpace(4141) called with curMem=6568, maxMem=1124251729
16/03/16 16:16:17 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1072.2 MB)
16/03/16 16:16:17 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:52513 (size: 4.0 KB, free: 1072.2 MB)
16/03/16 16:16:17 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 16:16:17 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:17 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 16:16:17 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 16:16:17 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 16:16:17 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125177425
16/03/16 16:16:17 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-1c2fe6d3-c1b8-4f0f-9edf-9b3c170738ce/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: area
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: issue
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: planning
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: permission
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: economy
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: composition
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: agency
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 16:16:25 INFO PythonRunner: Times: total = 7750, boot = 468, init = 348, finish = 6934
16/03/16 16:16:25 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 16:16:25 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 16:16:25 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 16:16:25 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7853 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: set
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): adding to parents: syn =  Synset('set.n.01') ; keyword:  used  in syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: bend
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: giant
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: astatine
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: present
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: area
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
16/03/16 16:16:25 INFO PythonRunner: Times: total = 265, boot = 155, init = 0, finish = 110
16/03/16 16:16:25 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 16:16:25 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.127 s
16/03/16 16:16:25 INFO DAGScheduler: looking for newly runnable stages
16/03/16 16:16:25 INFO DAGScheduler: running: Set()
16/03/16 16:16:25 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 16:16:25 INFO DAGScheduler: failed: Set()
16/03/16 16:16:25 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 16:16:25 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 16:16:25 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10709, maxMem=1124251729
16/03/16 16:16:25 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1072.2 MB)
16/03/16 16:16:25 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15693, maxMem=1124251729
16/03/16 16:16:25 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1072.2 MB)
16/03/16 16:16:25 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 287 ms on localhost (2/2)
16/03/16 16:16:25 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 16:16:25 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:52513 (size: 3.0 KB, free: 1072.2 MB)
16/03/16 16:16:25 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 16:16:25 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:25 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 16:16:25 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:16:25 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 16:16:25 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:16:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 16:16:25 INFO PythonRunner: Times: total = 171, boot = 170, init = 1, finish = 0
16/03/16 16:16:25 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 16:16:25 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:16:25 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 16:16:25 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:16:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
16/03/16 16:16:25 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 199 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'set']
16/03/16 16:16:26 INFO PythonRunner: Times: total = 178, boot = 177, init = 0, finish = 1
16/03/16 16:16:26 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1229 bytes result sent to driver
16/03/16 16:16:26 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 204 ms on localhost (2/2)
16/03/16 16:16:26 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.378 s
16/03/16 16:16:26 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 16:16:26 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.543526 s
16/03/16 16:16:26 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:16:26 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:16:26 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:26 INFO DAGScheduler: Parents of final stage: List()
16/03/16 16:16:26 INFO DAGScheduler: Missing parents: List()
16/03/16 16:16:26 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:16:26 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18741, maxMem=1124251729
16/03/16 16:16:26 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1072.1 MB)
16/03/16 16:16:26 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24557, maxMem=1124251729
16/03/16 16:16:26 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1072.1 MB)
16/03/16 16:16:26 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:52513 (size: 3.3 KB, free: 1072.2 MB)
16/03/16 16:16:26 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 16:16:26 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:26 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 16:16:26 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 16:16:26 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 16:16:26 INFO PythonRunner: Times: total = 84, boot = 83, init = 0, finish = 1
16/03/16 16:16:26 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 16:16:26 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2259 bytes)
16/03/16 16:16:26 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 16:16:26 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 112 ms on localhost (1/2)
16/03/16 16:16:26 INFO PythonRunner: Times: total = 165, boot = 165, init = 0, finish = 0
16/03/16 16:16:26 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1295 bytes result sent to driver
16/03/16 16:16:26 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 181 ms on localhost (2/2)
16/03/16 16:16:26 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 16:16:26 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.260 s
16/03/16 16:16:26 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.313277 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 16:16:26 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 16:16:26 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 16:16:26 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 16:16:26 INFO MemoryStore: MemoryStore cleared
16/03/16 16:16:26 INFO BlockManager: BlockManager stopped
16/03/16 16:16:26 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 16:16:26 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 16:16:26 INFO SparkContext: Successfully stopped SparkContext
16/03/16 16:16:26 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 16:16:26 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 16:16:26 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'set']
16/03/16 16:16:27 INFO SparkContext: Running Spark version 1.5.2
16/03/16 16:16:27 INFO SecurityManager: Changing view acls to: root
16/03/16 16:16:27 INFO SecurityManager: Changing modify acls to: root
16/03/16 16:16:27 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 16:16:27 INFO Slf4jLogger: Slf4jLogger started
16/03/16 16:16:27 INFO Remoting: Starting remoting
16/03/16 16:16:27 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:52146]
16/03/16 16:16:27 INFO Utils: Successfully started service 'sparkDriver' on port 52146.
16/03/16 16:16:27 INFO SparkEnv: Registering MapOutputTracker
16/03/16 16:16:27 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 16:16:27 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-b6514ce9-f4c2-4cdd-9c4c-d47d3f4b2549
16/03/16 16:16:27 INFO MemoryStore: MemoryStore started with capacity 1072.2 MB
16/03/16 16:16:27 INFO HttpFileServer: HTTP File server directory is /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/httpd-afc9ce0b-2d2a-429c-bf56-d0208897bf25
16/03/16 16:16:27 INFO HttpServer: Starting HTTP Server
16/03/16 16:16:27 INFO Utils: Successfully started service 'HTTP file server' on port 37994.
16/03/16 16:16:27 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 16:16:27 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 16:16:27 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 16:16:27 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-c56ac036-da1d-4936-9d6b-808a90022521/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 16:16:27 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125187790
16/03/16 16:16:27 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 16:16:27 INFO Executor: Starting executor ID driver on host localhost
16/03/16 16:16:27 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58272.
16/03/16 16:16:27 INFO NettyBlockTransferService: Server created on 58272
16/03/16 16:16:27 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 16:16:27 INFO BlockManagerMasterEndpoint: Registering block manager localhost:58272 with 1072.2 MB RAM, BlockManagerId(driver, localhost, 58272)
16/03/16 16:16:27 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): usually
16/03/16 16:16:27 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:16:27 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:27 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:16:27 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 16:16:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 16:16:27 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:16:27 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1124251729
16/03/16 16:16:27 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1072.2 MB)
16/03/16 16:16:27 INFO MemoryStore: ensureFreeSpace(4141) called with curMem=6568, maxMem=1124251729
16/03/16 16:16:27 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1072.2 MB)
16/03/16 16:16:27 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:58272 (size: 4.0 KB, free: 1072.2 MB)
16/03/16 16:16:27 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 16:16:27 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:27 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 16:16:27 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 16:16:27 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 16:16:27 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125187790
16/03/16 16:16:28 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-c56ac036-da1d-4936-9d6b-808a90022521/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: area
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  usually  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: issue
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: planning
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: permission
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: economy
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: composition
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: agency
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
16/03/16 16:16:35 INFO PythonRunner: Times: total = 7704, boot = 456, init = 360, finish = 6888
16/03/16 16:16:35 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 16:16:35 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 16:16:35 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 16:16:35 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7797 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: set
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: bend
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: giant
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: astatine
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: present
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: area
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  usually  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
16/03/16 16:16:36 INFO PythonRunner: Times: total = 242, boot = 137, init = 1, finish = 104
16/03/16 16:16:36 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 16:16:36 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 278 ms on localhost (2/2)
16/03/16 16:16:36 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 16:16:36 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.067 s
16/03/16 16:16:36 INFO DAGScheduler: looking for newly runnable stages
16/03/16 16:16:36 INFO DAGScheduler: running: Set()
16/03/16 16:16:36 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 16:16:36 INFO DAGScheduler: failed: Set()
16/03/16 16:16:36 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 16:16:36 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 16:16:36 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10709, maxMem=1124251729
16/03/16 16:16:36 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1072.2 MB)
16/03/16 16:16:36 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15693, maxMem=1124251729
16/03/16 16:16:36 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1072.2 MB)
16/03/16 16:16:36 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:58272 (size: 3.0 KB, free: 1072.2 MB)
16/03/16 16:16:36 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 16:16:36 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:36 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 16:16:36 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:16:36 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 16:16:36 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:16:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/16 16:16:36 INFO PythonRunner: Times: total = 120, boot = 119, init = 1, finish = 0
16/03/16 16:16:36 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 16:16:36 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:16:36 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 16:16:36 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:16:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 16:16:36 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 167 ms on localhost (1/2)
reduceFunction_Parents(): returns= [u'area', 'None', u'area']
16/03/16 16:16:36 INFO PythonRunner: Times: total = 152, boot = 151, init = 0, finish = 1
16/03/16 16:16:36 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1241 bytes result sent to driver
16/03/16 16:16:36 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.315 s
16/03/16 16:16:36 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.445416 s
16/03/16 16:16:36 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 183 ms on localhost (2/2)
16/03/16 16:16:36 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 16:16:36 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:16:36 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:16:36 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:36 INFO DAGScheduler: Parents of final stage: List()
16/03/16 16:16:36 INFO DAGScheduler: Missing parents: List()
16/03/16 16:16:36 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:16:36 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18741, maxMem=1124251729
16/03/16 16:16:36 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1072.1 MB)
16/03/16 16:16:36 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24557, maxMem=1124251729
16/03/16 16:16:36 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1072.1 MB)
16/03/16 16:16:36 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:58272 (size: 3.3 KB, free: 1072.2 MB)
16/03/16 16:16:36 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 16:16:36 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:36 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 16:16:36 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 16:16:36 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 16:16:36 INFO PythonRunner: Times: total = 15, boot = 4, init = 11, finish = 0
16/03/16 16:16:36 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 16:16:36 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2271 bytes)
16/03/16 16:16:36 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 58 ms on localhost (1/2)
16/03/16 16:16:36 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 16:16:36 INFO PythonRunner: Times: total = 167, boot = 167, init = 0, finish = 0
16/03/16 16:16:36 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1307 bytes result sent to driver
16/03/16 16:16:36 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 186 ms on localhost (2/2)
16/03/16 16:16:36 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 16:16:36 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.219 s
16/03/16 16:16:36 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.265849 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 16:16:36 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 16:16:36 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 16:16:36 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 16:16:36 INFO MemoryStore: MemoryStore cleared
16/03/16 16:16:36 INFO BlockManager: BlockManager stopped
16/03/16 16:16:36 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 16:16:36 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 16:16:36 INFO SparkContext: Successfully stopped SparkContext
16/03/16 16:16:36 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 16:16:36 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 16:16:36 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'area', u'None', u'area']
16/03/16 16:16:37 INFO SparkContext: Running Spark version 1.5.2
16/03/16 16:16:37 INFO SecurityManager: Changing view acls to: root
16/03/16 16:16:37 INFO SecurityManager: Changing modify acls to: root
16/03/16 16:16:37 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 16:16:37 INFO Slf4jLogger: Slf4jLogger started
16/03/16 16:16:37 INFO Remoting: Starting remoting
16/03/16 16:16:37 INFO Utils: Successfully started service 'sparkDriver' on port 39280.
16/03/16 16:16:37 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:39280]
16/03/16 16:16:37 INFO SparkEnv: Registering MapOutputTracker
16/03/16 16:16:37 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 16:16:37 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-3a40a3f8-e473-47e7-a784-d44e795bee79
16/03/16 16:16:37 INFO MemoryStore: MemoryStore started with capacity 1072.2 MB
16/03/16 16:16:38 INFO HttpFileServer: HTTP File server directory is /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/httpd-ccd9812e-d648-4755-8657-0fc103e96b07
16/03/16 16:16:38 INFO HttpServer: Starting HTTP Server
16/03/16 16:16:38 INFO Utils: Successfully started service 'HTTP file server' on port 60669.
16/03/16 16:16:38 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 16:16:38 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 16:16:38 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 16:16:38 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-5010757d-51be-4bd0-9d14-a671aaa8a243/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 16:16:38 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125198184
16/03/16 16:16:38 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 16:16:38 INFO Executor: Starting executor ID driver on host localhost
16/03/16 16:16:38 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41439.
16/03/16 16:16:38 INFO NettyBlockTransferService: Server created on 41439
16/03/16 16:16:38 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 16:16:38 INFO BlockManagerMasterEndpoint: Registering block manager localhost:41439 with 1072.2 MB RAM, BlockManagerId(driver, localhost, 41439)
16/03/16 16:16:38 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): moment
16/03/16 16:16:38 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:16:38 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:38 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:16:38 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 16:16:38 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 16:16:38 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:16:38 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1124251729
16/03/16 16:16:38 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1072.2 MB)
16/03/16 16:16:38 INFO MemoryStore: ensureFreeSpace(4141) called with curMem=6568, maxMem=1124251729
16/03/16 16:16:38 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1072.2 MB)
16/03/16 16:16:38 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:41439 (size: 4.0 KB, free: 1072.2 MB)
16/03/16 16:16:38 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 16:16:38 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:38 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 16:16:38 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 16:16:38 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 16:16:38 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125198184
16/03/16 16:16:38 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-5010757d-51be-4bd0-9d14-a671aaa8a243/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: area
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: issue
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: planning
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: permission
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: economy
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: composition
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: agency
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 16:16:46 INFO PythonRunner: Times: total = 8005, boot = 572, init = 443, finish = 6990
16/03/16 16:16:46 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 16:16:46 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 16:16:46 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 16:16:46 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8161 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: set
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: bend
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: giant
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: astatine
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: present
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('present.n.01') ; keyword:  moment  in syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= [u'present']
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: area
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
16/03/16 16:16:46 INFO PythonRunner: Times: total = 241, boot = 139, init = 0, finish = 102
16/03/16 16:16:46 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 16:16:46 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 275 ms on localhost (2/2)
16/03/16 16:16:46 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 16:16:46 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.419 s
16/03/16 16:16:46 INFO DAGScheduler: looking for newly runnable stages
16/03/16 16:16:46 INFO DAGScheduler: running: Set()
16/03/16 16:16:46 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 16:16:46 INFO DAGScheduler: failed: Set()
16/03/16 16:16:46 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 16:16:46 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 16:16:46 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10709, maxMem=1124251729
16/03/16 16:16:46 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1072.2 MB)
16/03/16 16:16:46 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15693, maxMem=1124251729
16/03/16 16:16:46 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1072.2 MB)
16/03/16 16:16:46 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:41439 (size: 3.0 KB, free: 1072.2 MB)
16/03/16 16:16:46 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 16:16:46 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:46 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 16:16:46 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:16:46 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 16:16:46 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:16:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 16:16:47 INFO PythonRunner: Times: total = 122, boot = 122, init = 0, finish = 0
16/03/16 16:16:47 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 16:16:47 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:16:47 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 16:16:47 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:16:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 16:16:47 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 175 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'present']
16/03/16 16:16:47 INFO PythonRunner: Times: total = 173, boot = 172, init = 1, finish = 0
16/03/16 16:16:47 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1241 bytes result sent to driver
16/03/16 16:16:47 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 190 ms on localhost (2/2)
16/03/16 16:16:47 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 16:16:47 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.316 s
16/03/16 16:16:47 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.815038 s
16/03/16 16:16:47 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:16:47 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:16:47 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:47 INFO DAGScheduler: Parents of final stage: List()
16/03/16 16:16:47 INFO DAGScheduler: Missing parents: List()
16/03/16 16:16:47 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:16:47 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18741, maxMem=1124251729
16/03/16 16:16:47 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1072.1 MB)
16/03/16 16:16:47 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24557, maxMem=1124251729
16/03/16 16:16:47 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1072.1 MB)
16/03/16 16:16:47 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:41439 (size: 3.3 KB, free: 1072.2 MB)
16/03/16 16:16:47 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 16:16:47 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:47 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 16:16:47 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 16:16:47 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 16:16:47 INFO PythonRunner: Times: total = 62, boot = 62, init = 0, finish = 0
16/03/16 16:16:47 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 16:16:47 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2271 bytes)
16/03/16 16:16:47 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 86 ms on localhost (1/2)
16/03/16 16:16:47 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 16:16:47 INFO PythonRunner: Times: total = 166, boot = 166, init = 0, finish = 0
16/03/16 16:16:47 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1310 bytes result sent to driver
16/03/16 16:16:47 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 190 ms on localhost (2/2)
16/03/16 16:16:47 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 16:16:47 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.247 s
16/03/16 16:16:47 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.287173 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 16:16:47 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 16:16:47 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 16:16:47 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 16:16:47 INFO MemoryStore: MemoryStore cleared
16/03/16 16:16:47 INFO BlockManager: BlockManager stopped
16/03/16 16:16:47 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 16:16:47 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 16:16:47 INFO SparkContext: Successfully stopped SparkContext
16/03/16 16:16:47 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 16:16:47 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 16:16:47 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'present']
16/03/16 16:16:48 INFO SparkContext: Running Spark version 1.5.2
16/03/16 16:16:48 INFO SecurityManager: Changing view acls to: root
16/03/16 16:16:48 INFO SecurityManager: Changing modify acls to: root
16/03/16 16:16:48 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 16:16:48 INFO Slf4jLogger: Slf4jLogger started
16/03/16 16:16:48 INFO Remoting: Starting remoting
16/03/16 16:16:48 INFO Utils: Successfully started service 'sparkDriver' on port 36034.
16/03/16 16:16:48 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:36034]
16/03/16 16:16:48 INFO SparkEnv: Registering MapOutputTracker
16/03/16 16:16:48 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 16:16:48 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-4f835d73-5fad-41ed-96af-e2f7d2f05171
16/03/16 16:16:48 INFO MemoryStore: MemoryStore started with capacity 1072.2 MB
16/03/16 16:16:48 INFO HttpFileServer: HTTP File server directory is /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/httpd-9e3e0537-3785-42fd-a875-54778bf615da
16/03/16 16:16:48 INFO HttpServer: Starting HTTP Server
16/03/16 16:16:48 INFO Utils: Successfully started service 'HTTP file server' on port 35572.
16/03/16 16:16:48 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 16:16:48 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 16:16:48 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 16:16:48 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-6fc77966-34cd-4c30-b287-d254a1ac3e8d/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 16:16:48 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125208941
16/03/16 16:16:48 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 16:16:48 INFO Executor: Starting executor ID driver on host localhost
16/03/16 16:16:49 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44432.
16/03/16 16:16:49 INFO NettyBlockTransferService: Server created on 44432
16/03/16 16:16:49 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 16:16:49 INFO BlockManagerMasterEndpoint: Registering block manager localhost:44432 with 1072.2 MB RAM, BlockManagerId(driver, localhost, 44432)
16/03/16 16:16:49 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): purpose
16/03/16 16:16:49 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:16:49 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:49 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:16:49 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 16:16:49 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 16:16:49 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:16:49 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1124251729
16/03/16 16:16:49 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1072.2 MB)
16/03/16 16:16:49 INFO MemoryStore: ensureFreeSpace(4141) called with curMem=6568, maxMem=1124251729
16/03/16 16:16:49 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1072.2 MB)
16/03/16 16:16:49 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:44432 (size: 4.0 KB, free: 1072.2 MB)
16/03/16 16:16:49 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 16:16:49 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:49 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 16:16:49 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 16:16:49 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 16:16:49 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125208941
16/03/16 16:16:49 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-6fc77966-34cd-4c30-b287-d254a1ac3e8d/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: area
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  purpose  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: issue
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: planning
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: permission
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: economy
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: composition
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: agency
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
16/03/16 16:16:57 INFO PythonRunner: Times: total = 7899, boot = 489, init = 361, finish = 7049
16/03/16 16:16:57 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 16:16:57 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 16:16:57 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 16:16:57 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8031 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: set
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: bend
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: giant
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: astatine
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: present
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: area
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  purpose  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
16/03/16 16:16:57 INFO PythonRunner: Times: total = 270, boot = 153, init = 1, finish = 116
16/03/16 16:16:57 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 16:16:57 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 304 ms on localhost (2/2)
16/03/16 16:16:57 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.312 s
16/03/16 16:16:57 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 16:16:57 INFO DAGScheduler: looking for newly runnable stages
16/03/16 16:16:57 INFO DAGScheduler: running: Set()
16/03/16 16:16:57 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 16:16:57 INFO DAGScheduler: failed: Set()
16/03/16 16:16:57 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 16:16:57 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 16:16:57 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10709, maxMem=1124251729
16/03/16 16:16:57 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1072.2 MB)
16/03/16 16:16:57 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15693, maxMem=1124251729
16/03/16 16:16:57 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1072.2 MB)
16/03/16 16:16:57 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:44432 (size: 3.0 KB, free: 1072.2 MB)
16/03/16 16:16:57 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 16:16:57 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:57 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 16:16:57 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:16:57 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 16:16:57 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:16:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 16:16:57 INFO PythonRunner: Times: total = 162, boot = 161, init = 1, finish = 0
16/03/16 16:16:57 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 16:16:57 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:16:57 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 16:16:57 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:16:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/16 16:16:57 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 194 ms on localhost (1/2)
reduceFunction_Parents(): returns= [u'area', 'None', u'area']
16/03/16 16:16:57 INFO PythonRunner: Times: total = 163, boot = 163, init = 0, finish = 0
16/03/16 16:16:57 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1241 bytes result sent to driver
16/03/16 16:16:57 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 184 ms on localhost (2/2)
16/03/16 16:16:57 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 16:16:57 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.353 s
16/03/16 16:16:57 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.722012 s
16/03/16 16:16:57 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:16:57 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:16:57 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:57 INFO DAGScheduler: Parents of final stage: List()
16/03/16 16:16:57 INFO DAGScheduler: Missing parents: List()
16/03/16 16:16:57 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:16:57 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18741, maxMem=1124251729
16/03/16 16:16:57 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1072.1 MB)
16/03/16 16:16:57 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24557, maxMem=1124251729
16/03/16 16:16:57 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1072.1 MB)
16/03/16 16:16:57 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:44432 (size: 3.3 KB, free: 1072.2 MB)
16/03/16 16:16:57 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 16:16:57 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:57 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 16:16:57 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 16:16:57 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 16:16:58 INFO PythonRunner: Times: total = 92, boot = 92, init = 0, finish = 0
16/03/16 16:16:58 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 16:16:58 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2271 bytes)
16/03/16 16:16:58 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 16:16:58 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 112 ms on localhost (1/2)
16/03/16 16:16:58 INFO PythonRunner: Times: total = 175, boot = 175, init = 0, finish = 0
16/03/16 16:16:58 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1307 bytes result sent to driver
16/03/16 16:16:58 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.300 s
16/03/16 16:16:58 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.322238 s
16/03/16 16:16:58 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 193 ms on localhost (2/2)
16/03/16 16:16:58 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 16:16:58 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 16:16:58 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 16:16:58 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 16:16:58 INFO MemoryStore: MemoryStore cleared
16/03/16 16:16:58 INFO BlockManager: BlockManager stopped
16/03/16 16:16:58 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 16:16:58 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 16:16:58 INFO SparkContext: Successfully stopped SparkContext
16/03/16 16:16:58 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 16:16:58 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 16:16:58 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'area', u'None', u'area']
16/03/16 16:16:59 INFO SparkContext: Running Spark version 1.5.2
16/03/16 16:16:59 INFO SecurityManager: Changing view acls to: root
16/03/16 16:16:59 INFO SecurityManager: Changing modify acls to: root
16/03/16 16:16:59 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 16:16:59 INFO Slf4jLogger: Slf4jLogger started
16/03/16 16:16:59 INFO Remoting: Starting remoting
16/03/16 16:16:59 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:36456]
16/03/16 16:16:59 INFO Utils: Successfully started service 'sparkDriver' on port 36456.
16/03/16 16:16:59 INFO SparkEnv: Registering MapOutputTracker
16/03/16 16:16:59 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 16:16:59 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-ca7b7e68-15b7-4d85-b70c-9db420b8b16d
16/03/16 16:16:59 INFO MemoryStore: MemoryStore started with capacity 1072.2 MB
16/03/16 16:16:59 INFO HttpFileServer: HTTP File server directory is /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/httpd-fe48363e-d193-498f-977c-27bc4c53dd0e
16/03/16 16:16:59 INFO HttpServer: Starting HTTP Server
16/03/16 16:16:59 INFO Utils: Successfully started service 'HTTP file server' on port 51043.
16/03/16 16:16:59 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 16:16:59 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 16:16:59 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 16:16:59 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-9900cf2b-f79d-4b5c-8a8b-7d15dca3b4b4/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 16:16:59 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125219584
16/03/16 16:16:59 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 16:16:59 INFO Executor: Starting executor ID driver on host localhost
16/03/16 16:16:59 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45881.
16/03/16 16:16:59 INFO NettyBlockTransferService: Server created on 45881
16/03/16 16:16:59 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 16:16:59 INFO BlockManagerMasterEndpoint: Registering block manager localhost:45881 with 1072.2 MB RAM, BlockManagerId(driver, localhost, 45881)
16/03/16 16:16:59 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): segment
16/03/16 16:16:59 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:16:59 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:59 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:16:59 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 16:16:59 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 16:16:59 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:16:59 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1124251729
16/03/16 16:16:59 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1072.2 MB)
16/03/16 16:16:59 INFO MemoryStore: ensureFreeSpace(4141) called with curMem=6568, maxMem=1124251729
16/03/16 16:16:59 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1072.2 MB)
16/03/16 16:16:59 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:45881 (size: 4.0 KB, free: 1072.2 MB)
16/03/16 16:16:59 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 16:16:59 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:59 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 16:16:59 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 16:16:59 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 16:16:59 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125219584
16/03/16 16:16:59 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-9900cf2b-f79d-4b5c-8a8b-7d15dca3b4b4/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: area
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: issue
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: planning
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: permission
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: economy
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: composition
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: agency
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 16:17:07 INFO PythonRunner: Times: total = 7887, boot = 471, init = 359, finish = 7057
16/03/16 16:17:07 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 16:17:07 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 16:17:07 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 16:17:07 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7965 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: set
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: bend
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): adding to parents: syn =  Synset('bend.n.01') ; keyword:  segment  in syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= [u'bend']
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: giant
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: astatine
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: present
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: area
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
16/03/16 16:17:07 INFO PythonRunner: Times: total = 282, boot = 175, init = 0, finish = 107
16/03/16 16:17:07 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 16:17:07 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.263 s
16/03/16 16:17:07 INFO DAGScheduler: looking for newly runnable stages
16/03/16 16:17:07 INFO DAGScheduler: running: Set()
16/03/16 16:17:07 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 16:17:07 INFO DAGScheduler: failed: Set()
16/03/16 16:17:07 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 16:17:07 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 16:17:08 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10709, maxMem=1124251729
16/03/16 16:17:08 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1072.2 MB)
16/03/16 16:17:08 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15693, maxMem=1124251729
16/03/16 16:17:08 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1072.2 MB)
16/03/16 16:17:08 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 306 ms on localhost (2/2)
16/03/16 16:17:08 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 16:17:08 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:45881 (size: 3.0 KB, free: 1072.2 MB)
16/03/16 16:17:08 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 16:17:08 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:17:08 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 16:17:08 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:17:08 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 16:17:08 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:17:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 16:17:08 INFO PythonRunner: Times: total = 157, boot = 156, init = 1, finish = 0
16/03/16 16:17:08 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 16:17:08 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:17:08 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 16:17:08 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:17:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/16 16:17:08 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 187 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'bend']
16/03/16 16:17:08 INFO PythonRunner: Times: total = 166, boot = 165, init = 0, finish = 1
16/03/16 16:17:08 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1230 bytes result sent to driver
16/03/16 16:17:08 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.353 s
16/03/16 16:17:08 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.653734 s
16/03/16 16:17:08 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 191 ms on localhost (2/2)
16/03/16 16:17:08 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 16:17:08 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:17:08 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:17:08 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:17:08 INFO DAGScheduler: Parents of final stage: List()
16/03/16 16:17:08 INFO DAGScheduler: Missing parents: List()
16/03/16 16:17:08 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:17:08 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18741, maxMem=1124251729
16/03/16 16:17:08 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1072.1 MB)
16/03/16 16:17:08 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24557, maxMem=1124251729
16/03/16 16:17:08 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1072.1 MB)
16/03/16 16:17:08 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:45881 (size: 3.3 KB, free: 1072.2 MB)
16/03/16 16:17:08 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 16:17:08 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:17:08 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 16:17:08 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 16:17:08 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 16:17:08 INFO PythonRunner: Times: total = 116, boot = 115, init = 1, finish = 0
16/03/16 16:17:08 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 16:17:08 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2260 bytes)
16/03/16 16:17:08 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 16:17:08 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 139 ms on localhost (1/2)
16/03/16 16:17:08 INFO PythonRunner: Times: total = 170, boot = 170, init = 0, finish = 0
16/03/16 16:17:08 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1296 bytes result sent to driver
16/03/16 16:17:08 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 192 ms on localhost (2/2)
16/03/16 16:17:08 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 16:17:08 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.309 s
16/03/16 16:17:08 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.353178 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 16:17:08 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 16:17:08 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 16:17:08 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 16:17:08 INFO MemoryStore: MemoryStore cleared
16/03/16 16:17:08 INFO BlockManager: BlockManager stopped
16/03/16 16:17:08 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 16:17:08 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 16:17:08 INFO SparkContext: Successfully stopped SparkContext
16/03/16 16:17:08 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 16:17:08 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 16:17:08 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'bend']
16/03/16 16:17:09 INFO SparkContext: Running Spark version 1.5.2
16/03/16 16:17:09 INFO SecurityManager: Changing view acls to: root
16/03/16 16:17:09 INFO SecurityManager: Changing modify acls to: root
16/03/16 16:17:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 16:17:09 INFO Slf4jLogger: Slf4jLogger started
16/03/16 16:17:09 INFO Remoting: Starting remoting
16/03/16 16:17:09 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:33251]
16/03/16 16:17:09 INFO Utils: Successfully started service 'sparkDriver' on port 33251.
16/03/16 16:17:09 INFO SparkEnv: Registering MapOutputTracker
16/03/16 16:17:09 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 16:17:09 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-cf1f97aa-b1df-497a-856f-93ba143533f7
16/03/16 16:17:10 INFO MemoryStore: MemoryStore started with capacity 1072.2 MB
16/03/16 16:17:10 INFO HttpFileServer: HTTP File server directory is /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/httpd-ffa14d38-c828-4fb6-b4ad-0ed00f389caa
16/03/16 16:17:10 INFO HttpServer: Starting HTTP Server
16/03/16 16:17:10 INFO Utils: Successfully started service 'HTTP file server' on port 33719.
16/03/16 16:17:10 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 16:17:10 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 16:17:10 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 16:17:10 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-f5df1aa3-09f1-4eb4-9d7d-c0fc39b20d7a/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 16:17:10 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125230168
16/03/16 16:17:10 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 16:17:10 INFO Executor: Starting executor ID driver on host localhost
16/03/16 16:17:10 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58694.
16/03/16 16:17:10 INFO NettyBlockTransferService: Server created on 58694
16/03/16 16:17:10 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 16:17:10 INFO BlockManagerMasterEndpoint: Registering block manager localhost:58694 with 1072.2 MB RAM, BlockManagerId(driver, localhost, 58694)
16/03/16 16:17:10 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): radioactive
16/03/16 16:17:10 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:17:10 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:17:10 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:17:10 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:17:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 16:17:10 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 16:17:10 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:17:10 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1124251729
16/03/16 16:17:10 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1072.2 MB)
16/03/16 16:17:10 INFO MemoryStore: ensureFreeSpace(4139) called with curMem=6568, maxMem=1124251729
16/03/16 16:17:10 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1072.2 MB)
16/03/16 16:17:10 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:58694 (size: 4.0 KB, free: 1072.2 MB)
16/03/16 16:17:10 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 16:17:10 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:17:10 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 16:17:10 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 16:17:10 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 16:17:10 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125230168
16/03/16 16:17:10 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-f5df1aa3-09f1-4eb4-9d7d-c0fc39b20d7a/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: area
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: issue
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: planning
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: permission
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: economy
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: composition
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: agency
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 16:17:18 INFO PythonRunner: Times: total = 7918, boot = 486, init = 354, finish = 7078
16/03/16 16:17:18 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 16:17:18 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 16:17:18 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 16:17:18 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8050 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: set
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: bend
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: giant
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: astatine
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('astatine.n.01') ; keyword:  radioactive  in syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= [u'astatine']
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: present
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: area
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
16/03/16 16:17:18 INFO PythonRunner: Times: total = 252, boot = 145, init = 0, finish = 107
16/03/16 16:17:18 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 16:17:18 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 284 ms on localhost (2/2)
16/03/16 16:17:18 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 16:17:18 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.326 s
16/03/16 16:17:18 INFO DAGScheduler: looking for newly runnable stages
16/03/16 16:17:18 INFO DAGScheduler: running: Set()
16/03/16 16:17:18 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 16:17:18 INFO DAGScheduler: failed: Set()
16/03/16 16:17:18 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 16:17:18 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 16:17:18 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10707, maxMem=1124251729
16/03/16 16:17:18 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1072.2 MB)
16/03/16 16:17:18 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15691, maxMem=1124251729
16/03/16 16:17:18 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1072.2 MB)
16/03/16 16:17:18 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:58694 (size: 3.0 KB, free: 1072.2 MB)
16/03/16 16:17:18 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 16:17:18 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:17:18 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 16:17:18 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:17:18 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 16:17:18 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:17:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/16 16:17:19 INFO PythonRunner: Times: total = 135, boot = 135, init = 0, finish = 0
16/03/16 16:17:19 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 16:17:19 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:17:19 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 16:17:19 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 151 ms on localhost (1/2)
16/03/16 16:17:19 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:17:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
reduceFunction_Parents(): returns= ['None', 'None', u'astatine']
16/03/16 16:17:19 INFO PythonRunner: Times: total = 173, boot = 172, init = 0, finish = 1
16/03/16 16:17:19 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1242 bytes result sent to driver
16/03/16 16:17:19 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.377 s
16/03/16 16:17:19 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.741864 s
16/03/16 16:17:19 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 227 ms on localhost (2/2)
16/03/16 16:17:19 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 16:17:19 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:17:19 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:17:19 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:17:19 INFO DAGScheduler: Parents of final stage: List()
16/03/16 16:17:19 INFO DAGScheduler: Missing parents: List()
16/03/16 16:17:19 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:17:19 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18739, maxMem=1124251729
16/03/16 16:17:19 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1072.1 MB)
16/03/16 16:17:19 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24555, maxMem=1124251729
16/03/16 16:17:19 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1072.1 MB)
16/03/16 16:17:19 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:58694 (size: 3.3 KB, free: 1072.2 MB)
16/03/16 16:17:19 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 16:17:19 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:17:19 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 16:17:19 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 16:17:19 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 16:17:19 INFO PythonRunner: Times: total = 44, boot = 44, init = 0, finish = 0
16/03/16 16:17:19 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 16:17:19 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2272 bytes)
16/03/16 16:17:19 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 64 ms on localhost (1/2)
16/03/16 16:17:19 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 16:17:19 INFO PythonRunner: Times: total = 156, boot = 156, init = 0, finish = 0
16/03/16 16:17:19 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1311 bytes result sent to driver
16/03/16 16:17:19 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 200 ms on localhost (2/2)
16/03/16 16:17:19 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 16:17:19 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.259 s
16/03/16 16:17:19 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.306265 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 16:17:19 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 16:17:19 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 16:17:19 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 16:17:19 INFO MemoryStore: MemoryStore cleared
16/03/16 16:17:19 INFO BlockManager: BlockManager stopped
16/03/16 16:17:19 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 16:17:19 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 16:17:19 INFO SparkContext: Successfully stopped SparkContext
16/03/16 16:17:19 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 16:17:19 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 16:17:19 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'astatine']
16/03/16 16:17:20 INFO SparkContext: Running Spark version 1.5.2
16/03/16 16:17:20 INFO SecurityManager: Changing view acls to: root
16/03/16 16:17:20 INFO SecurityManager: Changing modify acls to: root
16/03/16 16:17:20 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 16:17:20 INFO Slf4jLogger: Slf4jLogger started
16/03/16 16:17:20 INFO Remoting: Starting remoting
16/03/16 16:17:20 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:58617]
16/03/16 16:17:20 INFO Utils: Successfully started service 'sparkDriver' on port 58617.
16/03/16 16:17:20 INFO SparkEnv: Registering MapOutputTracker
16/03/16 16:17:20 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 16:17:20 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-4238d91e-d23a-4c0f-9d76-1cbcde4bda9b
16/03/16 16:17:20 INFO MemoryStore: MemoryStore started with capacity 1071.0 MB
16/03/16 16:17:20 INFO HttpFileServer: HTTP File server directory is /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/httpd-8736e8c0-5ba7-405d-8c93-67ec3706ae62
16/03/16 16:17:20 INFO HttpServer: Starting HTTP Server
16/03/16 16:17:20 INFO Utils: Successfully started service 'HTTP file server' on port 56753.
16/03/16 16:17:20 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 16:17:21 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 16:17:21 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 16:17:21 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-17affc3b-3ed6-4bd5-a84b-aef1d1ccf722/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 16:17:21 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125241075
16/03/16 16:17:21 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 16:17:21 INFO Executor: Starting executor ID driver on host localhost
16/03/16 16:17:21 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46145.
16/03/16 16:17:21 INFO NettyBlockTransferService: Server created on 46145
16/03/16 16:17:21 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 16:17:21 INFO BlockManagerMasterEndpoint: Registering block manager localhost:46145 with 1071.0 MB RAM, BlockManagerId(driver, localhost, 46145)
16/03/16 16:17:21 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): happening
16/03/16 16:17:21 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:17:21 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:17:21 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:17:21 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:17:21 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 16:17:21 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 16:17:21 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:17:21 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1122977710
16/03/16 16:17:21 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1070.9 MB)
16/03/16 16:17:21 INFO MemoryStore: ensureFreeSpace(4141) called with curMem=6568, maxMem=1122977710
16/03/16 16:17:21 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1070.9 MB)
16/03/16 16:17:21 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:46145 (size: 4.0 KB, free: 1071.0 MB)
16/03/16 16:17:21 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 16:17:21 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:17:21 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 16:17:21 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 16:17:21 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 16:17:21 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125241075
16/03/16 16:17:21 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-17affc3b-3ed6-4bd5-a84b-aef1d1ccf722/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: area
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: issue
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: planning
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: permission
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: economy
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: composition
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: agency
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 16:17:29 INFO PythonRunner: Times: total = 8084, boot = 469, init = 362, finish = 7253
16/03/16 16:17:29 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 16:17:29 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 16:17:29 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 16:17:29 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8176 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: set
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: bend
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: giant
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: astatine
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: present
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('present.n.01') ; keyword:  happening  in syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= [u'present']
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: area
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
16/03/16 16:17:29 INFO PythonRunner: Times: total = 284, boot = 187, init = 1, finish = 96
16/03/16 16:17:29 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 16:17:29 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 314 ms on localhost (2/2)
16/03/16 16:17:29 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 16:17:29 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.464 s
16/03/16 16:17:29 INFO DAGScheduler: looking for newly runnable stages
16/03/16 16:17:29 INFO DAGScheduler: running: Set()
16/03/16 16:17:29 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 16:17:29 INFO DAGScheduler: failed: Set()
16/03/16 16:17:29 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 16:17:29 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 16:17:29 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10709, maxMem=1122977710
16/03/16 16:17:29 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1070.9 MB)
16/03/16 16:17:29 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15693, maxMem=1122977710
16/03/16 16:17:29 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1070.9 MB)
16/03/16 16:17:29 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:46145 (size: 3.0 KB, free: 1070.9 MB)
16/03/16 16:17:29 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 16:17:29 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:17:29 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 16:17:29 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:17:29 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 16:17:29 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:17:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/16 16:17:29 INFO PythonRunner: Times: total = 146, boot = 145, init = 1, finish = 0
16/03/16 16:17:29 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 16:17:29 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:17:29 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 16:17:29 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:17:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 16:17:29 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 181 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'present']
16/03/16 16:17:30 INFO PythonRunner: Times: total = 171, boot = 170, init = 0, finish = 1
16/03/16 16:17:30 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1241 bytes result sent to driver
16/03/16 16:17:30 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.351 s
16/03/16 16:17:30 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.870308 s
16/03/16 16:17:30 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 193 ms on localhost (2/2)
16/03/16 16:17:30 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 16:17:30 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:17:30 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:17:30 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:17:30 INFO DAGScheduler: Parents of final stage: List()
16/03/16 16:17:30 INFO DAGScheduler: Missing parents: List()
16/03/16 16:17:30 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:17:30 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18741, maxMem=1122977710
16/03/16 16:17:30 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1070.9 MB)
16/03/16 16:17:30 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24557, maxMem=1122977710
16/03/16 16:17:30 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1070.9 MB)
16/03/16 16:17:30 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:46145 (size: 3.3 KB, free: 1070.9 MB)
16/03/16 16:17:30 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 16:17:30 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:17:30 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 16:17:30 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 16:17:30 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 16:17:30 INFO PythonRunner: Times: total = 94, boot = 94, init = 0, finish = 0
16/03/16 16:17:30 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 16:17:30 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2271 bytes)
16/03/16 16:17:30 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 114 ms on localhost (1/2)
16/03/16 16:17:30 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 16:17:30 INFO PythonRunner: Times: total = 169, boot = 168, init = 1, finish = 0
16/03/16 16:17:30 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1310 bytes result sent to driver
16/03/16 16:17:30 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.285 s
16/03/16 16:17:30 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.324346 s
16/03/16 16:17:30 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 189 ms on localhost (2/2)
16/03/16 16:17:30 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 16:17:30 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 16:17:30 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 16:17:30 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 16:17:30 INFO MemoryStore: MemoryStore cleared
16/03/16 16:17:30 INFO BlockManager: BlockManager stopped
16/03/16 16:17:30 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 16:17:30 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 16:17:30 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 16:17:30 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 16:17:30 INFO SparkContext: Successfully stopped SparkContext
16/03/16 16:17:30 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'present']
16/03/16 16:17:31 INFO SparkContext: Running Spark version 1.5.2
16/03/16 16:17:31 INFO SecurityManager: Changing view acls to: root
16/03/16 16:17:31 INFO SecurityManager: Changing modify acls to: root
16/03/16 16:17:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 16:17:31 INFO Slf4jLogger: Slf4jLogger started
16/03/16 16:17:31 INFO Remoting: Starting remoting
16/03/16 16:17:31 INFO Utils: Successfully started service 'sparkDriver' on port 54383.
16/03/16 16:17:31 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:54383]
16/03/16 16:17:31 INFO SparkEnv: Registering MapOutputTracker
16/03/16 16:17:31 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 16:17:31 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-f34fb9a1-8801-4d27-8a92-98d8ac441aed
16/03/16 16:17:31 INFO MemoryStore: MemoryStore started with capacity 1071.0 MB
16/03/16 16:17:31 INFO HttpFileServer: HTTP File server directory is /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/httpd-e21af925-6987-4442-96b6-260334bfecc7
16/03/16 16:17:31 INFO HttpServer: Starting HTTP Server
16/03/16 16:17:31 INFO Utils: Successfully started service 'HTTP file server' on port 40764.
16/03/16 16:17:31 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 16:17:31 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 16:17:31 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 16:17:31 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-25e14efa-3720-491d-bafc-1016d68febd3/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 16:17:31 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125251951
16/03/16 16:17:31 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 16:17:32 INFO Executor: Starting executor ID driver on host localhost
16/03/16 16:17:32 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60981.
16/03/16 16:17:32 INFO NettyBlockTransferService: Server created on 60981
16/03/16 16:17:32 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 16:17:32 INFO BlockManagerMasterEndpoint: Registering block manager localhost:60981 with 1071.0 MB RAM, BlockManagerId(driver, localhost, 60981)
16/03/16 16:17:32 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): curve
16/03/16 16:17:32 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:17:32 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:17:32 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:17:32 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:17:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 16:17:32 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 16:17:32 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:17:32 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1122977710
16/03/16 16:17:32 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1070.9 MB)
16/03/16 16:17:32 INFO MemoryStore: ensureFreeSpace(4141) called with curMem=6568, maxMem=1122977710
16/03/16 16:17:32 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1070.9 MB)
16/03/16 16:17:32 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:60981 (size: 4.0 KB, free: 1071.0 MB)
16/03/16 16:17:32 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 16:17:32 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:17:32 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 16:17:32 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 16:17:32 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 16:17:32 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125251951
16/03/16 16:17:32 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-25e14efa-3720-491d-bafc-1016d68febd3/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: area
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: issue
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: planning
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: permission
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: economy
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: composition
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: agency
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 16:17:41 INFO PythonRunner: Times: total = 9732, boot = 456, init = 396, finish = 8880
16/03/16 16:17:41 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 16:17:41 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 16:17:41 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 16:17:41 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9838 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: set
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: bend
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): adding to parents: syn =  Synset('bend.n.01') ; keyword:  curve  in syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= [u'bend']
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: giant
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: astatine
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: present
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: area
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
16/03/16 16:17:42 INFO PythonRunner: Times: total = 369, boot = 220, init = 1, finish = 148
16/03/16 16:17:42 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 16:17:42 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 10.253 s
16/03/16 16:17:42 INFO DAGScheduler: looking for newly runnable stages
16/03/16 16:17:42 INFO DAGScheduler: running: Set()
16/03/16 16:17:42 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 16:17:42 INFO DAGScheduler: failed: Set()
16/03/16 16:17:42 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 16:17:42 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 16:17:42 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10709, maxMem=1122977710
16/03/16 16:17:42 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1070.9 MB)
16/03/16 16:17:42 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15693, maxMem=1122977710
16/03/16 16:17:42 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1070.9 MB)
16/03/16 16:17:42 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 427 ms on localhost (2/2)
16/03/16 16:17:42 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 16:17:42 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:60981 (size: 3.0 KB, free: 1070.9 MB)
16/03/16 16:17:42 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 16:17:42 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:17:42 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 16:17:42 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:17:42 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 16:17:42 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:17:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 16:17:42 INFO PythonRunner: Times: total = 199, boot = 199, init = 0, finish = 0
16/03/16 16:17:42 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 16:17:42 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:17:42 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 16:17:42 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:17:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 16:17:42 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 229 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'bend']
16/03/16 16:17:42 INFO PythonRunner: Times: total = 324, boot = 323, init = 1, finish = 0
16/03/16 16:17:42 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1230 bytes result sent to driver
16/03/16 16:17:42 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.559 s
16/03/16 16:17:42 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 10.852262 s
16/03/16 16:17:42 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 352 ms on localhost (2/2)
16/03/16 16:17:42 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 16:17:43 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:17:43 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:17:43 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:17:43 INFO DAGScheduler: Parents of final stage: List()
16/03/16 16:17:43 INFO DAGScheduler: Missing parents: List()
16/03/16 16:17:43 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:17:43 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18741, maxMem=1122977710
16/03/16 16:17:43 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1070.9 MB)
16/03/16 16:17:43 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24557, maxMem=1122977710
16/03/16 16:17:43 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1070.9 MB)
16/03/16 16:17:43 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:60981 (size: 3.3 KB, free: 1070.9 MB)
16/03/16 16:17:43 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 16:17:43 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:17:43 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 16:17:43 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 16:17:43 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 16:17:43 INFO PythonRunner: Times: total = 137, boot = 137, init = 0, finish = 0
16/03/16 16:17:43 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 16:17:43 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2260 bytes)
16/03/16 16:17:43 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 152 ms on localhost (1/2)
16/03/16 16:17:43 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 16:17:43 INFO PythonRunner: Times: total = 259, boot = 259, init = 0, finish = 0
16/03/16 16:17:43 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1296 bytes result sent to driver
16/03/16 16:17:43 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 280 ms on localhost (2/2)
16/03/16 16:17:43 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 16:17:43 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.413 s
16/03/16 16:17:43 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.449093 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 16:17:43 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 16:17:43 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 16:17:43 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 16:17:43 INFO MemoryStore: MemoryStore cleared
16/03/16 16:17:43 INFO BlockManager: BlockManager stopped
16/03/16 16:17:43 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 16:17:43 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 16:17:43 INFO SparkContext: Successfully stopped SparkContext
16/03/16 16:17:43 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 16:17:43 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 16:17:43 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'bend']
16/03/16 16:17:44 INFO SparkContext: Running Spark version 1.5.2
16/03/16 16:17:44 INFO SecurityManager: Changing view acls to: root
16/03/16 16:17:44 INFO SecurityManager: Changing modify acls to: root
16/03/16 16:17:44 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 16:17:44 INFO Slf4jLogger: Slf4jLogger started
16/03/16 16:17:44 INFO Remoting: Starting remoting
16/03/16 16:17:44 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:58032]
16/03/16 16:17:44 INFO Utils: Successfully started service 'sparkDriver' on port 58032.
16/03/16 16:17:44 INFO SparkEnv: Registering MapOutputTracker
16/03/16 16:17:44 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 16:17:44 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-6dc8064d-e7d6-414d-a887-ec0f68c8053d
16/03/16 16:17:44 INFO MemoryStore: MemoryStore started with capacity 1071.0 MB
16/03/16 16:17:44 INFO HttpFileServer: HTTP File server directory is /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/httpd-0dfdc2eb-6b37-4f27-b30c-9c090e38d4c8
16/03/16 16:17:44 INFO HttpServer: Starting HTTP Server
16/03/16 16:17:44 INFO Utils: Successfully started service 'HTTP file server' on port 57970.
16/03/16 16:17:45 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 16:17:45 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 16:17:45 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 16:17:45 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-78db499f-6ba8-4ab8-9c84-a04bfa2e43b6/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 16:17:45 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125265133
16/03/16 16:17:45 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 16:17:45 INFO Executor: Starting executor ID driver on host localhost
16/03/16 16:17:45 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34115.
16/03/16 16:17:45 INFO NettyBlockTransferService: Server created on 34115
16/03/16 16:17:45 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 16:17:45 INFO BlockManagerMasterEndpoint: Registering block manager localhost:34115 with 1071.0 MB RAM, BlockManagerId(driver, localhost, 34115)
16/03/16 16:17:45 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): together
16/03/16 16:17:45 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:17:45 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:17:45 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:17:45 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:17:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 16:17:45 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 16:17:45 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:17:45 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1122977710
16/03/16 16:17:45 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1070.9 MB)
16/03/16 16:17:45 INFO MemoryStore: ensureFreeSpace(4141) called with curMem=6568, maxMem=1122977710
16/03/16 16:17:45 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1070.9 MB)
16/03/16 16:17:45 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:34115 (size: 4.0 KB, free: 1071.0 MB)
16/03/16 16:17:45 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 16:17:45 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:17:45 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 16:17:45 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 16:17:45 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 16:17:45 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125265133
16/03/16 16:17:45 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-78db499f-6ba8-4ab8-9c84-a04bfa2e43b6/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: area
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: issue
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: planning
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: permission
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: economy
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: composition
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: agency
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 16:17:55 INFO PythonRunner: Times: total = 9780, boot = 711, init = 431, finish = 8638
16/03/16 16:17:55 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 16:17:55 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 16:17:55 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 16:17:55 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9923 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: set
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): adding to parents: syn =  Synset('set.n.01') ; keyword:  together  in syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: bend
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: giant
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: astatine
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: present
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: area
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
16/03/16 16:17:55 INFO PythonRunner: Times: total = 348, boot = 222, init = 1, finish = 125
16/03/16 16:17:55 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 16:17:55 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 418 ms on localhost (2/2)
16/03/16 16:17:55 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 16:17:55 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 10.292 s
16/03/16 16:17:55 INFO DAGScheduler: looking for newly runnable stages
16/03/16 16:17:55 INFO DAGScheduler: running: Set()
16/03/16 16:17:55 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 16:17:55 INFO DAGScheduler: failed: Set()
16/03/16 16:17:55 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 16:17:55 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 16:17:55 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10709, maxMem=1122977710
16/03/16 16:17:55 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1070.9 MB)
16/03/16 16:17:55 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15693, maxMem=1122977710
16/03/16 16:17:55 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1070.9 MB)
16/03/16 16:17:55 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:34115 (size: 3.0 KB, free: 1070.9 MB)
16/03/16 16:17:55 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 16:17:55 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:17:55 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 16:17:55 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:17:55 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 16:17:55 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:17:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 16:17:55 INFO PythonRunner: Times: total = 158, boot = 158, init = 0, finish = 0
16/03/16 16:17:55 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 16:17:55 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:17:55 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 16:17:55 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:17:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 14 ms
16/03/16 16:17:55 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 216 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'set']
16/03/16 16:17:56 INFO PythonRunner: Times: total = 289, boot = 288, init = 0, finish = 1
16/03/16 16:17:56 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1229 bytes result sent to driver
16/03/16 16:17:56 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.511 s
16/03/16 16:17:56 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 10.857531 s
16/03/16 16:17:56 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 329 ms on localhost (2/2)
16/03/16 16:17:56 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 16:17:56 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:17:56 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:17:56 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:17:56 INFO DAGScheduler: Parents of final stage: List()
16/03/16 16:17:56 INFO DAGScheduler: Missing parents: List()
16/03/16 16:17:56 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:17:56 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18741, maxMem=1122977710
16/03/16 16:17:56 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1070.9 MB)
16/03/16 16:17:56 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24557, maxMem=1122977710
16/03/16 16:17:56 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1070.9 MB)
16/03/16 16:17:56 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:34115 (size: 3.3 KB, free: 1070.9 MB)
16/03/16 16:17:56 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 16:17:56 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:17:56 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 16:17:56 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 16:17:56 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 16:17:56 INFO PythonRunner: Times: total = 142, boot = 142, init = 0, finish = 0
16/03/16 16:17:56 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 16:17:56 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2259 bytes)
16/03/16 16:17:56 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 166 ms on localhost (1/2)
16/03/16 16:17:56 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 16:17:56 INFO PythonRunner: Times: total = 237, boot = 236, init = 1, finish = 0
16/03/16 16:17:56 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1295 bytes result sent to driver
16/03/16 16:17:56 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 267 ms on localhost (2/2)
16/03/16 16:17:56 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 16:17:56 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.413 s
16/03/16 16:17:56 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.436659 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 16:17:56 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 16:17:56 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 16:17:56 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 16:17:56 INFO MemoryStore: MemoryStore cleared
16/03/16 16:17:56 INFO BlockManager: BlockManager stopped
16/03/16 16:17:56 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 16:17:56 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 16:17:56 INFO SparkContext: Successfully stopped SparkContext
16/03/16 16:17:56 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 16:17:56 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 16:17:56 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'set']
16/03/16 16:17:57 INFO SparkContext: Running Spark version 1.5.2
16/03/16 16:17:57 INFO SecurityManager: Changing view acls to: root
16/03/16 16:17:57 INFO SecurityManager: Changing modify acls to: root
16/03/16 16:17:57 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 16:17:57 INFO Slf4jLogger: Slf4jLogger started
16/03/16 16:17:57 INFO Remoting: Starting remoting
16/03/16 16:17:57 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:33200]
16/03/16 16:17:57 INFO Utils: Successfully started service 'sparkDriver' on port 33200.
16/03/16 16:17:57 INFO SparkEnv: Registering MapOutputTracker
16/03/16 16:17:57 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 16:17:57 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-8cd85c4f-5b4c-47d3-b605-70da7e76b75b
16/03/16 16:17:57 INFO MemoryStore: MemoryStore started with capacity 1071.0 MB
16/03/16 16:17:58 INFO HttpFileServer: HTTP File server directory is /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/httpd-f391a33a-d36e-4072-9fc4-127a5aaa5c8d
16/03/16 16:17:58 INFO HttpServer: Starting HTTP Server
16/03/16 16:17:58 INFO Utils: Successfully started service 'HTTP file server' on port 36103.
16/03/16 16:17:58 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 16:17:58 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 16:17:58 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 16:17:58 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-7bb8c92c-900f-449b-aa67-9426c32ff79c/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 16:17:58 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125278199
16/03/16 16:17:58 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 16:17:58 INFO Executor: Starting executor ID driver on host localhost
16/03/16 16:17:58 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37408.
16/03/16 16:17:58 INFO NettyBlockTransferService: Server created on 37408
16/03/16 16:17:58 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 16:17:58 INFO BlockManagerMasterEndpoint: Registering block manager localhost:37408 with 1071.0 MB RAM, BlockManagerId(driver, localhost, 37408)
16/03/16 16:17:58 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): element
16/03/16 16:17:58 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:17:58 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:17:58 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:17:58 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:17:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 16:17:58 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 16:17:58 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:17:58 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1122977710
16/03/16 16:17:58 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1070.9 MB)
16/03/16 16:17:58 INFO MemoryStore: ensureFreeSpace(4141) called with curMem=6568, maxMem=1122977710
16/03/16 16:17:58 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1070.9 MB)
16/03/16 16:17:58 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:37408 (size: 4.0 KB, free: 1071.0 MB)
16/03/16 16:17:58 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 16:17:58 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:17:58 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 16:17:58 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 16:17:58 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 16:17:58 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125278199
16/03/16 16:17:58 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-7bb8c92c-900f-449b-aa67-9426c32ff79c/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: area
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: issue
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: planning
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: permission
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: economy
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: composition
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: agency
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 16:18:07 INFO PythonRunner: Times: total = 9058, boot = 527, init = 429, finish = 8102
16/03/16 16:18:07 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 16:18:07 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 16:18:07 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 16:18:07 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9200 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: set
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: bend
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: giant
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: astatine
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('astatine.n.01') ; keyword:  element  in syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= [u'astatine']
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: present
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: area
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
16/03/16 16:18:07 INFO PythonRunner: Times: total = 337, boot = 203, init = 0, finish = 134
16/03/16 16:18:07 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 16:18:07 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 370 ms on localhost (2/2)
16/03/16 16:18:07 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 9.553 s
16/03/16 16:18:07 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 16:18:07 INFO DAGScheduler: looking for newly runnable stages
16/03/16 16:18:07 INFO DAGScheduler: running: Set()
16/03/16 16:18:07 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 16:18:07 INFO DAGScheduler: failed: Set()
16/03/16 16:18:07 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 16:18:07 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 16:18:07 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10709, maxMem=1122977710
16/03/16 16:18:07 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1070.9 MB)
16/03/16 16:18:07 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15693, maxMem=1122977710
16/03/16 16:18:07 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1070.9 MB)
16/03/16 16:18:07 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:37408 (size: 3.0 KB, free: 1070.9 MB)
16/03/16 16:18:07 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 16:18:07 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:18:07 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 16:18:07 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:18:07 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 16:18:07 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:18:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 16:18:08 INFO PythonRunner: Times: total = 197, boot = 196, init = 0, finish = 1
16/03/16 16:18:08 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 16:18:08 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:18:08 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 16:18:08 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:18:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
16/03/16 16:18:08 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 250 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'astatine']
16/03/16 16:18:08 INFO PythonRunner: Times: total = 219, boot = 218, init = 1, finish = 0
16/03/16 16:18:08 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1242 bytes result sent to driver
16/03/16 16:18:08 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 250 ms on localhost (2/2)
16/03/16 16:18:08 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 16:18:08 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.471 s
16/03/16 16:18:08 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 10.078070 s
16/03/16 16:18:08 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:18:08 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:18:08 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:18:08 INFO DAGScheduler: Parents of final stage: List()
16/03/16 16:18:08 INFO DAGScheduler: Missing parents: List()
16/03/16 16:18:08 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:18:08 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18741, maxMem=1122977710
16/03/16 16:18:08 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1070.9 MB)
16/03/16 16:18:08 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24557, maxMem=1122977710
16/03/16 16:18:08 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1070.9 MB)
16/03/16 16:18:08 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:37408 (size: 3.3 KB, free: 1070.9 MB)
16/03/16 16:18:08 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 16:18:08 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:18:08 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 16:18:08 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 16:18:08 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 16:18:08 INFO PythonRunner: Times: total = 34, boot = 29, init = 5, finish = 0
16/03/16 16:18:08 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 16:18:08 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2272 bytes)
16/03/16 16:18:08 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 68 ms on localhost (1/2)
16/03/16 16:18:08 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 16:18:09 INFO PythonRunner: Times: total = 281, boot = 281, init = 0, finish = 0
16/03/16 16:18:09 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1311 bytes result sent to driver
16/03/16 16:18:09 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 313 ms on localhost (2/2)
16/03/16 16:18:09 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 16:18:09 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.370 s
16/03/16 16:18:09 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.393680 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 16:18:09 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 16:18:09 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 16:18:09 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 16:18:09 INFO MemoryStore: MemoryStore cleared
16/03/16 16:18:09 INFO BlockManager: BlockManager stopped
16/03/16 16:18:09 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 16:18:09 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 16:18:09 INFO SparkContext: Successfully stopped SparkContext
16/03/16 16:18:09 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 16:18:09 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 16:18:09 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'astatine']
16/03/16 16:18:10 INFO SparkContext: Running Spark version 1.5.2
16/03/16 16:18:10 INFO SecurityManager: Changing view acls to: root
16/03/16 16:18:10 INFO SecurityManager: Changing modify acls to: root
16/03/16 16:18:10 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 16:18:10 INFO Slf4jLogger: Slf4jLogger started
16/03/16 16:18:10 INFO Remoting: Starting remoting
16/03/16 16:18:10 INFO Utils: Successfully started service 'sparkDriver' on port 34080.
16/03/16 16:18:10 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:34080]
16/03/16 16:18:10 INFO SparkEnv: Registering MapOutputTracker
16/03/16 16:18:10 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 16:18:10 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-8352a078-868b-4a99-b583-2e809642d768
16/03/16 16:18:10 INFO MemoryStore: MemoryStore started with capacity 1071.0 MB
16/03/16 16:18:10 INFO HttpFileServer: HTTP File server directory is /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/httpd-080aff86-faed-4d7e-b039-fa75ab669484
16/03/16 16:18:10 INFO HttpServer: Starting HTTP Server
16/03/16 16:18:10 INFO Utils: Successfully started service 'HTTP file server' on port 51136.
16/03/16 16:18:10 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 16:18:10 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 16:18:10 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 16:18:10 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-fc955a79-7d06-48e4-b6ec-d9683beaeb26/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 16:18:10 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125290610
16/03/16 16:18:10 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 16:18:10 INFO Executor: Starting executor ID driver on host localhost
16/03/16 16:18:10 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40210.
16/03/16 16:18:10 INFO NettyBlockTransferService: Server created on 40210
16/03/16 16:18:10 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 16:18:10 INFO BlockManagerMasterEndpoint: Registering block manager localhost:40210 with 1071.0 MB RAM, BlockManagerId(driver, localhost, 40210)
16/03/16 16:18:10 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): person
16/03/16 16:18:11 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:18:11 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:18:11 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:18:11 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:18:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 16:18:11 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 16:18:11 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:18:11 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1122977710
16/03/16 16:18:11 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1070.9 MB)
16/03/16 16:18:11 INFO MemoryStore: ensureFreeSpace(4141) called with curMem=6568, maxMem=1122977710
16/03/16 16:18:11 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1070.9 MB)
16/03/16 16:18:11 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:40210 (size: 4.0 KB, free: 1071.0 MB)
16/03/16 16:18:11 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 16:18:11 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:18:11 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 16:18:11 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 16:18:11 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 16:18:11 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125290610
16/03/16 16:18:11 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-fc955a79-7d06-48e4-b6ec-d9683beaeb26/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: area
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: issue
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: planning
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: permission
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: economy
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: composition
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: agency
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 16:18:21 INFO PythonRunner: Times: total = 10468, boot = 870, init = 766, finish = 8832
16/03/16 16:18:21 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 16:18:21 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 16:18:21 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 16:18:21 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 10672 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: set
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: bend
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: giant
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): adding to parents: syn =  Synset('colossus.n.02') ; keyword:  person  in syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= [u'giant']
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: astatine
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: present
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: area
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
16/03/16 16:18:22 INFO PythonRunner: Times: total = 372, boot = 223, init = 0, finish = 149
16/03/16 16:18:22 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 16:18:22 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 431 ms on localhost (2/2)
16/03/16 16:18:22 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 16:18:22 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 11.085 s
16/03/16 16:18:22 INFO DAGScheduler: looking for newly runnable stages
16/03/16 16:18:22 INFO DAGScheduler: running: Set()
16/03/16 16:18:22 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 16:18:22 INFO DAGScheduler: failed: Set()
16/03/16 16:18:22 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 16:18:22 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 16:18:22 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10709, maxMem=1122977710
16/03/16 16:18:22 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1070.9 MB)
16/03/16 16:18:22 INFO MemoryStore: ensureFreeSpace(3047) called with curMem=15693, maxMem=1122977710
16/03/16 16:18:22 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1070.9 MB)
16/03/16 16:18:22 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:40210 (size: 3.0 KB, free: 1070.9 MB)
16/03/16 16:18:22 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 16:18:22 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:18:22 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 16:18:22 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:18:22 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 16:18:22 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:18:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/16 16:18:22 INFO PythonRunner: Times: total = 180, boot = 180, init = 0, finish = 0
16/03/16 16:18:22 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 16:18:22 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:18:22 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 16:18:22 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:18:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 16:18:22 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 228 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'giant']
16/03/16 16:18:22 INFO PythonRunner: Times: total = 198, boot = 197, init = 0, finish = 1
16/03/16 16:18:22 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1239 bytes result sent to driver
16/03/16 16:18:22 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.447 s
16/03/16 16:18:22 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 11.573003 s
16/03/16 16:18:22 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 219 ms on localhost (2/2)
16/03/16 16:18:22 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 16:18:22 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:18:22 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:18:22 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:18:22 INFO DAGScheduler: Parents of final stage: List()
16/03/16 16:18:22 INFO DAGScheduler: Missing parents: List()
16/03/16 16:18:22 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:18:22 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18740, maxMem=1122977710
16/03/16 16:18:22 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1070.9 MB)
16/03/16 16:18:22 INFO MemoryStore: ensureFreeSpace(3374) called with curMem=24556, maxMem=1122977710
16/03/16 16:18:22 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1070.9 MB)
16/03/16 16:18:22 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:40210 (size: 3.3 KB, free: 1070.9 MB)
16/03/16 16:18:22 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 16:18:22 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:18:22 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 16:18:22 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 16:18:22 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 16:18:22 INFO PythonRunner: Times: total = 121, boot = 121, init = 0, finish = 0
16/03/16 16:18:22 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 16:18:22 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2269 bytes)
16/03/16 16:18:22 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 136 ms on localhost (1/2)
16/03/16 16:18:22 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 16:18:23 INFO PythonRunner: Times: total = 211, boot = 210, init = 1, finish = 0
16/03/16 16:18:23 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1308 bytes result sent to driver
16/03/16 16:18:23 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 228 ms on localhost (2/2)
16/03/16 16:18:23 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 16:18:23 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.362 s
16/03/16 16:18:23 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.387814 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 16:18:23 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 16:18:23 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 16:18:23 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 16:18:23 INFO MemoryStore: MemoryStore cleared
16/03/16 16:18:23 INFO BlockManager: BlockManager stopped
16/03/16 16:18:23 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 16:18:23 INFO SparkContext: Successfully stopped SparkContext
16/03/16 16:18:23 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 16:18:23 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 16:18:23 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 16:18:23 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'giant']
16/03/16 16:18:24 INFO SparkContext: Running Spark version 1.5.2
16/03/16 16:18:24 INFO SecurityManager: Changing view acls to: root
16/03/16 16:18:24 INFO SecurityManager: Changing modify acls to: root
16/03/16 16:18:24 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 16:18:24 INFO Slf4jLogger: Slf4jLogger started
16/03/16 16:18:24 INFO Remoting: Starting remoting
16/03/16 16:18:24 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:46117]
16/03/16 16:18:24 INFO Utils: Successfully started service 'sparkDriver' on port 46117.
16/03/16 16:18:24 INFO SparkEnv: Registering MapOutputTracker
16/03/16 16:18:24 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 16:18:24 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-89671c25-ce28-4727-a04d-fa1b73f53e6a
16/03/16 16:18:24 INFO MemoryStore: MemoryStore started with capacity 1072.6 MB
16/03/16 16:18:25 INFO HttpFileServer: HTTP File server directory is /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/httpd-c547a7e4-41b4-4ac1-a432-481a3d81ad23
16/03/16 16:18:25 INFO HttpServer: Starting HTTP Server
16/03/16 16:18:25 INFO Utils: Successfully started service 'HTTP file server' on port 45382.
16/03/16 16:18:25 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 16:18:25 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 16:18:25 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 16:18:25 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-981ba880-1ce3-4b5d-90b8-40768c5277fa/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 16:18:25 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125305315
16/03/16 16:18:25 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 16:18:25 INFO Executor: Starting executor ID driver on host localhost
16/03/16 16:18:25 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52582.
16/03/16 16:18:25 INFO NettyBlockTransferService: Server created on 52582
16/03/16 16:18:25 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 16:18:25 INFO BlockManagerMasterEndpoint: Registering block manager localhost:52582 with 1072.6 MB RAM, BlockManagerId(driver, localhost, 52582)
16/03/16 16:18:25 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): reputation
16/03/16 16:18:25 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:18:25 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:18:25 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:18:25 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:18:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 16:18:25 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 16:18:25 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:18:25 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1124676403
16/03/16 16:18:25 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1072.6 MB)
16/03/16 16:18:25 INFO MemoryStore: ensureFreeSpace(4141) called with curMem=6568, maxMem=1124676403
16/03/16 16:18:25 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1072.6 MB)
16/03/16 16:18:25 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:52582 (size: 4.0 KB, free: 1072.6 MB)
16/03/16 16:18:25 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 16:18:25 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:18:25 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 16:18:25 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 16:18:25 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 16:18:25 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125305315
16/03/16 16:18:25 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-981ba880-1ce3-4b5d-90b8-40768c5277fa/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: area
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: issue
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: planning
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: permission
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: economy
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: composition
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: agency
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 16:18:35 INFO PythonRunner: Times: total = 9447, boot = 902, init = 543, finish = 8002
16/03/16 16:18:35 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 16:18:35 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 16:18:35 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 16:18:35 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9633 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: set
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: bend
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: giant
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): adding to parents: syn =  Synset('colossus.n.02') ; keyword:  reputation  in syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= [u'giant']
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: astatine
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: present
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: area
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
16/03/16 16:18:35 INFO PythonRunner: Times: total = 255, boot = 151, init = 0, finish = 104
16/03/16 16:18:35 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 16:18:35 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 289 ms on localhost (2/2)
16/03/16 16:18:35 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 16:18:35 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 9.900 s
16/03/16 16:18:35 INFO DAGScheduler: looking for newly runnable stages
16/03/16 16:18:35 INFO DAGScheduler: running: Set()
16/03/16 16:18:35 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 16:18:35 INFO DAGScheduler: failed: Set()
16/03/16 16:18:35 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 16:18:35 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 16:18:35 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10709, maxMem=1124676403
16/03/16 16:18:35 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1072.6 MB)
16/03/16 16:18:35 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15693, maxMem=1124676403
16/03/16 16:18:35 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1072.6 MB)
16/03/16 16:18:35 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:52582 (size: 3.0 KB, free: 1072.6 MB)
16/03/16 16:18:35 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 16:18:35 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:18:35 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 16:18:35 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:18:35 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 16:18:35 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:18:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 16:18:35 INFO PythonRunner: Times: total = 131, boot = 131, init = 0, finish = 0
16/03/16 16:18:35 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 16:18:35 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:18:35 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 16:18:35 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 153 ms on localhost (1/2)
16/03/16 16:18:35 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:18:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
reduceFunction_Parents(): returns= ['None', 'None', u'giant']
16/03/16 16:18:35 INFO PythonRunner: Times: total = 175, boot = 174, init = 1, finish = 0
16/03/16 16:18:35 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1239 bytes result sent to driver
16/03/16 16:18:35 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 204 ms on localhost (2/2)
16/03/16 16:18:35 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.356 s
16/03/16 16:18:35 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 16:18:35 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 10.323799 s
16/03/16 16:18:36 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:18:36 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:18:36 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:18:36 INFO DAGScheduler: Parents of final stage: List()
16/03/16 16:18:36 INFO DAGScheduler: Missing parents: List()
16/03/16 16:18:36 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:18:36 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18741, maxMem=1124676403
16/03/16 16:18:36 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1072.6 MB)
16/03/16 16:18:36 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24557, maxMem=1124676403
16/03/16 16:18:36 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1072.5 MB)
16/03/16 16:18:36 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:52582 (size: 3.3 KB, free: 1072.6 MB)
16/03/16 16:18:36 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 16:18:36 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:18:36 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 16:18:36 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 16:18:36 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 16:18:36 INFO PythonRunner: Times: total = 47, boot = 47, init = 0, finish = 0
16/03/16 16:18:36 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 16:18:36 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2269 bytes)
16/03/16 16:18:36 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 63 ms on localhost (1/2)
16/03/16 16:18:36 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 16:18:36 INFO PythonRunner: Times: total = 146, boot = 146, init = 0, finish = 0
16/03/16 16:18:36 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1308 bytes result sent to driver
16/03/16 16:18:36 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 183 ms on localhost (2/2)
16/03/16 16:18:36 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 16:18:36 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.227 s
16/03/16 16:18:36 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.263200 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 16:18:36 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 16:18:36 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 16:18:36 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 16:18:36 INFO MemoryStore: MemoryStore cleared
16/03/16 16:18:36 INFO BlockManager: BlockManager stopped
16/03/16 16:18:36 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 16:18:36 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 16:18:36 INFO SparkContext: Successfully stopped SparkContext
16/03/16 16:18:36 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'giant']
16/03/16 16:18:37 INFO SparkContext: Running Spark version 1.5.2
16/03/16 16:18:37 INFO SecurityManager: Changing view acls to: root
16/03/16 16:18:37 INFO SecurityManager: Changing modify acls to: root
16/03/16 16:18:37 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 16:18:37 INFO Slf4jLogger: Slf4jLogger started
16/03/16 16:18:37 INFO Remoting: Starting remoting
16/03/16 16:18:37 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:57987]
16/03/16 16:18:37 INFO Utils: Successfully started service 'sparkDriver' on port 57987.
16/03/16 16:18:37 INFO SparkEnv: Registering MapOutputTracker
16/03/16 16:18:37 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 16:18:37 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-a47e4b3c-492f-4cf5-865b-47b1b56831c1
16/03/16 16:18:37 INFO MemoryStore: MemoryStore started with capacity 1072.6 MB
16/03/16 16:18:37 INFO HttpFileServer: HTTP File server directory is /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/httpd-d59e088d-6825-4a24-977e-78d83a6831cb
16/03/16 16:18:37 INFO HttpServer: Starting HTTP Server
16/03/16 16:18:37 INFO Utils: Successfully started service 'HTTP file server' on port 47833.
16/03/16 16:18:37 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 16:18:37 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 16:18:37 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 16:18:37 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-2891844f-80e9-4d55-82c8-0e94acf5e087/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 16:18:37 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125317729
16/03/16 16:18:37 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 16:18:37 INFO Executor: Starting executor ID driver on host localhost
16/03/16 16:18:37 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53777.
16/03/16 16:18:37 INFO NettyBlockTransferService: Server created on 53777
16/03/16 16:18:37 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 16:18:37 INFO BlockManagerMasterEndpoint: Registering block manager localhost:53777 with 1072.6 MB RAM, BlockManagerId(driver, localhost, 53777)
16/03/16 16:18:37 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): time
16/03/16 16:18:37 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:18:37 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:18:37 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:18:37 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:18:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 16:18:37 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 16:18:37 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:18:37 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1124676403
16/03/16 16:18:37 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1072.6 MB)
16/03/16 16:18:37 INFO MemoryStore: ensureFreeSpace(4141) called with curMem=6568, maxMem=1124676403
16/03/16 16:18:37 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1072.6 MB)
16/03/16 16:18:37 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:53777 (size: 4.0 KB, free: 1072.6 MB)
16/03/16 16:18:37 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 16:18:37 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:18:37 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 16:18:37 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 16:18:37 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 16:18:37 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125317729
16/03/16 16:18:37 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-2891844f-80e9-4d55-82c8-0e94acf5e087/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: area
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: issue
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: planning
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: permission
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: economy
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: composition
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: agency
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 16:18:45 INFO PythonRunner: Times: total = 7766, boot = 471, init = 355, finish = 6940
16/03/16 16:18:45 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 16:18:45 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 16:18:45 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 16:18:45 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7877 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: set
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: bend
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: giant
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: astatine
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: present
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('present.n.01') ; keyword:  time  in syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= [u'present']
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: area
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
16/03/16 16:18:46 INFO PythonRunner: Times: total = 263, boot = 154, init = 0, finish = 109
16/03/16 16:18:46 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 16:18:46 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.207 s
16/03/16 16:18:46 INFO DAGScheduler: looking for newly runnable stages
16/03/16 16:18:46 INFO DAGScheduler: running: Set()
16/03/16 16:18:46 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 16:18:46 INFO DAGScheduler: failed: Set()
16/03/16 16:18:46 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 16:18:46 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 16:18:46 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10709, maxMem=1124676403
16/03/16 16:18:46 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1072.6 MB)
16/03/16 16:18:46 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 329 ms on localhost (2/2)
16/03/16 16:18:46 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 16:18:46 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15693, maxMem=1124676403
16/03/16 16:18:46 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1072.6 MB)
16/03/16 16:18:46 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:53777 (size: 3.0 KB, free: 1072.6 MB)
16/03/16 16:18:46 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 16:18:46 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:18:46 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 16:18:46 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:18:46 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 16:18:46 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:18:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 16:18:46 INFO PythonRunner: Times: total = 158, boot = 158, init = 0, finish = 0
16/03/16 16:18:46 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 16:18:46 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:18:46 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 16:18:46 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:18:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 16:18:46 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 189 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'present']
16/03/16 16:18:46 INFO PythonRunner: Times: total = 219, boot = 218, init = 1, finish = 0
16/03/16 16:18:46 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1241 bytes result sent to driver
16/03/16 16:18:46 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 243 ms on localhost (2/2)
16/03/16 16:18:46 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.419 s
16/03/16 16:18:46 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.663511 s
16/03/16 16:18:46 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 16:18:46 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:18:46 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:18:46 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:18:46 INFO DAGScheduler: Parents of final stage: List()
16/03/16 16:18:46 INFO DAGScheduler: Missing parents: List()
16/03/16 16:18:46 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:18:46 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18741, maxMem=1124676403
16/03/16 16:18:46 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1072.6 MB)
16/03/16 16:18:46 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24557, maxMem=1124676403
16/03/16 16:18:46 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1072.5 MB)
16/03/16 16:18:46 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:53777 (size: 3.3 KB, free: 1072.6 MB)
16/03/16 16:18:46 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 16:18:46 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:18:46 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 16:18:46 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 16:18:46 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 16:18:46 INFO PythonRunner: Times: total = 162, boot = 162, init = 0, finish = 0
16/03/16 16:18:46 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 16:18:46 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2271 bytes)
16/03/16 16:18:46 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 181 ms on localhost (1/2)
16/03/16 16:18:46 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 16:18:47 INFO PythonRunner: Times: total = 206, boot = 206, init = 0, finish = 0
16/03/16 16:18:47 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1310 bytes result sent to driver
16/03/16 16:18:47 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 230 ms on localhost (2/2)
16/03/16 16:18:47 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 16:18:47 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.410 s
16/03/16 16:18:47 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.422166 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 16:18:47 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 16:18:47 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 16:18:47 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 16:18:47 INFO MemoryStore: MemoryStore cleared
16/03/16 16:18:47 INFO BlockManager: BlockManager stopped
16/03/16 16:18:47 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 16:18:47 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 16:18:47 INFO SparkContext: Successfully stopped SparkContext
16/03/16 16:18:47 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 16:18:47 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 16:18:47 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'present']
16/03/16 16:18:48 INFO SparkContext: Running Spark version 1.5.2
16/03/16 16:18:48 INFO SecurityManager: Changing view acls to: root
16/03/16 16:18:48 INFO SecurityManager: Changing modify acls to: root
16/03/16 16:18:48 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 16:18:48 INFO Slf4jLogger: Slf4jLogger started
16/03/16 16:18:48 INFO Remoting: Starting remoting
16/03/16 16:18:48 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:46784]
16/03/16 16:18:48 INFO Utils: Successfully started service 'sparkDriver' on port 46784.
16/03/16 16:18:48 INFO SparkEnv: Registering MapOutputTracker
16/03/16 16:18:48 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 16:18:48 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-d690a948-98c0-4a7b-8f98-77d29af67280
16/03/16 16:18:48 INFO MemoryStore: MemoryStore started with capacity 1072.6 MB
16/03/16 16:18:48 INFO HttpFileServer: HTTP File server directory is /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/httpd-62944f5e-1a86-40ba-9905-a52467936ea9
16/03/16 16:18:48 INFO HttpServer: Starting HTTP Server
16/03/16 16:18:48 INFO Utils: Successfully started service 'HTTP file server' on port 38101.
16/03/16 16:18:48 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 16:18:48 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 16:18:48 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 16:18:48 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-3badf1dc-241a-49ce-8ae5-bd2cd33b698e/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 16:18:48 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125328457
16/03/16 16:18:48 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 16:18:48 INFO Executor: Starting executor ID driver on host localhost
16/03/16 16:18:48 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58485.
16/03/16 16:18:48 INFO NettyBlockTransferService: Server created on 58485
16/03/16 16:18:48 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 16:18:48 INFO BlockManagerMasterEndpoint: Registering block manager localhost:58485 with 1072.6 MB RAM, BlockManagerId(driver, localhost, 58485)
16/03/16 16:18:48 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): position
16/03/16 16:18:48 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:18:48 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:18:48 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:18:48 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:18:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 16:18:48 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 16:18:48 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:18:48 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1124676403
16/03/16 16:18:48 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1072.6 MB)
16/03/16 16:18:48 INFO MemoryStore: ensureFreeSpace(4141) called with curMem=6568, maxMem=1124676403
16/03/16 16:18:48 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1072.6 MB)
16/03/16 16:18:48 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:58485 (size: 4.0 KB, free: 1072.6 MB)
16/03/16 16:18:48 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 16:18:48 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:18:48 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 16:18:48 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 16:18:48 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 16:18:48 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125328457
16/03/16 16:18:48 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-3badf1dc-241a-49ce-8ae5-bd2cd33b698e/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: area
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: issue
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: planning
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: permission
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: economy
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: composition
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: agency
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 16:18:59 INFO PythonRunner: Times: total = 11176, boot = 474, init = 361, finish = 10341
16/03/16 16:18:59 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 16:18:59 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 16:18:59 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 16:18:59 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 11310 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: set
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: bend
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: giant
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: astatine
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: present
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): adding to parents: syn =  Synset('metropolitan.n.01') ; keyword:  position  in syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= [u'metropolitan']
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: area
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
16/03/16 16:19:00 INFO PythonRunner: Times: total = 674, boot = 421, init = 0, finish = 253
16/03/16 16:19:00 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 16:19:00 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 726 ms on localhost (2/2)
16/03/16 16:19:00 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 12.018 s
16/03/16 16:19:00 INFO DAGScheduler: looking for newly runnable stages
16/03/16 16:19:00 INFO DAGScheduler: running: Set()
16/03/16 16:19:00 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 16:19:00 INFO DAGScheduler: failed: Set()
16/03/16 16:19:00 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 16:19:00 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 16:19:00 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 16:19:00 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10709, maxMem=1124676403
16/03/16 16:19:00 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1072.6 MB)
16/03/16 16:19:00 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15693, maxMem=1124676403
16/03/16 16:19:00 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1072.6 MB)
16/03/16 16:19:00 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:58485 (size: 3.0 KB, free: 1072.6 MB)
16/03/16 16:19:00 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 16:19:00 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:19:00 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 16:19:00 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:19:00 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 16:19:00 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:19:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 16:19:01 INFO PythonRunner: Times: total = 352, boot = 351, init = 0, finish = 1
16/03/16 16:19:01 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 16:19:01 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:19:01 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 16:19:01 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:19:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
16/03/16 16:19:01 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 400 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'metropolitan']
16/03/16 16:19:01 INFO PythonRunner: Times: total = 408, boot = 405, init = 0, finish = 3
16/03/16 16:19:01 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1246 bytes result sent to driver
16/03/16 16:19:01 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 443 ms on localhost (2/2)
16/03/16 16:19:01 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 16:19:01 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.840 s
16/03/16 16:19:01 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 12.911377 s
16/03/16 16:19:01 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:19:01 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:19:01 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:19:01 INFO DAGScheduler: Parents of final stage: List()
16/03/16 16:19:01 INFO DAGScheduler: Missing parents: List()
16/03/16 16:19:01 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:19:01 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18741, maxMem=1124676403
16/03/16 16:19:01 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1072.6 MB)
16/03/16 16:19:01 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24557, maxMem=1124676403
16/03/16 16:19:01 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1072.5 MB)
16/03/16 16:19:01 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:58485 (size: 3.3 KB, free: 1072.6 MB)
16/03/16 16:19:01 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 16:19:01 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:19:01 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 16:19:01 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 16:19:01 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 16:19:01 INFO PythonRunner: Times: total = 193, boot = 192, init = 1, finish = 0
16/03/16 16:19:01 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 16:19:01 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2276 bytes)
16/03/16 16:19:01 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 228 ms on localhost (1/2)
16/03/16 16:19:01 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 16:19:02 INFO PythonRunner: Times: total = 318, boot = 318, init = 0, finish = 0
16/03/16 16:19:02 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1315 bytes result sent to driver
16/03/16 16:19:02 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 345 ms on localhost (2/2)
16/03/16 16:19:02 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 16:19:02 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.553 s
16/03/16 16:19:02 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.601368 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 16:19:02 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 16:19:02 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 16:19:02 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 16:19:02 INFO MemoryStore: MemoryStore cleared
16/03/16 16:19:02 INFO BlockManager: BlockManager stopped
16/03/16 16:19:02 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 16:19:02 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 16:19:02 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 16:19:02 INFO SparkContext: Successfully stopped SparkContext
16/03/16 16:19:02 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'metropolitan']
16/03/16 16:19:03 INFO SparkContext: Running Spark version 1.5.2
16/03/16 16:19:03 INFO SecurityManager: Changing view acls to: root
16/03/16 16:19:03 INFO SecurityManager: Changing modify acls to: root
16/03/16 16:19:03 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 16:19:03 INFO Slf4jLogger: Slf4jLogger started
16/03/16 16:19:03 INFO Remoting: Starting remoting
16/03/16 16:19:03 INFO Utils: Successfully started service 'sparkDriver' on port 42491.
16/03/16 16:19:03 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:42491]
16/03/16 16:19:03 INFO SparkEnv: Registering MapOutputTracker
16/03/16 16:19:03 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 16:19:03 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-f6d9e9f4-d751-4995-b4f8-ce8900dca24b
16/03/16 16:19:03 INFO MemoryStore: MemoryStore started with capacity 1072.6 MB
16/03/16 16:19:03 INFO HttpFileServer: HTTP File server directory is /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/httpd-27c342d2-7d56-4bc0-92bb-8493776f62c6
16/03/16 16:19:03 INFO HttpServer: Starting HTTP Server
16/03/16 16:19:03 INFO Utils: Successfully started service 'HTTP file server' on port 43505.
16/03/16 16:19:03 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 16:19:03 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 16:19:03 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 16:19:03 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-ca667e47-ee18-4fcd-ba79-fbe065a78967/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 16:19:03 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125343834
16/03/16 16:19:03 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 16:19:03 INFO Executor: Starting executor ID driver on host localhost
16/03/16 16:19:04 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58759.
16/03/16 16:19:04 INFO NettyBlockTransferService: Server created on 58759
16/03/16 16:19:04 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 16:19:04 INFO BlockManagerMasterEndpoint: Registering block manager localhost:58759 with 1072.6 MB RAM, BlockManagerId(driver, localhost, 58759)
16/03/16 16:19:04 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): quantity
16/03/16 16:19:04 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:19:04 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:19:04 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:19:04 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:19:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 16:19:04 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 16:19:04 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:19:04 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1124676403
16/03/16 16:19:04 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1072.6 MB)
16/03/16 16:19:04 INFO MemoryStore: ensureFreeSpace(4141) called with curMem=6568, maxMem=1124676403
16/03/16 16:19:04 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1072.6 MB)
16/03/16 16:19:04 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:58759 (size: 4.0 KB, free: 1072.6 MB)
16/03/16 16:19:04 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 16:19:04 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:19:04 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 16:19:04 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 16:19:04 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 16:19:04 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125343834
16/03/16 16:19:04 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-ca667e47-ee18-4fcd-ba79-fbe065a78967/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: area
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: issue
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: planning
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: permission
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: economy
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: composition
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: agency
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 16:19:13 INFO PythonRunner: Times: total = 9386, boot = 563, init = 370, finish = 8453
16/03/16 16:19:13 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 16:19:13 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 16:19:13 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 16:19:13 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9505 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: set
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: bend
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: giant
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: astatine
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: present
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: area
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 16:19:13 INFO PythonRunner: Times: total = 263, boot = 162, init = 1, finish = 100
16/03/16 16:19:13 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 16:19:13 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 9.767 s
16/03/16 16:19:13 INFO DAGScheduler: looking for newly runnable stages
16/03/16 16:19:13 INFO DAGScheduler: running: Set()
16/03/16 16:19:13 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 16:19:13 INFO DAGScheduler: failed: Set()
16/03/16 16:19:13 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 16:19:13 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 16:19:13 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10709, maxMem=1124676403
16/03/16 16:19:13 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1072.6 MB)
16/03/16 16:19:13 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15693, maxMem=1124676403
16/03/16 16:19:13 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1072.6 MB)
16/03/16 16:19:13 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 287 ms on localhost (2/2)
16/03/16 16:19:13 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 16:19:13 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:58759 (size: 3.0 KB, free: 1072.6 MB)
16/03/16 16:19:13 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 16:19:13 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:19:13 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 16:19:13 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:19:13 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 16:19:13 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:19:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/16 16:19:14 INFO PythonRunner: Times: total = 169, boot = 168, init = 0, finish = 1
16/03/16 16:19:14 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 16:19:14 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:19:14 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 16:19:14 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:19:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 16:19:14 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 203 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None']
16/03/16 16:19:14 INFO PythonRunner: Times: total = 163, boot = 162, init = 0, finish = 1
16/03/16 16:19:14 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1227 bytes result sent to driver
16/03/16 16:19:14 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 191 ms on localhost (2/2)
16/03/16 16:19:14 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 16:19:14 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.372 s
16/03/16 16:19:14 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 10.184355 s
16/03/16 16:19:14 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:19:14 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:19:14 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:19:14 INFO DAGScheduler: Parents of final stage: List()
16/03/16 16:19:14 INFO DAGScheduler: Missing parents: List()
16/03/16 16:19:14 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:19:14 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18741, maxMem=1124676403
16/03/16 16:19:14 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1072.6 MB)
16/03/16 16:19:14 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24557, maxMem=1124676403
16/03/16 16:19:14 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1072.5 MB)
16/03/16 16:19:14 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:58759 (size: 3.3 KB, free: 1072.6 MB)
16/03/16 16:19:14 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 16:19:14 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:19:14 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 16:19:14 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 16:19:14 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 16:19:14 INFO PythonRunner: Times: total = 102, boot = 102, init = 0, finish = 0
16/03/16 16:19:14 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 16:19:14 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2257 bytes)
16/03/16 16:19:14 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 16:19:14 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 123 ms on localhost (1/2)
16/03/16 16:19:14 INFO PythonRunner: Times: total = 170, boot = 170, init = 0, finish = 0
16/03/16 16:19:14 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1296 bytes result sent to driver
16/03/16 16:19:14 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 183 ms on localhost (2/2)
16/03/16 16:19:14 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 16:19:14 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.304 s
16/03/16 16:19:14 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.318589 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 16:19:14 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 16:19:14 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 16:19:14 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 16:19:14 INFO MemoryStore: MemoryStore cleared
16/03/16 16:19:14 INFO BlockManager: BlockManager stopped
16/03/16 16:19:14 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 16:19:14 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 16:19:14 INFO SparkContext: Successfully stopped SparkContext
16/03/16 16:19:14 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 16:19:14 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 16:19:14 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None']
InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:freqterms1= [u'serving', u'Madras', u'Bengal', u'course', u'relation', u'geography', u'group', u'decay', u'program', u'Tamil', u'exceptional', u'Bay', u'formulating', u'serves', u'item', u'miles', u'unstable', u'including', u'people', u'series', u'Christianity', u'culture', u'meters', u'special', u'0.621371', u'Orthodox', u'definite', u'boundary', u'business', u'importance', u'equivalent', u'thorium', u'approval', u'providing', u'region', u'title', u'equal', u'length', u'resulting', u'act', u'action', u'whole', u'businesses', u'1000', u'formerly', u'period', u'highly', u'production', u'indefinite', u'unit', u'city', u'use', u'consumption', u'Eastern', u'stretch', u'archbishop', u'system', u'halogen', u'continuous', u'western', u'particular', u'given', u'kind', u'official', u'patriarch', u'Church', u'distribution', u'property', u'distinguished', u'metric', u'heaviest', u'purposes', u'general', u'something', u'bishop', u'things', u'belong', u'uranium', u'arrangement', u'parts', u'speech', u'geographical', u'spatial', u'Nadu', u'circular', u'product', u'used', u'usually', u'moment', u'purpose', u'segment', u'radioactive', u'happening', u'curve', u'together', u'element', u'person', u'reputation', u'time', u'position', u'quantity']
16/03/16 16:19:15 INFO SparkContext: Running Spark version 1.5.2
16/03/16 16:19:15 INFO SecurityManager: Changing view acls to: root
16/03/16 16:19:15 INFO SecurityManager: Changing modify acls to: root
16/03/16 16:19:15 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 16:19:15 INFO Slf4jLogger: Slf4jLogger started
16/03/16 16:19:15 INFO Remoting: Starting remoting
16/03/16 16:19:15 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:41840]
16/03/16 16:19:15 INFO Utils: Successfully started service 'sparkDriver' on port 41840.
16/03/16 16:19:15 INFO SparkEnv: Registering MapOutputTracker
16/03/16 16:19:15 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 16:19:15 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-470fa28d-2a0a-43fc-8d85-f3b48bf083c0
16/03/16 16:19:15 INFO MemoryStore: MemoryStore started with capacity 1072.6 MB
16/03/16 16:19:15 INFO HttpFileServer: HTTP File server directory is /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/httpd-5c00570e-dda9-4eb2-8b62-436c4459fc6d
16/03/16 16:19:15 INFO HttpServer: Starting HTTP Server
16/03/16 16:19:15 INFO Utils: Successfully started service 'HTTP file server' on port 39409.
16/03/16 16:19:15 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 16:19:16 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 16:19:16 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 16:19:16 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-baed041f-af1f-4a6e-954e-298278d08233/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 16:19:16 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125356043
16/03/16 16:19:16 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 16:19:16 INFO Executor: Starting executor ID driver on host localhost
16/03/16 16:19:16 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51652.
16/03/16 16:19:16 INFO NettyBlockTransferService: Server created on 51652
16/03/16 16:19:16 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 16:19:16 INFO BlockManagerMasterEndpoint: Registering block manager localhost:51652 with 1072.6 MB RAM, BlockManagerId(driver, localhost, 51652)
16/03/16 16:19:16 INFO BlockManagerMaster: Registered BlockManager
Spark_MapReduce(): wordsatthislevel: [u'serving', u'Madras', u'Bengal', u'course', u'relation', u'geography', u'group', u'decay', u'program', u'Tamil', u'exceptional', u'Bay', u'formulating', u'serves', u'item', u'miles', u'unstable', u'including', u'people', u'series', u'Christianity', u'culture', u'meters', u'special', u'0.621371', u'Orthodox', u'definite', u'boundary', u'business', u'importance', u'equivalent', u'thorium', u'approval', u'providing', u'region', u'title', u'equal', u'length', u'resulting', u'act', u'action', u'whole', u'businesses', u'1000', u'formerly', u'period', u'highly', u'production', u'indefinite', u'unit', u'city', u'use', u'consumption', u'Eastern', u'stretch', u'archbishop', u'system', u'halogen', u'continuous', u'western', u'particular', u'given', u'kind', u'official', u'patriarch', u'Church', u'distribution', u'property', u'distinguished', u'metric', u'heaviest', u'purposes', u'general', u'something', u'bishop', u'things', u'belong', u'uranium', u'arrangement', u'parts', u'speech', u'geographical', u'spatial', u'Nadu', u'circular', u'product', u'used', u'usually', u'moment', u'purpose', u'segment', u'radioactive', u'happening', u'curve', u'together', u'element', u'person', u'reputation', u'time', u'position', u'quantity']
16/03/16 16:19:16 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230
16/03/16 16:19:16 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230)
16/03/16 16:19:16 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230) with 2 output partitions
16/03/16 16:19:16 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230)
16/03/16 16:19:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 16:19:16 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 16:19:16 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230), which has no missing parents
16/03/16 16:19:16 INFO MemoryStore: ensureFreeSpace(6552) called with curMem=0, maxMem=1124676403
16/03/16 16:19:16 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1072.6 MB)
16/03/16 16:19:16 INFO MemoryStore: ensureFreeSpace(4132) called with curMem=6552, maxMem=1124676403
16/03/16 16:19:16 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1072.6 MB)
16/03/16 16:19:16 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:51652 (size: 4.0 KB, free: 1072.6 MB)
16/03/16 16:19:16 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 16:19:16 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230)
16/03/16 16:19:16 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 16:19:16 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2927 bytes)
16/03/16 16:19:16 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 16:19:16 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125356043
16/03/16 16:19:16 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-baed041f-af1f-4a6e-954e-298278d08233/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
mapFunction(): freqterms1: serving
mapFunction(): freqterms1: Madras
mapFunction(): freqterms1: Bengal
mapFunction(): freqterms1: course
mapFunction(): freqterms1: relation
mapFunction(): freqterms1: geography
mapFunction(): freqterms1: group
mapFunction(): freqterms1: decay
mapFunction(): freqterms1: program
mapFunction(): freqterms1: Tamil
mapFunction(): freqterms1: exceptional
mapFunction(): freqterms1: Bay
mapFunction(): freqterms1: formulating
mapFunction(): freqterms1: serves
mapFunction(): freqterms1: item
mapFunction(): freqterms1: miles
mapFunction(): freqterms1: unstable
mapFunction(): freqterms1: including
mapFunction(): freqterms1: people
mapFunction(): freqterms1: series
mapFunction(): freqterms1: Christianity
mapFunction(): freqterms1: culture
mapFunction(): freqterms1: meters
mapFunction(): freqterms1: special
mapFunction(): freqterms1: 0.621371
mapFunction(): freqterms1: Orthodox
mapFunction(): freqterms1: definite
mapFunction(): freqterms1: boundary
mapFunction(): freqterms1: business
mapFunction(): freqterms1: importance
mapFunction(): freqterms1: equivalent
mapFunction(): freqterms1: thorium
mapFunction(): freqterms1: approval
mapFunction(): freqterms1: providing
mapFunction(): freqterms1: region
mapFunction(): freqterms1: title
mapFunction(): freqterms1: equal
mapFunction(): freqterms1: length
mapFunction(): freqterms1: resulting
mapFunction(): freqterms1: act
mapFunction(): freqterms1: action
mapFunction(): freqterms1: whole
mapFunction(): freqterms1: businesses
mapFunction(): freqterms1: 1000
mapFunction(): freqterms1: formerly
mapFunction(): freqterms1: period
mapFunction(): freqterms1: highly
mapFunction(): freqterms1: production
mapFunction(): freqterms1: indefinite
mapFunction(): freqterms1: unit
16/03/16 16:19:25 INFO PythonRunner: Times: total = 9253, boot = 482, init = 353, finish = 8418
16/03/16 16:19:25 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 16:19:25 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2968 bytes)
16/03/16 16:19:25 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 16:19:25 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9353 ms on localhost (1/2)
mapFunction(): freqterms1: city
mapFunction(): freqterms1: use
mapFunction(): freqterms1: consumption
mapFunction(): freqterms1: Eastern
mapFunction(): freqterms1: stretch
mapFunction(): freqterms1: archbishop
mapFunction(): freqterms1: system
mapFunction(): freqterms1: halogen
mapFunction(): freqterms1: continuous
mapFunction(): freqterms1: western
mapFunction(): freqterms1: particular
mapFunction(): freqterms1: given
mapFunction(): freqterms1: kind
mapFunction(): freqterms1: official
mapFunction(): freqterms1: patriarch
mapFunction(): freqterms1: Church
mapFunction(): freqterms1: distribution
mapFunction(): freqterms1: property
mapFunction(): freqterms1: distinguished
mapFunction(): freqterms1: metric
mapFunction(): freqterms1: heaviest
mapFunction(): freqterms1: purposes
mapFunction(): freqterms1: general
mapFunction(): freqterms1: something
mapFunction(): freqterms1: bishop
mapFunction(): freqterms1: things
mapFunction(): freqterms1: belong
mapFunction(): freqterms1: uranium
mapFunction(): freqterms1: arrangement
mapFunction(): freqterms1: parts
mapFunction(): freqterms1: speech
mapFunction(): freqterms1: geographical
mapFunction(): freqterms1: spatial
mapFunction(): freqterms1: Nadu
mapFunction(): freqterms1: circular
mapFunction(): freqterms1: product
mapFunction(): freqterms1: used
mapFunction(): freqterms1: usually
mapFunction(): freqterms1: moment
mapFunction(): freqterms1: purpose
mapFunction(): freqterms1: segment
mapFunction(): freqterms1: radioactive
mapFunction(): freqterms1: happening
mapFunction(): freqterms1: curve
mapFunction(): freqterms1: together
mapFunction(): freqterms1: element
mapFunction(): freqterms1: person
mapFunction(): freqterms1: reputation
mapFunction(): freqterms1: time
mapFunction(): freqterms1: position
mapFunction(): freqterms1: quantity
16/03/16 16:19:27 INFO PythonRunner: Times: total = 1557, boot = 186, init = 1, finish = 1370
16/03/16 16:19:27 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 16:19:27 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 1584 ms on localhost (2/2)
16/03/16 16:19:27 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230) finished in 10.922 s
16/03/16 16:19:27 INFO DAGScheduler: looking for newly runnable stages
16/03/16 16:19:27 INFO DAGScheduler: running: Set()
16/03/16 16:19:27 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 16:19:27 INFO DAGScheduler: failed: Set()
16/03/16 16:19:27 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 16:19:27 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230), which is now runnable
16/03/16 16:19:27 INFO MemoryStore: ensureFreeSpace(4976) called with curMem=10684, maxMem=1124676403
16/03/16 16:19:27 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1072.6 MB)
16/03/16 16:19:27 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 16:19:27 INFO MemoryStore: ensureFreeSpace(3040) called with curMem=15660, maxMem=1124676403
16/03/16 16:19:27 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1072.6 MB)
16/03/16 16:19:27 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:51652 (size: 3.0 KB, free: 1072.6 MB)
16/03/16 16:19:27 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 16:19:27 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230)
16/03/16 16:19:27 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 16:19:27 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:19:27 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 16:19:27 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:19:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/16 16:19:27 INFO PythonRunner: Times: total = 163, boot = 162, init = 1, finish = 0
16/03/16 16:19:27 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 16:19:27 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:19:27 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 16:19:27 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:19:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 16:19:27 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 199 ms on localhost (1/2)
16/03/16 16:19:27 INFO PythonRunner: Times: total = 173, boot = 170, init = 0, finish = 3
16/03/16 16:19:27 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 10972 bytes result sent to driver
16/03/16 16:19:27 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 200 ms on localhost (2/2)
16/03/16 16:19:27 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230) finished in 0.371 s
16/03/16 16:19:27 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 16:19:27 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230, took 11.342938 s
16/03/16 16:19:27 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230
16/03/16 16:19:27 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230) with 2 output partitions
16/03/16 16:19:27 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230)
16/03/16 16:19:27 INFO DAGScheduler: Parents of final stage: List()
16/03/16 16:19:27 INFO DAGScheduler: Missing parents: List()
16/03/16 16:19:27 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230), which has no missing parents
16/03/16 16:19:27 INFO MemoryStore: ensureFreeSpace(5872) called with curMem=18700, maxMem=1124676403
16/03/16 16:19:27 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1072.6 MB)
16/03/16 16:19:27 INFO MemoryStore: ensureFreeSpace(3416) called with curMem=24572, maxMem=1124676403
16/03/16 16:19:27 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1072.5 MB)
16/03/16 16:19:27 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:51652 (size: 3.3 KB, free: 1072.6 MB)
16/03/16 16:19:27 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 16:19:27 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230)
16/03/16 16:19:27 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 16:19:27 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 16:19:27 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 16:19:27 INFO PythonRunner: Times: total = 64, boot = 63, init = 1, finish = 0
16/03/16 16:19:27 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 16:19:27 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 11918 bytes)
16/03/16 16:19:27 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 91 ms on localhost (1/2)
16/03/16 16:19:27 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 16:19:28 INFO PythonRunner: Times: total = 178, boot = 177, init = 0, finish = 1
16/03/16 16:19:28 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 11279 bytes result sent to driver
16/03/16 16:19:28 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 249 ms on localhost (2/2)
16/03/16 16:19:28 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230) finished in 0.334 s
16/03/16 16:19:28 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 16:19:28 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230, took 0.348359 s
Spark_MapReduce() - SparkSQL DataFrame query results:
Row(tokensatthislevel=[u'individual', u'quantity', u'food', u'drink', u'taken', u'part', u'meal', u'state', u'southeastern', u'India', u'Bay', u'Bengal', u'south', u'Andhra', u'Pradesh', u'formerly', u'Madras', u'region', u'whose', u'eastern', u'part', u'Bangladesh', u'whose', u'western', u'part', u'included', u'India', u'education', u'imparted', u'series', u'lessons', u'meetings', u'act', u'sexual', u'procreation', u'man', u'woman', u'man', u'penis', u'inserted', u'woman', u'vagina', u'excited', u'orgasm', u'ejaculation', u'occur', u'study', u'earth', u'surface', u'includes', u'people', u'responses', u'topography', u'climate', u'soil', u'vegetation', u'number', u'entities', u'members', u'considered', u'unit', u'gradual', u'decrease', u'stored', u'charge', u'current', u'series', u'steps', u'carried', u'goals', u'accomplished', u'member', u'mixed', u'Dravidian', u'Caucasian', u'people', u'southern', u'India', u'Sri', u'Lanka', u'deviating', u'widely', u'norm', u'physical', u'mental', u'ability', u'used', u'especially', u'children', u'normal', u'intelligence', u'indentation', u'shoreline', u'larger', u'cove', u'smaller', u'gulf', u'come', u'idea', u'plan', u'explanation', u'theory', u'principle', u'mental', u'effort', u'sports', u'stroke', u'puts', u'ball', u'play', u'distinct', u'part', u'specified', u'separately', u'group', u'things', u'could', u'enumerated', u'list', u'unit', u'length', u'equal', u'1,760', u'yards', u'5,280', u'feet', u'exactly', u'1609.344', u'meters', u'lacking', u'stability', u'fixity', u'firmness', u'part', u'made', u'plural', u'group', u'human', u'beings', u'men', u'women', u'children', u'collectively', u'similar', u'things', u'placed', u'order', u'happening', u'one', u'another', u'monotheistic', u'system', u'beliefs', u'practices', u'based', u'Old', u'Testament', u'teachings', u'Jesus', u'embodied', u'New', u'Testament', u'emphasizing', u'role', u'Jesus', u'savior', u'particular', u'society', u'particular', u'time', u'place', u'basic', u'unit', u'length', u'adopted', u'Systeme', u'International', u"d'Unites", u'approximately', u'1.094', u'yards', u'special', u'offering', u'usually', u'temporary', u'reduced', u'price', u'featured', u'advertising', u'pertaining', u'characteristic', u'Judaism', u'precise', u'explicit', u'clearly', u'defined', u'line', u'determining', u'limits', u'area', u'commercial', u'industrial', u'enterprise', u'people', u'constitute', u'prominent', u'status', u'person', u'thing', u'equal', u'another', u'value', u'measure', u'force', u'effect', u'significance', u'etc', u'soft', u'silvery-white', u'tetravalent', u'radioactive', u'metallic', u'element', u'isotope', u'232', u'used', u'power', u'source', u'nuclear', u'reactors', u'occurs', u'thorite', u'monazite', u'sands', u'feeling', u'liking', u'something', u'someone', u'good', u'give', u'something', u'useful', u'necessary', u'extended', u'spatial', u'location', u'something', u'heading', u'names', u'statute', u'legislative', u'bill', u'give', u'brief', u'summary', u'matters', u'deals', u'person', u'equal', u'standing', u'another', u'group', u'linear', u'extent', u'space', u'one', u'end', u'longest', u'dimension', u'something', u'fixed', u'place', u'issue', u'terminate', u'specified', u'way', u'state', u'etc', u'end', u'legal', u'document', u'codifying', u'result', u'deliberations', u'committee', u'society', u'legislative', u'body', u'military', u'engagement', u'something', u'including', u'component', u'elements', u'parts', u'commercial', u'industrial', u'enterprise', u'people', u'constitute', u'cardinal', u'number', u'product', u'10', u'100', u'previous', u'time', u'amount', u'time', u'high', u'degree', u'extent', u'favorably', u'much', u'respect', u'act', u'process', u'producing', u'something', u'vague', u'clearly', u'defined', u'stated', u'division', u'quantity', u'accepted', u'standard', u'measurement', u'exchange', u'large', u'densely', u'populated', u'urban', u'area', u'include', u'several', u'independent', u'administrative', u'districts', u'act', u'using', u'process', u'taking', u'food', u'body', u'mouth', u'eating', u'lying', u'toward', u'situated', u'east', u'large', u'unbroken', u'expanse', u'distance', u'bishop', u'highest', u'rank', u'instrumentality', u'combines', u'interrelated', u'interacting', u'artifacts', u'designed', u'work', u'coherent', u'entity', u'five', u'related', u'nonmetallic', u'elements', u'fluorine', u'chlorine', u'bromine', u'iodine', u'astatine', u'monovalent', u'readily', u'form', u'negative', u'ions', u'continuing', u'time', u'space', u'without', u'interruption', u'film', u'life', u'western', u'United', u'States', u'period', u'exploration', u'development', u'fact', u'part', u'opposed', u'general', u'assumption', u'taken', u'granted', u'category', u'things', u'distinguished', u'common', u'characteristic', u'quality', u'worker', u'holds', u'invested', u'office', u'man', u'older', u'higher', u'rank', u'one', u'groups', u'Christians', u'beliefs', u'forms', u'worship', u'statistics', u'arrangement', u'values', u'variable', u'showing', u'observed', u'theoretical', u'frequency', u'occurrence', u'something', u'owned', u'tangible', u'intangible', u'possession', u'owned', u'someone', u'mark', u'different', u'function', u'topological', u'space', u'gives', u'two', u'points', u'space', u'value', u'equal', u'distance', u'usually', u'describes', u'large', u'person', u'fat', u'large', u'frame', u'carry', u'anticipated', u'outcome', u'intended', u'guides', u'planned', u'actions', u'general', u'officer', u'highest', u'rank', u'senior', u'member', u'Christian', u'clergy', u'spiritual', u'administrative', u'authority', u'appointed', u'Christian', u'churches', u'oversee', u'priests', u'ministers', u'considered', u'churches', u'successors', u'twelve', u'Apostles', u'Christ', u'movable', u'possession', u'especially', u'articles', u'clothing', u'owned', u'possession', u'heavy', u'toxic', u'silvery-white', u'radioactive', u'metallic', u'element', u'occurs', u'many', u'isotopes', u'used', u'nuclear', u'fuels', u'nuclear', u'weapons', u'orderly', u'grouping', u'things', u'persons', u'considered', u'unit', u'result', u'arranging', u'something', u'less', u'whole', u'human', u'artifact', u'act', u'delivering', u'formal', u'spoken', u'communication', u'audience', u'relating', u'science', u'geography', u'pertaining', u'involving', u'nature', u'space', u'advertisement', u'usually', u'printed', u'page', u'leaflet', u'intended', u'wide', u'distribution', u'commodities', u'offered', u'sale', u'put', u'service', u'make', u'work', u'employ', u'particular', u'purpose', u'inherent', u'natural', u'purpose', u'normal', u'conditions', u'particular', u'point', u'time', u'anticipated', u'outcome', u'intended', u'guides', u'planned', u'actions', u'one', u'several', u'parts', u'pieces', u'fit', u'others', u'constitute', u'whole', u'object', u'exhibiting', u'caused', u'radioactivity', u'event', u'happens', u'trace', u'point', u'whose', u'direction', u'motion', u'changes', u'mentally', u'emotionally', u'stable', u'abstract', u'part', u'something', u'human', u'general', u'estimation', u'public', u'person', u'instance', u'single', u'occasion', u'event', u'particular', u'portion', u'space', u'occupied', u'something', u'concept', u'something', u'magnitude', u'represented', u'mathematical', u'expressions', u'constant', u'variable'])
16/03/16 16:19:28 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 16:19:28 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 16:19:28 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 16:19:28 INFO MemoryStore: MemoryStore cleared
16/03/16 16:19:28 INFO BlockManager: BlockManager stopped
16/03/16 16:19:28 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 16:19:28 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 16:19:28 INFO SparkContext: Successfully stopped SparkContext
16/03/16 16:19:28 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 16:19:28 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:tokensofthislevel: [u'individual', u'quantity', u'food', u'drink', u'taken', u'part', u'meal', u'state', u'southeastern', u'India', u'Bay', u'Bengal', u'south', u'Andhra', u'Pradesh', u'formerly', u'Madras', u'region', u'whose', u'eastern', u'part', u'Bangladesh', u'whose', u'western', u'part', u'included', u'India', u'education', u'imparted', u'series', u'lessons', u'meetings', u'act', u'sexual', u'procreation', u'man', u'woman', u'man', u'penis', u'inserted', u'woman', u'vagina', u'excited', u'orgasm', u'ejaculation', u'occur', u'study', u'earth', u'surface', u'includes', u'people', u'responses', u'topography', u'climate', u'soil', u'vegetation', u'number', u'entities', u'members', u'considered', u'unit', u'gradual', u'decrease', u'stored', u'charge', u'current', u'series', u'steps', u'carried', u'goals', u'accomplished', u'member', u'mixed', u'Dravidian', u'Caucasian', u'people', u'southern', u'India', u'Sri', u'Lanka', u'deviating', u'widely', u'norm', u'physical', u'mental', u'ability', u'used', u'especially', u'children', u'normal', u'intelligence', u'indentation', u'shoreline', u'larger', u'cove', u'smaller', u'gulf', u'come', u'idea', u'plan', u'explanation', u'theory', u'principle', u'mental', u'effort', u'sports', u'stroke', u'puts', u'ball', u'play', u'distinct', u'part', u'specified', u'separately', u'group', u'things', u'could', u'enumerated', u'list', u'unit', u'length', u'equal', u'1,760', u'yards', u'5,280', u'feet', u'exactly', u'1609.344', u'meters', u'lacking', u'stability', u'fixity', u'firmness', u'part', u'made', u'plural', u'group', u'human', u'beings', u'men', u'women', u'children', u'collectively', u'similar', u'things', u'placed', u'order', u'happening', u'one', u'another', u'monotheistic', u'system', u'beliefs', u'practices', u'based', u'Old', u'Testament', u'teachings', u'Jesus', u'embodied', u'New', u'Testament', u'emphasizing', u'role', u'Jesus', u'savior', u'particular', u'society', u'particular', u'time', u'place', u'basic', u'unit', u'length', u'adopted', u'Systeme', u'International', u"d'Unites", u'approximately', u'1.094', u'yards', u'special', u'offering', u'usually', u'temporary', u'reduced', u'price', u'featured', u'advertising', u'pertaining', u'characteristic', u'Judaism', u'precise', u'explicit', u'clearly', u'defined', u'line', u'determining', u'limits', u'area', u'commercial', u'industrial', u'enterprise', u'people', u'constitute', u'prominent', u'status', u'person', u'thing', u'equal', u'another', u'value', u'measure', u'force', u'effect', u'significance', u'etc', u'soft', u'silvery-white', u'tetravalent', u'radioactive', u'metallic', u'element', u'isotope', u'232', u'used', u'power', u'source', u'nuclear', u'reactors', u'occurs', u'thorite', u'monazite', u'sands', u'feeling', u'liking', u'something', u'someone', u'good', u'give', u'something', u'useful', u'necessary', u'extended', u'spatial', u'location', u'something', u'heading', u'names', u'statute', u'legislative', u'bill', u'give', u'brief', u'summary', u'matters', u'deals', u'person', u'equal', u'standing', u'another', u'group', u'linear', u'extent', u'space', u'one', u'end', u'longest', u'dimension', u'something', u'fixed', u'place', u'issue', u'terminate', u'specified', u'way', u'state', u'etc', u'end', u'legal', u'document', u'codifying', u'result', u'deliberations', u'committee', u'society', u'legislative', u'body', u'military', u'engagement', u'something', u'including', u'component', u'elements', u'parts', u'commercial', u'industrial', u'enterprise', u'people', u'constitute', u'cardinal', u'number', u'product', u'10', u'100', u'previous', u'time', u'amount', u'time', u'high', u'degree', u'extent', u'favorably', u'much', u'respect', u'act', u'process', u'producing', u'something', u'vague', u'clearly', u'defined', u'stated', u'division', u'quantity', u'accepted', u'standard', u'measurement', u'exchange', u'large', u'densely', u'populated', u'urban', u'area', u'include', u'several', u'independent', u'administrative', u'districts', u'act', u'using', u'process', u'taking', u'food', u'body', u'mouth', u'eating', u'lying', u'toward', u'situated', u'east', u'large', u'unbroken', u'expanse', u'distance', u'bishop', u'highest', u'rank', u'instrumentality', u'combines', u'interrelated', u'interacting', u'artifacts', u'designed', u'work', u'coherent', u'entity', u'five', u'related', u'nonmetallic', u'elements', u'fluorine', u'chlorine', u'bromine', u'iodine', u'astatine', u'monovalent', u'readily', u'form', u'negative', u'ions', u'continuing', u'time', u'space', u'without', u'interruption', u'film', u'life', u'western', u'United', u'States', u'period', u'exploration', u'development', u'fact', u'part', u'opposed', u'general', u'assumption', u'taken', u'granted', u'category', u'things', u'distinguished', u'common', u'characteristic', u'quality', u'worker', u'holds', u'invested', u'office', u'man', u'older', u'higher', u'rank', u'one', u'groups', u'Christians', u'beliefs', u'forms', u'worship', u'statistics', u'arrangement', u'values', u'variable', u'showing', u'observed', u'theoretical', u'frequency', u'occurrence', u'something', u'owned', u'tangible', u'intangible', u'possession', u'owned', u'someone', u'mark', u'different', u'function', u'topological', u'space', u'gives', u'two', u'points', u'space', u'value', u'equal', u'distance', u'usually', u'describes', u'large', u'person', u'fat', u'large', u'frame', u'carry', u'anticipated', u'outcome', u'intended', u'guides', u'planned', u'actions', u'general', u'officer', u'highest', u'rank', u'senior', u'member', u'Christian', u'clergy', u'spiritual', u'administrative', u'authority', u'appointed', u'Christian', u'churches', u'oversee', u'priests', u'ministers', u'considered', u'churches', u'successors', u'twelve', u'Apostles', u'Christ', u'movable', u'possession', u'especially', u'articles', u'clothing', u'owned', u'possession', u'heavy', u'toxic', u'silvery-white', u'radioactive', u'metallic', u'element', u'occurs', u'many', u'isotopes', u'used', u'nuclear', u'fuels', u'nuclear', u'weapons', u'orderly', u'grouping', u'things', u'persons', u'considered', u'unit', u'result', u'arranging', u'something', u'less', u'whole', u'human', u'artifact', u'act', u'delivering', u'formal', u'spoken', u'communication', u'audience', u'relating', u'science', u'geography', u'pertaining', u'involving', u'nature', u'space', u'advertisement', u'usually', u'printed', u'page', u'leaflet', u'intended', u'wide', u'distribution', u'commodities', u'offered', u'sale', u'put', u'service', u'make', u'work', u'employ', u'particular', u'purpose', u'inherent', u'natural', u'purpose', u'normal', u'conditions', u'particular', u'point', u'time', u'anticipated', u'outcome', u'intended', u'guides', u'planned', u'actions', u'one', u'several', u'parts', u'pieces', u'fit', u'others', u'constitute', u'whole', u'object', u'exhibiting', u'caused', u'radioactivity', u'event', u'happens', u'trace', u'point', u'whose', u'direction', u'motion', u'changes', u'mentally', u'emotionally', u'stable', u'abstract', u'part', u'something', u'human', u'general', u'estimation', u'public', u'person', u'instance', u'single', u'occasion', u'event', u'particular', u'portion', u'space', u'occupied', u'something', u'concept', u'something', u'magnitude', u'represented', u'mathematical', u'expressions', u'constant', u'variable']
prevlevelsynsets: [Synset('helping.n.01'), Synset('tamil_nadu.n.01'), Synset('bengal.n.01'), Synset('course.n.01'), Synset('sexual_intercourse.n.01'), Synset('geography.n.01'), Synset('group.n.01'), Synset('decay.n.01'), Synset('plan.n.01'), Synset('tamil.n.01'), Synset('exceeding.s.01'), Synset('bay.n.01'), Synset('invent.v.01'), Synset('serve.n.01'), Synset('item.n.01'), Synset('mile.n.01'), Synset('unstable.a.01'), Synset('include.v.01'), Synset('people.n.01'), Synset('series.n.01'), Synset('christianity.n.01'), Synset('culture.n.01'), Synset('meter.n.01'), Synset('special.n.01'), Synset('orthodox.a.01'), Synset('definite.a.01'), Synset('boundary.n.01'), Synset('business.n.01'), Synset('importance.n.01'), Synset('equivalent.n.01'), Synset('thorium.n.01'), Synset('blessing.n.01'), Synset('supply.n.01'), Synset('region.n.01'), Synset('title.n.01'), Synset('peer.n.01'), Synset('length.n.01'), Synset('consequence.n.01'), Synset('act.n.01'), Synset('military_action.n.01'), Synset('whole.n.01'), Synset('business.n.01'), Synset('thousand.n.01'), Synset('once.r.01'), Synset('time_period.n.01'), Synset('highly.r.01'), Synset('production.n.01'), Synset('indefinite.a.01'), Synset('unit_of_measurement.n.01'), Synset('city.n.01'), Synset('use.n.01'), Synset('consumption.n.01'), Synset('eastern.s.01'), Synset('stretch.n.01'), Synset('archbishop.n.01'), Synset('system.n.01'), Synset('halogen.n.01'), Synset('continuous.a.01'), Synset('western.n.01'), Synset('particular.n.01'), Synset('given.n.01'), Synset('kind.n.01'), Synset('official.n.01'), Synset('patriarch.n.01'), Synset('church.n.01'), Synset('distribution.n.01'), Synset('property.n.01'), Synset('distinguish.v.01'), Synset('metric_function.n.01'), Synset('fleshy.s.01'), Synset('purpose.n.01'), Synset('general.n.01'), Synset('bishop.n.01'), Synset('things.n.01'), Synset('belong.v.01'), Synset('uranium.n.01'), Synset('agreement.n.04'), Synset('part.n.01'), Synset('address.n.01'), Synset('geographic.a.01'), Synset('spatial.a.01'), Synset('circular.n.01'), Synset('merchandise.n.01'), Synset('use.n.01'), Synset('normally.r.01'), Synset('moment.n.01'), Synset('purpose.n.01'), Synset('section.n.01'), Synset('radioactive.a.01'), Synset('happening.n.01'), Synset('curve.n.01'), Synset('together.s.01'), Synset('component.n.01'), Synset('person.n.01'), Synset('repute.n.01'), Synset('time.n.01'), Synset('position.n.01'), Synset('measure.n.02')]
defaultdict(<type 'list'>, {u'serving': [u'area', u'None', u'area'], u'Madras': [u'None', u'Chennai', u'None', u'Chennai'], u'Bengal': [u'None', u'Chennai', u'None', u'Chennai'], u'course': [u'None', u'planning', u'None'], u'relation': [u'None', u'composition', u'None'], u'geography': [u'area', u'None', u'area'], u'group': [u'None', u'set'], u'decay': [u'None', u'None', u'astatine'], u'halogen': [u'None', u'None', u'astatine'], u'Tamil': [u'None', u'Chennai', u'None', u'Chennai'], u'exceptional': [u'None', u'None', u'giant'], u'Bay': [u'None', u'Chennai', u'None', u'Chennai'], u'formulating': [u'None', u'planning', u'None'], u'serves': [u'None', u'agency', u'None'], u'item': [u'None', u'None'], u'miles': [u'None', u'kilometer', u'None', u'kilometer'], u'unstable': [u'None', u'None', u'astatine'], u'including': [u'None', u'None', u'present'], u'people': [u'area', u'None', u'area'], u'series': [u'None', u'None', u'astatine'], u'Christianity': [u'None', u'None', u'metropolitan'], u'culture': [u'area', u'None', u'area'], u'meters': [u'None', u'kilometer', u'None', u'kilometer'], u'special': [u'area', u'None', u'area'], u'0.621371': [u'None', u'kilometer', u'None', u'kilometer'], u'Orthodox': [u'None', u'None', u'metropolitan'], u'definite': [u'None', u'planning', u'None'], u'boundary': [u'area', u'None', u'area'], u'business': [u'None', u'agency', u'None'], u'importance': [u'None', u'None', u'giant'], u'equivalent': [u'None', u'None', u'metropolitan'], u'thorium': [u'None', u'None', u'astatine'], u'approval': [u'None', u'permission', u'None'], u'providing': [u'None', u'None'], u'region': [u'area', u'None', u'area'], u'title': [u'None', u'None', u'metropolitan'], u'equal': [u'None', u'kilometer', u'None', u'kilometer'], u'length': [u'None', u'kilometer', u'None', u'kilometer'], u'resulting': [u'None', u'composition', u'None'], u'act': [u'None', u'planning', u'None'], u'action': [u'None', u'planning', u'None'], u'whole': [u'None', u'composition', u'None'], u'businesses': [u'None', u'agency', u'None'], u'1000': [u'None', u'kilometer', u'None', u'kilometer'], u'formerly': [u'None', u'Chennai', u'None', u'Chennai'], u'period': [u'None', u'None', u'present'], u'highly': [u'None', u'None', u'astatine'], u'production': [u'None', u'economy', u'None'], u'indefinite': [u'area', u'None', u'area'], u'unit': [u'None', u'kilometer', u'None', u'kilometer'], u'city': [u'None', u'Chennai', u'None', u'Chennai'], u'use': [u'None', u'None'], u'consumption': [u'None', u'economy', u'None'], u'Eastern': [u'None', u'None', u'metropolitan'], u'stretch': [u'None', u'None', u'present'], u'archbishop': [u'None', u'None', u'metropolitan'], u'system': [u'None', u'economy', u'None'], u'program': [u'None', u'planning', u'None'], u'continuous': [u'None', u'None', u'present'], u'western': [u'None', u'None', u'metropolitan'], u'particular': [u'area', u'None', u'area'], u'given': [u'None', u'None', u'metropolitan'], u'kind': [u'None', u'set'], u'official': [u'None', u'None'], u'patriarch': [u'None', u'None', u'metropolitan'], u'Church': [u'None', u'None', u'metropolitan'], u'distribution': [u'None', u'economy', u'None'], u'property': [u'None', u'composition', u'None'], u'distinguished': [u'area', u'None', u'area'], u'metric': [u'None', u'kilometer', u'None', u'kilometer'], u'heaviest': [u'None', u'None', u'astatine'], u'purposes': [u'None', u'None'], u'general': [u'None', u'None'], u'something': [u'None', u'permission', u'None'], u'bishop': [u'None', u'None', u'metropolitan'], u'things': [u'None', u'set'], u'belong': [u'None', u'set'], u'uranium': [u'None', u'None', u'astatine'], u'arrangement': [u'None', u'composition', u'None'], u'parts': [u'None', u'composition', u'None'], u'speech': [u'None', u'None', u'present'], u'geographical': [u'area', u'None', u'area'], u'spatial': [u'None', u'composition', u'None'], u'Nadu': [u'None', u'Chennai', u'None', u'Chennai'], u'circular': [u'None', u'bend'], u'product': [u'None', u'None', u'astatine'], u'used': [u'None', u'set'], u'usually': [u'area', u'None', u'area'], u'moment': [u'None', u'None', u'present'], u'purpose': [u'area', u'None', u'area'], u'segment': [u'None', u'bend'], u'radioactive': [u'None', u'None', u'astatine'], u'happening': [u'None', u'None', u'present'], u'curve': [u'None', u'bend'], u'together': [u'None', u'set'], u'element': [u'None', u'None', u'astatine'], u'person': [u'None', u'None', u'giant'], u'reputation': [u'None', u'None', u'giant'], u'time': [u'None', u'None', u'present'], u'position': [u'None', u'None', u'metropolitan'], u'quantity': [u'None', u'None']})
ksynset= Synset('helping.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('helping.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('helping.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('tamil_nadu.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('tamil_nadu.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('tamil_nadu.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('tamil_nadu.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('bengal.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('bengal.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('bengal.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('bengal.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('course.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('course.n.01')
lsynset= Synset('planning.n.01')
ksynset= Synset('course.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('relation.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('relation.n.01')
lsynset= Synset('composition.n.01')
ksynset= Synset('relation.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('geography.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('geography.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('geography.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('group.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('group.n.01')
lsynset= Synset('set.n.01')
ksynset= Synset('decay.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('decay.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('decay.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('halogen.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('halogen.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('halogen.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('tamil.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('tamil.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('tamil.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('tamil.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('exceeding.s.01')
lsynset= Synset('none.n.01')
ksynset= Synset('exceeding.s.01')
lsynset= Synset('none.n.01')
ksynset= Synset('exceeding.s.01')
lsynset= Synset('giant.n.01')
ksynset= Synset('bay.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('bay.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('bay.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('bay.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('explicate.v.02')
lsynset= Synset('none.n.01')
ksynset= Synset('explicate.v.02')
lsynset= Synset('planning.n.01')
ksynset= Synset('explicate.v.02')
lsynset= Synset('none.n.01')
ksynset= Synset('serve.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('serve.n.01')
lsynset= Synset('agency.n.01')
ksynset= Synset('serve.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('item.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('item.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('mile.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('mile.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('mile.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('mile.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('unstable.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('unstable.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('unstable.a.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('include.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('include.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('include.v.01')
lsynset= Synset('present.n.01')
ksynset= Synset('people.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('people.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('people.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('series.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('series.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('series.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('christianity.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('christianity.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('christianity.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('culture.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('culture.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('culture.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('meter.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('meter.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('meter.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('meter.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('special.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('special.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('special.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('orthodox.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('orthodox.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('orthodox.a.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('definite.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('definite.a.01')
lsynset= Synset('planning.n.01')
ksynset= Synset('definite.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('boundary.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('boundary.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('boundary.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('business.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('business.n.01')
lsynset= Synset('agency.n.01')
ksynset= Synset('business.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('importance.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('importance.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('importance.n.01')
lsynset= Synset('giant.n.01')
ksynset= Synset('equivalent.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('equivalent.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('equivalent.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('thorium.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('thorium.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('thorium.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('blessing.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('blessing.n.01')
lsynset= Synset('permission.n.01')
ksynset= Synset('blessing.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('supply.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('supply.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('region.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('region.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('region.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('title.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('title.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('title.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('peer.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('peer.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('peer.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('peer.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('length.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('length.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('length.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('length.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('result.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('result.v.01')
lsynset= Synset('composition.n.01')
ksynset= Synset('result.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('act.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('act.n.01')
lsynset= Synset('planning.n.01')
ksynset= Synset('act.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('action.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('action.n.01')
lsynset= Synset('planning.n.01')
ksynset= Synset('action.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('whole.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('whole.n.01')
lsynset= Synset('composition.n.01')
ksynset= Synset('whole.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('business.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('business.n.01')
lsynset= Synset('agency.n.01')
ksynset= Synset('business.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('thousand.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('thousand.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('thousand.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('thousand.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('once.r.03')
lsynset= Synset('none.n.01')
ksynset= Synset('once.r.03')
lsynset= Synset('chennai.n.01')
ksynset= Synset('once.r.03')
lsynset= Synset('none.n.01')
ksynset= Synset('once.r.03')
lsynset= Synset('chennai.n.01')
ksynset= Synset('time_period.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('time_period.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('time_period.n.01')
lsynset= Synset('present.n.01')
ksynset= Synset('highly.r.01')
lsynset= Synset('none.n.01')
ksynset= Synset('highly.r.01')
lsynset= Synset('none.n.01')
ksynset= Synset('highly.r.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('production.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('production.n.01')
lsynset= Synset('economy.n.01')
ksynset= Synset('production.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('indefinite.a.01')
lsynset= Synset('area.n.01')
ksynset= Synset('indefinite.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('indefinite.a.01')
lsynset= Synset('area.n.01')
ksynset= Synset('unit_of_measurement.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('unit_of_measurement.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('unit_of_measurement.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('unit_of_measurement.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('city.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('city.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('city.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('city.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('use.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('use.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('consumption.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('consumption.n.01')
lsynset= Synset('economy.n.01')
ksynset= Synset('consumption.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('eastern.s.01')
lsynset= Synset('none.n.01')
ksynset= Synset('eastern.s.01')
lsynset= Synset('none.n.01')
ksynset= Synset('eastern.s.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('stretch.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('stretch.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('stretch.n.01')
lsynset= Synset('present.n.01')
ksynset= Synset('archbishop.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('archbishop.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('archbishop.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('system.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('system.n.01')
lsynset= Synset('economy.n.01')
ksynset= Synset('system.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('plan.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('plan.n.01')
lsynset= Synset('planning.n.01')
ksynset= Synset('plan.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('continuous.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('continuous.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('continuous.a.01')
lsynset= Synset('present.n.01')
ksynset= Synset('western.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('western.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('western.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('particular.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('particular.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('particular.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('given.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('given.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('given.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('kind.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('kind.n.01')
lsynset= Synset('set.n.01')
ksynset= Synset('official.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('official.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('patriarch.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('patriarch.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('patriarch.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('church.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('church.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('church.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('distribution.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('distribution.n.01')
lsynset= Synset('economy.n.01')
ksynset= Synset('distribution.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('property.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('property.n.01')
lsynset= Synset('composition.n.01')
ksynset= Synset('property.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('distinguish.v.01')
lsynset= Synset('area.n.01')
ksynset= Synset('distinguish.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('distinguish.v.01')
lsynset= Synset('area.n.01')
ksynset= Synset('metric_function.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('metric_function.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('metric_function.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('metric_function.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('heavy.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('heavy.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('heavy.a.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('purpose.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('purpose.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('general.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('general.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('bishop.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('bishop.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('bishop.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('things.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('things.n.01')
lsynset= Synset('set.n.01')
ksynset= Synset('belong.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('belong.v.01')
lsynset= Synset('set.n.01')
ksynset= Synset('uranium.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('uranium.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('uranium.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('agreement.n.04')
lsynset= Synset('none.n.01')
ksynset= Synset('agreement.n.04')
lsynset= Synset('composition.n.01')
ksynset= Synset('agreement.n.04')
lsynset= Synset('none.n.01')
ksynset= Synset('parts.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('parts.n.01')
lsynset= Synset('composition.n.01')
ksynset= Synset('parts.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('address.n.03')
lsynset= Synset('none.n.01')
ksynset= Synset('address.n.03')
lsynset= Synset('none.n.01')
ksynset= Synset('address.n.03')
lsynset= Synset('present.n.01')
ksynset= Synset('geographic.a.01')
lsynset= Synset('area.n.01')
ksynset= Synset('geographic.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('geographic.a.01')
lsynset= Synset('area.n.01')
ksynset= Synset('spatial.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('spatial.a.01')
lsynset= Synset('composition.n.01')
ksynset= Synset('spatial.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('circular.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('circular.n.01')
lsynset= Synset('bend.n.01')
ksynset= Synset('merchandise.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('merchandise.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('merchandise.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('use.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('use.v.01')
lsynset= Synset('set.n.01')
ksynset= Synset('normally.r.01')
lsynset= Synset('area.n.01')
ksynset= Synset('normally.r.01')
lsynset= Synset('none.n.01')
ksynset= Synset('normally.r.01')
lsynset= Synset('area.n.01')
ksynset= Synset('moment.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('moment.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('moment.n.01')
lsynset= Synset('present.n.01')
ksynset= Synset('purpose.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('purpose.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('purpose.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('section.n.04')
lsynset= Synset('none.n.01')
ksynset= Synset('section.n.04')
lsynset= Synset('bend.n.01')
ksynset= Synset('radioactive.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('radioactive.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('radioactive.a.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('happening.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('happening.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('happening.n.01')
lsynset= Synset('present.n.01')
ksynset= Synset('curve.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('curve.n.01')
lsynset= Synset('bend.n.01')
ksynset= Synset('together.s.01')
lsynset= Synset('none.n.01')
ksynset= Synset('together.s.01')
lsynset= Synset('set.n.01')
ksynset= Synset('component.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('component.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('component.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('person.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('person.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('person.n.01')
lsynset= Synset('giant.n.01')
ksynset= Synset('repute.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('repute.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('repute.n.01')
lsynset= Synset('giant.n.01')
ksynset= Synset('time.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('time.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('time.n.01')
lsynset= Synset('present.n.01')
ksynset= Synset('position.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('position.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('position.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('measure.n.02')
lsynset= Synset('none.n.01')
ksynset= Synset('measure.n.02')
lsynset= Synset('none.n.01')
Core number (sorted) : [(u'area', 13), (u'metropolitan', 12), (u'astatine', 11), (u'kilometer', 8), (u'present', 8), (u'Chennai', 7), (u'composition', 7), (u'planning', 6), (u'set', 6), (u'giant', 4), (u'economy', 4), (u'bend', 3), (u'agency', 3), (u'serving', 2), (u'Madras', 2), (u'Bengal', 2), (u'course', 2), (u'relation', 2), (u'geography', 2), (u'group', 2), (u'title', 2), (u'halogen', 2), (u'Tamil', 2), (u'permission', 2), (u'Bay', 2), (u'formulating', 2), (u'serves', 2), (u'miles', 2), (u'unstable', 2), (u'including', 2), (u'people', 2), (u'series', 2), (u'Christianity', 2), (u'culture', 2), (u'meters', 2), (u'special', 2), (u'0.621371', 2), (u'Orthodox', 2), (u'definite', 2), (u'boundary', 2), (u'business', 2), (u'importance', 2), (u'equivalent', 2), (u'thorium', 2), (u'approval', 2), (u'region', 2), (u'decay', 2), (u'equal', 2), (u'length', 2), (u'resulting', 2), (u'act', 2), (u'action', 2), (u'whole', 2), (u'businesses', 2), (u'1000', 2), (u'formerly', 2), (u'period', 2), (u'highly', 2), (u'production', 2), (u'indefinite', 2), (u'unit', 2), (u'city', 2), (u'given', 2), (u'consumption', 2), (u'stretch', 2), (u'archbishop', 2), (u'system', 2), (u'program', 2), (u'exceptional', 2), (u'continuous', 2), (u'western', 2), (u'particular', 2), (u'kind', 2), (u'patriarch', 2), (u'Eastern', 2), (u'Church', 2), (u'distribution', 2), (u'property', 2), (u'distinguished', 2), (u'something', 2), (u'metric', 2), (u'heaviest', 2), (u'bishop', 2), (u'things', 2), (u'belong', 2), (u'uranium', 2), (u'arrangement', 2), (u'parts', 2), (u'speech', 2), (u'geographical', 2), (u'spatial', 2), (u'Nadu', 2), (u'circular', 2), (u'product', 2), (u'used', 2), (u'usually', 2), (u'moment', 2), (u'purpose', 2), (u'segment', 2), (u'radioactive', 2), (u'happening', 2), (u'curve', 2), (u'together', 2), (u'element', 2), (u'person', 2), (u'reputation', 2), (u'time', 2), (u'position', 2), (u'item', 0), (u'None', 0), (u'use', 0), (u'providing', 0), (u'official', 0), (u'purposes', 0), (u'general', 0), (u'quantity', 0)]
=============================================================================================================
Unsupervised Classification based on top percentile Core numbers of the definition graph(subgraph of WordNet)
=============================================================================================================
This document belongs to class: area ,core number= 13
This document belongs to class: metropolitan ,core number= 12
This document belongs to class: astatine ,core number= 11
This document belongs to class: kilometer ,core number= 8
This document belongs to class: present ,core number= 8
This document belongs to class: Chennai ,core number= 7
This document belongs to class: composition ,core number= 7
This document belongs to class: planning ,core number= 6
This document belongs to class: set ,core number= 6
This document belongs to class: giant ,core number= 4
This document belongs to class: economy ,core number= 4
This document belongs to class: bend ,core number= 3
This document belongs to class: agency ,core number= 3
max_core_number 13
===================================================================
Page Rank of the vertices of RGO Definition Graph
===================================================================
[(u'area', 0.05964397617197671), (u'metropolitan', 0.05543677058743772), (u'astatine', 0.051229565002898755), (u'kilometer', 0.03860794824928188), (u'present', 0.03860794824928188), (u'Chennai', 0.034400742664742925), (u'composition', 0.034400742664742925), (u'planning', 0.030193537080203968), (u'set', 0.030193537080203968), (u'giant', 0.021779125911126046), (u'economy', 0.02177912591112604), (u'agency', 0.01757192032658708), (u'bend', 0.017571920326587075), (u'permission', 0.013364714742048119), (u'approval', 0.0070539063652396775), (u'something', 0.0070539063652396775), (u'serves', 0.006352705434483184), (u'business', 0.006352705434483184), (u'businesses', 0.006352705434483184), (u'circular', 0.006352705434483183), (u'segment', 0.006352705434483183), (u'curve', 0.006352705434483183), (u'importance', 0.006002104969104938), (u'production', 0.006002104969104938), (u'consumption', 0.006002104969104938), (u'system', 0.006002104969104938), (u'distribution', 0.006002104969104938), (u'exceptional', 0.006002104969104938), (u'person', 0.006002104969104938), (u'reputation', 0.006002104969104938), (u'course', 0.0056515045037266905), (u'group', 0.0056515045037266905), (u'program', 0.0056515045037266905), (u'formulating', 0.0056515045037266905), (u'definite', 0.0056515045037266905), (u'act', 0.0056515045037266905), (u'action', 0.0056515045037266905), (u'belong', 0.0056515045037266905), (u'kind', 0.0056515045037266905), (u'things', 0.0056515045037266905), (u'used', 0.0056515045037266905), (u'together', 0.0056515045037266905), (u'Madras', 0.005551332942190048), (u'Bengal', 0.005551332942190048), (u'relation', 0.005551332942190048), (u'Tamil', 0.005551332942190048), (u'Bay', 0.005551332942190048), (u'resulting', 0.005551332942190048), (u'whole', 0.005551332942190048), (u'formerly', 0.005551332942190048), (u'city', 0.005551332942190048), (u'property', 0.005551332942190048), (u'arrangement', 0.005551332942190048), (u'parts', 0.005551332942190048), (u'spatial', 0.005551332942190048), (u'Nadu', 0.005551332942190048), (u'miles', 0.0054762042710375675), (u'including', 0.0054762042710375675), (u'meters', 0.0054762042710375675), (u'0.621371', 0.0054762042710375675), (u'equal', 0.0054762042710375675), (u'length', 0.0054762042710375675), (u'1000', 0.0054762042710375675), (u'period', 0.0054762042710375675), (u'unit', 0.0054762042710375675), (u'stretch', 0.0054762042710375675), (u'continuous', 0.0054762042710375675), (u'metric', 0.0054762042710375675), (u'speech', 0.0054762042710375675), (u'moment', 0.0054762042710375675), (u'happening', 0.0054762042710375675), (u'time', 0.0054762042710375675), (u'unstable', 0.005332776807928284), (u'series', 0.005332776807928284), (u'thorium', 0.005332776807928284), (u'decay', 0.005332776807928284), (u'highly', 0.005332776807928284), (u'halogen', 0.005332776807928284), (u'heaviest', 0.005332776807928284), (u'uranium', 0.005332776807928284), (u'product', 0.005332776807928284), (u'radioactive', 0.005332776807928284), (u'element', 0.005332776807928284), (u'title', 0.005300904038348444), (u'Christianity', 0.005300904038348444), (u'Orthodox', 0.005300904038348444), (u'equivalent', 0.005300904038348444), (u'given', 0.005300904038348444), (u'archbishop', 0.005300904038348444), (u'western', 0.005300904038348444), (u'patriarch', 0.005300904038348444), (u'Eastern', 0.005300904038348444), (u'Church', 0.005300904038348444), (u'bishop', 0.005300904038348444), (u'position', 0.005300904038348444), (u'serving', 0.005273934771780889), (u'geography', 0.005273934771780889), (u'people', 0.005273934771780889), (u'culture', 0.005273934771780889), (u'special', 0.005273934771780889), (u'boundary', 0.005273934771780889), (u'region', 0.005273934771780889), (u'indefinite', 0.005273934771780889), (u'particular', 0.005273934771780889), (u'distinguished', 0.005273934771780889), (u'geographical', 0.005273934771780889), (u'usually', 0.005273934771780889), (u'purpose', 0.005273934771780889), (u'item', 0.001373626373626374), (u'None', 0.001373626373626374), (u'use', 0.001373626373626374), (u'providing', 0.001373626373626374), (u'official', 0.001373626373626374), (u'purposes', 0.001373626373626374), (u'general', 0.001373626373626374), (u'quantity', 0.001373626373626374)]
==========================================================================================================
Alternative Quantitative Intrinsic Merit  - connectivity of RGO Definition Graph - Mengers Theorem
==========================================================================================================
0
==========================================================================================================
Alternative Quantitative Intrinsic Merit  - Maxflow-Mincut of RGO Definition Graph - Minimum Edge Cut
==========================================================================================================
==========================================================================================================
Alternative Quantitative Intrinsic Merit  - Maxflow-Mincut of RGO Definition Graph - Stoer-Wagner
==========================================================================================================
shnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:14:23 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:14:23 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:14:23 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:14:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 16:14:23 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 16:14:23 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:14:23 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1132178964
16/03/16 16:14:23 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1079.7 MB)
16/03/16 16:14:23 INFO MemoryStore: ensureFreeSpace(4141) called with curMem=6568, maxMem=1132178964
16/03/16 16:14:23 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1079.7 MB)
16/03/16 16:14:23 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:47333 (size: 4.0 KB, free: 1079.7 MB)
16/03/16 16:14:23 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 16:14:23 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:14:23 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 16:14:23 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 16:14:23 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 16:14:23 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125063094
16/03/16 16:14:23 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-29676747-1513-4814-9fb6-9739cb19a9c3/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: area
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: issue
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: planning
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: permission
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: economy
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: composition
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: agency
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 16:14:31 INFO PythonRunner: Times: total = 7757, boot = 455, init = 353, finish = 6949
16/03/16 16:14:31 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 16:14:31 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 16:14:31 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 16:14:31 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7842 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: set
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): adding to parents: syn =  Synset('set.n.01') ; keyword:  belong  in syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: bend
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: giant
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: astatine
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: present
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: area
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
16/03/16 16:14:31 INFO PythonRunner: Times: total = 267, boot = 169, init = 0, finish = 98
16/03/16 16:14:31 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 16:14:31 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.130 s
16/03/16 16:14:31 INFO DAGScheduler: looking for newly runnable stages
16/03/16 16:14:31 INFO DAGScheduler: running: Set()
16/03/16 16:14:31 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 16:14:31 INFO DAGScheduler: failed: Set()
16/03/16 16:14:31 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 16:14:31 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 16:14:31 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10709, maxMem=1132178964
16/03/16 16:14:31 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1079.7 MB)
16/03/16 16:14:31 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15693, maxMem=1132178964
16/03/16 16:14:31 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1079.7 MB)
16/03/16 16:14:31 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 299 ms on localhost (2/2)
16/03/16 16:14:31 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 16:14:31 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:47333 (size: 3.0 KB, free: 1079.7 MB)
16/03/16 16:14:31 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 16:14:31 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:14:31 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 16:14:31 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:14:31 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 16:14:31 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:14:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 16:14:31 INFO PythonRunner: Times: total = 170, boot = 169, init = 1, finish = 0
16/03/16 16:14:31 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 16:14:31 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:14:31 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 16:14:31 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:14:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/16 16:14:31 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 200 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'set']
16/03/16 16:14:31 INFO PythonRunner: Times: total = 177, boot = 176, init = 0, finish = 1
16/03/16 16:14:31 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1229 bytes result sent to driver
16/03/16 16:14:31 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 229 ms on localhost (2/2)
16/03/16 16:14:31 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 16:14:31 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.404 s
16/03/16 16:14:31 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.565030 s
16/03/16 16:14:31 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:14:31 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:14:31 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:14:31 INFO DAGScheduler: Parents of final stage: List()
16/03/16 16:14:31 INFO DAGScheduler: Missing parents: List()
16/03/16 16:14:31 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:14:31 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18741, maxMem=1132178964
16/03/16 16:14:31 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1079.7 MB)
16/03/16 16:14:31 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24557, maxMem=1132178964
16/03/16 16:14:31 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1079.7 MB)
16/03/16 16:14:31 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:47333 (size: 3.3 KB, free: 1079.7 MB)
16/03/16 16:14:31 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 16:14:31 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:14:31 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 16:14:31 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 16:14:31 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 16:14:32 INFO PythonRunner: Times: total = 19, boot = 1, init = 18, finish = 0
16/03/16 16:14:32 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 16:14:32 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2259 bytes)
16/03/16 16:14:32 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 44 ms on localhost (1/2)
16/03/16 16:14:32 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 16:14:32 INFO PythonRunner: Times: total = 164, boot = 164, init = 0, finish = 0
16/03/16 16:14:32 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1295 bytes result sent to driver
16/03/16 16:14:32 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.225 s
16/03/16 16:14:32 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.286528 s
16/03/16 16:14:32 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 201 ms on localhost (2/2)
16/03/16 16:14:32 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 16:14:32 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 16:14:32 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 16:14:32 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 16:14:32 INFO MemoryStore: MemoryStore cleared
16/03/16 16:14:32 INFO BlockManager: BlockManager stopped
16/03/16 16:14:32 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 16:14:32 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 16:14:32 INFO SparkContext: Successfully stopped SparkContext
16/03/16 16:14:32 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 16:14:32 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 16:14:32 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'set']
16/03/16 16:14:33 INFO SparkContext: Running Spark version 1.5.2
16/03/16 16:14:33 INFO SecurityManager: Changing view acls to: root
16/03/16 16:14:33 INFO SecurityManager: Changing modify acls to: root
16/03/16 16:14:33 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 16:14:33 INFO Slf4jLogger: Slf4jLogger started
16/03/16 16:14:33 INFO Remoting: Starting remoting
16/03/16 16:14:33 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:49896]
16/03/16 16:14:33 INFO Utils: Successfully started service 'sparkDriver' on port 49896.
16/03/16 16:14:33 INFO SparkEnv: Registering MapOutputTracker
16/03/16 16:14:33 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 16:14:33 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-94241a97-6af5-406f-9904-da2dad1a6855
16/03/16 16:14:33 INFO MemoryStore: MemoryStore started with capacity 1079.7 MB
16/03/16 16:14:33 INFO HttpFileServer: HTTP File server directory is /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/httpd-f5aeeb1e-9c5e-4de8-8a59-27f9ad55674a
16/03/16 16:14:33 INFO HttpServer: Starting HTTP Server
16/03/16 16:14:33 INFO Utils: Successfully started service 'HTTP file server' on port 57280.
16/03/16 16:14:33 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 16:14:33 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 16:14:33 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 16:14:33 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-137ef2eb-8ce5-41c0-a58f-f2956c1d038b/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 16:14:33 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125073507
16/03/16 16:14:33 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 16:14:33 INFO Executor: Starting executor ID driver on host localhost
16/03/16 16:14:33 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42892.
16/03/16 16:14:33 INFO NettyBlockTransferService: Server created on 42892
16/03/16 16:14:33 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 16:14:33 INFO BlockManagerMasterEndpoint: Registering block manager localhost:42892 with 1079.7 MB RAM, BlockManagerId(driver, localhost, 42892)
16/03/16 16:14:33 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): uranium
16/03/16 16:14:33 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:14:33 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:14:33 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:14:33 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:14:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 16:14:33 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 16:14:33 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:14:33 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1132178964
16/03/16 16:14:33 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1079.7 MB)
16/03/16 16:14:33 INFO MemoryStore: ensureFreeSpace(4141) called with curMem=6568, maxMem=1132178964
16/03/16 16:14:33 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1079.7 MB)
16/03/16 16:14:33 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:42892 (size: 4.0 KB, free: 1079.7 MB)
16/03/16 16:14:33 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 16:14:33 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:14:33 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 16:14:33 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 16:14:33 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 16:14:33 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125073507
16/03/16 16:14:33 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-137ef2eb-8ce5-41c0-a58f-f2956c1d038b/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: area
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: issue
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: planning
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: permission
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: economy
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: composition
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: agency
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 16:14:41 INFO PythonRunner: Times: total = 7833, boot = 471, init = 358, finish = 7004
16/03/16 16:14:41 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 16:14:41 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 16:14:41 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 16:14:41 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7921 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: set
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: bend
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: giant
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: astatine
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('astatine.n.01') ; keyword:  uranium  in syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= [u'astatine']
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: present
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: area
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
16/03/16 16:14:41 INFO PythonRunner: Times: total = 248, boot = 145, init = 1, finish = 102
16/03/16 16:14:41 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 16:14:41 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 282 ms on localhost (2/2)
16/03/16 16:14:41 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 16:14:41 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.200 s
16/03/16 16:14:41 INFO DAGScheduler: looking for newly runnable stages
16/03/16 16:14:41 INFO DAGScheduler: running: Set()
16/03/16 16:14:41 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 16:14:41 INFO DAGScheduler: failed: Set()
16/03/16 16:14:41 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 16:14:41 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 16:14:41 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10709, maxMem=1132178964
16/03/16 16:14:41 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1079.7 MB)
16/03/16 16:14:41 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15693, maxMem=1132178964
16/03/16 16:14:41 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1079.7 MB)
16/03/16 16:14:41 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:42892 (size: 3.0 KB, free: 1079.7 MB)
16/03/16 16:14:41 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 16:14:41 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:14:41 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 16:14:41 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:14:41 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 16:14:41 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:14:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
16/03/16 16:14:42 INFO PythonRunner: Times: total = 120, boot = 119, init = 1, finish = 0
16/03/16 16:14:42 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 16:14:42 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:14:42 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 16:14:42 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:14:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/16 16:14:42 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 163 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'astatine']
16/03/16 16:14:42 INFO PythonRunner: Times: total = 161, boot = 160, init = 0, finish = 1
16/03/16 16:14:42 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1242 bytes result sent to driver
16/03/16 16:14:42 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.315 s
16/03/16 16:14:42 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.562453 s
16/03/16 16:14:42 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 188 ms on localhost (2/2)
16/03/16 16:14:42 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 16:14:42 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:14:42 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:14:42 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:14:42 INFO DAGScheduler: Parents of final stage: List()
16/03/16 16:14:42 INFO DAGScheduler: Missing parents: List()
16/03/16 16:14:42 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:14:42 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18741, maxMem=1132178964
16/03/16 16:14:42 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1079.7 MB)
16/03/16 16:14:42 INFO MemoryStore: ensureFreeSpace(3373) called with curMem=24557, maxMem=1132178964
16/03/16 16:14:42 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1079.7 MB)
16/03/16 16:14:42 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:42892 (size: 3.3 KB, free: 1079.7 MB)
16/03/16 16:14:42 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 16:14:42 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:14:42 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 16:14:42 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 16:14:42 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 16:14:42 INFO PythonRunner: Times: total = 36, boot = 26, init = 10, finish = 0
16/03/16 16:14:42 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 16:14:42 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2272 bytes)
16/03/16 16:14:42 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 72 ms on localhost (1/2)
16/03/16 16:14:42 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 16:14:42 INFO PythonRunner: Times: total = 163, boot = 163, init = 0, finish = 0
16/03/16 16:14:42 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1311 bytes result sent to driver
16/03/16 16:14:42 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 194 ms on localhost (2/2)
16/03/16 16:14:42 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 16:14:42 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.252 s
16/03/16 16:14:42 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.301512 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 16:14:42 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 16:14:42 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 16:14:42 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 16:14:42 INFO MemoryStore: MemoryStore cleared
16/03/16 16:14:42 INFO BlockManager: BlockManager stopped
16/03/16 16:14:42 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 16:14:42 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 16:14:42 INFO SparkContext: Successfully stopped SparkContext
16/03/16 16:14:42 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 16:14:42 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 16:14:42 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'astatine']
16/03/16 16:14:43 INFO SparkContext: Running Spark version 1.5.2
16/03/16 16:14:43 INFO SecurityManager: Changing view acls to: root
16/03/16 16:14:43 INFO SecurityManager: Changing modify acls to: root
16/03/16 16:14:43 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 16:14:43 INFO Slf4jLogger: Slf4jLogger started
16/03/16 16:14:43 INFO Remoting: Starting remoting
16/03/16 16:14:43 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:42940]
16/03/16 16:14:43 INFO Utils: Successfully started service 'sparkDriver' on port 42940.
16/03/16 16:14:43 INFO SparkEnv: Registering MapOutputTracker
16/03/16 16:14:43 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 16:14:43 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-a1e10303-0ca7-4511-88f8-b4cc00fb5cd9
16/03/16 16:14:43 INFO MemoryStore: MemoryStore started with capacity 1079.7 MB
16/03/16 16:14:43 INFO HttpFileServer: HTTP File server directory is /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/httpd-152fdf45-1df2-431f-a92c-b89f8666cc76
16/03/16 16:14:43 INFO HttpServer: Starting HTTP Server
16/03/16 16:14:43 INFO Utils: Successfully started service 'HTTP file server' on port 42898.
16/03/16 16:14:43 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 16:14:43 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 16:14:43 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 16:14:43 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-25fe8f54-b95b-4a49-b248-388497d2f5d3/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 16:14:43 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125083924
16/03/16 16:14:43 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 16:14:43 INFO Executor: Starting executor ID driver on host localhost
16/03/16 16:14:44 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45035.
16/03/16 16:14:44 INFO NettyBlockTransferService: Server created on 45035
16/03/16 16:14:44 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 16:14:44 INFO BlockManagerMasterEndpoint: Registering block manager localhost:45035 with 1079.7 MB RAM, BlockManagerId(driver, localhost, 45035)
16/03/16 16:14:44 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): arrangement
16/03/16 16:14:44 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:14:44 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:14:44 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:14:44 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:14:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 16:14:44 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 16:14:44 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:14:44 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1132178964
16/03/16 16:14:44 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1079.7 MB)
16/03/16 16:14:44 INFO MemoryStore: ensureFreeSpace(4141) called with curMem=6568, maxMem=1132178964
16/03/16 16:14:44 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1079.7 MB)
16/03/16 16:14:44 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:45035 (size: 4.0 KB, free: 1079.7 MB)
16/03/16 16:14:44 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 16:14:44 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:14:44 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 16:14:44 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 16:14:44 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 16:14:44 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125083924
16/03/16 16:14:44 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-25fe8f54-b95b-4a49-b248-388497d2f5d3/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: area
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: issue
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: planning
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: permission
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: economy
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: composition
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): adding to parents: syn =  Synset('composition.n.01') ; keyword:  arrangement  in syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= [u'composition']
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: agency
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
16/03/16 16:14:51 INFO PythonRunner: Times: total = 7843, boot = 463, init = 354, finish = 7026
16/03/16 16:14:52 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 16:14:52 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 16:14:52 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 16:14:52 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7917 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: set
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: bend
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: giant
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: astatine
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: present
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: area
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 16:14:52 INFO PythonRunner: Times: total = 284, boot = 179, init = 1, finish = 104
16/03/16 16:14:52 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 16:14:52 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 326 ms on localhost (2/2)
16/03/16 16:14:52 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.244 s
16/03/16 16:14:52 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 16:14:52 INFO DAGScheduler: looking for newly runnable stages
16/03/16 16:14:52 INFO DAGScheduler: running: Set()
16/03/16 16:14:52 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 16:14:52 INFO DAGScheduler: failed: Set()
16/03/16 16:14:52 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 16:14:52 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 16:14:52 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10709, maxMem=1132178964
16/03/16 16:14:52 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1079.7 MB)
16/03/16 16:14:52 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15693, maxMem=1132178964
16/03/16 16:14:52 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1079.7 MB)
16/03/16 16:14:52 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:45035 (size: 3.0 KB, free: 1079.7 MB)
16/03/16 16:14:52 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 16:14:52 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:14:52 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 16:14:52 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:14:52 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 16:14:52 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:14:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/16 16:14:52 INFO PythonRunner: Times: total = 140, boot = 140, init = 0, finish = 0
16/03/16 16:14:52 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 16:14:52 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:14:52 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 16:14:52 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:14:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
16/03/16 16:14:52 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 157 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'composition', 'None']
16/03/16 16:14:52 INFO PythonRunner: Times: total = 165, boot = 164, init = 1, finish = 0
16/03/16 16:14:52 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1245 bytes result sent to driver
16/03/16 16:14:52 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 184 ms on localhost (2/2)
16/03/16 16:14:52 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 16:14:52 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.336 s
16/03/16 16:14:52 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.612768 s
16/03/16 16:14:52 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:14:52 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:14:52 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:14:52 INFO DAGScheduler: Parents of final stage: List()
16/03/16 16:14:52 INFO DAGScheduler: Missing parents: List()
16/03/16 16:14:52 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:14:52 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18741, maxMem=1132178964
16/03/16 16:14:52 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1079.7 MB)
16/03/16 16:14:52 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24557, maxMem=1132178964
16/03/16 16:14:52 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1079.7 MB)
16/03/16 16:14:52 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:45035 (size: 3.3 KB, free: 1079.7 MB)
16/03/16 16:14:52 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 16:14:52 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:14:52 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 16:14:52 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 16:14:52 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 16:14:52 INFO PythonRunner: Times: total = 59, boot = 58, init = 0, finish = 1
16/03/16 16:14:52 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 16:14:52 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2275 bytes)
16/03/16 16:14:52 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 74 ms on localhost (1/2)
16/03/16 16:14:52 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 16:14:53 INFO PythonRunner: Times: total = 177, boot = 177, init = 0, finish = 0
16/03/16 16:14:53 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1314 bytes result sent to driver
16/03/16 16:14:53 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 192 ms on localhost (2/2)
16/03/16 16:14:53 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 16:14:53 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.262 s
16/03/16 16:14:53 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.291863 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 16:14:53 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 16:14:53 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 16:14:53 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 16:14:53 INFO MemoryStore: MemoryStore cleared
16/03/16 16:14:53 INFO BlockManager: BlockManager stopped
16/03/16 16:14:53 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 16:14:53 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 16:14:53 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 16:14:53 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 16:14:53 INFO SparkContext: Successfully stopped SparkContext
16/03/16 16:14:53 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'composition', u'None']
16/03/16 16:14:54 INFO SparkContext: Running Spark version 1.5.2
16/03/16 16:14:54 INFO SecurityManager: Changing view acls to: root
16/03/16 16:14:54 INFO SecurityManager: Changing modify acls to: root
16/03/16 16:14:54 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 16:14:54 INFO Slf4jLogger: Slf4jLogger started
16/03/16 16:14:54 INFO Remoting: Starting remoting
16/03/16 16:14:54 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:33857]
16/03/16 16:14:54 INFO Utils: Successfully started service 'sparkDriver' on port 33857.
16/03/16 16:14:54 INFO SparkEnv: Registering MapOutputTracker
16/03/16 16:14:54 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 16:14:54 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-cfb77262-dc7d-4cbe-8534-1c915734a444
16/03/16 16:14:54 INFO MemoryStore: MemoryStore started with capacity 1079.7 MB
16/03/16 16:14:54 INFO HttpFileServer: HTTP File server directory is /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/httpd-ec4c8179-4358-4e5a-b5cd-7d7f67dc1220
16/03/16 16:14:54 INFO HttpServer: Starting HTTP Server
16/03/16 16:14:54 INFO Utils: Successfully started service 'HTTP file server' on port 53844.
16/03/16 16:14:54 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 16:14:54 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 16:14:54 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 16:14:54 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-1c553bd8-144c-467e-a6c8-3ecc5bae484e/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 16:14:54 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125094342
16/03/16 16:14:54 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 16:14:54 INFO Executor: Starting executor ID driver on host localhost
16/03/16 16:14:54 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37401.
16/03/16 16:14:54 INFO NettyBlockTransferService: Server created on 37401
16/03/16 16:14:54 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 16:14:54 INFO BlockManagerMasterEndpoint: Registering block manager localhost:37401 with 1079.7 MB RAM, BlockManagerId(driver, localhost, 37401)
16/03/16 16:14:54 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): parts
16/03/16 16:14:54 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:14:54 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:14:54 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:14:54 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:14:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 16:14:54 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 16:14:54 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:14:54 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1132178964
16/03/16 16:14:54 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1079.7 MB)
16/03/16 16:14:54 INFO MemoryStore: ensureFreeSpace(4141) called with curMem=6568, maxMem=1132178964
16/03/16 16:14:54 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1079.7 MB)
16/03/16 16:14:54 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:37401 (size: 4.0 KB, free: 1079.7 MB)
16/03/16 16:14:54 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 16:14:54 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:14:54 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 16:14:54 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 16:14:54 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 16:14:54 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125094342
16/03/16 16:14:54 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-1c553bd8-144c-467e-a6c8-3ecc5bae484e/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: area
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: issue
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: planning
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: permission
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: economy
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: composition
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): adding to parents: syn =  Synset('composition.n.01') ; keyword:  parts  in syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= [u'composition']
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: agency
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
16/03/16 16:15:04 INFO PythonRunner: Times: total = 9445, boot = 457, init = 358, finish = 8630
16/03/16 16:15:04 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 16:15:04 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 16:15:04 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 16:15:04 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9547 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: set
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: bend
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: giant
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: astatine
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: present
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: area
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 16:15:04 INFO PythonRunner: Times: total = 408, boot = 243, init = 2, finish = 163
16/03/16 16:15:04 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 16:15:04 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 9.990 s
16/03/16 16:15:04 INFO DAGScheduler: looking for newly runnable stages
16/03/16 16:15:04 INFO DAGScheduler: running: Set()
16/03/16 16:15:04 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 16:15:04 INFO DAGScheduler: failed: Set()
16/03/16 16:15:04 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 16:15:04 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 16:15:04 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 453 ms on localhost (2/2)
16/03/16 16:15:04 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 16:15:04 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10709, maxMem=1132178964
16/03/16 16:15:04 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1079.7 MB)
16/03/16 16:15:04 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15693, maxMem=1132178964
16/03/16 16:15:04 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1079.7 MB)
16/03/16 16:15:04 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:37401 (size: 3.0 KB, free: 1079.7 MB)
16/03/16 16:15:04 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 16:15:04 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:15:04 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 16:15:04 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:15:04 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 16:15:04 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:15:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 16:15:04 INFO PythonRunner: Times: total = 14, boot = -117, init = 130, finish = 1
16/03/16 16:15:04 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 16:15:05 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:15:05 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 16:15:05 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 63 ms on localhost (1/2)
16/03/16 16:15:05 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:15:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
reduceFunction_Parents(): returns= ['None', u'composition', 'None']
16/03/16 16:15:05 INFO PythonRunner: Times: total = 192, boot = 189, init = 0, finish = 3
16/03/16 16:15:05 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1245 bytes result sent to driver
16/03/16 16:15:05 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.287 s
16/03/16 16:15:05 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 232 ms on localhost (2/2)
16/03/16 16:15:05 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 16:15:05 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 10.765643 s
16/03/16 16:15:05 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:15:05 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:15:05 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:15:05 INFO DAGScheduler: Parents of final stage: List()
16/03/16 16:15:05 INFO DAGScheduler: Missing parents: List()
16/03/16 16:15:05 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:15:05 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18741, maxMem=1132178964
16/03/16 16:15:05 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1079.7 MB)
16/03/16 16:15:05 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24557, maxMem=1132178964
16/03/16 16:15:05 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1079.7 MB)
16/03/16 16:15:05 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:37401 (size: 3.3 KB, free: 1079.7 MB)
16/03/16 16:15:05 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 16:15:05 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:15:05 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 16:15:05 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 16:15:05 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 16:15:05 INFO PythonRunner: Times: total = 113, boot = 113, init = 0, finish = 0
16/03/16 16:15:05 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 16:15:05 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2275 bytes)
16/03/16 16:15:05 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 132 ms on localhost (1/2)
16/03/16 16:15:05 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 16:15:05 INFO PythonRunner: Times: total = 213, boot = 213, init = 0, finish = 0
16/03/16 16:15:05 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1314 bytes result sent to driver
16/03/16 16:15:05 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 228 ms on localhost (2/2)
16/03/16 16:15:05 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 16:15:05 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.355 s
16/03/16 16:15:05 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.372806 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 16:15:05 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 16:15:05 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 16:15:05 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 16:15:05 INFO MemoryStore: MemoryStore cleared
16/03/16 16:15:05 INFO BlockManager: BlockManager stopped
16/03/16 16:15:05 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 16:15:05 INFO SparkContext: Successfully stopped SparkContext
16/03/16 16:15:05 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 16:15:05 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 16:15:05 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 16:15:05 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'composition', u'None']
16/03/16 16:15:06 INFO SparkContext: Running Spark version 1.5.2
16/03/16 16:15:06 INFO SecurityManager: Changing view acls to: root
16/03/16 16:15:06 INFO SecurityManager: Changing modify acls to: root
16/03/16 16:15:06 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 16:15:06 INFO Slf4jLogger: Slf4jLogger started
16/03/16 16:15:06 INFO Remoting: Starting remoting
16/03/16 16:15:06 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:47745]
16/03/16 16:15:06 INFO Utils: Successfully started service 'sparkDriver' on port 47745.
16/03/16 16:15:06 INFO SparkEnv: Registering MapOutputTracker
16/03/16 16:15:06 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 16:15:06 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-c4cf4363-95a8-42ef-97cd-e73baee3f8ce
16/03/16 16:15:06 INFO MemoryStore: MemoryStore started with capacity 1081.1 MB
16/03/16 16:15:06 INFO HttpFileServer: HTTP File server directory is /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/httpd-ffbf2c79-b371-4dd2-8412-2064d9cd10ce
16/03/16 16:15:06 INFO HttpServer: Starting HTTP Server
16/03/16 16:15:07 INFO Utils: Successfully started service 'HTTP file server' on port 52943.
16/03/16 16:15:07 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 16:15:07 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 16:15:07 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 16:15:07 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-d7592fe7-b9af-44d5-afa0-fe8956d6b995/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 16:15:07 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125107181
16/03/16 16:15:07 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 16:15:07 INFO Executor: Starting executor ID driver on host localhost
16/03/16 16:15:07 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37559.
16/03/16 16:15:07 INFO NettyBlockTransferService: Server created on 37559
16/03/16 16:15:07 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 16:15:07 INFO BlockManagerMasterEndpoint: Registering block manager localhost:37559 with 1081.1 MB RAM, BlockManagerId(driver, localhost, 37559)
16/03/16 16:15:07 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): speech
16/03/16 16:15:07 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:15:07 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:15:07 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:15:07 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:15:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 16:15:07 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 16:15:07 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:15:07 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1133594542
16/03/16 16:15:07 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1081.1 MB)
16/03/16 16:15:07 INFO MemoryStore: ensureFreeSpace(4142) called with curMem=6568, maxMem=1133594542
16/03/16 16:15:07 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1081.1 MB)
16/03/16 16:15:07 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:37559 (size: 4.0 KB, free: 1081.1 MB)
16/03/16 16:15:07 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 16:15:07 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:15:07 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 16:15:07 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 16:15:07 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 16:15:07 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125107181
16/03/16 16:15:07 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-d7592fe7-b9af-44d5-afa0-fe8956d6b995/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: area
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: issue
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: planning
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: permission
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: economy
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: composition
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: agency
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 16:15:16 INFO PythonRunner: Times: total = 9263, boot = 494, init = 433, finish = 8336
16/03/16 16:15:16 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 16:15:16 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 16:15:16 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 16:15:16 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9382 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: set
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: bend
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: giant
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: astatine
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: present
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('present.n.01') ; keyword:  speech  in syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= [u'present']
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: area
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
16/03/16 16:15:17 INFO PythonRunner: Times: total = 329, boot = 218, init = 1, finish = 110
16/03/16 16:15:17 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 16:15:17 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 372 ms on localhost (2/2)
16/03/16 16:15:17 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 9.736 s
16/03/16 16:15:17 INFO DAGScheduler: looking for newly runnable stages
16/03/16 16:15:17 INFO DAGScheduler: running: Set()
16/03/16 16:15:17 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 16:15:17 INFO DAGScheduler: failed: Set()
16/03/16 16:15:17 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 16:15:17 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 16:15:17 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10710, maxMem=1133594542
16/03/16 16:15:17 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1081.1 MB)
16/03/16 16:15:17 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 16:15:17 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15694, maxMem=1133594542
16/03/16 16:15:17 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1081.1 MB)
16/03/16 16:15:17 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:37559 (size: 3.0 KB, free: 1081.1 MB)
16/03/16 16:15:17 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 16:15:17 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:15:17 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 16:15:17 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:15:17 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 16:15:17 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:15:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/16 16:15:17 INFO PythonRunner: Times: total = 204, boot = 204, init = 0, finish = 0
16/03/16 16:15:17 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 16:15:17 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:15:17 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 16:15:17 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:15:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/16 16:15:17 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 232 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'present']
16/03/16 16:15:17 INFO PythonRunner: Times: total = 207, boot = 205, init = 0, finish = 2
16/03/16 16:15:17 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1241 bytes result sent to driver
16/03/16 16:15:17 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.447 s
16/03/16 16:15:17 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 10.237558 s
16/03/16 16:15:17 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 227 ms on localhost (2/2)
16/03/16 16:15:17 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 16:15:17 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:15:17 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:15:17 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:15:17 INFO DAGScheduler: Parents of final stage: List()
16/03/16 16:15:17 INFO DAGScheduler: Missing parents: List()
16/03/16 16:15:17 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:15:17 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18742, maxMem=1133594542
16/03/16 16:15:17 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1081.1 MB)
16/03/16 16:15:17 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24558, maxMem=1133594542
16/03/16 16:15:17 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1081.1 MB)
16/03/16 16:15:17 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:37559 (size: 3.3 KB, free: 1081.1 MB)
16/03/16 16:15:17 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 16:15:17 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:15:17 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 16:15:17 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 16:15:17 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 16:15:17 INFO PythonRunner: Times: total = 64, boot = 64, init = 0, finish = 0
16/03/16 16:15:17 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 16:15:17 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2271 bytes)
16/03/16 16:15:17 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 16:15:17 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 79 ms on localhost (1/2)
16/03/16 16:15:18 INFO PythonRunner: Times: total = 222, boot = 221, init = 0, finish = 1
16/03/16 16:15:18 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1310 bytes result sent to driver
16/03/16 16:15:18 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 238 ms on localhost (2/2)
16/03/16 16:15:18 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 16:15:18 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.306 s
16/03/16 16:15:18 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.333293 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 16:15:18 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 16:15:18 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 16:15:18 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 16:15:18 INFO MemoryStore: MemoryStore cleared
16/03/16 16:15:18 INFO BlockManager: BlockManager stopped
16/03/16 16:15:18 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 16:15:18 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 16:15:18 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 16:15:18 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 16:15:18 INFO SparkContext: Successfully stopped SparkContext
16/03/16 16:15:18 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'present']
16/03/16 16:15:19 INFO SparkContext: Running Spark version 1.5.2
16/03/16 16:15:19 INFO SecurityManager: Changing view acls to: root
16/03/16 16:15:19 INFO SecurityManager: Changing modify acls to: root
16/03/16 16:15:19 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 16:15:19 INFO Slf4jLogger: Slf4jLogger started
16/03/16 16:15:19 INFO Remoting: Starting remoting
16/03/16 16:15:19 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:51207]
16/03/16 16:15:19 INFO Utils: Successfully started service 'sparkDriver' on port 51207.
16/03/16 16:15:19 INFO SparkEnv: Registering MapOutputTracker
16/03/16 16:15:19 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 16:15:19 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-1fc0e949-c34a-434b-ac2e-1cf4e1e9ce86
16/03/16 16:15:19 INFO MemoryStore: MemoryStore started with capacity 1081.1 MB
16/03/16 16:15:19 INFO HttpFileServer: HTTP File server directory is /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/httpd-992de2c7-6e60-4f66-93c9-9933514b30c6
16/03/16 16:15:19 INFO HttpServer: Starting HTTP Server
16/03/16 16:15:19 INFO Utils: Successfully started service 'HTTP file server' on port 46478.
16/03/16 16:15:19 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 16:15:19 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 16:15:19 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 16:15:19 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-ac11c308-74a0-46d5-98cb-3544f0280afc/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 16:15:19 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125119558
16/03/16 16:15:19 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 16:15:19 INFO Executor: Starting executor ID driver on host localhost
16/03/16 16:15:19 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49958.
16/03/16 16:15:19 INFO NettyBlockTransferService: Server created on 49958
16/03/16 16:15:19 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 16:15:19 INFO BlockManagerMasterEndpoint: Registering block manager localhost:49958 with 1081.1 MB RAM, BlockManagerId(driver, localhost, 49958)
16/03/16 16:15:19 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): geographical
16/03/16 16:15:19 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:15:19 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:15:19 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:15:19 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:15:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 16:15:19 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 16:15:19 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:15:19 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1133594542
16/03/16 16:15:19 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1081.1 MB)
16/03/16 16:15:19 INFO MemoryStore: ensureFreeSpace(4141) called with curMem=6568, maxMem=1133594542
16/03/16 16:15:19 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1081.1 MB)
16/03/16 16:15:19 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:49958 (size: 4.0 KB, free: 1081.1 MB)
16/03/16 16:15:19 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 16:15:19 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:15:19 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 16:15:19 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 16:15:19 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 16:15:19 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125119558
16/03/16 16:15:19 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-ac11c308-74a0-46d5-98cb-3544f0280afc/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: area
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  geographical  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: issue
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: planning
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: permission
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: economy
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: composition
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: agency
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
16/03/16 16:15:30 INFO PythonRunner: Times: total = 10452, boot = 511, init = 398, finish = 9543
16/03/16 16:15:30 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 16:15:30 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 16:15:30 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 16:15:30 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 10564 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: set
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: bend
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: giant
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: astatine
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: present
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: area
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  geographical  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
16/03/16 16:15:30 INFO PythonRunner: Times: total = 291, boot = 187, init = 1, finish = 103
16/03/16 16:15:30 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 16:15:30 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 327 ms on localhost (2/2)
16/03/16 16:15:30 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 16:15:30 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 10.898 s
16/03/16 16:15:30 INFO DAGScheduler: looking for newly runnable stages
16/03/16 16:15:30 INFO DAGScheduler: running: Set()
16/03/16 16:15:30 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 16:15:30 INFO DAGScheduler: failed: Set()
16/03/16 16:15:30 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 16:15:30 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 16:15:30 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10709, maxMem=1133594542
16/03/16 16:15:30 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1081.1 MB)
16/03/16 16:15:30 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15693, maxMem=1133594542
16/03/16 16:15:30 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1081.1 MB)
16/03/16 16:15:30 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:49958 (size: 3.0 KB, free: 1081.1 MB)
16/03/16 16:15:30 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 16:15:30 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:15:30 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 16:15:30 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:15:30 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 16:15:30 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:15:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 16:15:30 INFO PythonRunner: Times: total = 149, boot = 149, init = 0, finish = 0
16/03/16 16:15:30 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 16:15:30 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:15:30 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 16:15:30 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:15:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 16:15:30 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 178 ms on localhost (1/2)
reduceFunction_Parents(): returns= [u'area', 'None', u'area']
16/03/16 16:15:31 INFO PythonRunner: Times: total = 324, boot = 323, init = 1, finish = 0
16/03/16 16:15:31 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1241 bytes result sent to driver
16/03/16 16:15:31 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.518 s
16/03/16 16:15:31 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 11.447292 s
16/03/16 16:15:31 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 350 ms on localhost (2/2)
16/03/16 16:15:31 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 16:15:31 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:15:31 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:15:31 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:15:31 INFO DAGScheduler: Parents of final stage: List()
16/03/16 16:15:31 INFO DAGScheduler: Missing parents: List()
16/03/16 16:15:31 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:15:31 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18741, maxMem=1133594542
16/03/16 16:15:31 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1081.1 MB)
16/03/16 16:15:31 INFO MemoryStore: ensureFreeSpace(3374) called with curMem=24557, maxMem=1133594542
16/03/16 16:15:31 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1081.1 MB)
16/03/16 16:15:31 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:49958 (size: 3.3 KB, free: 1081.1 MB)
16/03/16 16:15:31 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 16:15:31 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:15:31 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 16:15:31 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 16:15:31 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 16:15:31 INFO PythonRunner: Times: total = 214, boot = 214, init = 0, finish = 0
16/03/16 16:15:31 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 16:15:31 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2271 bytes)
16/03/16 16:15:31 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 243 ms on localhost (1/2)
16/03/16 16:15:31 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 16:15:31 INFO PythonRunner: Times: total = 234, boot = 233, init = 0, finish = 1
16/03/16 16:15:31 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1307 bytes result sent to driver
16/03/16 16:15:31 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 275 ms on localhost (2/2)
16/03/16 16:15:31 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.490 s
16/03/16 16:15:31 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.566703 s
16/03/16 16:15:31 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 16:15:32 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 16:15:32 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 16:15:32 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 16:15:32 INFO MemoryStore: MemoryStore cleared
16/03/16 16:15:32 INFO BlockManager: BlockManager stopped
16/03/16 16:15:32 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 16:15:32 INFO SparkContext: Successfully stopped SparkContext
16/03/16 16:15:32 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 16:15:32 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 16:15:32 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 16:15:32 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'area', u'None', u'area']
16/03/16 16:15:32 INFO SparkContext: Running Spark version 1.5.2
16/03/16 16:15:32 INFO SecurityManager: Changing view acls to: root
16/03/16 16:15:32 INFO SecurityManager: Changing modify acls to: root
16/03/16 16:15:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 16:15:33 INFO Slf4jLogger: Slf4jLogger started
16/03/16 16:15:33 INFO Remoting: Starting remoting
16/03/16 16:15:33 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:53136]
16/03/16 16:15:33 INFO Utils: Successfully started service 'sparkDriver' on port 53136.
16/03/16 16:15:33 INFO SparkEnv: Registering MapOutputTracker
16/03/16 16:15:33 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 16:15:33 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-afb83dc9-daca-428f-9199-9bfb43cb23e3
16/03/16 16:15:33 INFO MemoryStore: MemoryStore started with capacity 1081.1 MB
16/03/16 16:15:33 INFO HttpFileServer: HTTP File server directory is /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/httpd-1060c6cf-dcac-4ff3-bcc1-5bf86f33f8e4
16/03/16 16:15:33 INFO HttpServer: Starting HTTP Server
16/03/16 16:15:33 INFO Utils: Successfully started service 'HTTP file server' on port 59462.
16/03/16 16:15:33 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 16:15:33 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 16:15:33 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 16:15:33 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-248b61d3-6c1a-43fc-9831-6aaaa87fc188/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 16:15:33 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125133241
16/03/16 16:15:33 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 16:15:33 INFO Executor: Starting executor ID driver on host localhost
16/03/16 16:15:33 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34850.
16/03/16 16:15:33 INFO NettyBlockTransferService: Server created on 34850
16/03/16 16:15:33 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 16:15:33 INFO BlockManagerMasterEndpoint: Registering block manager localhost:34850 with 1081.1 MB RAM, BlockManagerId(driver, localhost, 34850)
16/03/16 16:15:33 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): spatial
16/03/16 16:15:33 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:15:33 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:15:33 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:15:33 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:15:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 16:15:33 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 16:15:33 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:15:33 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1133594542
16/03/16 16:15:33 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1081.1 MB)
16/03/16 16:15:33 INFO MemoryStore: ensureFreeSpace(4141) called with curMem=6568, maxMem=1133594542
16/03/16 16:15:33 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1081.1 MB)
16/03/16 16:15:33 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:34850 (size: 4.0 KB, free: 1081.1 MB)
16/03/16 16:15:33 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 16:15:33 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:15:33 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 16:15:33 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 16:15:33 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 16:15:33 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125133241
16/03/16 16:15:33 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-248b61d3-6c1a-43fc-9831-6aaaa87fc188/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: area
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: issue
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: planning
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: permission
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: economy
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: composition
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): adding to parents: syn =  Synset('composition.n.01') ; keyword:  spatial  in syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= [u'composition']
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: agency
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
16/03/16 16:15:41 INFO PythonRunner: Times: total = 7870, boot = 471, init = 412, finish = 6987
16/03/16 16:15:41 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 16:15:41 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 16:15:41 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 16:15:41 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7984 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: set
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: bend
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: giant
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: astatine
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: present
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: area
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 16:15:41 INFO PythonRunner: Times: total = 226, boot = 122, init = 1, finish = 103
16/03/16 16:15:41 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 16:15:41 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 293 ms on localhost (2/2)
16/03/16 16:15:41 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 16:15:41 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.255 s
16/03/16 16:15:41 INFO DAGScheduler: looking for newly runnable stages
16/03/16 16:15:41 INFO DAGScheduler: running: Set()
16/03/16 16:15:41 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 16:15:41 INFO DAGScheduler: failed: Set()
16/03/16 16:15:41 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 16:15:41 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 16:15:41 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10709, maxMem=1133594542
16/03/16 16:15:41 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1081.1 MB)
16/03/16 16:15:41 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15693, maxMem=1133594542
16/03/16 16:15:41 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1081.1 MB)
16/03/16 16:15:41 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:34850 (size: 3.0 KB, free: 1081.1 MB)
16/03/16 16:15:41 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 16:15:41 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:15:41 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 16:15:41 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:15:41 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 16:15:41 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:15:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 16:15:41 INFO PythonRunner: Times: total = 171, boot = 170, init = 1, finish = 0
16/03/16 16:15:41 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 16:15:41 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:15:41 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 16:15:41 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 185 ms on localhost (1/2)
16/03/16 16:15:41 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:15:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
reduceFunction_Parents(): returns= ['None', u'composition', 'None']
16/03/16 16:15:42 INFO PythonRunner: Times: total = 181, boot = 180, init = 1, finish = 0
16/03/16 16:15:42 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1245 bytes result sent to driver
16/03/16 16:15:42 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.378 s
16/03/16 16:15:42 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.674815 s
16/03/16 16:15:42 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 204 ms on localhost (2/2)
16/03/16 16:15:42 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 16:15:42 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:15:42 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:15:42 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:15:42 INFO DAGScheduler: Parents of final stage: List()
16/03/16 16:15:42 INFO DAGScheduler: Missing parents: List()
16/03/16 16:15:42 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:15:42 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18741, maxMem=1133594542
16/03/16 16:15:42 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1081.1 MB)
16/03/16 16:15:42 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24557, maxMem=1133594542
16/03/16 16:15:42 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1081.1 MB)
16/03/16 16:15:42 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:34850 (size: 3.3 KB, free: 1081.1 MB)
16/03/16 16:15:42 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 16:15:42 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:15:42 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 16:15:42 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 16:15:42 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 16:15:42 INFO PythonRunner: Times: total = 123, boot = 122, init = 1, finish = 0
16/03/16 16:15:42 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 16:15:42 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2275 bytes)
16/03/16 16:15:42 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 140 ms on localhost (1/2)
16/03/16 16:15:42 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 16:15:42 INFO PythonRunner: Times: total = 154, boot = 154, init = 0, finish = 0
16/03/16 16:15:42 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1314 bytes result sent to driver
16/03/16 16:15:42 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 176 ms on localhost (2/2)
16/03/16 16:15:42 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 16:15:42 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.311 s
16/03/16 16:15:42 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.351052 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 16:15:42 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 16:15:42 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 16:15:42 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 16:15:42 INFO MemoryStore: MemoryStore cleared
16/03/16 16:15:42 INFO BlockManager: BlockManager stopped
16/03/16 16:15:42 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 16:15:42 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 16:15:42 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 16:15:42 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 16:15:42 INFO SparkContext: Successfully stopped SparkContext
16/03/16 16:15:42 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'composition', u'None']
16/03/16 16:15:43 INFO SparkContext: Running Spark version 1.5.2
16/03/16 16:15:43 INFO SecurityManager: Changing view acls to: root
16/03/16 16:15:43 INFO SecurityManager: Changing modify acls to: root
16/03/16 16:15:43 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 16:15:43 INFO Slf4jLogger: Slf4jLogger started
16/03/16 16:15:43 INFO Remoting: Starting remoting
16/03/16 16:15:43 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:41294]
16/03/16 16:15:43 INFO Utils: Successfully started service 'sparkDriver' on port 41294.
16/03/16 16:15:43 INFO SparkEnv: Registering MapOutputTracker
16/03/16 16:15:43 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 16:15:43 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-d865a035-50d0-4f42-83a1-4120ec59fe7e
16/03/16 16:15:43 INFO MemoryStore: MemoryStore started with capacity 1081.1 MB
16/03/16 16:15:43 INFO HttpFileServer: HTTP File server directory is /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/httpd-06ed5def-23d1-45be-a461-5361868d7d54
16/03/16 16:15:43 INFO HttpServer: Starting HTTP Server
16/03/16 16:15:43 INFO Utils: Successfully started service 'HTTP file server' on port 41455.
16/03/16 16:15:43 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 16:15:43 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 16:15:43 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 16:15:43 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-7a5b5357-a5b6-4562-a35b-a06b88222738/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 16:15:43 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125143786
16/03/16 16:15:43 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 16:15:43 INFO Executor: Starting executor ID driver on host localhost
16/03/16 16:15:43 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57797.
16/03/16 16:15:43 INFO NettyBlockTransferService: Server created on 57797
16/03/16 16:15:43 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 16:15:43 INFO BlockManagerMasterEndpoint: Registering block manager localhost:57797 with 1081.1 MB RAM, BlockManagerId(driver, localhost, 57797)
16/03/16 16:15:43 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): Nadu
16/03/16 16:15:43 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:15:43 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:15:43 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:15:43 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:15:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 16:15:43 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 16:15:43 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:15:43 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1133594542
16/03/16 16:15:43 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1081.1 MB)
16/03/16 16:15:43 INFO MemoryStore: ensureFreeSpace(4140) called with curMem=6568, maxMem=1133594542
16/03/16 16:15:43 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1081.1 MB)
16/03/16 16:15:43 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:57797 (size: 4.0 KB, free: 1081.1 MB)
16/03/16 16:15:43 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 16:15:43 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:15:43 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 16:15:43 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 16:15:43 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 16:15:43 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125143786
16/03/16 16:15:43 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-7a5b5357-a5b6-4562-a35b-a06b88222738/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: area
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: issue
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: planning
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: permission
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: economy
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: composition
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: agency
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): adding to parents: syn =  Synset('chennai.n.01') ; keyword:  Nadu  in syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= [u'Chennai']
reduceFunction_Parents(): returns= ['None', u'Chennai']
16/03/16 16:15:51 INFO PythonRunner: Times: total = 7784, boot = 467, init = 363, finish = 6954
16/03/16 16:15:51 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 16:15:51 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 16:15:51 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 16:15:51 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7873 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: set
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: bend
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: giant
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: astatine
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: present
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): adding to parents: syn =  Synset('chennai.n.01') ; keyword:  Nadu  in syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= [u'Chennai']
reduceFunction_Parents(): returns= ['None', u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: area
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'Chennai']
16/03/16 16:15:52 INFO PythonRunner: Times: total = 303, boot = 185, init = 1, finish = 117
16/03/16 16:15:52 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 16:15:52 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.180 s
16/03/16 16:15:52 INFO DAGScheduler: looking for newly runnable stages
16/03/16 16:15:52 INFO DAGScheduler: running: Set()
16/03/16 16:15:52 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 16:15:52 INFO DAGScheduler: failed: Set()
16/03/16 16:15:52 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 16:15:52 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 16:15:52 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10708, maxMem=1133594542
16/03/16 16:15:52 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1081.1 MB)
16/03/16 16:15:52 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 332 ms on localhost (2/2)
16/03/16 16:15:52 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 16:15:52 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15692, maxMem=1133594542
16/03/16 16:15:52 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1081.1 MB)
16/03/16 16:15:52 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:57797 (size: 3.0 KB, free: 1081.1 MB)
16/03/16 16:15:52 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 16:15:52 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:15:52 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 16:15:52 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:15:52 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 16:15:52 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:15:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/16 16:15:52 INFO PythonRunner: Times: total = 142, boot = 141, init = 1, finish = 0
16/03/16 16:15:52 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 16:15:52 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:15:52 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 16:15:52 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:15:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/16 16:15:52 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 180 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'Chennai', 'None', u'Chennai']
16/03/16 16:15:52 INFO PythonRunner: Times: total = 170, boot = 169, init = 0, finish = 1
16/03/16 16:15:52 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1255 bytes result sent to driver
16/03/16 16:15:52 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 186 ms on localhost (2/2)
16/03/16 16:15:52 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.338 s
16/03/16 16:15:52 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.552292 s
16/03/16 16:15:52 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 16:15:52 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:15:52 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:15:52 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:15:52 INFO DAGScheduler: Parents of final stage: List()
16/03/16 16:15:52 INFO DAGScheduler: Missing parents: List()
16/03/16 16:15:52 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:15:52 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18740, maxMem=1133594542
16/03/16 16:15:52 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1081.1 MB)
16/03/16 16:15:52 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24556, maxMem=1133594542
16/03/16 16:15:52 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1081.1 MB)
16/03/16 16:15:52 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:57797 (size: 3.3 KB, free: 1081.1 MB)
16/03/16 16:15:52 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 16:15:52 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:15:52 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 16:15:52 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 16:15:52 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 16:15:52 INFO PythonRunner: Times: total = 164, boot = 164, init = 0, finish = 0
16/03/16 16:15:52 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 16:15:52 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2285 bytes)
16/03/16 16:15:52 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 182 ms on localhost (1/2)
16/03/16 16:15:52 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 16:15:52 INFO PythonRunner: Times: total = 172, boot = 172, init = 0, finish = 0
16/03/16 16:15:52 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1324 bytes result sent to driver
16/03/16 16:15:52 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 188 ms on localhost (2/2)
16/03/16 16:15:52 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 16:15:52 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.356 s
16/03/16 16:15:52 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.377130 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 16:15:53 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 16:15:53 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 16:15:53 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 16:15:53 INFO MemoryStore: MemoryStore cleared
16/03/16 16:15:53 INFO BlockManager: BlockManager stopped
16/03/16 16:15:53 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 16:15:53 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 16:15:53 INFO SparkContext: Successfully stopped SparkContext
16/03/16 16:15:53 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 16:15:53 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 16:15:53 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'Chennai', u'None', u'Chennai']
16/03/16 16:15:53 INFO SparkContext: Running Spark version 1.5.2
16/03/16 16:15:53 INFO SecurityManager: Changing view acls to: root
16/03/16 16:15:53 INFO SecurityManager: Changing modify acls to: root
16/03/16 16:15:53 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 16:15:54 INFO Slf4jLogger: Slf4jLogger started
16/03/16 16:15:54 INFO Remoting: Starting remoting
16/03/16 16:15:54 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:60966]
16/03/16 16:15:54 INFO Utils: Successfully started service 'sparkDriver' on port 60966.
16/03/16 16:15:54 INFO SparkEnv: Registering MapOutputTracker
16/03/16 16:15:54 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 16:15:54 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-facc572d-5cf6-4412-9758-cfed6686a47b
16/03/16 16:15:54 INFO MemoryStore: MemoryStore started with capacity 1081.1 MB
16/03/16 16:15:54 INFO HttpFileServer: HTTP File server directory is /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/httpd-e79a16ca-b242-4206-9d5e-5cd6936a1637
16/03/16 16:15:54 INFO HttpServer: Starting HTTP Server
16/03/16 16:15:54 INFO Utils: Successfully started service 'HTTP file server' on port 38293.
16/03/16 16:15:54 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 16:15:54 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 16:15:54 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 16:15:54 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-1d0eb567-32d0-4b98-b41c-c8925cead094/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 16:15:54 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125154254
16/03/16 16:15:54 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 16:15:54 INFO Executor: Starting executor ID driver on host localhost
16/03/16 16:15:54 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37498.
16/03/16 16:15:54 INFO NettyBlockTransferService: Server created on 37498
16/03/16 16:15:54 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 16:15:54 INFO BlockManagerMasterEndpoint: Registering block manager localhost:37498 with 1081.1 MB RAM, BlockManagerId(driver, localhost, 37498)
16/03/16 16:15:54 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): circular
16/03/16 16:15:54 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:15:54 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:15:54 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:15:54 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:15:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 16:15:54 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 16:15:54 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:15:54 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1133594542
16/03/16 16:15:54 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1081.1 MB)
16/03/16 16:15:54 INFO MemoryStore: ensureFreeSpace(4141) called with curMem=6568, maxMem=1133594542
16/03/16 16:15:54 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1081.1 MB)
16/03/16 16:15:54 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:37498 (size: 4.0 KB, free: 1081.1 MB)
16/03/16 16:15:54 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 16:15:54 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:15:54 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 16:15:54 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 16:15:54 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 16:15:54 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125154254
16/03/16 16:15:54 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-1d0eb567-32d0-4b98-b41c-c8925cead094/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: area
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: issue
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: planning
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: permission
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: economy
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: composition
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: agency
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 16:16:02 INFO PythonRunner: Times: total = 8032, boot = 460, init = 362, finish = 7210
16/03/16 16:16:02 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 16:16:02 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 16:16:02 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 16:16:02 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8160 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: set
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: bend
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): adding to parents: syn =  Synset('bend.n.01') ; keyword:  circular  in syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= [u'bend']
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: giant
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: astatine
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: present
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: area
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
16/03/16 16:16:02 INFO PythonRunner: Times: total = 220, boot = 115, init = 0, finish = 105
16/03/16 16:16:02 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 16:16:02 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.459 s
16/03/16 16:16:02 INFO DAGScheduler: looking for newly runnable stages
16/03/16 16:16:02 INFO DAGScheduler: running: Set()
16/03/16 16:16:02 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 16:16:02 INFO DAGScheduler: failed: Set()
16/03/16 16:16:02 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 16:16:02 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 16:16:02 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10709, maxMem=1133594542
16/03/16 16:16:02 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 302 ms on localhost (2/2)
16/03/16 16:16:02 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 16:16:02 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1081.1 MB)
16/03/16 16:16:02 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15693, maxMem=1133594542
16/03/16 16:16:02 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1081.1 MB)
16/03/16 16:16:02 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:37498 (size: 3.0 KB, free: 1081.1 MB)
16/03/16 16:16:02 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 16:16:02 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:02 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 16:16:02 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:16:02 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 16:16:02 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:16:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 16:16:03 INFO PythonRunner: Times: total = 128, boot = 127, init = 0, finish = 1
16/03/16 16:16:03 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 16:16:03 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:16:03 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 16:16:03 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:16:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 16:16:03 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 163 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'bend']
16/03/16 16:16:03 INFO PythonRunner: Times: total = 174, boot = 173, init = 1, finish = 0
16/03/16 16:16:03 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1230 bytes result sent to driver
16/03/16 16:16:03 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 193 ms on localhost (2/2)
16/03/16 16:16:03 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.342 s
16/03/16 16:16:03 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 16:16:03 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.847244 s
16/03/16 16:16:03 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:16:03 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:16:03 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:03 INFO DAGScheduler: Parents of final stage: List()
16/03/16 16:16:03 INFO DAGScheduler: Missing parents: List()
16/03/16 16:16:03 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:16:03 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18741, maxMem=1133594542
16/03/16 16:16:03 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1081.1 MB)
16/03/16 16:16:03 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24557, maxMem=1133594542
16/03/16 16:16:03 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1081.1 MB)
16/03/16 16:16:03 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:37498 (size: 3.3 KB, free: 1081.1 MB)
16/03/16 16:16:03 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 16:16:03 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:03 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 16:16:03 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 16:16:03 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 16:16:03 INFO PythonRunner: Times: total = 143, boot = 142, init = 1, finish = 0
16/03/16 16:16:03 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 16:16:03 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2260 bytes)
16/03/16 16:16:03 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 16:16:03 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 161 ms on localhost (1/2)
16/03/16 16:16:03 INFO PythonRunner: Times: total = 181, boot = 181, init = 0, finish = 0
16/03/16 16:16:03 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1296 bytes result sent to driver
16/03/16 16:16:03 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.343 s
16/03/16 16:16:03 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.393127 s
16/03/16 16:16:03 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 196 ms on localhost (2/2)
16/03/16 16:16:03 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 16:16:03 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 16:16:03 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 16:16:03 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 16:16:04 INFO MemoryStore: MemoryStore cleared
16/03/16 16:16:04 INFO BlockManager: BlockManager stopped
16/03/16 16:16:04 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 16:16:04 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 16:16:04 INFO SparkContext: Successfully stopped SparkContext
16/03/16 16:16:04 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 16:16:04 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 16:16:04 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'bend']
16/03/16 16:16:04 INFO SparkContext: Running Spark version 1.5.2
16/03/16 16:16:04 INFO SecurityManager: Changing view acls to: root
16/03/16 16:16:04 INFO SecurityManager: Changing modify acls to: root
16/03/16 16:16:04 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 16:16:04 INFO Slf4jLogger: Slf4jLogger started
16/03/16 16:16:04 INFO Remoting: Starting remoting
16/03/16 16:16:05 INFO Utils: Successfully started service 'sparkDriver' on port 33700.
16/03/16 16:16:05 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:33700]
16/03/16 16:16:05 INFO SparkEnv: Registering MapOutputTracker
16/03/16 16:16:05 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 16:16:05 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-d6160ab7-d8d8-43df-bc9b-b3b306488a62
16/03/16 16:16:05 INFO MemoryStore: MemoryStore started with capacity 1081.1 MB
16/03/16 16:16:05 INFO HttpFileServer: HTTP File server directory is /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/httpd-fbb79736-b72a-4612-8d7f-b377b93bd35b
16/03/16 16:16:05 INFO HttpServer: Starting HTTP Server
16/03/16 16:16:05 INFO Utils: Successfully started service 'HTTP file server' on port 33294.
16/03/16 16:16:05 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 16:16:05 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 16:16:05 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 16:16:05 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-630e0a33-d554-4d32-9945-94dac89170d6/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 16:16:05 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125165339
16/03/16 16:16:05 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 16:16:05 INFO Executor: Starting executor ID driver on host localhost
16/03/16 16:16:05 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 47991.
16/03/16 16:16:05 INFO NettyBlockTransferService: Server created on 47991
16/03/16 16:16:05 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 16:16:05 INFO BlockManagerMasterEndpoint: Registering block manager localhost:47991 with 1081.1 MB RAM, BlockManagerId(driver, localhost, 47991)
16/03/16 16:16:05 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): product
16/03/16 16:16:05 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:16:05 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:05 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:16:05 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 16:16:05 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 16:16:05 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:16:05 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1133594542
16/03/16 16:16:05 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1081.1 MB)
16/03/16 16:16:05 INFO MemoryStore: ensureFreeSpace(4141) called with curMem=6568, maxMem=1133594542
16/03/16 16:16:05 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1081.1 MB)
16/03/16 16:16:05 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:47991 (size: 4.0 KB, free: 1081.1 MB)
16/03/16 16:16:05 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 16:16:05 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:05 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 16:16:05 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 16:16:05 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 16:16:05 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125165339
16/03/16 16:16:05 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-630e0a33-d554-4d32-9945-94dac89170d6/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: area
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: issue
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: planning
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: permission
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: economy
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: composition
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: agency
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 16:16:14 INFO PythonRunner: Times: total = 8807, boot = 483, init = 355, finish = 7969
16/03/16 16:16:14 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 16:16:14 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 16:16:14 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 16:16:14 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8934 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: set
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: bend
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: giant
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: astatine
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('astatine.n.01') ; keyword:  product  in syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= [u'astatine']
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: present
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: area
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
16/03/16 16:16:14 INFO PythonRunner: Times: total = 370, boot = 244, init = 0, finish = 126
16/03/16 16:16:14 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 16:16:14 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 9.326 s
16/03/16 16:16:14 INFO DAGScheduler: looking for newly runnable stages
16/03/16 16:16:14 INFO DAGScheduler: running: Set()
16/03/16 16:16:14 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 16:16:14 INFO DAGScheduler: failed: Set()
16/03/16 16:16:14 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 16:16:14 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 16:16:14 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10709, maxMem=1133594542
16/03/16 16:16:14 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1081.1 MB)
16/03/16 16:16:14 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15693, maxMem=1133594542
16/03/16 16:16:14 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1081.1 MB)
16/03/16 16:16:14 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 410 ms on localhost (2/2)
16/03/16 16:16:14 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 16:16:14 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:47991 (size: 3.0 KB, free: 1081.1 MB)
16/03/16 16:16:14 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 16:16:14 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:14 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 16:16:14 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:16:14 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 16:16:14 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:16:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 16:16:15 INFO PythonRunner: Times: total = 229, boot = 228, init = 0, finish = 1
16/03/16 16:16:15 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 16:16:15 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:16:15 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 16:16:15 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:16:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 16:16:15 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 251 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'astatine']
16/03/16 16:16:15 INFO PythonRunner: Times: total = 494, boot = 263, init = 231, finish = 0
16/03/16 16:16:15 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1242 bytes result sent to driver
16/03/16 16:16:15 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:47991 in memory (size: 4.0 KB, free: 1081.1 MB)
16/03/16 16:16:15 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 563 ms on localhost (2/2)
16/03/16 16:16:15 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 16:16:15 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.833 s
16/03/16 16:16:15 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 10.185098 s
16/03/16 16:16:15 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:16:15 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:16:15 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:15 INFO DAGScheduler: Parents of final stage: List()
16/03/16 16:16:15 INFO DAGScheduler: Missing parents: List()
16/03/16 16:16:15 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:16:15 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=8032, maxMem=1133594542
16/03/16 16:16:15 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1081.1 MB)
16/03/16 16:16:15 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=13848, maxMem=1133594542
16/03/16 16:16:15 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1081.1 MB)
16/03/16 16:16:15 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:47991 (size: 3.3 KB, free: 1081.1 MB)
16/03/16 16:16:15 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 16:16:15 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:15 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 16:16:15 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 16:16:15 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 16:16:15 INFO PythonRunner: Times: total = 77, boot = 34, init = 43, finish = 0
16/03/16 16:16:15 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 16:16:15 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2272 bytes)
16/03/16 16:16:15 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 95 ms on localhost (1/2)
16/03/16 16:16:15 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 16:16:16 INFO PythonRunner: Times: total = 177, boot = 177, init = 0, finish = 0
16/03/16 16:16:16 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1311 bytes result sent to driver
16/03/16 16:16:16 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 200 ms on localhost (2/2)
16/03/16 16:16:16 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 16:16:16 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.288 s
16/03/16 16:16:16 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.302754 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 16:16:16 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 16:16:16 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 16:16:16 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 16:16:16 INFO MemoryStore: MemoryStore cleared
16/03/16 16:16:16 INFO BlockManager: BlockManager stopped
16/03/16 16:16:16 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 16:16:16 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 16:16:16 INFO SparkContext: Successfully stopped SparkContext
16/03/16 16:16:16 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 16:16:16 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'astatine']
16/03/16 16:16:17 INFO SparkContext: Running Spark version 1.5.2
16/03/16 16:16:17 INFO SecurityManager: Changing view acls to: root
16/03/16 16:16:17 INFO SecurityManager: Changing modify acls to: root
16/03/16 16:16:17 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 16:16:17 INFO Slf4jLogger: Slf4jLogger started
16/03/16 16:16:17 INFO Remoting: Starting remoting
16/03/16 16:16:17 INFO Utils: Successfully started service 'sparkDriver' on port 38799.
16/03/16 16:16:17 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:38799]
16/03/16 16:16:17 INFO SparkEnv: Registering MapOutputTracker
16/03/16 16:16:17 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 16:16:17 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-44861a3a-8cba-4e10-94da-f12899feaefe
16/03/16 16:16:17 INFO MemoryStore: MemoryStore started with capacity 1072.2 MB
16/03/16 16:16:17 INFO HttpFileServer: HTTP File server directory is /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/httpd-aa62f867-74f4-40b0-b183-6c5c2141b959
16/03/16 16:16:17 INFO HttpServer: Starting HTTP Server
16/03/16 16:16:17 INFO Utils: Successfully started service 'HTTP file server' on port 56213.
16/03/16 16:16:17 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 16:16:17 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 16:16:17 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 16:16:17 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-1c2fe6d3-c1b8-4f0f-9edf-9b3c170738ce/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 16:16:17 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125177425
16/03/16 16:16:17 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 16:16:17 INFO Executor: Starting executor ID driver on host localhost
16/03/16 16:16:17 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52513.
16/03/16 16:16:17 INFO NettyBlockTransferService: Server created on 52513
16/03/16 16:16:17 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 16:16:17 INFO BlockManagerMasterEndpoint: Registering block manager localhost:52513 with 1072.2 MB RAM, BlockManagerId(driver, localhost, 52513)
16/03/16 16:16:17 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): used
16/03/16 16:16:17 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:16:17 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:17 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:16:17 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 16:16:17 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 16:16:17 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:16:17 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1124251729
16/03/16 16:16:17 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1072.2 MB)
16/03/16 16:16:17 INFO MemoryStore: ensureFreeSpace(4141) called with curMem=6568, maxMem=1124251729
16/03/16 16:16:17 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1072.2 MB)
16/03/16 16:16:17 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:52513 (size: 4.0 KB, free: 1072.2 MB)
16/03/16 16:16:17 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 16:16:17 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:17 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 16:16:17 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 16:16:17 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 16:16:17 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125177425
16/03/16 16:16:17 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-1c2fe6d3-c1b8-4f0f-9edf-9b3c170738ce/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: area
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: issue
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: planning
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: permission
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: economy
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: composition
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: agency
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 16:16:25 INFO PythonRunner: Times: total = 7750, boot = 468, init = 348, finish = 6934
16/03/16 16:16:25 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 16:16:25 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 16:16:25 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 16:16:25 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7853 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: set
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): adding to parents: syn =  Synset('set.n.01') ; keyword:  used  in syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: bend
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: giant
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: astatine
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: present
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: area
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
16/03/16 16:16:25 INFO PythonRunner: Times: total = 265, boot = 155, init = 0, finish = 110
16/03/16 16:16:25 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 16:16:25 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.127 s
16/03/16 16:16:25 INFO DAGScheduler: looking for newly runnable stages
16/03/16 16:16:25 INFO DAGScheduler: running: Set()
16/03/16 16:16:25 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 16:16:25 INFO DAGScheduler: failed: Set()
16/03/16 16:16:25 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 16:16:25 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 16:16:25 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10709, maxMem=1124251729
16/03/16 16:16:25 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1072.2 MB)
16/03/16 16:16:25 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15693, maxMem=1124251729
16/03/16 16:16:25 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1072.2 MB)
16/03/16 16:16:25 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 287 ms on localhost (2/2)
16/03/16 16:16:25 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 16:16:25 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:52513 (size: 3.0 KB, free: 1072.2 MB)
16/03/16 16:16:25 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 16:16:25 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:25 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 16:16:25 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:16:25 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 16:16:25 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:16:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 16:16:25 INFO PythonRunner: Times: total = 171, boot = 170, init = 1, finish = 0
16/03/16 16:16:25 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 16:16:25 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:16:25 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 16:16:25 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:16:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
16/03/16 16:16:25 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 199 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'set']
16/03/16 16:16:26 INFO PythonRunner: Times: total = 178, boot = 177, init = 0, finish = 1
16/03/16 16:16:26 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1229 bytes result sent to driver
16/03/16 16:16:26 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 204 ms on localhost (2/2)
16/03/16 16:16:26 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.378 s
16/03/16 16:16:26 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 16:16:26 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.543526 s
16/03/16 16:16:26 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:16:26 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:16:26 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:26 INFO DAGScheduler: Parents of final stage: List()
16/03/16 16:16:26 INFO DAGScheduler: Missing parents: List()
16/03/16 16:16:26 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:16:26 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18741, maxMem=1124251729
16/03/16 16:16:26 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1072.1 MB)
16/03/16 16:16:26 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24557, maxMem=1124251729
16/03/16 16:16:26 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1072.1 MB)
16/03/16 16:16:26 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:52513 (size: 3.3 KB, free: 1072.2 MB)
16/03/16 16:16:26 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 16:16:26 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:26 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 16:16:26 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 16:16:26 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 16:16:26 INFO PythonRunner: Times: total = 84, boot = 83, init = 0, finish = 1
16/03/16 16:16:26 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 16:16:26 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2259 bytes)
16/03/16 16:16:26 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 16:16:26 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 112 ms on localhost (1/2)
16/03/16 16:16:26 INFO PythonRunner: Times: total = 165, boot = 165, init = 0, finish = 0
16/03/16 16:16:26 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1295 bytes result sent to driver
16/03/16 16:16:26 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 181 ms on localhost (2/2)
16/03/16 16:16:26 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 16:16:26 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.260 s
16/03/16 16:16:26 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.313277 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 16:16:26 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 16:16:26 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 16:16:26 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 16:16:26 INFO MemoryStore: MemoryStore cleared
16/03/16 16:16:26 INFO BlockManager: BlockManager stopped
16/03/16 16:16:26 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 16:16:26 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 16:16:26 INFO SparkContext: Successfully stopped SparkContext
16/03/16 16:16:26 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 16:16:26 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 16:16:26 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'set']
16/03/16 16:16:27 INFO SparkContext: Running Spark version 1.5.2
16/03/16 16:16:27 INFO SecurityManager: Changing view acls to: root
16/03/16 16:16:27 INFO SecurityManager: Changing modify acls to: root
16/03/16 16:16:27 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 16:16:27 INFO Slf4jLogger: Slf4jLogger started
16/03/16 16:16:27 INFO Remoting: Starting remoting
16/03/16 16:16:27 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:52146]
16/03/16 16:16:27 INFO Utils: Successfully started service 'sparkDriver' on port 52146.
16/03/16 16:16:27 INFO SparkEnv: Registering MapOutputTracker
16/03/16 16:16:27 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 16:16:27 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-b6514ce9-f4c2-4cdd-9c4c-d47d3f4b2549
16/03/16 16:16:27 INFO MemoryStore: MemoryStore started with capacity 1072.2 MB
16/03/16 16:16:27 INFO HttpFileServer: HTTP File server directory is /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/httpd-afc9ce0b-2d2a-429c-bf56-d0208897bf25
16/03/16 16:16:27 INFO HttpServer: Starting HTTP Server
16/03/16 16:16:27 INFO Utils: Successfully started service 'HTTP file server' on port 37994.
16/03/16 16:16:27 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 16:16:27 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 16:16:27 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 16:16:27 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-c56ac036-da1d-4936-9d6b-808a90022521/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 16:16:27 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125187790
16/03/16 16:16:27 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 16:16:27 INFO Executor: Starting executor ID driver on host localhost
16/03/16 16:16:27 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58272.
16/03/16 16:16:27 INFO NettyBlockTransferService: Server created on 58272
16/03/16 16:16:27 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 16:16:27 INFO BlockManagerMasterEndpoint: Registering block manager localhost:58272 with 1072.2 MB RAM, BlockManagerId(driver, localhost, 58272)
16/03/16 16:16:27 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): usually
16/03/16 16:16:27 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:16:27 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:27 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:16:27 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 16:16:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 16:16:27 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:16:27 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1124251729
16/03/16 16:16:27 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1072.2 MB)
16/03/16 16:16:27 INFO MemoryStore: ensureFreeSpace(4141) called with curMem=6568, maxMem=1124251729
16/03/16 16:16:27 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1072.2 MB)
16/03/16 16:16:27 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:58272 (size: 4.0 KB, free: 1072.2 MB)
16/03/16 16:16:27 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 16:16:27 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:27 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 16:16:27 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 16:16:27 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 16:16:27 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125187790
16/03/16 16:16:28 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-c56ac036-da1d-4936-9d6b-808a90022521/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: area
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  usually  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: issue
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: planning
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: permission
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: economy
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: composition
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: agency
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
16/03/16 16:16:35 INFO PythonRunner: Times: total = 7704, boot = 456, init = 360, finish = 6888
16/03/16 16:16:35 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 16:16:35 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 16:16:35 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 16:16:35 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7797 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: set
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: bend
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: giant
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: astatine
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: present
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: area
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  usually  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
16/03/16 16:16:36 INFO PythonRunner: Times: total = 242, boot = 137, init = 1, finish = 104
16/03/16 16:16:36 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 16:16:36 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 278 ms on localhost (2/2)
16/03/16 16:16:36 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 16:16:36 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.067 s
16/03/16 16:16:36 INFO DAGScheduler: looking for newly runnable stages
16/03/16 16:16:36 INFO DAGScheduler: running: Set()
16/03/16 16:16:36 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 16:16:36 INFO DAGScheduler: failed: Set()
16/03/16 16:16:36 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 16:16:36 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 16:16:36 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10709, maxMem=1124251729
16/03/16 16:16:36 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1072.2 MB)
16/03/16 16:16:36 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15693, maxMem=1124251729
16/03/16 16:16:36 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1072.2 MB)
16/03/16 16:16:36 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:58272 (size: 3.0 KB, free: 1072.2 MB)
16/03/16 16:16:36 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 16:16:36 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:36 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 16:16:36 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:16:36 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 16:16:36 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:16:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/16 16:16:36 INFO PythonRunner: Times: total = 120, boot = 119, init = 1, finish = 0
16/03/16 16:16:36 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 16:16:36 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:16:36 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 16:16:36 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:16:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 16:16:36 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 167 ms on localhost (1/2)
reduceFunction_Parents(): returns= [u'area', 'None', u'area']
16/03/16 16:16:36 INFO PythonRunner: Times: total = 152, boot = 151, init = 0, finish = 1
16/03/16 16:16:36 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1241 bytes result sent to driver
16/03/16 16:16:36 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.315 s
16/03/16 16:16:36 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.445416 s
16/03/16 16:16:36 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 183 ms on localhost (2/2)
16/03/16 16:16:36 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 16:16:36 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:16:36 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:16:36 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:36 INFO DAGScheduler: Parents of final stage: List()
16/03/16 16:16:36 INFO DAGScheduler: Missing parents: List()
16/03/16 16:16:36 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:16:36 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18741, maxMem=1124251729
16/03/16 16:16:36 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1072.1 MB)
16/03/16 16:16:36 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24557, maxMem=1124251729
16/03/16 16:16:36 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1072.1 MB)
16/03/16 16:16:36 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:58272 (size: 3.3 KB, free: 1072.2 MB)
16/03/16 16:16:36 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 16:16:36 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:36 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 16:16:36 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 16:16:36 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 16:16:36 INFO PythonRunner: Times: total = 15, boot = 4, init = 11, finish = 0
16/03/16 16:16:36 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 16:16:36 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2271 bytes)
16/03/16 16:16:36 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 58 ms on localhost (1/2)
16/03/16 16:16:36 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 16:16:36 INFO PythonRunner: Times: total = 167, boot = 167, init = 0, finish = 0
16/03/16 16:16:36 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1307 bytes result sent to driver
16/03/16 16:16:36 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 186 ms on localhost (2/2)
16/03/16 16:16:36 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 16:16:36 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.219 s
16/03/16 16:16:36 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.265849 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 16:16:36 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 16:16:36 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 16:16:36 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 16:16:36 INFO MemoryStore: MemoryStore cleared
16/03/16 16:16:36 INFO BlockManager: BlockManager stopped
16/03/16 16:16:36 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 16:16:36 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 16:16:36 INFO SparkContext: Successfully stopped SparkContext
16/03/16 16:16:36 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 16:16:36 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 16:16:36 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'area', u'None', u'area']
16/03/16 16:16:37 INFO SparkContext: Running Spark version 1.5.2
16/03/16 16:16:37 INFO SecurityManager: Changing view acls to: root
16/03/16 16:16:37 INFO SecurityManager: Changing modify acls to: root
16/03/16 16:16:37 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 16:16:37 INFO Slf4jLogger: Slf4jLogger started
16/03/16 16:16:37 INFO Remoting: Starting remoting
16/03/16 16:16:37 INFO Utils: Successfully started service 'sparkDriver' on port 39280.
16/03/16 16:16:37 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:39280]
16/03/16 16:16:37 INFO SparkEnv: Registering MapOutputTracker
16/03/16 16:16:37 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 16:16:37 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-3a40a3f8-e473-47e7-a784-d44e795bee79
16/03/16 16:16:37 INFO MemoryStore: MemoryStore started with capacity 1072.2 MB
16/03/16 16:16:38 INFO HttpFileServer: HTTP File server directory is /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/httpd-ccd9812e-d648-4755-8657-0fc103e96b07
16/03/16 16:16:38 INFO HttpServer: Starting HTTP Server
16/03/16 16:16:38 INFO Utils: Successfully started service 'HTTP file server' on port 60669.
16/03/16 16:16:38 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 16:16:38 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 16:16:38 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 16:16:38 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-5010757d-51be-4bd0-9d14-a671aaa8a243/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 16:16:38 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125198184
16/03/16 16:16:38 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 16:16:38 INFO Executor: Starting executor ID driver on host localhost
16/03/16 16:16:38 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41439.
16/03/16 16:16:38 INFO NettyBlockTransferService: Server created on 41439
16/03/16 16:16:38 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 16:16:38 INFO BlockManagerMasterEndpoint: Registering block manager localhost:41439 with 1072.2 MB RAM, BlockManagerId(driver, localhost, 41439)
16/03/16 16:16:38 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): moment
16/03/16 16:16:38 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:16:38 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:38 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:16:38 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 16:16:38 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 16:16:38 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:16:38 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1124251729
16/03/16 16:16:38 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1072.2 MB)
16/03/16 16:16:38 INFO MemoryStore: ensureFreeSpace(4141) called with curMem=6568, maxMem=1124251729
16/03/16 16:16:38 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1072.2 MB)
16/03/16 16:16:38 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:41439 (size: 4.0 KB, free: 1072.2 MB)
16/03/16 16:16:38 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 16:16:38 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:38 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 16:16:38 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 16:16:38 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 16:16:38 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125198184
16/03/16 16:16:38 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-5010757d-51be-4bd0-9d14-a671aaa8a243/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: area
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: issue
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: planning
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: permission
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: economy
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: composition
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: agency
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 16:16:46 INFO PythonRunner: Times: total = 8005, boot = 572, init = 443, finish = 6990
16/03/16 16:16:46 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 16:16:46 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 16:16:46 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 16:16:46 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8161 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: set
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: bend
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: giant
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: astatine
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: present
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('present.n.01') ; keyword:  moment  in syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= [u'present']
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: area
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
16/03/16 16:16:46 INFO PythonRunner: Times: total = 241, boot = 139, init = 0, finish = 102
16/03/16 16:16:46 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 16:16:46 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 275 ms on localhost (2/2)
16/03/16 16:16:46 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 16:16:46 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.419 s
16/03/16 16:16:46 INFO DAGScheduler: looking for newly runnable stages
16/03/16 16:16:46 INFO DAGScheduler: running: Set()
16/03/16 16:16:46 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 16:16:46 INFO DAGScheduler: failed: Set()
16/03/16 16:16:46 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 16:16:46 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 16:16:46 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10709, maxMem=1124251729
16/03/16 16:16:46 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1072.2 MB)
16/03/16 16:16:46 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15693, maxMem=1124251729
16/03/16 16:16:46 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1072.2 MB)
16/03/16 16:16:46 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:41439 (size: 3.0 KB, free: 1072.2 MB)
16/03/16 16:16:46 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 16:16:46 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:46 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 16:16:46 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:16:46 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 16:16:46 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:16:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 16:16:47 INFO PythonRunner: Times: total = 122, boot = 122, init = 0, finish = 0
16/03/16 16:16:47 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 16:16:47 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:16:47 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 16:16:47 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:16:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 16:16:47 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 175 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'present']
16/03/16 16:16:47 INFO PythonRunner: Times: total = 173, boot = 172, init = 1, finish = 0
16/03/16 16:16:47 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1241 bytes result sent to driver
16/03/16 16:16:47 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 190 ms on localhost (2/2)
16/03/16 16:16:47 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 16:16:47 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.316 s
16/03/16 16:16:47 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.815038 s
16/03/16 16:16:47 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:16:47 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:16:47 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:47 INFO DAGScheduler: Parents of final stage: List()
16/03/16 16:16:47 INFO DAGScheduler: Missing parents: List()
16/03/16 16:16:47 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:16:47 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18741, maxMem=1124251729
16/03/16 16:16:47 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1072.1 MB)
16/03/16 16:16:47 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24557, maxMem=1124251729
16/03/16 16:16:47 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1072.1 MB)
16/03/16 16:16:47 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:41439 (size: 3.3 KB, free: 1072.2 MB)
16/03/16 16:16:47 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 16:16:47 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:47 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 16:16:47 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 16:16:47 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 16:16:47 INFO PythonRunner: Times: total = 62, boot = 62, init = 0, finish = 0
16/03/16 16:16:47 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 16:16:47 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2271 bytes)
16/03/16 16:16:47 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 86 ms on localhost (1/2)
16/03/16 16:16:47 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 16:16:47 INFO PythonRunner: Times: total = 166, boot = 166, init = 0, finish = 0
16/03/16 16:16:47 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1310 bytes result sent to driver
16/03/16 16:16:47 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 190 ms on localhost (2/2)
16/03/16 16:16:47 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 16:16:47 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.247 s
16/03/16 16:16:47 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.287173 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 16:16:47 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 16:16:47 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 16:16:47 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 16:16:47 INFO MemoryStore: MemoryStore cleared
16/03/16 16:16:47 INFO BlockManager: BlockManager stopped
16/03/16 16:16:47 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 16:16:47 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 16:16:47 INFO SparkContext: Successfully stopped SparkContext
16/03/16 16:16:47 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 16:16:47 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 16:16:47 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'present']
16/03/16 16:16:48 INFO SparkContext: Running Spark version 1.5.2
16/03/16 16:16:48 INFO SecurityManager: Changing view acls to: root
16/03/16 16:16:48 INFO SecurityManager: Changing modify acls to: root
16/03/16 16:16:48 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 16:16:48 INFO Slf4jLogger: Slf4jLogger started
16/03/16 16:16:48 INFO Remoting: Starting remoting
16/03/16 16:16:48 INFO Utils: Successfully started service 'sparkDriver' on port 36034.
16/03/16 16:16:48 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:36034]
16/03/16 16:16:48 INFO SparkEnv: Registering MapOutputTracker
16/03/16 16:16:48 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 16:16:48 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-4f835d73-5fad-41ed-96af-e2f7d2f05171
16/03/16 16:16:48 INFO MemoryStore: MemoryStore started with capacity 1072.2 MB
16/03/16 16:16:48 INFO HttpFileServer: HTTP File server directory is /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/httpd-9e3e0537-3785-42fd-a875-54778bf615da
16/03/16 16:16:48 INFO HttpServer: Starting HTTP Server
16/03/16 16:16:48 INFO Utils: Successfully started service 'HTTP file server' on port 35572.
16/03/16 16:16:48 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 16:16:48 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 16:16:48 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 16:16:48 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-6fc77966-34cd-4c30-b287-d254a1ac3e8d/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 16:16:48 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125208941
16/03/16 16:16:48 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 16:16:48 INFO Executor: Starting executor ID driver on host localhost
16/03/16 16:16:49 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44432.
16/03/16 16:16:49 INFO NettyBlockTransferService: Server created on 44432
16/03/16 16:16:49 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 16:16:49 INFO BlockManagerMasterEndpoint: Registering block manager localhost:44432 with 1072.2 MB RAM, BlockManagerId(driver, localhost, 44432)
16/03/16 16:16:49 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): purpose
16/03/16 16:16:49 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:16:49 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:49 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:16:49 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 16:16:49 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 16:16:49 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:16:49 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1124251729
16/03/16 16:16:49 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1072.2 MB)
16/03/16 16:16:49 INFO MemoryStore: ensureFreeSpace(4141) called with curMem=6568, maxMem=1124251729
16/03/16 16:16:49 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1072.2 MB)
16/03/16 16:16:49 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:44432 (size: 4.0 KB, free: 1072.2 MB)
16/03/16 16:16:49 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 16:16:49 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:49 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 16:16:49 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 16:16:49 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 16:16:49 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125208941
16/03/16 16:16:49 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-6fc77966-34cd-4c30-b287-d254a1ac3e8d/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: area
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  purpose  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: issue
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: planning
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: permission
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: economy
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: composition
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: agency
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
16/03/16 16:16:57 INFO PythonRunner: Times: total = 7899, boot = 489, init = 361, finish = 7049
16/03/16 16:16:57 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 16:16:57 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 16:16:57 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 16:16:57 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8031 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: set
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: bend
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: giant
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: astatine
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: present
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: area
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  purpose  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
16/03/16 16:16:57 INFO PythonRunner: Times: total = 270, boot = 153, init = 1, finish = 116
16/03/16 16:16:57 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 16:16:57 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 304 ms on localhost (2/2)
16/03/16 16:16:57 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.312 s
16/03/16 16:16:57 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 16:16:57 INFO DAGScheduler: looking for newly runnable stages
16/03/16 16:16:57 INFO DAGScheduler: running: Set()
16/03/16 16:16:57 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 16:16:57 INFO DAGScheduler: failed: Set()
16/03/16 16:16:57 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 16:16:57 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 16:16:57 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10709, maxMem=1124251729
16/03/16 16:16:57 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1072.2 MB)
16/03/16 16:16:57 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15693, maxMem=1124251729
16/03/16 16:16:57 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1072.2 MB)
16/03/16 16:16:57 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:44432 (size: 3.0 KB, free: 1072.2 MB)
16/03/16 16:16:57 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 16:16:57 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:57 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 16:16:57 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:16:57 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 16:16:57 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:16:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 16:16:57 INFO PythonRunner: Times: total = 162, boot = 161, init = 1, finish = 0
16/03/16 16:16:57 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 16:16:57 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:16:57 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 16:16:57 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:16:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/16 16:16:57 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 194 ms on localhost (1/2)
reduceFunction_Parents(): returns= [u'area', 'None', u'area']
16/03/16 16:16:57 INFO PythonRunner: Times: total = 163, boot = 163, init = 0, finish = 0
16/03/16 16:16:57 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1241 bytes result sent to driver
16/03/16 16:16:57 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 184 ms on localhost (2/2)
16/03/16 16:16:57 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 16:16:57 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.353 s
16/03/16 16:16:57 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.722012 s
16/03/16 16:16:57 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:16:57 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:16:57 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:57 INFO DAGScheduler: Parents of final stage: List()
16/03/16 16:16:57 INFO DAGScheduler: Missing parents: List()
16/03/16 16:16:57 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:16:57 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18741, maxMem=1124251729
16/03/16 16:16:57 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1072.1 MB)
16/03/16 16:16:57 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24557, maxMem=1124251729
16/03/16 16:16:57 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1072.1 MB)
16/03/16 16:16:57 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:44432 (size: 3.3 KB, free: 1072.2 MB)
16/03/16 16:16:57 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 16:16:57 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:57 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 16:16:57 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 16:16:57 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 16:16:58 INFO PythonRunner: Times: total = 92, boot = 92, init = 0, finish = 0
16/03/16 16:16:58 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 16:16:58 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2271 bytes)
16/03/16 16:16:58 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 16:16:58 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 112 ms on localhost (1/2)
16/03/16 16:16:58 INFO PythonRunner: Times: total = 175, boot = 175, init = 0, finish = 0
16/03/16 16:16:58 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1307 bytes result sent to driver
16/03/16 16:16:58 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.300 s
16/03/16 16:16:58 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.322238 s
16/03/16 16:16:58 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 193 ms on localhost (2/2)
16/03/16 16:16:58 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 16:16:58 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 16:16:58 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 16:16:58 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 16:16:58 INFO MemoryStore: MemoryStore cleared
16/03/16 16:16:58 INFO BlockManager: BlockManager stopped
16/03/16 16:16:58 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 16:16:58 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 16:16:58 INFO SparkContext: Successfully stopped SparkContext
16/03/16 16:16:58 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 16:16:58 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 16:16:58 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'area', u'None', u'area']
16/03/16 16:16:59 INFO SparkContext: Running Spark version 1.5.2
16/03/16 16:16:59 INFO SecurityManager: Changing view acls to: root
16/03/16 16:16:59 INFO SecurityManager: Changing modify acls to: root
16/03/16 16:16:59 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 16:16:59 INFO Slf4jLogger: Slf4jLogger started
16/03/16 16:16:59 INFO Remoting: Starting remoting
16/03/16 16:16:59 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:36456]
16/03/16 16:16:59 INFO Utils: Successfully started service 'sparkDriver' on port 36456.
16/03/16 16:16:59 INFO SparkEnv: Registering MapOutputTracker
16/03/16 16:16:59 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 16:16:59 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-ca7b7e68-15b7-4d85-b70c-9db420b8b16d
16/03/16 16:16:59 INFO MemoryStore: MemoryStore started with capacity 1072.2 MB
16/03/16 16:16:59 INFO HttpFileServer: HTTP File server directory is /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/httpd-fe48363e-d193-498f-977c-27bc4c53dd0e
16/03/16 16:16:59 INFO HttpServer: Starting HTTP Server
16/03/16 16:16:59 INFO Utils: Successfully started service 'HTTP file server' on port 51043.
16/03/16 16:16:59 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 16:16:59 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 16:16:59 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 16:16:59 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-9900cf2b-f79d-4b5c-8a8b-7d15dca3b4b4/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 16:16:59 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125219584
16/03/16 16:16:59 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 16:16:59 INFO Executor: Starting executor ID driver on host localhost
16/03/16 16:16:59 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45881.
16/03/16 16:16:59 INFO NettyBlockTransferService: Server created on 45881
16/03/16 16:16:59 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 16:16:59 INFO BlockManagerMasterEndpoint: Registering block manager localhost:45881 with 1072.2 MB RAM, BlockManagerId(driver, localhost, 45881)
16/03/16 16:16:59 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): segment
16/03/16 16:16:59 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:16:59 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:59 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:16:59 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 16:16:59 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 16:16:59 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:16:59 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1124251729
16/03/16 16:16:59 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1072.2 MB)
16/03/16 16:16:59 INFO MemoryStore: ensureFreeSpace(4141) called with curMem=6568, maxMem=1124251729
16/03/16 16:16:59 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1072.2 MB)
16/03/16 16:16:59 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:45881 (size: 4.0 KB, free: 1072.2 MB)
16/03/16 16:16:59 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 16:16:59 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:16:59 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 16:16:59 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 16:16:59 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 16:16:59 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125219584
16/03/16 16:16:59 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-9900cf2b-f79d-4b5c-8a8b-7d15dca3b4b4/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: area
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: issue
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: planning
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: permission
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: economy
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: composition
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: agency
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 16:17:07 INFO PythonRunner: Times: total = 7887, boot = 471, init = 359, finish = 7057
16/03/16 16:17:07 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 16:17:07 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 16:17:07 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 16:17:07 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7965 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: set
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: bend
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): adding to parents: syn =  Synset('bend.n.01') ; keyword:  segment  in syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= [u'bend']
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: giant
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: astatine
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: present
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: area
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
16/03/16 16:17:07 INFO PythonRunner: Times: total = 282, boot = 175, init = 0, finish = 107
16/03/16 16:17:07 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 16:17:07 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.263 s
16/03/16 16:17:07 INFO DAGScheduler: looking for newly runnable stages
16/03/16 16:17:07 INFO DAGScheduler: running: Set()
16/03/16 16:17:07 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 16:17:07 INFO DAGScheduler: failed: Set()
16/03/16 16:17:07 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 16:17:07 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 16:17:08 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10709, maxMem=1124251729
16/03/16 16:17:08 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1072.2 MB)
16/03/16 16:17:08 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15693, maxMem=1124251729
16/03/16 16:17:08 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1072.2 MB)
16/03/16 16:17:08 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 306 ms on localhost (2/2)
16/03/16 16:17:08 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 16:17:08 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:45881 (size: 3.0 KB, free: 1072.2 MB)
16/03/16 16:17:08 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 16:17:08 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:17:08 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 16:17:08 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:17:08 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 16:17:08 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:17:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 16:17:08 INFO PythonRunner: Times: total = 157, boot = 156, init = 1, finish = 0
16/03/16 16:17:08 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 16:17:08 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:17:08 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 16:17:08 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:17:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/16 16:17:08 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 187 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'bend']
16/03/16 16:17:08 INFO PythonRunner: Times: total = 166, boot = 165, init = 0, finish = 1
16/03/16 16:17:08 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1230 bytes result sent to driver
16/03/16 16:17:08 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.353 s
16/03/16 16:17:08 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.653734 s
16/03/16 16:17:08 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 191 ms on localhost (2/2)
16/03/16 16:17:08 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 16:17:08 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:17:08 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:17:08 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:17:08 INFO DAGScheduler: Parents of final stage: List()
16/03/16 16:17:08 INFO DAGScheduler: Missing parents: List()
16/03/16 16:17:08 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:17:08 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18741, maxMem=1124251729
16/03/16 16:17:08 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1072.1 MB)
16/03/16 16:17:08 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24557, maxMem=1124251729
16/03/16 16:17:08 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1072.1 MB)
16/03/16 16:17:08 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:45881 (size: 3.3 KB, free: 1072.2 MB)
16/03/16 16:17:08 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 16:17:08 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:17:08 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 16:17:08 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 16:17:08 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 16:17:08 INFO PythonRunner: Times: total = 116, boot = 115, init = 1, finish = 0
16/03/16 16:17:08 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 16:17:08 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2260 bytes)
16/03/16 16:17:08 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 16:17:08 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 139 ms on localhost (1/2)
16/03/16 16:17:08 INFO PythonRunner: Times: total = 170, boot = 170, init = 0, finish = 0
16/03/16 16:17:08 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1296 bytes result sent to driver
16/03/16 16:17:08 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 192 ms on localhost (2/2)
16/03/16 16:17:08 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 16:17:08 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.309 s
16/03/16 16:17:08 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.353178 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 16:17:08 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 16:17:08 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 16:17:08 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 16:17:08 INFO MemoryStore: MemoryStore cleared
16/03/16 16:17:08 INFO BlockManager: BlockManager stopped
16/03/16 16:17:08 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 16:17:08 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 16:17:08 INFO SparkContext: Successfully stopped SparkContext
16/03/16 16:17:08 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 16:17:08 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 16:17:08 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'bend']
16/03/16 16:17:09 INFO SparkContext: Running Spark version 1.5.2
16/03/16 16:17:09 INFO SecurityManager: Changing view acls to: root
16/03/16 16:17:09 INFO SecurityManager: Changing modify acls to: root
16/03/16 16:17:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 16:17:09 INFO Slf4jLogger: Slf4jLogger started
16/03/16 16:17:09 INFO Remoting: Starting remoting
16/03/16 16:17:09 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:33251]
16/03/16 16:17:09 INFO Utils: Successfully started service 'sparkDriver' on port 33251.
16/03/16 16:17:09 INFO SparkEnv: Registering MapOutputTracker
16/03/16 16:17:09 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 16:17:09 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-cf1f97aa-b1df-497a-856f-93ba143533f7
16/03/16 16:17:10 INFO MemoryStore: MemoryStore started with capacity 1072.2 MB
16/03/16 16:17:10 INFO HttpFileServer: HTTP File server directory is /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/httpd-ffa14d38-c828-4fb6-b4ad-0ed00f389caa
16/03/16 16:17:10 INFO HttpServer: Starting HTTP Server
16/03/16 16:17:10 INFO Utils: Successfully started service 'HTTP file server' on port 33719.
16/03/16 16:17:10 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 16:17:10 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 16:17:10 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 16:17:10 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-f5df1aa3-09f1-4eb4-9d7d-c0fc39b20d7a/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 16:17:10 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125230168
16/03/16 16:17:10 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 16:17:10 INFO Executor: Starting executor ID driver on host localhost
16/03/16 16:17:10 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58694.
16/03/16 16:17:10 INFO NettyBlockTransferService: Server created on 58694
16/03/16 16:17:10 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 16:17:10 INFO BlockManagerMasterEndpoint: Registering block manager localhost:58694 with 1072.2 MB RAM, BlockManagerId(driver, localhost, 58694)
16/03/16 16:17:10 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): radioactive
16/03/16 16:17:10 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:17:10 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:17:10 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:17:10 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:17:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 16:17:10 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 16:17:10 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:17:10 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1124251729
16/03/16 16:17:10 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1072.2 MB)
16/03/16 16:17:10 INFO MemoryStore: ensureFreeSpace(4139) called with curMem=6568, maxMem=1124251729
16/03/16 16:17:10 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1072.2 MB)
16/03/16 16:17:10 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:58694 (size: 4.0 KB, free: 1072.2 MB)
16/03/16 16:17:10 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 16:17:10 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:17:10 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 16:17:10 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 16:17:10 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 16:17:10 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125230168
16/03/16 16:17:10 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-f5df1aa3-09f1-4eb4-9d7d-c0fc39b20d7a/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: area
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: issue
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: planning
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: permission
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: economy
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: composition
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: agency
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 16:17:18 INFO PythonRunner: Times: total = 7918, boot = 486, init = 354, finish = 7078
16/03/16 16:17:18 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 16:17:18 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 16:17:18 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 16:17:18 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8050 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: set
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: bend
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: giant
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: astatine
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('astatine.n.01') ; keyword:  radioactive  in syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= [u'astatine']
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: present
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: area
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
16/03/16 16:17:18 INFO PythonRunner: Times: total = 252, boot = 145, init = 0, finish = 107
16/03/16 16:17:18 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 16:17:18 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 284 ms on localhost (2/2)
16/03/16 16:17:18 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 16:17:18 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.326 s
16/03/16 16:17:18 INFO DAGScheduler: looking for newly runnable stages
16/03/16 16:17:18 INFO DAGScheduler: running: Set()
16/03/16 16:17:18 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 16:17:18 INFO DAGScheduler: failed: Set()
16/03/16 16:17:18 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 16:17:18 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 16:17:18 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10707, maxMem=1124251729
16/03/16 16:17:18 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1072.2 MB)
16/03/16 16:17:18 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15691, maxMem=1124251729
16/03/16 16:17:18 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1072.2 MB)
16/03/16 16:17:18 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:58694 (size: 3.0 KB, free: 1072.2 MB)
16/03/16 16:17:18 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 16:17:18 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:17:18 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 16:17:18 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:17:18 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 16:17:18 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:17:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/16 16:17:19 INFO PythonRunner: Times: total = 135, boot = 135, init = 0, finish = 0
16/03/16 16:17:19 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 16:17:19 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:17:19 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 16:17:19 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 151 ms on localhost (1/2)
16/03/16 16:17:19 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:17:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
reduceFunction_Parents(): returns= ['None', 'None', u'astatine']
16/03/16 16:17:19 INFO PythonRunner: Times: total = 173, boot = 172, init = 0, finish = 1
16/03/16 16:17:19 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1242 bytes result sent to driver
16/03/16 16:17:19 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.377 s
16/03/16 16:17:19 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.741864 s
16/03/16 16:17:19 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 227 ms on localhost (2/2)
16/03/16 16:17:19 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 16:17:19 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:17:19 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:17:19 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:17:19 INFO DAGScheduler: Parents of final stage: List()
16/03/16 16:17:19 INFO DAGScheduler: Missing parents: List()
16/03/16 16:17:19 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:17:19 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18739, maxMem=1124251729
16/03/16 16:17:19 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1072.1 MB)
16/03/16 16:17:19 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24555, maxMem=1124251729
16/03/16 16:17:19 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1072.1 MB)
16/03/16 16:17:19 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:58694 (size: 3.3 KB, free: 1072.2 MB)
16/03/16 16:17:19 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 16:17:19 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:17:19 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 16:17:19 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 16:17:19 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 16:17:19 INFO PythonRunner: Times: total = 44, boot = 44, init = 0, finish = 0
16/03/16 16:17:19 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 16:17:19 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2272 bytes)
16/03/16 16:17:19 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 64 ms on localhost (1/2)
16/03/16 16:17:19 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 16:17:19 INFO PythonRunner: Times: total = 156, boot = 156, init = 0, finish = 0
16/03/16 16:17:19 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1311 bytes result sent to driver
16/03/16 16:17:19 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 200 ms on localhost (2/2)
16/03/16 16:17:19 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 16:17:19 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.259 s
16/03/16 16:17:19 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.306265 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 16:17:19 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 16:17:19 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 16:17:19 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 16:17:19 INFO MemoryStore: MemoryStore cleared
16/03/16 16:17:19 INFO BlockManager: BlockManager stopped
16/03/16 16:17:19 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 16:17:19 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 16:17:19 INFO SparkContext: Successfully stopped SparkContext
16/03/16 16:17:19 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 16:17:19 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 16:17:19 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'astatine']
16/03/16 16:17:20 INFO SparkContext: Running Spark version 1.5.2
16/03/16 16:17:20 INFO SecurityManager: Changing view acls to: root
16/03/16 16:17:20 INFO SecurityManager: Changing modify acls to: root
16/03/16 16:17:20 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 16:17:20 INFO Slf4jLogger: Slf4jLogger started
16/03/16 16:17:20 INFO Remoting: Starting remoting
16/03/16 16:17:20 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:58617]
16/03/16 16:17:20 INFO Utils: Successfully started service 'sparkDriver' on port 58617.
16/03/16 16:17:20 INFO SparkEnv: Registering MapOutputTracker
16/03/16 16:17:20 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 16:17:20 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-4238d91e-d23a-4c0f-9d76-1cbcde4bda9b
16/03/16 16:17:20 INFO MemoryStore: MemoryStore started with capacity 1071.0 MB
16/03/16 16:17:20 INFO HttpFileServer: HTTP File server directory is /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/httpd-8736e8c0-5ba7-405d-8c93-67ec3706ae62
16/03/16 16:17:20 INFO HttpServer: Starting HTTP Server
16/03/16 16:17:20 INFO Utils: Successfully started service 'HTTP file server' on port 56753.
16/03/16 16:17:20 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 16:17:21 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 16:17:21 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 16:17:21 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-17affc3b-3ed6-4bd5-a84b-aef1d1ccf722/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 16:17:21 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125241075
16/03/16 16:17:21 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 16:17:21 INFO Executor: Starting executor ID driver on host localhost
16/03/16 16:17:21 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46145.
16/03/16 16:17:21 INFO NettyBlockTransferService: Server created on 46145
16/03/16 16:17:21 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 16:17:21 INFO BlockManagerMasterEndpoint: Registering block manager localhost:46145 with 1071.0 MB RAM, BlockManagerId(driver, localhost, 46145)
16/03/16 16:17:21 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): happening
16/03/16 16:17:21 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:17:21 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:17:21 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:17:21 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:17:21 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 16:17:21 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 16:17:21 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:17:21 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1122977710
16/03/16 16:17:21 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1070.9 MB)
16/03/16 16:17:21 INFO MemoryStore: ensureFreeSpace(4141) called with curMem=6568, maxMem=1122977710
16/03/16 16:17:21 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1070.9 MB)
16/03/16 16:17:21 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:46145 (size: 4.0 KB, free: 1071.0 MB)
16/03/16 16:17:21 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 16:17:21 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:17:21 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 16:17:21 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 16:17:21 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 16:17:21 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125241075
16/03/16 16:17:21 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-17affc3b-3ed6-4bd5-a84b-aef1d1ccf722/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: area
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: issue
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: planning
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: permission
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: economy
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: composition
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: agency
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 16:17:29 INFO PythonRunner: Times: total = 8084, boot = 469, init = 362, finish = 7253
16/03/16 16:17:29 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 16:17:29 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 16:17:29 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 16:17:29 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8176 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: set
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: bend
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: giant
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: astatine
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: present
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('present.n.01') ; keyword:  happening  in syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= [u'present']
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: area
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
16/03/16 16:17:29 INFO PythonRunner: Times: total = 284, boot = 187, init = 1, finish = 96
16/03/16 16:17:29 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 16:17:29 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 314 ms on localhost (2/2)
16/03/16 16:17:29 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 16:17:29 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.464 s
16/03/16 16:17:29 INFO DAGScheduler: looking for newly runnable stages
16/03/16 16:17:29 INFO DAGScheduler: running: Set()
16/03/16 16:17:29 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 16:17:29 INFO DAGScheduler: failed: Set()
16/03/16 16:17:29 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 16:17:29 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 16:17:29 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10709, maxMem=1122977710
16/03/16 16:17:29 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1070.9 MB)
16/03/16 16:17:29 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15693, maxMem=1122977710
16/03/16 16:17:29 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1070.9 MB)
16/03/16 16:17:29 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:46145 (size: 3.0 KB, free: 1070.9 MB)
16/03/16 16:17:29 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 16:17:29 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:17:29 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 16:17:29 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:17:29 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 16:17:29 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:17:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/16 16:17:29 INFO PythonRunner: Times: total = 146, boot = 145, init = 1, finish = 0
16/03/16 16:17:29 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 16:17:29 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:17:29 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 16:17:29 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:17:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 16:17:29 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 181 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'present']
16/03/16 16:17:30 INFO PythonRunner: Times: total = 171, boot = 170, init = 0, finish = 1
16/03/16 16:17:30 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1241 bytes result sent to driver
16/03/16 16:17:30 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.351 s
16/03/16 16:17:30 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.870308 s
16/03/16 16:17:30 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 193 ms on localhost (2/2)
16/03/16 16:17:30 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 16:17:30 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:17:30 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:17:30 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:17:30 INFO DAGScheduler: Parents of final stage: List()
16/03/16 16:17:30 INFO DAGScheduler: Missing parents: List()
16/03/16 16:17:30 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:17:30 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18741, maxMem=1122977710
16/03/16 16:17:30 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1070.9 MB)
16/03/16 16:17:30 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24557, maxMem=1122977710
16/03/16 16:17:30 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1070.9 MB)
16/03/16 16:17:30 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:46145 (size: 3.3 KB, free: 1070.9 MB)
16/03/16 16:17:30 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 16:17:30 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:17:30 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 16:17:30 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 16:17:30 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 16:17:30 INFO PythonRunner: Times: total = 94, boot = 94, init = 0, finish = 0
16/03/16 16:17:30 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 16:17:30 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2271 bytes)
16/03/16 16:17:30 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 114 ms on localhost (1/2)
16/03/16 16:17:30 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 16:17:30 INFO PythonRunner: Times: total = 169, boot = 168, init = 1, finish = 0
16/03/16 16:17:30 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1310 bytes result sent to driver
16/03/16 16:17:30 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.285 s
16/03/16 16:17:30 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.324346 s
16/03/16 16:17:30 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 189 ms on localhost (2/2)
16/03/16 16:17:30 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 16:17:30 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 16:17:30 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 16:17:30 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 16:17:30 INFO MemoryStore: MemoryStore cleared
16/03/16 16:17:30 INFO BlockManager: BlockManager stopped
16/03/16 16:17:30 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 16:17:30 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 16:17:30 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 16:17:30 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 16:17:30 INFO SparkContext: Successfully stopped SparkContext
16/03/16 16:17:30 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'present']
16/03/16 16:17:31 INFO SparkContext: Running Spark version 1.5.2
16/03/16 16:17:31 INFO SecurityManager: Changing view acls to: root
16/03/16 16:17:31 INFO SecurityManager: Changing modify acls to: root
16/03/16 16:17:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 16:17:31 INFO Slf4jLogger: Slf4jLogger started
16/03/16 16:17:31 INFO Remoting: Starting remoting
16/03/16 16:17:31 INFO Utils: Successfully started service 'sparkDriver' on port 54383.
16/03/16 16:17:31 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:54383]
16/03/16 16:17:31 INFO SparkEnv: Registering MapOutputTracker
16/03/16 16:17:31 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 16:17:31 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-f34fb9a1-8801-4d27-8a92-98d8ac441aed
16/03/16 16:17:31 INFO MemoryStore: MemoryStore started with capacity 1071.0 MB
16/03/16 16:17:31 INFO HttpFileServer: HTTP File server directory is /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/httpd-e21af925-6987-4442-96b6-260334bfecc7
16/03/16 16:17:31 INFO HttpServer: Starting HTTP Server
16/03/16 16:17:31 INFO Utils: Successfully started service 'HTTP file server' on port 40764.
16/03/16 16:17:31 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 16:17:31 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 16:17:31 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 16:17:31 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-25e14efa-3720-491d-bafc-1016d68febd3/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 16:17:31 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125251951
16/03/16 16:17:31 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 16:17:32 INFO Executor: Starting executor ID driver on host localhost
16/03/16 16:17:32 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60981.
16/03/16 16:17:32 INFO NettyBlockTransferService: Server created on 60981
16/03/16 16:17:32 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 16:17:32 INFO BlockManagerMasterEndpoint: Registering block manager localhost:60981 with 1071.0 MB RAM, BlockManagerId(driver, localhost, 60981)
16/03/16 16:17:32 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): curve
16/03/16 16:17:32 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:17:32 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:17:32 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:17:32 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:17:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 16:17:32 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 16:17:32 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:17:32 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1122977710
16/03/16 16:17:32 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1070.9 MB)
16/03/16 16:17:32 INFO MemoryStore: ensureFreeSpace(4141) called with curMem=6568, maxMem=1122977710
16/03/16 16:17:32 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1070.9 MB)
16/03/16 16:17:32 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:60981 (size: 4.0 KB, free: 1071.0 MB)
16/03/16 16:17:32 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 16:17:32 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:17:32 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 16:17:32 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 16:17:32 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 16:17:32 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125251951
16/03/16 16:17:32 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-25e14efa-3720-491d-bafc-1016d68febd3/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: area
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: issue
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: planning
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: permission
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: economy
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: composition
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: agency
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 16:17:41 INFO PythonRunner: Times: total = 9732, boot = 456, init = 396, finish = 8880
16/03/16 16:17:41 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 16:17:41 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 16:17:41 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 16:17:41 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9838 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: set
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: bend
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): adding to parents: syn =  Synset('bend.n.01') ; keyword:  curve  in syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= [u'bend']
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: giant
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: astatine
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: present
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: area
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
16/03/16 16:17:42 INFO PythonRunner: Times: total = 369, boot = 220, init = 1, finish = 148
16/03/16 16:17:42 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 16:17:42 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 10.253 s
16/03/16 16:17:42 INFO DAGScheduler: looking for newly runnable stages
16/03/16 16:17:42 INFO DAGScheduler: running: Set()
16/03/16 16:17:42 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 16:17:42 INFO DAGScheduler: failed: Set()
16/03/16 16:17:42 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 16:17:42 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 16:17:42 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10709, maxMem=1122977710
16/03/16 16:17:42 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1070.9 MB)
16/03/16 16:17:42 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15693, maxMem=1122977710
16/03/16 16:17:42 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1070.9 MB)
16/03/16 16:17:42 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 427 ms on localhost (2/2)
16/03/16 16:17:42 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 16:17:42 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:60981 (size: 3.0 KB, free: 1070.9 MB)
16/03/16 16:17:42 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 16:17:42 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:17:42 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 16:17:42 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:17:42 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 16:17:42 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:17:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 16:17:42 INFO PythonRunner: Times: total = 199, boot = 199, init = 0, finish = 0
16/03/16 16:17:42 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 16:17:42 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:17:42 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 16:17:42 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:17:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 16:17:42 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 229 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'bend']
16/03/16 16:17:42 INFO PythonRunner: Times: total = 324, boot = 323, init = 1, finish = 0
16/03/16 16:17:42 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1230 bytes result sent to driver
16/03/16 16:17:42 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.559 s
16/03/16 16:17:42 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 10.852262 s
16/03/16 16:17:42 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 352 ms on localhost (2/2)
16/03/16 16:17:42 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 16:17:43 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:17:43 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:17:43 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:17:43 INFO DAGScheduler: Parents of final stage: List()
16/03/16 16:17:43 INFO DAGScheduler: Missing parents: List()
16/03/16 16:17:43 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:17:43 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18741, maxMem=1122977710
16/03/16 16:17:43 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1070.9 MB)
16/03/16 16:17:43 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24557, maxMem=1122977710
16/03/16 16:17:43 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1070.9 MB)
16/03/16 16:17:43 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:60981 (size: 3.3 KB, free: 1070.9 MB)
16/03/16 16:17:43 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 16:17:43 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:17:43 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 16:17:43 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 16:17:43 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 16:17:43 INFO PythonRunner: Times: total = 137, boot = 137, init = 0, finish = 0
16/03/16 16:17:43 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 16:17:43 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2260 bytes)
16/03/16 16:17:43 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 152 ms on localhost (1/2)
16/03/16 16:17:43 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 16:17:43 INFO PythonRunner: Times: total = 259, boot = 259, init = 0, finish = 0
16/03/16 16:17:43 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1296 bytes result sent to driver
16/03/16 16:17:43 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 280 ms on localhost (2/2)
16/03/16 16:17:43 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 16:17:43 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.413 s
16/03/16 16:17:43 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.449093 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 16:17:43 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 16:17:43 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 16:17:43 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 16:17:43 INFO MemoryStore: MemoryStore cleared
16/03/16 16:17:43 INFO BlockManager: BlockManager stopped
16/03/16 16:17:43 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 16:17:43 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 16:17:43 INFO SparkContext: Successfully stopped SparkContext
16/03/16 16:17:43 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 16:17:43 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 16:17:43 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'bend']
16/03/16 16:17:44 INFO SparkContext: Running Spark version 1.5.2
16/03/16 16:17:44 INFO SecurityManager: Changing view acls to: root
16/03/16 16:17:44 INFO SecurityManager: Changing modify acls to: root
16/03/16 16:17:44 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 16:17:44 INFO Slf4jLogger: Slf4jLogger started
16/03/16 16:17:44 INFO Remoting: Starting remoting
16/03/16 16:17:44 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:58032]
16/03/16 16:17:44 INFO Utils: Successfully started service 'sparkDriver' on port 58032.
16/03/16 16:17:44 INFO SparkEnv: Registering MapOutputTracker
16/03/16 16:17:44 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 16:17:44 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-6dc8064d-e7d6-414d-a887-ec0f68c8053d
16/03/16 16:17:44 INFO MemoryStore: MemoryStore started with capacity 1071.0 MB
16/03/16 16:17:44 INFO HttpFileServer: HTTP File server directory is /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/httpd-0dfdc2eb-6b37-4f27-b30c-9c090e38d4c8
16/03/16 16:17:44 INFO HttpServer: Starting HTTP Server
16/03/16 16:17:44 INFO Utils: Successfully started service 'HTTP file server' on port 57970.
16/03/16 16:17:45 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 16:17:45 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 16:17:45 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 16:17:45 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-78db499f-6ba8-4ab8-9c84-a04bfa2e43b6/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 16:17:45 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125265133
16/03/16 16:17:45 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 16:17:45 INFO Executor: Starting executor ID driver on host localhost
16/03/16 16:17:45 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34115.
16/03/16 16:17:45 INFO NettyBlockTransferService: Server created on 34115
16/03/16 16:17:45 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 16:17:45 INFO BlockManagerMasterEndpoint: Registering block manager localhost:34115 with 1071.0 MB RAM, BlockManagerId(driver, localhost, 34115)
16/03/16 16:17:45 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): together
16/03/16 16:17:45 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:17:45 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:17:45 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:17:45 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:17:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 16:17:45 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 16:17:45 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:17:45 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1122977710
16/03/16 16:17:45 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1070.9 MB)
16/03/16 16:17:45 INFO MemoryStore: ensureFreeSpace(4141) called with curMem=6568, maxMem=1122977710
16/03/16 16:17:45 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1070.9 MB)
16/03/16 16:17:45 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:34115 (size: 4.0 KB, free: 1071.0 MB)
16/03/16 16:17:45 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 16:17:45 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:17:45 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 16:17:45 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 16:17:45 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 16:17:45 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125265133
16/03/16 16:17:45 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-78db499f-6ba8-4ab8-9c84-a04bfa2e43b6/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: area
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: issue
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: planning
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: permission
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: economy
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: composition
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: agency
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 16:17:55 INFO PythonRunner: Times: total = 9780, boot = 711, init = 431, finish = 8638
16/03/16 16:17:55 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 16:17:55 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 16:17:55 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 16:17:55 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9923 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: set
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): adding to parents: syn =  Synset('set.n.01') ; keyword:  together  in syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: bend
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: giant
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: astatine
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: present
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: area
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
16/03/16 16:17:55 INFO PythonRunner: Times: total = 348, boot = 222, init = 1, finish = 125
16/03/16 16:17:55 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 16:17:55 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 418 ms on localhost (2/2)
16/03/16 16:17:55 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 16:17:55 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 10.292 s
16/03/16 16:17:55 INFO DAGScheduler: looking for newly runnable stages
16/03/16 16:17:55 INFO DAGScheduler: running: Set()
16/03/16 16:17:55 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 16:17:55 INFO DAGScheduler: failed: Set()
16/03/16 16:17:55 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 16:17:55 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 16:17:55 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10709, maxMem=1122977710
16/03/16 16:17:55 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1070.9 MB)
16/03/16 16:17:55 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15693, maxMem=1122977710
16/03/16 16:17:55 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1070.9 MB)
16/03/16 16:17:55 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:34115 (size: 3.0 KB, free: 1070.9 MB)
16/03/16 16:17:55 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 16:17:55 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:17:55 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 16:17:55 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:17:55 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 16:17:55 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:17:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 16:17:55 INFO PythonRunner: Times: total = 158, boot = 158, init = 0, finish = 0
16/03/16 16:17:55 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 16:17:55 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:17:55 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 16:17:55 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:17:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 14 ms
16/03/16 16:17:55 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 216 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'set']
16/03/16 16:17:56 INFO PythonRunner: Times: total = 289, boot = 288, init = 0, finish = 1
16/03/16 16:17:56 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1229 bytes result sent to driver
16/03/16 16:17:56 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.511 s
16/03/16 16:17:56 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 10.857531 s
16/03/16 16:17:56 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 329 ms on localhost (2/2)
16/03/16 16:17:56 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 16:17:56 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:17:56 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:17:56 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:17:56 INFO DAGScheduler: Parents of final stage: List()
16/03/16 16:17:56 INFO DAGScheduler: Missing parents: List()
16/03/16 16:17:56 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:17:56 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18741, maxMem=1122977710
16/03/16 16:17:56 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1070.9 MB)
16/03/16 16:17:56 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24557, maxMem=1122977710
16/03/16 16:17:56 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1070.9 MB)
16/03/16 16:17:56 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:34115 (size: 3.3 KB, free: 1070.9 MB)
16/03/16 16:17:56 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 16:17:56 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:17:56 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 16:17:56 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 16:17:56 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 16:17:56 INFO PythonRunner: Times: total = 142, boot = 142, init = 0, finish = 0
16/03/16 16:17:56 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 16:17:56 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2259 bytes)
16/03/16 16:17:56 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 166 ms on localhost (1/2)
16/03/16 16:17:56 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 16:17:56 INFO PythonRunner: Times: total = 237, boot = 236, init = 1, finish = 0
16/03/16 16:17:56 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1295 bytes result sent to driver
16/03/16 16:17:56 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 267 ms on localhost (2/2)
16/03/16 16:17:56 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 16:17:56 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.413 s
16/03/16 16:17:56 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.436659 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 16:17:56 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 16:17:56 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 16:17:56 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 16:17:56 INFO MemoryStore: MemoryStore cleared
16/03/16 16:17:56 INFO BlockManager: BlockManager stopped
16/03/16 16:17:56 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 16:17:56 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 16:17:56 INFO SparkContext: Successfully stopped SparkContext
16/03/16 16:17:56 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 16:17:56 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 16:17:56 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'set']
16/03/16 16:17:57 INFO SparkContext: Running Spark version 1.5.2
16/03/16 16:17:57 INFO SecurityManager: Changing view acls to: root
16/03/16 16:17:57 INFO SecurityManager: Changing modify acls to: root
16/03/16 16:17:57 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 16:17:57 INFO Slf4jLogger: Slf4jLogger started
16/03/16 16:17:57 INFO Remoting: Starting remoting
16/03/16 16:17:57 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:33200]
16/03/16 16:17:57 INFO Utils: Successfully started service 'sparkDriver' on port 33200.
16/03/16 16:17:57 INFO SparkEnv: Registering MapOutputTracker
16/03/16 16:17:57 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 16:17:57 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-8cd85c4f-5b4c-47d3-b605-70da7e76b75b
16/03/16 16:17:57 INFO MemoryStore: MemoryStore started with capacity 1071.0 MB
16/03/16 16:17:58 INFO HttpFileServer: HTTP File server directory is /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/httpd-f391a33a-d36e-4072-9fc4-127a5aaa5c8d
16/03/16 16:17:58 INFO HttpServer: Starting HTTP Server
16/03/16 16:17:58 INFO Utils: Successfully started service 'HTTP file server' on port 36103.
16/03/16 16:17:58 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 16:17:58 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 16:17:58 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 16:17:58 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-7bb8c92c-900f-449b-aa67-9426c32ff79c/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 16:17:58 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125278199
16/03/16 16:17:58 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 16:17:58 INFO Executor: Starting executor ID driver on host localhost
16/03/16 16:17:58 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37408.
16/03/16 16:17:58 INFO NettyBlockTransferService: Server created on 37408
16/03/16 16:17:58 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 16:17:58 INFO BlockManagerMasterEndpoint: Registering block manager localhost:37408 with 1071.0 MB RAM, BlockManagerId(driver, localhost, 37408)
16/03/16 16:17:58 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): element
16/03/16 16:17:58 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:17:58 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:17:58 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:17:58 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:17:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 16:17:58 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 16:17:58 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:17:58 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1122977710
16/03/16 16:17:58 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1070.9 MB)
16/03/16 16:17:58 INFO MemoryStore: ensureFreeSpace(4141) called with curMem=6568, maxMem=1122977710
16/03/16 16:17:58 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1070.9 MB)
16/03/16 16:17:58 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:37408 (size: 4.0 KB, free: 1071.0 MB)
16/03/16 16:17:58 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 16:17:58 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:17:58 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 16:17:58 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 16:17:58 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 16:17:58 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125278199
16/03/16 16:17:58 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-7bb8c92c-900f-449b-aa67-9426c32ff79c/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: area
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: issue
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: planning
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: permission
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: economy
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: composition
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: agency
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 16:18:07 INFO PythonRunner: Times: total = 9058, boot = 527, init = 429, finish = 8102
16/03/16 16:18:07 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 16:18:07 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 16:18:07 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 16:18:07 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9200 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: set
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: bend
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: giant
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: astatine
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('astatine.n.01') ; keyword:  element  in syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= [u'astatine']
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: present
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: area
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
16/03/16 16:18:07 INFO PythonRunner: Times: total = 337, boot = 203, init = 0, finish = 134
16/03/16 16:18:07 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 16:18:07 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 370 ms on localhost (2/2)
16/03/16 16:18:07 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 9.553 s
16/03/16 16:18:07 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 16:18:07 INFO DAGScheduler: looking for newly runnable stages
16/03/16 16:18:07 INFO DAGScheduler: running: Set()
16/03/16 16:18:07 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 16:18:07 INFO DAGScheduler: failed: Set()
16/03/16 16:18:07 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 16:18:07 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 16:18:07 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10709, maxMem=1122977710
16/03/16 16:18:07 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1070.9 MB)
16/03/16 16:18:07 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15693, maxMem=1122977710
16/03/16 16:18:07 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1070.9 MB)
16/03/16 16:18:07 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:37408 (size: 3.0 KB, free: 1070.9 MB)
16/03/16 16:18:07 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 16:18:07 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:18:07 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 16:18:07 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:18:07 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 16:18:07 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:18:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 16:18:08 INFO PythonRunner: Times: total = 197, boot = 196, init = 0, finish = 1
16/03/16 16:18:08 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 16:18:08 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:18:08 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 16:18:08 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:18:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
16/03/16 16:18:08 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 250 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'astatine']
16/03/16 16:18:08 INFO PythonRunner: Times: total = 219, boot = 218, init = 1, finish = 0
16/03/16 16:18:08 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1242 bytes result sent to driver
16/03/16 16:18:08 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 250 ms on localhost (2/2)
16/03/16 16:18:08 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 16:18:08 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.471 s
16/03/16 16:18:08 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 10.078070 s
16/03/16 16:18:08 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:18:08 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:18:08 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:18:08 INFO DAGScheduler: Parents of final stage: List()
16/03/16 16:18:08 INFO DAGScheduler: Missing parents: List()
16/03/16 16:18:08 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:18:08 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18741, maxMem=1122977710
16/03/16 16:18:08 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1070.9 MB)
16/03/16 16:18:08 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24557, maxMem=1122977710
16/03/16 16:18:08 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1070.9 MB)
16/03/16 16:18:08 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:37408 (size: 3.3 KB, free: 1070.9 MB)
16/03/16 16:18:08 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 16:18:08 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:18:08 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 16:18:08 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 16:18:08 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 16:18:08 INFO PythonRunner: Times: total = 34, boot = 29, init = 5, finish = 0
16/03/16 16:18:08 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 16:18:08 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2272 bytes)
16/03/16 16:18:08 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 68 ms on localhost (1/2)
16/03/16 16:18:08 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 16:18:09 INFO PythonRunner: Times: total = 281, boot = 281, init = 0, finish = 0
16/03/16 16:18:09 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1311 bytes result sent to driver
16/03/16 16:18:09 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 313 ms on localhost (2/2)
16/03/16 16:18:09 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 16:18:09 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.370 s
16/03/16 16:18:09 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.393680 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 16:18:09 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 16:18:09 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 16:18:09 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 16:18:09 INFO MemoryStore: MemoryStore cleared
16/03/16 16:18:09 INFO BlockManager: BlockManager stopped
16/03/16 16:18:09 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 16:18:09 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 16:18:09 INFO SparkContext: Successfully stopped SparkContext
16/03/16 16:18:09 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 16:18:09 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 16:18:09 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'astatine']
16/03/16 16:18:10 INFO SparkContext: Running Spark version 1.5.2
16/03/16 16:18:10 INFO SecurityManager: Changing view acls to: root
16/03/16 16:18:10 INFO SecurityManager: Changing modify acls to: root
16/03/16 16:18:10 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 16:18:10 INFO Slf4jLogger: Slf4jLogger started
16/03/16 16:18:10 INFO Remoting: Starting remoting
16/03/16 16:18:10 INFO Utils: Successfully started service 'sparkDriver' on port 34080.
16/03/16 16:18:10 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:34080]
16/03/16 16:18:10 INFO SparkEnv: Registering MapOutputTracker
16/03/16 16:18:10 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 16:18:10 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-8352a078-868b-4a99-b583-2e809642d768
16/03/16 16:18:10 INFO MemoryStore: MemoryStore started with capacity 1071.0 MB
16/03/16 16:18:10 INFO HttpFileServer: HTTP File server directory is /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/httpd-080aff86-faed-4d7e-b039-fa75ab669484
16/03/16 16:18:10 INFO HttpServer: Starting HTTP Server
16/03/16 16:18:10 INFO Utils: Successfully started service 'HTTP file server' on port 51136.
16/03/16 16:18:10 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 16:18:10 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 16:18:10 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 16:18:10 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-fc955a79-7d06-48e4-b6ec-d9683beaeb26/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 16:18:10 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125290610
16/03/16 16:18:10 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 16:18:10 INFO Executor: Starting executor ID driver on host localhost
16/03/16 16:18:10 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40210.
16/03/16 16:18:10 INFO NettyBlockTransferService: Server created on 40210
16/03/16 16:18:10 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 16:18:10 INFO BlockManagerMasterEndpoint: Registering block manager localhost:40210 with 1071.0 MB RAM, BlockManagerId(driver, localhost, 40210)
16/03/16 16:18:10 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): person
16/03/16 16:18:11 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:18:11 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:18:11 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:18:11 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:18:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 16:18:11 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 16:18:11 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:18:11 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1122977710
16/03/16 16:18:11 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1070.9 MB)
16/03/16 16:18:11 INFO MemoryStore: ensureFreeSpace(4141) called with curMem=6568, maxMem=1122977710
16/03/16 16:18:11 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1070.9 MB)
16/03/16 16:18:11 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:40210 (size: 4.0 KB, free: 1071.0 MB)
16/03/16 16:18:11 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 16:18:11 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:18:11 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 16:18:11 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 16:18:11 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 16:18:11 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125290610
16/03/16 16:18:11 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-fc955a79-7d06-48e4-b6ec-d9683beaeb26/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: area
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: issue
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: planning
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: permission
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: economy
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: composition
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: agency
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 16:18:21 INFO PythonRunner: Times: total = 10468, boot = 870, init = 766, finish = 8832
16/03/16 16:18:21 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 16:18:21 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 16:18:21 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 16:18:21 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 10672 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: set
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: bend
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: giant
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): adding to parents: syn =  Synset('colossus.n.02') ; keyword:  person  in syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= [u'giant']
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: astatine
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: present
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: area
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
16/03/16 16:18:22 INFO PythonRunner: Times: total = 372, boot = 223, init = 0, finish = 149
16/03/16 16:18:22 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 16:18:22 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 431 ms on localhost (2/2)
16/03/16 16:18:22 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 16:18:22 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 11.085 s
16/03/16 16:18:22 INFO DAGScheduler: looking for newly runnable stages
16/03/16 16:18:22 INFO DAGScheduler: running: Set()
16/03/16 16:18:22 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 16:18:22 INFO DAGScheduler: failed: Set()
16/03/16 16:18:22 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 16:18:22 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 16:18:22 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10709, maxMem=1122977710
16/03/16 16:18:22 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1070.9 MB)
16/03/16 16:18:22 INFO MemoryStore: ensureFreeSpace(3047) called with curMem=15693, maxMem=1122977710
16/03/16 16:18:22 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1070.9 MB)
16/03/16 16:18:22 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:40210 (size: 3.0 KB, free: 1070.9 MB)
16/03/16 16:18:22 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 16:18:22 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:18:22 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 16:18:22 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:18:22 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 16:18:22 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:18:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/16 16:18:22 INFO PythonRunner: Times: total = 180, boot = 180, init = 0, finish = 0
16/03/16 16:18:22 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 16:18:22 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:18:22 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 16:18:22 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:18:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 16:18:22 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 228 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'giant']
16/03/16 16:18:22 INFO PythonRunner: Times: total = 198, boot = 197, init = 0, finish = 1
16/03/16 16:18:22 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1239 bytes result sent to driver
16/03/16 16:18:22 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.447 s
16/03/16 16:18:22 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 11.573003 s
16/03/16 16:18:22 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 219 ms on localhost (2/2)
16/03/16 16:18:22 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 16:18:22 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:18:22 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:18:22 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:18:22 INFO DAGScheduler: Parents of final stage: List()
16/03/16 16:18:22 INFO DAGScheduler: Missing parents: List()
16/03/16 16:18:22 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:18:22 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18740, maxMem=1122977710
16/03/16 16:18:22 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1070.9 MB)
16/03/16 16:18:22 INFO MemoryStore: ensureFreeSpace(3374) called with curMem=24556, maxMem=1122977710
16/03/16 16:18:22 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1070.9 MB)
16/03/16 16:18:22 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:40210 (size: 3.3 KB, free: 1070.9 MB)
16/03/16 16:18:22 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 16:18:22 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:18:22 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 16:18:22 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 16:18:22 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 16:18:22 INFO PythonRunner: Times: total = 121, boot = 121, init = 0, finish = 0
16/03/16 16:18:22 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 16:18:22 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2269 bytes)
16/03/16 16:18:22 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 136 ms on localhost (1/2)
16/03/16 16:18:22 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 16:18:23 INFO PythonRunner: Times: total = 211, boot = 210, init = 1, finish = 0
16/03/16 16:18:23 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1308 bytes result sent to driver
16/03/16 16:18:23 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 228 ms on localhost (2/2)
16/03/16 16:18:23 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 16:18:23 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.362 s
16/03/16 16:18:23 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.387814 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 16:18:23 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 16:18:23 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 16:18:23 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 16:18:23 INFO MemoryStore: MemoryStore cleared
16/03/16 16:18:23 INFO BlockManager: BlockManager stopped
16/03/16 16:18:23 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 16:18:23 INFO SparkContext: Successfully stopped SparkContext
16/03/16 16:18:23 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 16:18:23 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 16:18:23 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 16:18:23 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'giant']
16/03/16 16:18:24 INFO SparkContext: Running Spark version 1.5.2
16/03/16 16:18:24 INFO SecurityManager: Changing view acls to: root
16/03/16 16:18:24 INFO SecurityManager: Changing modify acls to: root
16/03/16 16:18:24 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 16:18:24 INFO Slf4jLogger: Slf4jLogger started
16/03/16 16:18:24 INFO Remoting: Starting remoting
16/03/16 16:18:24 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:46117]
16/03/16 16:18:24 INFO Utils: Successfully started service 'sparkDriver' on port 46117.
16/03/16 16:18:24 INFO SparkEnv: Registering MapOutputTracker
16/03/16 16:18:24 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 16:18:24 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-89671c25-ce28-4727-a04d-fa1b73f53e6a
16/03/16 16:18:24 INFO MemoryStore: MemoryStore started with capacity 1072.6 MB
16/03/16 16:18:25 INFO HttpFileServer: HTTP File server directory is /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/httpd-c547a7e4-41b4-4ac1-a432-481a3d81ad23
16/03/16 16:18:25 INFO HttpServer: Starting HTTP Server
16/03/16 16:18:25 INFO Utils: Successfully started service 'HTTP file server' on port 45382.
16/03/16 16:18:25 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 16:18:25 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 16:18:25 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 16:18:25 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-981ba880-1ce3-4b5d-90b8-40768c5277fa/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 16:18:25 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125305315
16/03/16 16:18:25 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 16:18:25 INFO Executor: Starting executor ID driver on host localhost
16/03/16 16:18:25 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52582.
16/03/16 16:18:25 INFO NettyBlockTransferService: Server created on 52582
16/03/16 16:18:25 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 16:18:25 INFO BlockManagerMasterEndpoint: Registering block manager localhost:52582 with 1072.6 MB RAM, BlockManagerId(driver, localhost, 52582)
16/03/16 16:18:25 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): reputation
16/03/16 16:18:25 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:18:25 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:18:25 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:18:25 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:18:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 16:18:25 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 16:18:25 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:18:25 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1124676403
16/03/16 16:18:25 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1072.6 MB)
16/03/16 16:18:25 INFO MemoryStore: ensureFreeSpace(4141) called with curMem=6568, maxMem=1124676403
16/03/16 16:18:25 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1072.6 MB)
16/03/16 16:18:25 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:52582 (size: 4.0 KB, free: 1072.6 MB)
16/03/16 16:18:25 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 16:18:25 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:18:25 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 16:18:25 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 16:18:25 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 16:18:25 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125305315
16/03/16 16:18:25 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-981ba880-1ce3-4b5d-90b8-40768c5277fa/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: area
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: issue
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: planning
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: permission
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: economy
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: composition
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: agency
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 16:18:35 INFO PythonRunner: Times: total = 9447, boot = 902, init = 543, finish = 8002
16/03/16 16:18:35 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 16:18:35 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 16:18:35 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 16:18:35 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9633 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: set
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: bend
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: giant
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): adding to parents: syn =  Synset('colossus.n.02') ; keyword:  reputation  in syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= [u'giant']
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: astatine
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: present
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: area
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
16/03/16 16:18:35 INFO PythonRunner: Times: total = 255, boot = 151, init = 0, finish = 104
16/03/16 16:18:35 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 16:18:35 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 289 ms on localhost (2/2)
16/03/16 16:18:35 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 16:18:35 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 9.900 s
16/03/16 16:18:35 INFO DAGScheduler: looking for newly runnable stages
16/03/16 16:18:35 INFO DAGScheduler: running: Set()
16/03/16 16:18:35 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 16:18:35 INFO DAGScheduler: failed: Set()
16/03/16 16:18:35 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 16:18:35 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 16:18:35 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10709, maxMem=1124676403
16/03/16 16:18:35 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1072.6 MB)
16/03/16 16:18:35 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15693, maxMem=1124676403
16/03/16 16:18:35 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1072.6 MB)
16/03/16 16:18:35 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:52582 (size: 3.0 KB, free: 1072.6 MB)
16/03/16 16:18:35 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 16:18:35 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:18:35 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 16:18:35 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:18:35 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 16:18:35 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:18:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 16:18:35 INFO PythonRunner: Times: total = 131, boot = 131, init = 0, finish = 0
16/03/16 16:18:35 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 16:18:35 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:18:35 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 16:18:35 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 153 ms on localhost (1/2)
16/03/16 16:18:35 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:18:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
reduceFunction_Parents(): returns= ['None', 'None', u'giant']
16/03/16 16:18:35 INFO PythonRunner: Times: total = 175, boot = 174, init = 1, finish = 0
16/03/16 16:18:35 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1239 bytes result sent to driver
16/03/16 16:18:35 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 204 ms on localhost (2/2)
16/03/16 16:18:35 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.356 s
16/03/16 16:18:35 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 16:18:35 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 10.323799 s
16/03/16 16:18:36 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:18:36 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:18:36 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:18:36 INFO DAGScheduler: Parents of final stage: List()
16/03/16 16:18:36 INFO DAGScheduler: Missing parents: List()
16/03/16 16:18:36 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:18:36 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18741, maxMem=1124676403
16/03/16 16:18:36 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1072.6 MB)
16/03/16 16:18:36 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24557, maxMem=1124676403
16/03/16 16:18:36 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1072.5 MB)
16/03/16 16:18:36 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:52582 (size: 3.3 KB, free: 1072.6 MB)
16/03/16 16:18:36 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 16:18:36 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:18:36 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 16:18:36 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 16:18:36 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 16:18:36 INFO PythonRunner: Times: total = 47, boot = 47, init = 0, finish = 0
16/03/16 16:18:36 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 16:18:36 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2269 bytes)
16/03/16 16:18:36 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 63 ms on localhost (1/2)
16/03/16 16:18:36 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 16:18:36 INFO PythonRunner: Times: total = 146, boot = 146, init = 0, finish = 0
16/03/16 16:18:36 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1308 bytes result sent to driver
16/03/16 16:18:36 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 183 ms on localhost (2/2)
16/03/16 16:18:36 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 16:18:36 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.227 s
16/03/16 16:18:36 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.263200 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 16:18:36 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 16:18:36 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 16:18:36 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 16:18:36 INFO MemoryStore: MemoryStore cleared
16/03/16 16:18:36 INFO BlockManager: BlockManager stopped
16/03/16 16:18:36 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 16:18:36 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 16:18:36 INFO SparkContext: Successfully stopped SparkContext
16/03/16 16:18:36 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'giant']
16/03/16 16:18:37 INFO SparkContext: Running Spark version 1.5.2
16/03/16 16:18:37 INFO SecurityManager: Changing view acls to: root
16/03/16 16:18:37 INFO SecurityManager: Changing modify acls to: root
16/03/16 16:18:37 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 16:18:37 INFO Slf4jLogger: Slf4jLogger started
16/03/16 16:18:37 INFO Remoting: Starting remoting
16/03/16 16:18:37 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:57987]
16/03/16 16:18:37 INFO Utils: Successfully started service 'sparkDriver' on port 57987.
16/03/16 16:18:37 INFO SparkEnv: Registering MapOutputTracker
16/03/16 16:18:37 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 16:18:37 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-a47e4b3c-492f-4cf5-865b-47b1b56831c1
16/03/16 16:18:37 INFO MemoryStore: MemoryStore started with capacity 1072.6 MB
16/03/16 16:18:37 INFO HttpFileServer: HTTP File server directory is /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/httpd-d59e088d-6825-4a24-977e-78d83a6831cb
16/03/16 16:18:37 INFO HttpServer: Starting HTTP Server
16/03/16 16:18:37 INFO Utils: Successfully started service 'HTTP file server' on port 47833.
16/03/16 16:18:37 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 16:18:37 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 16:18:37 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 16:18:37 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-2891844f-80e9-4d55-82c8-0e94acf5e087/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 16:18:37 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125317729
16/03/16 16:18:37 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 16:18:37 INFO Executor: Starting executor ID driver on host localhost
16/03/16 16:18:37 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53777.
16/03/16 16:18:37 INFO NettyBlockTransferService: Server created on 53777
16/03/16 16:18:37 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 16:18:37 INFO BlockManagerMasterEndpoint: Registering block manager localhost:53777 with 1072.6 MB RAM, BlockManagerId(driver, localhost, 53777)
16/03/16 16:18:37 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): time
16/03/16 16:18:37 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:18:37 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:18:37 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:18:37 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:18:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 16:18:37 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 16:18:37 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:18:37 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1124676403
16/03/16 16:18:37 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1072.6 MB)
16/03/16 16:18:37 INFO MemoryStore: ensureFreeSpace(4141) called with curMem=6568, maxMem=1124676403
16/03/16 16:18:37 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1072.6 MB)
16/03/16 16:18:37 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:53777 (size: 4.0 KB, free: 1072.6 MB)
16/03/16 16:18:37 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 16:18:37 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:18:37 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 16:18:37 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 16:18:37 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 16:18:37 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125317729
16/03/16 16:18:37 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-2891844f-80e9-4d55-82c8-0e94acf5e087/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: area
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: issue
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: planning
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: permission
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: economy
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: composition
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: agency
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 16:18:45 INFO PythonRunner: Times: total = 7766, boot = 471, init = 355, finish = 6940
16/03/16 16:18:45 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 16:18:45 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 16:18:45 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 16:18:45 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7877 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: set
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: bend
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: giant
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: astatine
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: present
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('present.n.01') ; keyword:  time  in syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= [u'present']
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: area
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
16/03/16 16:18:46 INFO PythonRunner: Times: total = 263, boot = 154, init = 0, finish = 109
16/03/16 16:18:46 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 16:18:46 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.207 s
16/03/16 16:18:46 INFO DAGScheduler: looking for newly runnable stages
16/03/16 16:18:46 INFO DAGScheduler: running: Set()
16/03/16 16:18:46 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 16:18:46 INFO DAGScheduler: failed: Set()
16/03/16 16:18:46 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 16:18:46 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 16:18:46 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10709, maxMem=1124676403
16/03/16 16:18:46 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1072.6 MB)
16/03/16 16:18:46 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 329 ms on localhost (2/2)
16/03/16 16:18:46 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 16:18:46 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15693, maxMem=1124676403
16/03/16 16:18:46 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1072.6 MB)
16/03/16 16:18:46 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:53777 (size: 3.0 KB, free: 1072.6 MB)
16/03/16 16:18:46 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 16:18:46 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:18:46 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 16:18:46 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:18:46 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 16:18:46 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:18:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 16:18:46 INFO PythonRunner: Times: total = 158, boot = 158, init = 0, finish = 0
16/03/16 16:18:46 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 16:18:46 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:18:46 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 16:18:46 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:18:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 16:18:46 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 189 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'present']
16/03/16 16:18:46 INFO PythonRunner: Times: total = 219, boot = 218, init = 1, finish = 0
16/03/16 16:18:46 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1241 bytes result sent to driver
16/03/16 16:18:46 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 243 ms on localhost (2/2)
16/03/16 16:18:46 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.419 s
16/03/16 16:18:46 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.663511 s
16/03/16 16:18:46 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 16:18:46 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:18:46 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:18:46 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:18:46 INFO DAGScheduler: Parents of final stage: List()
16/03/16 16:18:46 INFO DAGScheduler: Missing parents: List()
16/03/16 16:18:46 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:18:46 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18741, maxMem=1124676403
16/03/16 16:18:46 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1072.6 MB)
16/03/16 16:18:46 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24557, maxMem=1124676403
16/03/16 16:18:46 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1072.5 MB)
16/03/16 16:18:46 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:53777 (size: 3.3 KB, free: 1072.6 MB)
16/03/16 16:18:46 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 16:18:46 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:18:46 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 16:18:46 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 16:18:46 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 16:18:46 INFO PythonRunner: Times: total = 162, boot = 162, init = 0, finish = 0
16/03/16 16:18:46 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 16:18:46 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2271 bytes)
16/03/16 16:18:46 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 181 ms on localhost (1/2)
16/03/16 16:18:46 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 16:18:47 INFO PythonRunner: Times: total = 206, boot = 206, init = 0, finish = 0
16/03/16 16:18:47 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1310 bytes result sent to driver
16/03/16 16:18:47 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 230 ms on localhost (2/2)
16/03/16 16:18:47 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 16:18:47 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.410 s
16/03/16 16:18:47 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.422166 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 16:18:47 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 16:18:47 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 16:18:47 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 16:18:47 INFO MemoryStore: MemoryStore cleared
16/03/16 16:18:47 INFO BlockManager: BlockManager stopped
16/03/16 16:18:47 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 16:18:47 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 16:18:47 INFO SparkContext: Successfully stopped SparkContext
16/03/16 16:18:47 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 16:18:47 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 16:18:47 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'present']
16/03/16 16:18:48 INFO SparkContext: Running Spark version 1.5.2
16/03/16 16:18:48 INFO SecurityManager: Changing view acls to: root
16/03/16 16:18:48 INFO SecurityManager: Changing modify acls to: root
16/03/16 16:18:48 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 16:18:48 INFO Slf4jLogger: Slf4jLogger started
16/03/16 16:18:48 INFO Remoting: Starting remoting
16/03/16 16:18:48 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:46784]
16/03/16 16:18:48 INFO Utils: Successfully started service 'sparkDriver' on port 46784.
16/03/16 16:18:48 INFO SparkEnv: Registering MapOutputTracker
16/03/16 16:18:48 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 16:18:48 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-d690a948-98c0-4a7b-8f98-77d29af67280
16/03/16 16:18:48 INFO MemoryStore: MemoryStore started with capacity 1072.6 MB
16/03/16 16:18:48 INFO HttpFileServer: HTTP File server directory is /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/httpd-62944f5e-1a86-40ba-9905-a52467936ea9
16/03/16 16:18:48 INFO HttpServer: Starting HTTP Server
16/03/16 16:18:48 INFO Utils: Successfully started service 'HTTP file server' on port 38101.
16/03/16 16:18:48 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 16:18:48 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 16:18:48 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 16:18:48 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-3badf1dc-241a-49ce-8ae5-bd2cd33b698e/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 16:18:48 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125328457
16/03/16 16:18:48 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 16:18:48 INFO Executor: Starting executor ID driver on host localhost
16/03/16 16:18:48 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58485.
16/03/16 16:18:48 INFO NettyBlockTransferService: Server created on 58485
16/03/16 16:18:48 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 16:18:48 INFO BlockManagerMasterEndpoint: Registering block manager localhost:58485 with 1072.6 MB RAM, BlockManagerId(driver, localhost, 58485)
16/03/16 16:18:48 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): position
16/03/16 16:18:48 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:18:48 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:18:48 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:18:48 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:18:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 16:18:48 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 16:18:48 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:18:48 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1124676403
16/03/16 16:18:48 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1072.6 MB)
16/03/16 16:18:48 INFO MemoryStore: ensureFreeSpace(4141) called with curMem=6568, maxMem=1124676403
16/03/16 16:18:48 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1072.6 MB)
16/03/16 16:18:48 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:58485 (size: 4.0 KB, free: 1072.6 MB)
16/03/16 16:18:48 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 16:18:48 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:18:48 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 16:18:48 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 16:18:48 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 16:18:48 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125328457
16/03/16 16:18:48 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-3badf1dc-241a-49ce-8ae5-bd2cd33b698e/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: area
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: issue
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: planning
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: permission
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: economy
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: composition
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: agency
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 16:18:59 INFO PythonRunner: Times: total = 11176, boot = 474, init = 361, finish = 10341
16/03/16 16:18:59 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 16:18:59 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 16:18:59 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 16:18:59 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 11310 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: set
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: bend
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: giant
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: astatine
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: present
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): adding to parents: syn =  Synset('metropolitan.n.01') ; keyword:  position  in syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= [u'metropolitan']
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: area
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
16/03/16 16:19:00 INFO PythonRunner: Times: total = 674, boot = 421, init = 0, finish = 253
16/03/16 16:19:00 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 16:19:00 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 726 ms on localhost (2/2)
16/03/16 16:19:00 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 12.018 s
16/03/16 16:19:00 INFO DAGScheduler: looking for newly runnable stages
16/03/16 16:19:00 INFO DAGScheduler: running: Set()
16/03/16 16:19:00 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 16:19:00 INFO DAGScheduler: failed: Set()
16/03/16 16:19:00 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 16:19:00 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 16:19:00 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 16:19:00 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10709, maxMem=1124676403
16/03/16 16:19:00 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1072.6 MB)
16/03/16 16:19:00 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15693, maxMem=1124676403
16/03/16 16:19:00 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1072.6 MB)
16/03/16 16:19:00 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:58485 (size: 3.0 KB, free: 1072.6 MB)
16/03/16 16:19:00 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 16:19:00 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:19:00 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 16:19:00 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:19:00 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 16:19:00 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:19:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 16:19:01 INFO PythonRunner: Times: total = 352, boot = 351, init = 0, finish = 1
16/03/16 16:19:01 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 16:19:01 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:19:01 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 16:19:01 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:19:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
16/03/16 16:19:01 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 400 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'metropolitan']
16/03/16 16:19:01 INFO PythonRunner: Times: total = 408, boot = 405, init = 0, finish = 3
16/03/16 16:19:01 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1246 bytes result sent to driver
16/03/16 16:19:01 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 443 ms on localhost (2/2)
16/03/16 16:19:01 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 16:19:01 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.840 s
16/03/16 16:19:01 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 12.911377 s
16/03/16 16:19:01 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:19:01 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:19:01 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:19:01 INFO DAGScheduler: Parents of final stage: List()
16/03/16 16:19:01 INFO DAGScheduler: Missing parents: List()
16/03/16 16:19:01 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:19:01 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18741, maxMem=1124676403
16/03/16 16:19:01 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1072.6 MB)
16/03/16 16:19:01 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24557, maxMem=1124676403
16/03/16 16:19:01 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1072.5 MB)
16/03/16 16:19:01 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:58485 (size: 3.3 KB, free: 1072.6 MB)
16/03/16 16:19:01 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 16:19:01 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:19:01 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 16:19:01 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 16:19:01 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 16:19:01 INFO PythonRunner: Times: total = 193, boot = 192, init = 1, finish = 0
16/03/16 16:19:01 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 16:19:01 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2276 bytes)
16/03/16 16:19:01 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 228 ms on localhost (1/2)
16/03/16 16:19:01 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 16:19:02 INFO PythonRunner: Times: total = 318, boot = 318, init = 0, finish = 0
16/03/16 16:19:02 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1315 bytes result sent to driver
16/03/16 16:19:02 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 345 ms on localhost (2/2)
16/03/16 16:19:02 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 16:19:02 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.553 s
16/03/16 16:19:02 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.601368 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 16:19:02 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 16:19:02 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 16:19:02 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 16:19:02 INFO MemoryStore: MemoryStore cleared
16/03/16 16:19:02 INFO BlockManager: BlockManager stopped
16/03/16 16:19:02 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 16:19:02 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 16:19:02 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 16:19:02 INFO SparkContext: Successfully stopped SparkContext
16/03/16 16:19:02 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'metropolitan']
16/03/16 16:19:03 INFO SparkContext: Running Spark version 1.5.2
16/03/16 16:19:03 INFO SecurityManager: Changing view acls to: root
16/03/16 16:19:03 INFO SecurityManager: Changing modify acls to: root
16/03/16 16:19:03 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 16:19:03 INFO Slf4jLogger: Slf4jLogger started
16/03/16 16:19:03 INFO Remoting: Starting remoting
16/03/16 16:19:03 INFO Utils: Successfully started service 'sparkDriver' on port 42491.
16/03/16 16:19:03 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:42491]
16/03/16 16:19:03 INFO SparkEnv: Registering MapOutputTracker
16/03/16 16:19:03 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 16:19:03 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-f6d9e9f4-d751-4995-b4f8-ce8900dca24b
16/03/16 16:19:03 INFO MemoryStore: MemoryStore started with capacity 1072.6 MB
16/03/16 16:19:03 INFO HttpFileServer: HTTP File server directory is /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/httpd-27c342d2-7d56-4bc0-92bb-8493776f62c6
16/03/16 16:19:03 INFO HttpServer: Starting HTTP Server
16/03/16 16:19:03 INFO Utils: Successfully started service 'HTTP file server' on port 43505.
16/03/16 16:19:03 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 16:19:03 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 16:19:03 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 16:19:03 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-ca667e47-ee18-4fcd-ba79-fbe065a78967/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 16:19:03 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125343834
16/03/16 16:19:03 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 16:19:03 INFO Executor: Starting executor ID driver on host localhost
16/03/16 16:19:04 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58759.
16/03/16 16:19:04 INFO NettyBlockTransferService: Server created on 58759
16/03/16 16:19:04 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 16:19:04 INFO BlockManagerMasterEndpoint: Registering block manager localhost:58759 with 1072.6 MB RAM, BlockManagerId(driver, localhost, 58759)
16/03/16 16:19:04 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): quantity
16/03/16 16:19:04 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:19:04 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:19:04 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:19:04 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:19:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 16:19:04 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 16:19:04 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:19:04 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1124676403
16/03/16 16:19:04 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1072.6 MB)
16/03/16 16:19:04 INFO MemoryStore: ensureFreeSpace(4141) called with curMem=6568, maxMem=1124676403
16/03/16 16:19:04 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1072.6 MB)
16/03/16 16:19:04 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:58759 (size: 4.0 KB, free: 1072.6 MB)
16/03/16 16:19:04 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 16:19:04 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:19:04 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 16:19:04 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 16:19:04 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 16:19:04 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125343834
16/03/16 16:19:04 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-ca667e47-ee18-4fcd-ba79-fbe065a78967/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: area
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: issue
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: planning
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: permission
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: economy
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: composition
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: agency
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 16:19:13 INFO PythonRunner: Times: total = 9386, boot = 563, init = 370, finish = 8453
16/03/16 16:19:13 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 16:19:13 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 16:19:13 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 16:19:13 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9505 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: set
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: bend
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: giant
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: astatine
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: present
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: area
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 16:19:13 INFO PythonRunner: Times: total = 263, boot = 162, init = 1, finish = 100
16/03/16 16:19:13 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 16:19:13 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 9.767 s
16/03/16 16:19:13 INFO DAGScheduler: looking for newly runnable stages
16/03/16 16:19:13 INFO DAGScheduler: running: Set()
16/03/16 16:19:13 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 16:19:13 INFO DAGScheduler: failed: Set()
16/03/16 16:19:13 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 16:19:13 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 16:19:13 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10709, maxMem=1124676403
16/03/16 16:19:13 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1072.6 MB)
16/03/16 16:19:13 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15693, maxMem=1124676403
16/03/16 16:19:13 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1072.6 MB)
16/03/16 16:19:13 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 287 ms on localhost (2/2)
16/03/16 16:19:13 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 16:19:13 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:58759 (size: 3.0 KB, free: 1072.6 MB)
16/03/16 16:19:13 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 16:19:13 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:19:13 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 16:19:13 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:19:13 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 16:19:13 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:19:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/16 16:19:14 INFO PythonRunner: Times: total = 169, boot = 168, init = 0, finish = 1
16/03/16 16:19:14 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 16:19:14 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:19:14 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 16:19:14 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:19:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 16:19:14 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 203 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None']
16/03/16 16:19:14 INFO PythonRunner: Times: total = 163, boot = 162, init = 0, finish = 1
16/03/16 16:19:14 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1227 bytes result sent to driver
16/03/16 16:19:14 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 191 ms on localhost (2/2)
16/03/16 16:19:14 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 16:19:14 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.372 s
16/03/16 16:19:14 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 10.184355 s
16/03/16 16:19:14 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 16:19:14 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 16:19:14 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:19:14 INFO DAGScheduler: Parents of final stage: List()
16/03/16 16:19:14 INFO DAGScheduler: Missing parents: List()
16/03/16 16:19:14 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 16:19:14 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18741, maxMem=1124676403
16/03/16 16:19:14 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1072.6 MB)
16/03/16 16:19:14 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24557, maxMem=1124676403
16/03/16 16:19:14 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1072.5 MB)
16/03/16 16:19:14 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:58759 (size: 3.3 KB, free: 1072.6 MB)
16/03/16 16:19:14 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 16:19:14 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 16:19:14 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 16:19:14 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 16:19:14 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 16:19:14 INFO PythonRunner: Times: total = 102, boot = 102, init = 0, finish = 0
16/03/16 16:19:14 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 16:19:14 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2257 bytes)
16/03/16 16:19:14 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 16:19:14 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 123 ms on localhost (1/2)
16/03/16 16:19:14 INFO PythonRunner: Times: total = 170, boot = 170, init = 0, finish = 0
16/03/16 16:19:14 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1296 bytes result sent to driver
16/03/16 16:19:14 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 183 ms on localhost (2/2)
16/03/16 16:19:14 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 16:19:14 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.304 s
16/03/16 16:19:14 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.318589 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 16:19:14 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 16:19:14 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 16:19:14 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 16:19:14 INFO MemoryStore: MemoryStore cleared
16/03/16 16:19:14 INFO BlockManager: BlockManager stopped
16/03/16 16:19:14 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 16:19:14 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 16:19:14 INFO SparkContext: Successfully stopped SparkContext
16/03/16 16:19:14 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 16:19:14 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 16:19:14 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None']
InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:freqterms1= [u'serving', u'Madras', u'Bengal', u'course', u'relation', u'geography', u'group', u'decay', u'program', u'Tamil', u'exceptional', u'Bay', u'formulating', u'serves', u'item', u'miles', u'unstable', u'including', u'people', u'series', u'Christianity', u'culture', u'meters', u'special', u'0.621371', u'Orthodox', u'definite', u'boundary', u'business', u'importance', u'equivalent', u'thorium', u'approval', u'providing', u'region', u'title', u'equal', u'length', u'resulting', u'act', u'action', u'whole', u'businesses', u'1000', u'formerly', u'period', u'highly', u'production', u'indefinite', u'unit', u'city', u'use', u'consumption', u'Eastern', u'stretch', u'archbishop', u'system', u'halogen', u'continuous', u'western', u'particular', u'given', u'kind', u'official', u'patriarch', u'Church', u'distribution', u'property', u'distinguished', u'metric', u'heaviest', u'purposes', u'general', u'something', u'bishop', u'things', u'belong', u'uranium', u'arrangement', u'parts', u'speech', u'geographical', u'spatial', u'Nadu', u'circular', u'product', u'used', u'usually', u'moment', u'purpose', u'segment', u'radioactive', u'happening', u'curve', u'together', u'element', u'person', u'reputation', u'time', u'position', u'quantity']
16/03/16 16:19:15 INFO SparkContext: Running Spark version 1.5.2
16/03/16 16:19:15 INFO SecurityManager: Changing view acls to: root
16/03/16 16:19:15 INFO SecurityManager: Changing modify acls to: root
16/03/16 16:19:15 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 16:19:15 INFO Slf4jLogger: Slf4jLogger started
16/03/16 16:19:15 INFO Remoting: Starting remoting
16/03/16 16:19:15 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:41840]
16/03/16 16:19:15 INFO Utils: Successfully started service 'sparkDriver' on port 41840.
16/03/16 16:19:15 INFO SparkEnv: Registering MapOutputTracker
16/03/16 16:19:15 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 16:19:15 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-470fa28d-2a0a-43fc-8d85-f3b48bf083c0
16/03/16 16:19:15 INFO MemoryStore: MemoryStore started with capacity 1072.6 MB
16/03/16 16:19:15 INFO HttpFileServer: HTTP File server directory is /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/httpd-5c00570e-dda9-4eb2-8b62-436c4459fc6d
16/03/16 16:19:15 INFO HttpServer: Starting HTTP Server
16/03/16 16:19:15 INFO Utils: Successfully started service 'HTTP file server' on port 39409.
16/03/16 16:19:15 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 16:19:16 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 16:19:16 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 16:19:16 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-baed041f-af1f-4a6e-954e-298278d08233/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 16:19:16 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125356043
16/03/16 16:19:16 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 16:19:16 INFO Executor: Starting executor ID driver on host localhost
16/03/16 16:19:16 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51652.
16/03/16 16:19:16 INFO NettyBlockTransferService: Server created on 51652
16/03/16 16:19:16 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 16:19:16 INFO BlockManagerMasterEndpoint: Registering block manager localhost:51652 with 1072.6 MB RAM, BlockManagerId(driver, localhost, 51652)
16/03/16 16:19:16 INFO BlockManagerMaster: Registered BlockManager
Spark_MapReduce(): wordsatthislevel: [u'serving', u'Madras', u'Bengal', u'course', u'relation', u'geography', u'group', u'decay', u'program', u'Tamil', u'exceptional', u'Bay', u'formulating', u'serves', u'item', u'miles', u'unstable', u'including', u'people', u'series', u'Christianity', u'culture', u'meters', u'special', u'0.621371', u'Orthodox', u'definite', u'boundary', u'business', u'importance', u'equivalent', u'thorium', u'approval', u'providing', u'region', u'title', u'equal', u'length', u'resulting', u'act', u'action', u'whole', u'businesses', u'1000', u'formerly', u'period', u'highly', u'production', u'indefinite', u'unit', u'city', u'use', u'consumption', u'Eastern', u'stretch', u'archbishop', u'system', u'halogen', u'continuous', u'western', u'particular', u'given', u'kind', u'official', u'patriarch', u'Church', u'distribution', u'property', u'distinguished', u'metric', u'heaviest', u'purposes', u'general', u'something', u'bishop', u'things', u'belong', u'uranium', u'arrangement', u'parts', u'speech', u'geographical', u'spatial', u'Nadu', u'circular', u'product', u'used', u'usually', u'moment', u'purpose', u'segment', u'radioactive', u'happening', u'curve', u'together', u'element', u'person', u'reputation', u'time', u'position', u'quantity']
16/03/16 16:19:16 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230
16/03/16 16:19:16 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230)
16/03/16 16:19:16 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230) with 2 output partitions
16/03/16 16:19:16 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230)
16/03/16 16:19:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 16:19:16 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 16:19:16 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230), which has no missing parents
16/03/16 16:19:16 INFO MemoryStore: ensureFreeSpace(6552) called with curMem=0, maxMem=1124676403
16/03/16 16:19:16 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1072.6 MB)
16/03/16 16:19:16 INFO MemoryStore: ensureFreeSpace(4132) called with curMem=6552, maxMem=1124676403
16/03/16 16:19:16 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1072.6 MB)
16/03/16 16:19:16 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:51652 (size: 4.0 KB, free: 1072.6 MB)
16/03/16 16:19:16 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 16:19:16 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230)
16/03/16 16:19:16 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 16:19:16 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2927 bytes)
16/03/16 16:19:16 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 16:19:16 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458125356043
16/03/16 16:19:16 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-ea887ce5-7c63-49e3-b124-c28f8964821f/userFiles-baed041f-af1f-4a6e-954e-298278d08233/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
mapFunction(): freqterms1: serving
mapFunction(): freqterms1: Madras
mapFunction(): freqterms1: Bengal
mapFunction(): freqterms1: course
mapFunction(): freqterms1: relation
mapFunction(): freqterms1: geography
mapFunction(): freqterms1: group
mapFunction(): freqterms1: decay
mapFunction(): freqterms1: program
mapFunction(): freqterms1: Tamil
mapFunction(): freqterms1: exceptional
mapFunction(): freqterms1: Bay
mapFunction(): freqterms1: formulating
mapFunction(): freqterms1: serves
mapFunction(): freqterms1: item
mapFunction(): freqterms1: miles
mapFunction(): freqterms1: unstable
mapFunction(): freqterms1: including
mapFunction(): freqterms1: people
mapFunction(): freqterms1: series
mapFunction(): freqterms1: Christianity
mapFunction(): freqterms1: culture
mapFunction(): freqterms1: meters
mapFunction(): freqterms1: special
mapFunction(): freqterms1: 0.621371
mapFunction(): freqterms1: Orthodox
mapFunction(): freqterms1: definite
mapFunction(): freqterms1: boundary
mapFunction(): freqterms1: business
mapFunction(): freqterms1: importance
mapFunction(): freqterms1: equivalent
mapFunction(): freqterms1: thorium
mapFunction(): freqterms1: approval
mapFunction(): freqterms1: providing
mapFunction(): freqterms1: region
mapFunction(): freqterms1: title
mapFunction(): freqterms1: equal
mapFunction(): freqterms1: length
mapFunction(): freqterms1: resulting
mapFunction(): freqterms1: act
mapFunction(): freqterms1: action
mapFunction(): freqterms1: whole
mapFunction(): freqterms1: businesses
mapFunction(): freqterms1: 1000
mapFunction(): freqterms1: formerly
mapFunction(): freqterms1: period
mapFunction(): freqterms1: highly
mapFunction(): freqterms1: production
mapFunction(): freqterms1: indefinite
mapFunction(): freqterms1: unit
16/03/16 16:19:25 INFO PythonRunner: Times: total = 9253, boot = 482, init = 353, finish = 8418
16/03/16 16:19:25 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 16:19:25 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2968 bytes)
16/03/16 16:19:25 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 16:19:25 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9353 ms on localhost (1/2)
mapFunction(): freqterms1: city
mapFunction(): freqterms1: use
mapFunction(): freqterms1: consumption
mapFunction(): freqterms1: Eastern
mapFunction(): freqterms1: stretch
mapFunction(): freqterms1: archbishop
mapFunction(): freqterms1: system
mapFunction(): freqterms1: halogen
mapFunction(): freqterms1: continuous
mapFunction(): freqterms1: western
mapFunction(): freqterms1: particular
mapFunction(): freqterms1: given
mapFunction(): freqterms1: kind
mapFunction(): freqterms1: official
mapFunction(): freqterms1: patriarch
mapFunction(): freqterms1: Church
mapFunction(): freqterms1: distribution
mapFunction(): freqterms1: property
mapFunction(): freqterms1: distinguished
mapFunction(): freqterms1: metric
mapFunction(): freqterms1: heaviest
mapFunction(): freqterms1: purposes
mapFunction(): freqterms1: general
mapFunction(): freqterms1: something
mapFunction(): freqterms1: bishop
mapFunction(): freqterms1: things
mapFunction(): freqterms1: belong
mapFunction(): freqterms1: uranium
mapFunction(): freqterms1: arrangement
mapFunction(): freqterms1: parts
mapFunction(): freqterms1: speech
mapFunction(): freqterms1: geographical
mapFunction(): freqterms1: spatial
mapFunction(): freqterms1: Nadu
mapFunction(): freqterms1: circular
mapFunction(): freqterms1: product
mapFunction(): freqterms1: used
mapFunction(): freqterms1: usually
mapFunction(): freqterms1: moment
mapFunction(): freqterms1: purpose
mapFunction(): freqterms1: segment
mapFunction(): freqterms1: radioactive
mapFunction(): freqterms1: happening
mapFunction(): freqterms1: curve
mapFunction(): freqterms1: together
mapFunction(): freqterms1: element
mapFunction(): freqterms1: person
mapFunction(): freqterms1: reputation
mapFunction(): freqterms1: time
mapFunction(): freqterms1: position
mapFunction(): freqterms1: quantity
16/03/16 16:19:27 INFO PythonRunner: Times: total = 1557, boot = 186, init = 1, finish = 1370
16/03/16 16:19:27 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 16:19:27 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 1584 ms on localhost (2/2)
16/03/16 16:19:27 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230) finished in 10.922 s
16/03/16 16:19:27 INFO DAGScheduler: looking for newly runnable stages
16/03/16 16:19:27 INFO DAGScheduler: running: Set()
16/03/16 16:19:27 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 16:19:27 INFO DAGScheduler: failed: Set()
16/03/16 16:19:27 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 16:19:27 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230), which is now runnable
16/03/16 16:19:27 INFO MemoryStore: ensureFreeSpace(4976) called with curMem=10684, maxMem=1124676403
16/03/16 16:19:27 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1072.6 MB)
16/03/16 16:19:27 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 16:19:27 INFO MemoryStore: ensureFreeSpace(3040) called with curMem=15660, maxMem=1124676403
16/03/16 16:19:27 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1072.6 MB)
16/03/16 16:19:27 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:51652 (size: 3.0 KB, free: 1072.6 MB)
16/03/16 16:19:27 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 16:19:27 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230)
16/03/16 16:19:27 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 16:19:27 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:19:27 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 16:19:27 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:19:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/16 16:19:27 INFO PythonRunner: Times: total = 163, boot = 162, init = 1, finish = 0
16/03/16 16:19:27 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 16:19:27 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 16:19:27 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 16:19:27 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 16:19:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 16:19:27 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 199 ms on localhost (1/2)
16/03/16 16:19:27 INFO PythonRunner: Times: total = 173, boot = 170, init = 0, finish = 3
16/03/16 16:19:27 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 10972 bytes result sent to driver
16/03/16 16:19:27 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 200 ms on localhost (2/2)
16/03/16 16:19:27 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230) finished in 0.371 s
16/03/16 16:19:27 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 16:19:27 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230, took 11.342938 s
16/03/16 16:19:27 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230
16/03/16 16:19:27 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230) with 2 output partitions
16/03/16 16:19:27 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230)
16/03/16 16:19:27 INFO DAGScheduler: Parents of final stage: List()
16/03/16 16:19:27 INFO DAGScheduler: Missing parents: List()
16/03/16 16:19:27 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230), which has no missing parents
16/03/16 16:19:27 INFO MemoryStore: ensureFreeSpace(5872) called with curMem=18700, maxMem=1124676403
16/03/16 16:19:27 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1072.6 MB)
16/03/16 16:19:27 INFO MemoryStore: ensureFreeSpace(3416) called with curMem=24572, maxMem=1124676403
16/03/16 16:19:27 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1072.5 MB)
16/03/16 16:19:27 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:51652 (size: 3.3 KB, free: 1072.6 MB)
16/03/16 16:19:27 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 16:19:27 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230)
16/03/16 16:19:27 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 16:19:27 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 16:19:27 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 16:19:27 INFO PythonRunner: Times: total = 64, boot = 63, init = 1, finish = 0
16/03/16 16:19:27 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 16:19:27 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 11918 bytes)
16/03/16 16:19:27 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 91 ms on localhost (1/2)
16/03/16 16:19:27 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 16:19:28 INFO PythonRunner: Times: total = 178, boot = 177, init = 0, finish = 1
16/03/16 16:19:28 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 11279 bytes result sent to driver
16/03/16 16:19:28 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 249 ms on localhost (2/2)
16/03/16 16:19:28 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230) finished in 0.334 s
16/03/16 16:19:28 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 16:19:28 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230, took 0.348359 s
Spark_MapReduce() - SparkSQL DataFrame query results:
Row(tokensatthislevel=[u'individual', u'quantity', u'food', u'drink', u'taken', u'part', u'meal', u'state', u'southeastern', u'India', u'Bay', u'Bengal', u'south', u'Andhra', u'Pradesh', u'formerly', u'Madras', u'region', u'whose', u'eastern', u'part', u'Bangladesh', u'whose', u'western', u'part', u'included', u'India', u'education', u'imparted', u'series', u'lessons', u'meetings', u'act', u'sexual', u'procreation', u'man', u'woman', u'man', u'penis', u'inserted', u'woman', u'vagina', u'excited', u'orgasm', u'ejaculation', u'occur', u'study', u'earth', u'surface', u'includes', u'people', u'responses', u'topography', u'climate', u'soil', u'vegetation', u'number', u'entities', u'members', u'considered', u'unit', u'gradual', u'decrease', u'stored', u'charge', u'current', u'series', u'steps', u'carried', u'goals', u'accomplished', u'member', u'mixed', u'Dravidian', u'Caucasian', u'people', u'southern', u'India', u'Sri', u'Lanka', u'deviating', u'widely', u'norm', u'physical', u'mental', u'ability', u'used', u'especially', u'children', u'normal', u'intelligence', u'indentation', u'shoreline', u'larger', u'cove', u'smaller', u'gulf', u'come', u'idea', u'plan', u'explanation', u'theory', u'principle', u'mental', u'effort', u'sports', u'stroke', u'puts', u'ball', u'play', u'distinct', u'part', u'specified', u'separately', u'group', u'things', u'could', u'enumerated', u'list', u'unit', u'length', u'equal', u'1,760', u'yards', u'5,280', u'feet', u'exactly', u'1609.344', u'meters', u'lacking', u'stability', u'fixity', u'firmness', u'part', u'made', u'plural', u'group', u'human', u'beings', u'men', u'women', u'children', u'collectively', u'similar', u'things', u'placed', u'order', u'happening', u'one', u'another', u'monotheistic', u'system', u'beliefs', u'practices', u'based', u'Old', u'Testament', u'teachings', u'Jesus', u'embodied', u'New', u'Testament', u'emphasizing', u'role', u'Jesus', u'savior', u'particular', u'society', u'particular', u'time', u'place', u'basic', u'unit', u'length', u'adopted', u'Systeme', u'International', u"d'Unites", u'approximately', u'1.094', u'yards', u'special', u'offering', u'usually', u'temporary', u'reduced', u'price', u'featured', u'advertising', u'pertaining', u'characteristic', u'Judaism', u'precise', u'explicit', u'clearly', u'defined', u'line', u'determining', u'limits', u'area', u'commercial', u'industrial', u'enterprise', u'people', u'constitute', u'prominent', u'status', u'person', u'thing', u'equal', u'another', u'value', u'measure', u'force', u'effect', u'significance', u'etc', u'soft', u'silvery-white', u'tetravalent', u'radioactive', u'metallic', u'element', u'isotope', u'232', u'used', u'power', u'source', u'nuclear', u'reactors', u'occurs', u'thorite', u'monazite', u'sands', u'feeling', u'liking', u'something', u'someone', u'good', u'give', u'something', u'useful', u'necessary', u'extended', u'spatial', u'location', u'something', u'heading', u'names', u'statute', u'legislative', u'bill', u'give', u'brief', u'summary', u'matters', u'deals', u'person', u'equal', u'standing', u'another', u'group', u'linear', u'extent', u'space', u'one', u'end', u'longest', u'dimension', u'something', u'fixed', u'place', u'issue', u'terminate', u'specified', u'way', u'state', u'etc', u'end', u'legal', u'document', u'codifying', u'result', u'deliberations', u'committee', u'society', u'legislative', u'body', u'military', u'engagement', u'something', u'including', u'component', u'elements', u'parts', u'commercial', u'industrial', u'enterprise', u'people', u'constitute', u'cardinal', u'number', u'product', u'10', u'100', u'previous', u'time', u'amount', u'time', u'high', u'degree', u'extent', u'favorably', u'much', u'respect', u'act', u'process', u'producing', u'something', u'vague', u'clearly', u'defined', u'stated', u'division', u'quantity', u'accepted', u'standard', u'measurement', u'exchange', u'large', u'densely', u'populated', u'urban', u'area', u'include', u'several', u'independent', u'administrative', u'districts', u'act', u'using', u'process', u'taking', u'food', u'body', u'mouth', u'eating', u'lying', u'toward', u'situated', u'east', u'large', u'unbroken', u'expanse', u'distance', u'bishop', u'highest', u'rank', u'instrumentality', u'combines', u'interrelated', u'interacting', u'artifacts', u'designed', u'work', u'coherent', u'entity', u'five', u'related', u'nonmetallic', u'elements', u'fluorine', u'chlorine', u'bromine', u'iodine', u'astatine', u'monovalent', u'readily', u'form', u'negative', u'ions', u'continuing', u'time', u'space', u'without', u'interruption', u'film', u'life', u'western', u'United', u'States', u'period', u'exploration', u'development', u'fact', u'part', u'opposed', u'general', u'assumption', u'taken', u'granted', u'category', u'things', u'distinguished', u'common', u'characteristic', u'quality', u'worker', u'holds', u'invested', u'office', u'man', u'older', u'higher', u'rank', u'one', u'groups', u'Christians', u'beliefs', u'forms', u'worship', u'statistics', u'arrangement', u'values', u'variable', u'showing', u'observed', u'theoretical', u'frequency', u'occurrence', u'something', u'owned', u'tangible', u'intangible', u'possession', u'owned', u'someone', u'mark', u'different', u'function', u'topological', u'space', u'gives', u'two', u'points', u'space', u'value', u'equal', u'distance', u'usually', u'describes', u'large', u'person', u'fat', u'large', u'frame', u'carry', u'anticipated', u'outcome', u'intended', u'guides', u'planned', u'actions', u'general', u'officer', u'highest', u'rank', u'senior', u'member', u'Christian', u'clergy', u'spiritual', u'administrative', u'authority', u'appointed', u'Christian', u'churches', u'oversee', u'priests', u'ministers', u'considered', u'churches', u'successors', u'twelve', u'Apostles', u'Christ', u'movable', u'possession', u'especially', u'articles', u'clothing', u'owned', u'possession', u'heavy', u'toxic', u'silvery-white', u'radioactive', u'metallic', u'element', u'occurs', u'many', u'isotopes', u'used', u'nuclear', u'fuels', u'nuclear', u'weapons', u'orderly', u'grouping', u'things', u'persons', u'considered', u'unit', u'result', u'arranging', u'something', u'less', u'whole', u'human', u'artifact', u'act', u'delivering', u'formal', u'spoken', u'communication', u'audience', u'relating', u'science', u'geography', u'pertaining', u'involving', u'nature', u'space', u'advertisement', u'usually', u'printed', u'page', u'leaflet', u'intended', u'wide', u'distribution', u'commodities', u'offered', u'sale', u'put', u'service', u'make', u'work', u'employ', u'particular', u'purpose', u'inherent', u'natural', u'purpose', u'normal', u'conditions', u'particular', u'point', u'time', u'anticipated', u'outcome', u'intended', u'guides', u'planned', u'actions', u'one', u'several', u'parts', u'pieces', u'fit', u'others', u'constitute', u'whole', u'object', u'exhibiting', u'caused', u'radioactivity', u'event', u'happens', u'trace', u'point', u'whose', u'direction', u'motion', u'changes', u'mentally', u'emotionally', u'stable', u'abstract', u'part', u'something', u'human', u'general', u'estimation', u'public', u'person', u'instance', u'single', u'occasion', u'event', u'particular', u'portion', u'space', u'occupied', u'something', u'concept', u'something', u'magnitude', u'represented', u'mathematical', u'expressions', u'constant', u'variable'])
16/03/16 16:19:28 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 16:19:28 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 16:19:28 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 16:19:28 INFO MemoryStore: MemoryStore cleared
16/03/16 16:19:28 INFO BlockManager: BlockManager stopped
16/03/16 16:19:28 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 16:19:28 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 16:19:28 INFO SparkContext: Successfully stopped SparkContext
16/03/16 16:19:28 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 16:19:28 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:tokensofthislevel: [u'individual', u'quantity', u'food', u'drink', u'taken', u'part', u'meal', u'state', u'southeastern', u'India', u'Bay', u'Bengal', u'south', u'Andhra', u'Pradesh', u'formerly', u'Madras', u'region', u'whose', u'eastern', u'part', u'Bangladesh', u'whose', u'western', u'part', u'included', u'India', u'education', u'imparted', u'series', u'lessons', u'meetings', u'act', u'sexual', u'procreation', u'man', u'woman', u'man', u'penis', u'inserted', u'woman', u'vagina', u'excited', u'orgasm', u'ejaculation', u'occur', u'study', u'earth', u'surface', u'includes', u'people', u'responses', u'topography', u'climate', u'soil', u'vegetation', u'number', u'entities', u'members', u'considered', u'unit', u'gradual', u'decrease', u'stored', u'charge', u'current', u'series', u'steps', u'carried', u'goals', u'accomplished', u'member', u'mixed', u'Dravidian', u'Caucasian', u'people', u'southern', u'India', u'Sri', u'Lanka', u'deviating', u'widely', u'norm', u'physical', u'mental', u'ability', u'used', u'especially', u'children', u'normal', u'intelligence', u'indentation', u'shoreline', u'larger', u'cove', u'smaller', u'gulf', u'come', u'idea', u'plan', u'explanation', u'theory', u'principle', u'mental', u'effort', u'sports', u'stroke', u'puts', u'ball', u'play', u'distinct', u'part', u'specified', u'separately', u'group', u'things', u'could', u'enumerated', u'list', u'unit', u'length', u'equal', u'1,760', u'yards', u'5,280', u'feet', u'exactly', u'1609.344', u'meters', u'lacking', u'stability', u'fixity', u'firmness', u'part', u'made', u'plural', u'group', u'human', u'beings', u'men', u'women', u'children', u'collectively', u'similar', u'things', u'placed', u'order', u'happening', u'one', u'another', u'monotheistic', u'system', u'beliefs', u'practices', u'based', u'Old', u'Testament', u'teachings', u'Jesus', u'embodied', u'New', u'Testament', u'emphasizing', u'role', u'Jesus', u'savior', u'particular', u'society', u'particular', u'time', u'place', u'basic', u'unit', u'length', u'adopted', u'Systeme', u'International', u"d'Unites", u'approximately', u'1.094', u'yards', u'special', u'offering', u'usually', u'temporary', u'reduced', u'price', u'featured', u'advertising', u'pertaining', u'characteristic', u'Judaism', u'precise', u'explicit', u'clearly', u'defined', u'line', u'determining', u'limits', u'area', u'commercial', u'industrial', u'enterprise', u'people', u'constitute', u'prominent', u'status', u'person', u'thing', u'equal', u'another', u'value', u'measure', u'force', u'effect', u'significance', u'etc', u'soft', u'silvery-white', u'tetravalent', u'radioactive', u'metallic', u'element', u'isotope', u'232', u'used', u'power', u'source', u'nuclear', u'reactors', u'occurs', u'thorite', u'monazite', u'sands', u'feeling', u'liking', u'something', u'someone', u'good', u'give', u'something', u'useful', u'necessary', u'extended', u'spatial', u'location', u'something', u'heading', u'names', u'statute', u'legislative', u'bill', u'give', u'brief', u'summary', u'matters', u'deals', u'person', u'equal', u'standing', u'another', u'group', u'linear', u'extent', u'space', u'one', u'end', u'longest', u'dimension', u'something', u'fixed', u'place', u'issue', u'terminate', u'specified', u'way', u'state', u'etc', u'end', u'legal', u'document', u'codifying', u'result', u'deliberations', u'committee', u'society', u'legislative', u'body', u'military', u'engagement', u'something', u'including', u'component', u'elements', u'parts', u'commercial', u'industrial', u'enterprise', u'people', u'constitute', u'cardinal', u'number', u'product', u'10', u'100', u'previous', u'time', u'amount', u'time', u'high', u'degree', u'extent', u'favorably', u'much', u'respect', u'act', u'process', u'producing', u'something', u'vague', u'clearly', u'defined', u'stated', u'division', u'quantity', u'accepted', u'standard', u'measurement', u'exchange', u'large', u'densely', u'populated', u'urban', u'area', u'include', u'several', u'independent', u'administrative', u'districts', u'act', u'using', u'process', u'taking', u'food', u'body', u'mouth', u'eating', u'lying', u'toward', u'situated', u'east', u'large', u'unbroken', u'expanse', u'distance', u'bishop', u'highest', u'rank', u'instrumentality', u'combines', u'interrelated', u'interacting', u'artifacts', u'designed', u'work', u'coherent', u'entity', u'five', u'related', u'nonmetallic', u'elements', u'fluorine', u'chlorine', u'bromine', u'iodine', u'astatine', u'monovalent', u'readily', u'form', u'negative', u'ions', u'continuing', u'time', u'space', u'without', u'interruption', u'film', u'life', u'western', u'United', u'States', u'period', u'exploration', u'development', u'fact', u'part', u'opposed', u'general', u'assumption', u'taken', u'granted', u'category', u'things', u'distinguished', u'common', u'characteristic', u'quality', u'worker', u'holds', u'invested', u'office', u'man', u'older', u'higher', u'rank', u'one', u'groups', u'Christians', u'beliefs', u'forms', u'worship', u'statistics', u'arrangement', u'values', u'variable', u'showing', u'observed', u'theoretical', u'frequency', u'occurrence', u'something', u'owned', u'tangible', u'intangible', u'possession', u'owned', u'someone', u'mark', u'different', u'function', u'topological', u'space', u'gives', u'two', u'points', u'space', u'value', u'equal', u'distance', u'usually', u'describes', u'large', u'person', u'fat', u'large', u'frame', u'carry', u'anticipated', u'outcome', u'intended', u'guides', u'planned', u'actions', u'general', u'officer', u'highest', u'rank', u'senior', u'member', u'Christian', u'clergy', u'spiritual', u'administrative', u'authority', u'appointed', u'Christian', u'churches', u'oversee', u'priests', u'ministers', u'considered', u'churches', u'successors', u'twelve', u'Apostles', u'Christ', u'movable', u'possession', u'especially', u'articles', u'clothing', u'owned', u'possession', u'heavy', u'toxic', u'silvery-white', u'radioactive', u'metallic', u'element', u'occurs', u'many', u'isotopes', u'used', u'nuclear', u'fuels', u'nuclear', u'weapons', u'orderly', u'grouping', u'things', u'persons', u'considered', u'unit', u'result', u'arranging', u'something', u'less', u'whole', u'human', u'artifact', u'act', u'delivering', u'formal', u'spoken', u'communication', u'audience', u'relating', u'science', u'geography', u'pertaining', u'involving', u'nature', u'space', u'advertisement', u'usually', u'printed', u'page', u'leaflet', u'intended', u'wide', u'distribution', u'commodities', u'offered', u'sale', u'put', u'service', u'make', u'work', u'employ', u'particular', u'purpose', u'inherent', u'natural', u'purpose', u'normal', u'conditions', u'particular', u'point', u'time', u'anticipated', u'outcome', u'intended', u'guides', u'planned', u'actions', u'one', u'several', u'parts', u'pieces', u'fit', u'others', u'constitute', u'whole', u'object', u'exhibiting', u'caused', u'radioactivity', u'event', u'happens', u'trace', u'point', u'whose', u'direction', u'motion', u'changes', u'mentally', u'emotionally', u'stable', u'abstract', u'part', u'something', u'human', u'general', u'estimation', u'public', u'person', u'instance', u'single', u'occasion', u'event', u'particular', u'portion', u'space', u'occupied', u'something', u'concept', u'something', u'magnitude', u'represented', u'mathematical', u'expressions', u'constant', u'variable']
prevlevelsynsets: [Synset('helping.n.01'), Synset('tamil_nadu.n.01'), Synset('bengal.n.01'), Synset('course.n.01'), Synset('sexual_intercourse.n.01'), Synset('geography.n.01'), Synset('group.n.01'), Synset('decay.n.01'), Synset('plan.n.01'), Synset('tamil.n.01'), Synset('exceeding.s.01'), Synset('bay.n.01'), Synset('invent.v.01'), Synset('serve.n.01'), Synset('item.n.01'), Synset('mile.n.01'), Synset('unstable.a.01'), Synset('include.v.01'), Synset('people.n.01'), Synset('series.n.01'), Synset('christianity.n.01'), Synset('culture.n.01'), Synset('meter.n.01'), Synset('special.n.01'), Synset('orthodox.a.01'), Synset('definite.a.01'), Synset('boundary.n.01'), Synset('business.n.01'), Synset('importance.n.01'), Synset('equivalent.n.01'), Synset('thorium.n.01'), Synset('blessing.n.01'), Synset('supply.n.01'), Synset('region.n.01'), Synset('title.n.01'), Synset('peer.n.01'), Synset('length.n.01'), Synset('consequence.n.01'), Synset('act.n.01'), Synset('military_action.n.01'), Synset('whole.n.01'), Synset('business.n.01'), Synset('thousand.n.01'), Synset('once.r.01'), Synset('time_period.n.01'), Synset('highly.r.01'), Synset('production.n.01'), Synset('indefinite.a.01'), Synset('unit_of_measurement.n.01'), Synset('city.n.01'), Synset('use.n.01'), Synset('consumption.n.01'), Synset('eastern.s.01'), Synset('stretch.n.01'), Synset('archbishop.n.01'), Synset('system.n.01'), Synset('halogen.n.01'), Synset('continuous.a.01'), Synset('western.n.01'), Synset('particular.n.01'), Synset('given.n.01'), Synset('kind.n.01'), Synset('official.n.01'), Synset('patriarch.n.01'), Synset('church.n.01'), Synset('distribution.n.01'), Synset('property.n.01'), Synset('distinguish.v.01'), Synset('metric_function.n.01'), Synset('fleshy.s.01'), Synset('purpose.n.01'), Synset('general.n.01'), Synset('bishop.n.01'), Synset('things.n.01'), Synset('belong.v.01'), Synset('uranium.n.01'), Synset('agreement.n.04'), Synset('part.n.01'), Synset('address.n.01'), Synset('geographic.a.01'), Synset('spatial.a.01'), Synset('circular.n.01'), Synset('merchandise.n.01'), Synset('use.n.01'), Synset('normally.r.01'), Synset('moment.n.01'), Synset('purpose.n.01'), Synset('section.n.01'), Synset('radioactive.a.01'), Synset('happening.n.01'), Synset('curve.n.01'), Synset('together.s.01'), Synset('component.n.01'), Synset('person.n.01'), Synset('repute.n.01'), Synset('time.n.01'), Synset('position.n.01'), Synset('measure.n.02')]
defaultdict(<type 'list'>, {u'serving': [u'area', u'None', u'area'], u'Madras': [u'None', u'Chennai', u'None', u'Chennai'], u'Bengal': [u'None', u'Chennai', u'None', u'Chennai'], u'course': [u'None', u'planning', u'None'], u'relation': [u'None', u'composition', u'None'], u'geography': [u'area', u'None', u'area'], u'group': [u'None', u'set'], u'decay': [u'None', u'None', u'astatine'], u'halogen': [u'None', u'None', u'astatine'], u'Tamil': [u'None', u'Chennai', u'None', u'Chennai'], u'exceptional': [u'None', u'None', u'giant'], u'Bay': [u'None', u'Chennai', u'None', u'Chennai'], u'formulating': [u'None', u'planning', u'None'], u'serves': [u'None', u'agency', u'None'], u'item': [u'None', u'None'], u'miles': [u'None', u'kilometer', u'None', u'kilometer'], u'unstable': [u'None', u'None', u'astatine'], u'including': [u'None', u'None', u'present'], u'people': [u'area', u'None', u'area'], u'series': [u'None', u'None', u'astatine'], u'Christianity': [u'None', u'None', u'metropolitan'], u'culture': [u'area', u'None', u'area'], u'meters': [u'None', u'kilometer', u'None', u'kilometer'], u'special': [u'area', u'None', u'area'], u'0.621371': [u'None', u'kilometer', u'None', u'kilometer'], u'Orthodox': [u'None', u'None', u'metropolitan'], u'definite': [u'None', u'planning', u'None'], u'boundary': [u'area', u'None', u'area'], u'business': [u'None', u'agency', u'None'], u'importance': [u'None', u'None', u'giant'], u'equivalent': [u'None', u'None', u'metropolitan'], u'thorium': [u'None', u'None', u'astatine'], u'approval': [u'None', u'permission', u'None'], u'providing': [u'None', u'None'], u'region': [u'area', u'None', u'area'], u'title': [u'None', u'None', u'metropolitan'], u'equal': [u'None', u'kilometer', u'None', u'kilometer'], u'length': [u'None', u'kilometer', u'None', u'kilometer'], u'resulting': [u'None', u'composition', u'None'], u'act': [u'None', u'planning', u'None'], u'action': [u'None', u'planning', u'None'], u'whole': [u'None', u'composition', u'None'], u'businesses': [u'None', u'agency', u'None'], u'1000': [u'None', u'kilometer', u'None', u'kilometer'], u'formerly': [u'None', u'Chennai', u'None', u'Chennai'], u'period': [u'None', u'None', u'present'], u'highly': [u'None', u'None', u'astatine'], u'production': [u'None', u'economy', u'None'], u'indefinite': [u'area', u'None', u'area'], u'unit': [u'None', u'kilometer', u'None', u'kilometer'], u'city': [u'None', u'Chennai', u'None', u'Chennai'], u'use': [u'None', u'None'], u'consumption': [u'None', u'economy', u'None'], u'Eastern': [u'None', u'None', u'metropolitan'], u'stretch': [u'None', u'None', u'present'], u'archbishop': [u'None', u'None', u'metropolitan'], u'system': [u'None', u'economy', u'None'], u'program': [u'None', u'planning', u'None'], u'continuous': [u'None', u'None', u'present'], u'western': [u'None', u'None', u'metropolitan'], u'particular': [u'area', u'None', u'area'], u'given': [u'None', u'None', u'metropolitan'], u'kind': [u'None', u'set'], u'official': [u'None', u'None'], u'patriarch': [u'None', u'None', u'metropolitan'], u'Church': [u'None', u'None', u'metropolitan'], u'distribution': [u'None', u'economy', u'None'], u'property': [u'None', u'composition', u'None'], u'distinguished': [u'area', u'None', u'area'], u'metric': [u'None', u'kilometer', u'None', u'kilometer'], u'heaviest': [u'None', u'None', u'astatine'], u'purposes': [u'None', u'None'], u'general': [u'None', u'None'], u'something': [u'None', u'permission', u'None'], u'bishop': [u'None', u'None', u'metropolitan'], u'things': [u'None', u'set'], u'belong': [u'None', u'set'], u'uranium': [u'None', u'None', u'astatine'], u'arrangement': [u'None', u'composition', u'None'], u'parts': [u'None', u'composition', u'None'], u'speech': [u'None', u'None', u'present'], u'geographical': [u'area', u'None', u'area'], u'spatial': [u'None', u'composition', u'None'], u'Nadu': [u'None', u'Chennai', u'None', u'Chennai'], u'circular': [u'None', u'bend'], u'product': [u'None', u'None', u'astatine'], u'used': [u'None', u'set'], u'usually': [u'area', u'None', u'area'], u'moment': [u'None', u'None', u'present'], u'purpose': [u'area', u'None', u'area'], u'segment': [u'None', u'bend'], u'radioactive': [u'None', u'None', u'astatine'], u'happening': [u'None', u'None', u'present'], u'curve': [u'None', u'bend'], u'together': [u'None', u'set'], u'element': [u'None', u'None', u'astatine'], u'person': [u'None', u'None', u'giant'], u'reputation': [u'None', u'None', u'giant'], u'time': [u'None', u'None', u'present'], u'position': [u'None', u'None', u'metropolitan'], u'quantity': [u'None', u'None']})
ksynset= Synset('helping.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('helping.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('helping.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('tamil_nadu.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('tamil_nadu.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('tamil_nadu.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('tamil_nadu.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('bengal.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('bengal.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('bengal.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('bengal.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('course.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('course.n.01')
lsynset= Synset('planning.n.01')
ksynset= Synset('course.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('relation.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('relation.n.01')
lsynset= Synset('composition.n.01')
ksynset= Synset('relation.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('geography.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('geography.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('geography.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('group.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('group.n.01')
lsynset= Synset('set.n.01')
ksynset= Synset('decay.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('decay.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('decay.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('halogen.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('halogen.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('halogen.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('tamil.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('tamil.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('tamil.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('tamil.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('exceeding.s.01')
lsynset= Synset('none.n.01')
ksynset= Synset('exceeding.s.01')
lsynset= Synset('none.n.01')
ksynset= Synset('exceeding.s.01')
lsynset= Synset('giant.n.01')
ksynset= Synset('bay.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('bay.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('bay.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('bay.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('explicate.v.02')
lsynset= Synset('none.n.01')
ksynset= Synset('explicate.v.02')
lsynset= Synset('planning.n.01')
ksynset= Synset('explicate.v.02')
lsynset= Synset('none.n.01')
ksynset= Synset('serve.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('serve.n.01')
lsynset= Synset('agency.n.01')
ksynset= Synset('serve.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('item.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('item.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('mile.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('mile.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('mile.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('mile.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('unstable.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('unstable.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('unstable.a.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('include.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('include.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('include.v.01')
lsynset= Synset('present.n.01')
ksynset= Synset('people.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('people.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('people.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('series.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('series.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('series.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('christianity.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('christianity.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('christianity.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('culture.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('culture.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('culture.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('meter.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('meter.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('meter.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('meter.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('special.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('special.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('special.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('orthodox.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('orthodox.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('orthodox.a.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('definite.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('definite.a.01')
lsynset= Synset('planning.n.01')
ksynset= Synset('definite.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('boundary.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('boundary.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('boundary.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('business.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('business.n.01')
lsynset= Synset('agency.n.01')
ksynset= Synset('business.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('importance.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('importance.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('importance.n.01')
lsynset= Synset('giant.n.01')
ksynset= Synset('equivalent.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('equivalent.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('equivalent.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('thorium.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('thorium.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('thorium.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('blessing.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('blessing.n.01')
lsynset= Synset('permission.n.01')
ksynset= Synset('blessing.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('supply.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('supply.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('region.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('region.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('region.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('title.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('title.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('title.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('peer.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('peer.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('peer.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('peer.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('length.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('length.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('length.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('length.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('result.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('result.v.01')
lsynset= Synset('composition.n.01')
ksynset= Synset('result.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('act.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('act.n.01')
lsynset= Synset('planning.n.01')
ksynset= Synset('act.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('action.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('action.n.01')
lsynset= Synset('planning.n.01')
ksynset= Synset('action.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('whole.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('whole.n.01')
lsynset= Synset('composition.n.01')
ksynset= Synset('whole.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('business.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('business.n.01')
lsynset= Synset('agency.n.01')
ksynset= Synset('business.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('thousand.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('thousand.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('thousand.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('thousand.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('once.r.03')
lsynset= Synset('none.n.01')
ksynset= Synset('once.r.03')
lsynset= Synset('chennai.n.01')
ksynset= Synset('once.r.03')
lsynset= Synset('none.n.01')
ksynset= Synset('once.r.03')
lsynset= Synset('chennai.n.01')
ksynset= Synset('time_period.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('time_period.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('time_period.n.01')
lsynset= Synset('present.n.01')
ksynset= Synset('highly.r.01')
lsynset= Synset('none.n.01')
ksynset= Synset('highly.r.01')
lsynset= Synset('none.n.01')
ksynset= Synset('highly.r.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('production.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('production.n.01')
lsynset= Synset('economy.n.01')
ksynset= Synset('production.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('indefinite.a.01')
lsynset= Synset('area.n.01')
ksynset= Synset('indefinite.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('indefinite.a.01')
lsynset= Synset('area.n.01')
ksynset= Synset('unit_of_measurement.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('unit_of_measurement.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('unit_of_measurement.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('unit_of_measurement.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('city.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('city.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('city.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('city.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('use.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('use.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('consumption.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('consumption.n.01')
lsynset= Synset('economy.n.01')
ksynset= Synset('consumption.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('eastern.s.01')
lsynset= Synset('none.n.01')
ksynset= Synset('eastern.s.01')
lsynset= Synset('none.n.01')
ksynset= Synset('eastern.s.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('stretch.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('stretch.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('stretch.n.01')
lsynset= Synset('present.n.01')
ksynset= Synset('archbishop.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('archbishop.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('archbishop.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('system.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('system.n.01')
lsynset= Synset('economy.n.01')
ksynset= Synset('system.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('plan.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('plan.n.01')
lsynset= Synset('planning.n.01')
ksynset= Synset('plan.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('continuous.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('continuous.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('continuous.a.01')
lsynset= Synset('present.n.01')
ksynset= Synset('western.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('western.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('western.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('particular.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('particular.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('particular.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('given.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('given.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('given.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('kind.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('kind.n.01')
lsynset= Synset('set.n.01')
ksynset= Synset('official.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('official.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('patriarch.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('patriarch.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('patriarch.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('church.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('church.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('church.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('distribution.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('distribution.n.01')
lsynset= Synset('economy.n.01')
ksynset= Synset('distribution.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('property.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('property.n.01')
lsynset= Synset('composition.n.01')
ksynset= Synset('property.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('distinguish.v.01')
lsynset= Synset('area.n.01')
ksynset= Synset('distinguish.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('distinguish.v.01')
lsynset= Synset('area.n.01')
ksynset= Synset('metric_function.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('metric_function.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('metric_function.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('metric_function.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('heavy.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('heavy.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('heavy.a.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('purpose.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('purpose.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('general.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('general.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('bishop.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('bishop.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('bishop.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('things.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('things.n.01')
lsynset= Synset('set.n.01')
ksynset= Synset('belong.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('belong.v.01')
lsynset= Synset('set.n.01')
ksynset= Synset('uranium.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('uranium.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('uranium.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('agreement.n.04')
lsynset= Synset('none.n.01')
ksynset= Synset('agreement.n.04')
lsynset= Synset('composition.n.01')
ksynset= Synset('agreement.n.04')
lsynset= Synset('none.n.01')
ksynset= Synset('parts.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('parts.n.01')
lsynset= Synset('composition.n.01')
ksynset= Synset('parts.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('address.n.03')
lsynset= Synset('none.n.01')
ksynset= Synset('address.n.03')
lsynset= Synset('none.n.01')
ksynset= Synset('address.n.03')
lsynset= Synset('present.n.01')
ksynset= Synset('geographic.a.01')
lsynset= Synset('area.n.01')
ksynset= Synset('geographic.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('geographic.a.01')
lsynset= Synset('area.n.01')
ksynset= Synset('spatial.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('spatial.a.01')
lsynset= Synset('composition.n.01')
ksynset= Synset('spatial.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('circular.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('circular.n.01')
lsynset= Synset('bend.n.01')
ksynset= Synset('merchandise.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('merchandise.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('merchandise.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('use.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('use.v.01')
lsynset= Synset('set.n.01')
ksynset= Synset('normally.r.01')
lsynset= Synset('area.n.01')
ksynset= Synset('normally.r.01')
lsynset= Synset('none.n.01')
ksynset= Synset('normally.r.01')
lsynset= Synset('area.n.01')
ksynset= Synset('moment.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('moment.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('moment.n.01')
lsynset= Synset('present.n.01')
ksynset= Synset('purpose.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('purpose.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('purpose.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('section.n.04')
lsynset= Synset('none.n.01')
ksynset= Synset('section.n.04')
lsynset= Synset('bend.n.01')
ksynset= Synset('radioactive.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('radioactive.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('radioactive.a.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('happening.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('happening.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('happening.n.01')
lsynset= Synset('present.n.01')
ksynset= Synset('curve.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('curve.n.01')
lsynset= Synset('bend.n.01')
ksynset= Synset('together.s.01')
lsynset= Synset('none.n.01')
ksynset= Synset('together.s.01')
lsynset= Synset('set.n.01')
ksynset= Synset('component.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('component.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('component.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('person.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('person.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('person.n.01')
lsynset= Synset('giant.n.01')
ksynset= Synset('repute.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('repute.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('repute.n.01')
lsynset= Synset('giant.n.01')
ksynset= Synset('time.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('time.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('time.n.01')
lsynset= Synset('present.n.01')
ksynset= Synset('position.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('position.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('position.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('measure.n.02')
lsynset= Synset('none.n.01')
ksynset= Synset('measure.n.02')
lsynset= Synset('none.n.01')
Core number (sorted) : [(u'area', 13), (u'metropolitan', 12), (u'astatine', 11), (u'kilometer', 8), (u'present', 8), (u'Chennai', 7), (u'composition', 7), (u'planning', 6), (u'set', 6), (u'giant', 4), (u'economy', 4), (u'bend', 3), (u'agency', 3), (u'serving', 2), (u'Madras', 2), (u'Bengal', 2), (u'course', 2), (u'relation', 2), (u'geography', 2), (u'group', 2), (u'title', 2), (u'halogen', 2), (u'Tamil', 2), (u'permission', 2), (u'Bay', 2), (u'formulating', 2), (u'serves', 2), (u'miles', 2), (u'unstable', 2), (u'including', 2), (u'people', 2), (u'series', 2), (u'Christianity', 2), (u'culture', 2), (u'meters', 2), (u'special', 2), (u'0.621371', 2), (u'Orthodox', 2), (u'definite', 2), (u'boundary', 2), (u'business', 2), (u'importance', 2), (u'equivalent', 2), (u'thorium', 2), (u'approval', 2), (u'region', 2), (u'decay', 2), (u'equal', 2), (u'length', 2), (u'resulting', 2), (u'act', 2), (u'action', 2), (u'whole', 2), (u'businesses', 2), (u'1000', 2), (u'formerly', 2), (u'period', 2), (u'highly', 2), (u'production', 2), (u'indefinite', 2), (u'unit', 2), (u'city', 2), (u'given', 2), (u'consumption', 2), (u'stretch', 2), (u'archbishop', 2), (u'system', 2), (u'program', 2), (u'exceptional', 2), (u'continuous', 2), (u'western', 2), (u'particular', 2), (u'kind', 2), (u'patriarch', 2), (u'Eastern', 2), (u'Church', 2), (u'distribution', 2), (u'property', 2), (u'distinguished', 2), (u'something', 2), (u'metric', 2), (u'heaviest', 2), (u'bishop', 2), (u'things', 2), (u'belong', 2), (u'uranium', 2), (u'arrangement', 2), (u'parts', 2), (u'speech', 2), (u'geographical', 2), (u'spatial', 2), (u'Nadu', 2), (u'circular', 2), (u'product', 2), (u'used', 2), (u'usually', 2), (u'moment', 2), (u'purpose', 2), (u'segment', 2), (u'radioactive', 2), (u'happening', 2), (u'curve', 2), (u'together', 2), (u'element', 2), (u'person', 2), (u'reputation', 2), (u'time', 2), (u'position', 2), (u'item', 0), (u'None', 0), (u'use', 0), (u'providing', 0), (u'official', 0), (u'purposes', 0), (u'general', 0), (u'quantity', 0)]
=============================================================================================================
Unsupervised Classification based on top percentile Core numbers of the definition graph(subgraph of WordNet)
=============================================================================================================
This document belongs to class: area ,core number= 13
This document belongs to class: metropolitan ,core number= 12
This document belongs to class: astatine ,core number= 11
This document belongs to class: kilometer ,core number= 8
This document belongs to class: present ,core number= 8
This document belongs to class: Chennai ,core number= 7
This document belongs to class: composition ,core number= 7
This document belongs to class: planning ,core number= 6
This document belongs to class: set ,core number= 6
This document belongs to class: giant ,core number= 4
This document belongs to class: economy ,core number= 4
This document belongs to class: bend ,core number= 3
This document belongs to class: agency ,core number= 3
max_core_number 13
===================================================================
Page Rank of the vertices of RGO Definition Graph
===================================================================
[(u'area', 0.05964397617197671), (u'metropolitan', 0.05543677058743772), (u'astatine', 0.051229565002898755), (u'kilometer', 0.03860794824928188), (u'present', 0.03860794824928188), (u'Chennai', 0.034400742664742925), (u'composition', 0.034400742664742925), (u'planning', 0.030193537080203968), (u'set', 0.030193537080203968), (u'giant', 0.021779125911126046), (u'economy', 0.02177912591112604), (u'agency', 0.01757192032658708), (u'bend', 0.017571920326587075), (u'permission', 0.013364714742048119), (u'approval', 0.0070539063652396775), (u'something', 0.0070539063652396775), (u'serves', 0.006352705434483184), (u'business', 0.006352705434483184), (u'businesses', 0.006352705434483184), (u'circular', 0.006352705434483183), (u'segment', 0.006352705434483183), (u'curve', 0.006352705434483183), (u'importance', 0.006002104969104938), (u'production', 0.006002104969104938), (u'consumption', 0.006002104969104938), (u'system', 0.006002104969104938), (u'distribution', 0.006002104969104938), (u'exceptional', 0.006002104969104938), (u'person', 0.006002104969104938), (u'reputation', 0.006002104969104938), (u'course', 0.0056515045037266905), (u'group', 0.0056515045037266905), (u'program', 0.0056515045037266905), (u'formulating', 0.0056515045037266905), (u'definite', 0.0056515045037266905), (u'act', 0.0056515045037266905), (u'action', 0.0056515045037266905), (u'belong', 0.0056515045037266905), (u'kind', 0.0056515045037266905), (u'things', 0.0056515045037266905), (u'used', 0.0056515045037266905), (u'together', 0.0056515045037266905), (u'Madras', 0.005551332942190048), (u'Bengal', 0.005551332942190048), (u'relation', 0.005551332942190048), (u'Tamil', 0.005551332942190048), (u'Bay', 0.005551332942190048), (u'resulting', 0.005551332942190048), (u'whole', 0.005551332942190048), (u'formerly', 0.005551332942190048), (u'city', 0.005551332942190048), (u'property', 0.005551332942190048), (u'arrangement', 0.005551332942190048), (u'parts', 0.005551332942190048), (u'spatial', 0.005551332942190048), (u'Nadu', 0.005551332942190048), (u'miles', 0.0054762042710375675), (u'including', 0.0054762042710375675), (u'meters', 0.0054762042710375675), (u'0.621371', 0.0054762042710375675), (u'equal', 0.0054762042710375675), (u'length', 0.0054762042710375675), (u'1000', 0.0054762042710375675), (u'period', 0.0054762042710375675), (u'unit', 0.0054762042710375675), (u'stretch', 0.0054762042710375675), (u'continuous', 0.0054762042710375675), (u'metric', 0.0054762042710375675), (u'speech', 0.0054762042710375675), (u'moment', 0.0054762042710375675), (u'happening', 0.0054762042710375675), (u'time', 0.0054762042710375675), (u'unstable', 0.005332776807928284), (u'series', 0.005332776807928284), (u'thorium', 0.005332776807928284), (u'decay', 0.005332776807928284), (u'highly', 0.005332776807928284), (u'halogen', 0.005332776807928284), (u'heaviest', 0.005332776807928284), (u'uranium', 0.005332776807928284), (u'product', 0.005332776807928284), (u'radioactive', 0.005332776807928284), (u'element', 0.005332776807928284), (u'title', 0.005300904038348444), (u'Christianity', 0.005300904038348444), (u'Orthodox', 0.005300904038348444), (u'equivalent', 0.005300904038348444), (u'given', 0.005300904038348444), (u'archbishop', 0.005300904038348444), (u'western', 0.005300904038348444), (u'patriarch', 0.005300904038348444), (u'Eastern', 0.005300904038348444), (u'Church', 0.005300904038348444), (u'bishop', 0.005300904038348444), (u'position', 0.005300904038348444), (u'serving', 0.005273934771780889), (u'geography', 0.005273934771780889), (u'people', 0.005273934771780889), (u'culture', 0.005273934771780889), (u'special', 0.005273934771780889), (u'boundary', 0.005273934771780889), (u'region', 0.005273934771780889), (u'indefinite', 0.005273934771780889), (u'particular', 0.005273934771780889), (u'distinguished', 0.005273934771780889), (u'geographical', 0.005273934771780889), (u'usually', 0.005273934771780889), (u'purpose', 0.005273934771780889), (u'item', 0.001373626373626374), (u'None', 0.001373626373626374), (u'use', 0.001373626373626374), (u'providing', 0.001373626373626374), (u'official', 0.001373626373626374), (u'purposes', 0.001373626373626374), (u'general', 0.001373626373626374), (u'quantity', 0.001373626373626374)]
==========================================================================================================
Alternative Quantitative Intrinsic Merit  - connectivity of RGO Definition Graph - Mengers Theorem
==========================================================================================================
0
==========================================================================================================
Alternative Quantitative Intrinsic Merit  - Maxflow-Mincut of RGO Definition Graph - Minimum Edge Cut
==========================================================================================================
==========================================================================================================
Alternative Quantitative Intrinsic Merit  - Maxflow-Mincut of RGO Definition Graph - Stoer-Wagner
==========================================================================================================
B

