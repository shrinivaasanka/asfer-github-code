iewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458121846063
16/03/16 15:20:46 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 15:20:46 INFO Executor: Starting executor ID driver on host localhost
16/03/16 15:20:46 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50168.
16/03/16 15:20:46 INFO NettyBlockTransferService: Server created on 50168
16/03/16 15:20:46 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 15:20:46 INFO BlockManagerMasterEndpoint: Registering block manager localhost:50168 with 1080.9 MB RAM, BlockManagerId(driver, localhost, 50168)
16/03/16 15:20:46 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): belong
16/03/16 15:20:46 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 15:20:46 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:20:46 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 15:20:46 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:20:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 15:20:46 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 15:20:46 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 15:20:46 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1133452984
16/03/16 15:20:46 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1080.9 MB)
16/03/16 15:20:46 INFO MemoryStore: ensureFreeSpace(4141) called with curMem=6568, maxMem=1133452984
16/03/16 15:20:46 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1080.9 MB)
16/03/16 15:20:46 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:50168 (size: 4.0 KB, free: 1080.9 MB)
16/03/16 15:20:46 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 15:20:46 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:20:46 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 15:20:46 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 15:20:46 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 15:20:46 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458121846063
16/03/16 15:20:46 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/userFiles-8ddf2807-7090-4ff7-8793-6e5940130e5f/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: area
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: issue
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: planning
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: permission
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: economy
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: composition
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: agency
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 15:20:54 INFO PythonRunner: Times: total = 8020, boot = 470, init = 368, finish = 7182
16/03/16 15:20:54 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 15:20:54 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 15:20:54 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 15:20:54 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8123 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: set
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): adding to parents: syn =  Synset('set.n.01') ; keyword:  belong  in syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: bend
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: giant
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: astatine
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: present
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: area
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): belong
mapFunction_Parents(): keyword: belong ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= belong ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
16/03/16 15:20:54 INFO PythonRunner: Times: total = 315, boot = 198, init = 1, finish = 116
16/03/16 15:20:54 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 15:20:54 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.441 s
16/03/16 15:20:54 INFO DAGScheduler: looking for newly runnable stages
16/03/16 15:20:54 INFO DAGScheduler: running: Set()
16/03/16 15:20:54 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 15:20:54 INFO DAGScheduler: failed: Set()
16/03/16 15:20:54 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 15:20:54 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 15:20:54 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10709, maxMem=1133452984
16/03/16 15:20:54 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1080.9 MB)
16/03/16 15:20:54 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 338 ms on localhost (2/2)
16/03/16 15:20:54 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 15:20:54 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15693, maxMem=1133452984
16/03/16 15:20:54 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1080.9 MB)
16/03/16 15:20:54 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:50168 (size: 3.0 KB, free: 1080.9 MB)
16/03/16 15:20:54 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 15:20:54 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:20:54 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 15:20:54 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 15:20:54 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 15:20:54 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 15:20:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/16 15:20:54 INFO PythonRunner: Times: total = 156, boot = 155, init = 0, finish = 1
16/03/16 15:20:54 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 15:20:54 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 15:20:54 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 15:20:54 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 15:20:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/16 15:20:54 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 185 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'set']
16/03/16 15:20:55 INFO PythonRunner: Times: total = 167, boot = 166, init = 0, finish = 1
16/03/16 15:20:55 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1229 bytes result sent to driver
16/03/16 15:20:55 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.351 s
16/03/16 15:20:55 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.858332 s
16/03/16 15:20:55 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 181 ms on localhost (2/2)
16/03/16 15:20:55 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 15:20:55 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 15:20:55 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 15:20:55 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:20:55 INFO DAGScheduler: Parents of final stage: List()
16/03/16 15:20:55 INFO DAGScheduler: Missing parents: List()
16/03/16 15:20:55 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 15:20:55 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18741, maxMem=1133452984
16/03/16 15:20:55 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1080.9 MB)
16/03/16 15:20:55 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24557, maxMem=1133452984
16/03/16 15:20:55 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1080.9 MB)
16/03/16 15:20:55 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:50168 (size: 3.3 KB, free: 1080.9 MB)
16/03/16 15:20:55 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 15:20:55 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:20:55 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 15:20:55 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 15:20:55 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 15:20:55 INFO PythonRunner: Times: total = 98, boot = 98, init = 0, finish = 0
16/03/16 15:20:55 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 15:20:55 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2259 bytes)
16/03/16 15:20:55 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 132 ms on localhost (1/2)
16/03/16 15:20:55 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 15:20:55 INFO PythonRunner: Times: total = 163, boot = 162, init = 1, finish = 0
16/03/16 15:20:55 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1295 bytes result sent to driver
16/03/16 15:20:55 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 186 ms on localhost (2/2)
16/03/16 15:20:55 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 15:20:55 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.302 s
16/03/16 15:20:55 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.343269 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 15:20:55 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 15:20:55 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 15:20:55 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 15:20:55 INFO MemoryStore: MemoryStore cleared
16/03/16 15:20:55 INFO BlockManager: BlockManager stopped
16/03/16 15:20:55 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 15:20:55 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 15:20:55 INFO SparkContext: Successfully stopped SparkContext
16/03/16 15:20:55 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 15:20:55 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 15:20:55 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'set']
16/03/16 15:20:56 INFO SparkContext: Running Spark version 1.5.2
16/03/16 15:20:56 INFO SecurityManager: Changing view acls to: root
16/03/16 15:20:56 INFO SecurityManager: Changing modify acls to: root
16/03/16 15:20:56 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 15:20:56 INFO Slf4jLogger: Slf4jLogger started
16/03/16 15:20:56 INFO Remoting: Starting remoting
16/03/16 15:20:56 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:45794]
16/03/16 15:20:56 INFO Utils: Successfully started service 'sparkDriver' on port 45794.
16/03/16 15:20:56 INFO SparkEnv: Registering MapOutputTracker
16/03/16 15:20:56 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 15:20:56 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-2c836acd-2099-4e7e-9e99-50b302f9fc67
16/03/16 15:20:56 INFO MemoryStore: MemoryStore started with capacity 1080.9 MB
16/03/16 15:20:56 INFO HttpFileServer: HTTP File server directory is /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/httpd-05830385-89ae-49ef-91c2-501f52a6f093
16/03/16 15:20:56 INFO HttpServer: Starting HTTP Server
16/03/16 15:20:56 INFO Utils: Successfully started service 'HTTP file server' on port 54961.
16/03/16 15:20:56 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 15:20:56 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 15:20:56 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 15:20:56 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/userFiles-c09640fb-0a64-4e89-bed1-6da7f68b0eb5/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 15:20:56 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458121856774
16/03/16 15:20:56 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 15:20:56 INFO Executor: Starting executor ID driver on host localhost
16/03/16 15:20:56 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55411.
16/03/16 15:20:56 INFO NettyBlockTransferService: Server created on 55411
16/03/16 15:20:56 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 15:20:56 INFO BlockManagerMasterEndpoint: Registering block manager localhost:55411 with 1080.9 MB RAM, BlockManagerId(driver, localhost, 55411)
16/03/16 15:20:56 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): uranium
16/03/16 15:20:56 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 15:20:56 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:20:56 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 15:20:56 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:20:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 15:20:56 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 15:20:56 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 15:20:56 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1133452984
16/03/16 15:20:56 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1080.9 MB)
16/03/16 15:20:56 INFO MemoryStore: ensureFreeSpace(4140) called with curMem=6568, maxMem=1133452984
16/03/16 15:20:56 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1080.9 MB)
16/03/16 15:20:56 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:55411 (size: 4.0 KB, free: 1080.9 MB)
16/03/16 15:20:56 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 15:20:56 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:20:56 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 15:20:56 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 15:20:56 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 15:20:56 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458121856774
16/03/16 15:20:56 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/userFiles-c09640fb-0a64-4e89-bed1-6da7f68b0eb5/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: area
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: issue
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: planning
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: permission
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: economy
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: composition
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: agency
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 15:21:05 INFO PythonRunner: Times: total = 8043, boot = 455, init = 348, finish = 7240
16/03/16 15:21:05 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 15:21:05 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 15:21:05 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 15:21:05 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8124 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: set
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: bend
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: giant
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: astatine
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('astatine.n.01') ; keyword:  uranium  in syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= [u'astatine']
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: present
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: area
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): uranium
mapFunction_Parents(): keyword: uranium ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= uranium ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
16/03/16 15:21:05 INFO PythonRunner: Times: total = 279, boot = 175, init = 0, finish = 104
16/03/16 15:21:05 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 15:21:05 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.407 s
16/03/16 15:21:05 INFO DAGScheduler: looking for newly runnable stages
16/03/16 15:21:05 INFO DAGScheduler: running: Set()
16/03/16 15:21:05 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 15:21:05 INFO DAGScheduler: failed: Set()
16/03/16 15:21:05 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 15:21:05 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 15:21:05 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10708, maxMem=1133452984
16/03/16 15:21:05 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1080.9 MB)
16/03/16 15:21:05 INFO MemoryStore: ensureFreeSpace(3047) called with curMem=15692, maxMem=1133452984
16/03/16 15:21:05 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1080.9 MB)
16/03/16 15:21:05 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 305 ms on localhost (2/2)
16/03/16 15:21:05 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 15:21:05 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:55411 (size: 3.0 KB, free: 1080.9 MB)
16/03/16 15:21:05 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 15:21:05 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:21:05 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 15:21:05 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 15:21:05 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 15:21:05 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 15:21:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 15:21:05 INFO PythonRunner: Times: total = 172, boot = 171, init = 1, finish = 0
16/03/16 15:21:05 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 15:21:05 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 15:21:05 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 15:21:05 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 15:21:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
16/03/16 15:21:05 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 208 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'astatine']
16/03/16 15:21:05 INFO PythonRunner: Times: total = 171, boot = 169, init = 0, finish = 2
16/03/16 15:21:05 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1242 bytes result sent to driver
16/03/16 15:21:05 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 198 ms on localhost (2/2)
16/03/16 15:21:05 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 15:21:05 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.375 s
16/03/16 15:21:05 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.812374 s
16/03/16 15:21:05 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 15:21:05 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 15:21:05 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:21:05 INFO DAGScheduler: Parents of final stage: List()
16/03/16 15:21:05 INFO DAGScheduler: Missing parents: List()
16/03/16 15:21:05 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 15:21:05 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18739, maxMem=1133452984
16/03/16 15:21:05 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1080.9 MB)
16/03/16 15:21:05 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24555, maxMem=1133452984
16/03/16 15:21:05 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1080.9 MB)
16/03/16 15:21:05 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:55411 (size: 3.3 KB, free: 1080.9 MB)
16/03/16 15:21:05 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 15:21:05 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:21:05 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 15:21:05 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 15:21:05 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 15:21:05 INFO PythonRunner: Times: total = 109, boot = 108, init = 1, finish = 0
16/03/16 15:21:05 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 15:21:05 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2272 bytes)
16/03/16 15:21:05 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 126 ms on localhost (1/2)
16/03/16 15:21:05 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 15:21:06 INFO PythonRunner: Times: total = 191, boot = 190, init = 1, finish = 0
16/03/16 15:21:06 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1311 bytes result sent to driver
16/03/16 15:21:06 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 209 ms on localhost (2/2)
16/03/16 15:21:06 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 15:21:06 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.316 s
16/03/16 15:21:06 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.350041 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 15:21:06 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 15:21:06 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 15:21:06 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 15:21:06 INFO MemoryStore: MemoryStore cleared
16/03/16 15:21:06 INFO BlockManager: BlockManager stopped
16/03/16 15:21:06 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 15:21:06 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 15:21:06 INFO SparkContext: Successfully stopped SparkContext
16/03/16 15:21:06 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'astatine']
16/03/16 15:21:07 INFO SparkContext: Running Spark version 1.5.2
16/03/16 15:21:07 INFO SecurityManager: Changing view acls to: root
16/03/16 15:21:07 INFO SecurityManager: Changing modify acls to: root
16/03/16 15:21:07 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 15:21:07 INFO Slf4jLogger: Slf4jLogger started
16/03/16 15:21:07 INFO Remoting: Starting remoting
16/03/16 15:21:07 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:39615]
16/03/16 15:21:07 INFO Utils: Successfully started service 'sparkDriver' on port 39615.
16/03/16 15:21:07 INFO SparkEnv: Registering MapOutputTracker
16/03/16 15:21:07 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 15:21:07 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-f07ddd74-5fe6-414c-b070-5a000396eb35
16/03/16 15:21:07 INFO MemoryStore: MemoryStore started with capacity 1080.9 MB
16/03/16 15:21:07 INFO HttpFileServer: HTTP File server directory is /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/httpd-836b9409-850e-4b5c-9da6-bdb53ef08620
16/03/16 15:21:07 INFO HttpServer: Starting HTTP Server
16/03/16 15:21:07 INFO Utils: Successfully started service 'HTTP file server' on port 39234.
16/03/16 15:21:07 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 15:21:07 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 15:21:07 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 15:21:07 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/userFiles-b8ee0f70-6648-4042-a8fc-dca98d919f64/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 15:21:07 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458121867486
16/03/16 15:21:07 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 15:21:07 INFO Executor: Starting executor ID driver on host localhost
16/03/16 15:21:07 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38390.
16/03/16 15:21:07 INFO NettyBlockTransferService: Server created on 38390
16/03/16 15:21:07 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 15:21:07 INFO BlockManagerMasterEndpoint: Registering block manager localhost:38390 with 1080.9 MB RAM, BlockManagerId(driver, localhost, 38390)
16/03/16 15:21:07 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): arrangement
16/03/16 15:21:07 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 15:21:07 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:21:07 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 15:21:07 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:21:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 15:21:07 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 15:21:07 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 15:21:07 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1133452984
16/03/16 15:21:07 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1080.9 MB)
16/03/16 15:21:07 INFO MemoryStore: ensureFreeSpace(4141) called with curMem=6568, maxMem=1133452984
16/03/16 15:21:07 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1080.9 MB)
16/03/16 15:21:07 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:38390 (size: 4.0 KB, free: 1080.9 MB)
16/03/16 15:21:07 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 15:21:07 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:21:07 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 15:21:07 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 15:21:07 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 15:21:07 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458121867486
16/03/16 15:21:07 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/userFiles-b8ee0f70-6648-4042-a8fc-dca98d919f64/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: area
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: issue
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: planning
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: permission
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: economy
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: composition
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): adding to parents: syn =  Synset('composition.n.01') ; keyword:  arrangement  in syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= [u'composition']
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: agency
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
16/03/16 15:21:15 INFO PythonRunner: Times: total = 7930, boot = 477, init = 367, finish = 7086
16/03/16 15:21:15 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 15:21:15 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 15:21:15 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 15:21:15 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8027 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: set
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: bend
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: giant
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: astatine
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: present
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: area
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): arrangement
mapFunction_Parents(): keyword: arrangement ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= arrangement ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 15:21:15 INFO PythonRunner: Times: total = 243, boot = 139, init = 1, finish = 103
16/03/16 15:21:15 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 15:21:15 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 291 ms on localhost (2/2)
16/03/16 15:21:15 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 15:21:15 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.313 s
16/03/16 15:21:15 INFO DAGScheduler: looking for newly runnable stages
16/03/16 15:21:15 INFO DAGScheduler: running: Set()
16/03/16 15:21:15 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 15:21:15 INFO DAGScheduler: failed: Set()
16/03/16 15:21:15 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 15:21:15 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 15:21:15 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10709, maxMem=1133452984
16/03/16 15:21:15 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1080.9 MB)
16/03/16 15:21:15 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15693, maxMem=1133452984
16/03/16 15:21:15 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1080.9 MB)
16/03/16 15:21:15 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:38390 (size: 3.0 KB, free: 1080.9 MB)
16/03/16 15:21:15 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 15:21:15 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:21:15 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 15:21:15 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 15:21:15 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 15:21:15 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 15:21:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 15:21:16 INFO PythonRunner: Times: total = 131, boot = 131, init = 0, finish = 0
16/03/16 15:21:16 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 15:21:16 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 15:21:16 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 15:21:16 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 15:21:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
16/03/16 15:21:16 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 171 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'composition', 'None']
16/03/16 15:21:16 INFO PythonRunner: Times: total = 179, boot = 178, init = 0, finish = 1
16/03/16 15:21:16 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1245 bytes result sent to driver
16/03/16 15:21:16 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 198 ms on localhost (2/2)
16/03/16 15:21:16 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.335 s
16/03/16 15:21:16 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 15:21:16 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.685393 s
16/03/16 15:21:16 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 15:21:16 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 15:21:16 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:21:16 INFO DAGScheduler: Parents of final stage: List()
16/03/16 15:21:16 INFO DAGScheduler: Missing parents: List()
16/03/16 15:21:16 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 15:21:16 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18741, maxMem=1133452984
16/03/16 15:21:16 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1080.9 MB)
16/03/16 15:21:16 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24557, maxMem=1133452984
16/03/16 15:21:16 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1080.9 MB)
16/03/16 15:21:16 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:38390 (size: 3.3 KB, free: 1080.9 MB)
16/03/16 15:21:16 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 15:21:16 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:21:16 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 15:21:16 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 15:21:16 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 15:21:16 INFO PythonRunner: Times: total = 96, boot = 96, init = 0, finish = 0
16/03/16 15:21:16 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 15:21:16 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2275 bytes)
16/03/16 15:21:16 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 112 ms on localhost (1/2)
16/03/16 15:21:16 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 15:21:16 INFO PythonRunner: Times: total = 178, boot = 178, init = 0, finish = 0
16/03/16 15:21:16 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1314 bytes result sent to driver
16/03/16 15:21:16 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.305 s
16/03/16 15:21:16 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.327279 s
16/03/16 15:21:16 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 197 ms on localhost (2/2)
16/03/16 15:21:16 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 15:21:16 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 15:21:16 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 15:21:16 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 15:21:16 INFO MemoryStore: MemoryStore cleared
16/03/16 15:21:16 INFO BlockManager: BlockManager stopped
16/03/16 15:21:16 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 15:21:16 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 15:21:16 INFO SparkContext: Successfully stopped SparkContext
16/03/16 15:21:16 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 15:21:16 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'composition', u'None']
16/03/16 15:21:17 INFO SparkContext: Running Spark version 1.5.2
16/03/16 15:21:17 INFO SecurityManager: Changing view acls to: root
16/03/16 15:21:17 INFO SecurityManager: Changing modify acls to: root
16/03/16 15:21:17 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 15:21:17 INFO Slf4jLogger: Slf4jLogger started
16/03/16 15:21:17 INFO Remoting: Starting remoting
16/03/16 15:21:17 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:54900]
16/03/16 15:21:17 INFO Utils: Successfully started service 'sparkDriver' on port 54900.
16/03/16 15:21:17 INFO SparkEnv: Registering MapOutputTracker
16/03/16 15:21:17 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 15:21:17 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-d92b0958-b1eb-4f5f-9fad-61789835bb3b
16/03/16 15:21:17 INFO MemoryStore: MemoryStore started with capacity 1080.9 MB
16/03/16 15:21:17 INFO HttpFileServer: HTTP File server directory is /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/httpd-14ee6a62-6474-421f-b131-191815697243
16/03/16 15:21:17 INFO HttpServer: Starting HTTP Server
16/03/16 15:21:17 INFO Utils: Successfully started service 'HTTP file server' on port 48509.
16/03/16 15:21:17 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 15:21:17 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 15:21:17 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 15:21:17 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/userFiles-977ebec3-7b63-47fc-ad4f-6646bf155044/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 15:21:17 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458121877983
16/03/16 15:21:18 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 15:21:18 INFO Executor: Starting executor ID driver on host localhost
16/03/16 15:21:18 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36706.
16/03/16 15:21:18 INFO NettyBlockTransferService: Server created on 36706
16/03/16 15:21:18 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 15:21:18 INFO BlockManagerMasterEndpoint: Registering block manager localhost:36706 with 1080.9 MB RAM, BlockManagerId(driver, localhost, 36706)
16/03/16 15:21:18 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): parts
16/03/16 15:21:18 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 15:21:18 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:21:18 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 15:21:18 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:21:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 15:21:18 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 15:21:18 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 15:21:18 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1133452984
16/03/16 15:21:18 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1080.9 MB)
16/03/16 15:21:18 INFO MemoryStore: ensureFreeSpace(4141) called with curMem=6568, maxMem=1133452984
16/03/16 15:21:18 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1080.9 MB)
16/03/16 15:21:18 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:36706 (size: 4.0 KB, free: 1080.9 MB)
16/03/16 15:21:18 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 15:21:18 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:21:18 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 15:21:18 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 15:21:18 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 15:21:18 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458121877983
16/03/16 15:21:18 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/userFiles-977ebec3-7b63-47fc-ad4f-6646bf155044/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: area
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: issue
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: planning
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: permission
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: economy
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: composition
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): adding to parents: syn =  Synset('composition.n.01') ; keyword:  parts  in syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= [u'composition']
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: agency
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
16/03/16 15:21:25 INFO PythonRunner: Times: total = 7767, boot = 463, init = 360, finish = 6944
16/03/16 15:21:25 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 15:21:25 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 15:21:25 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 15:21:25 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7869 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: set
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: bend
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: giant
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: astatine
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: present
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: area
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): parts
mapFunction_Parents(): keyword: parts ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= parts ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 15:21:26 INFO PythonRunner: Times: total = 252, boot = 150, init = 1, finish = 101
16/03/16 15:21:26 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 15:21:26 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 296 ms on localhost (2/2)
16/03/16 15:21:26 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 15:21:26 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.148 s
16/03/16 15:21:26 INFO DAGScheduler: looking for newly runnable stages
16/03/16 15:21:26 INFO DAGScheduler: running: Set()
16/03/16 15:21:26 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 15:21:26 INFO DAGScheduler: failed: Set()
16/03/16 15:21:26 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 15:21:26 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 15:21:26 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10709, maxMem=1133452984
16/03/16 15:21:26 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1080.9 MB)
16/03/16 15:21:26 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15693, maxMem=1133452984
16/03/16 15:21:26 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1080.9 MB)
16/03/16 15:21:26 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:36706 (size: 3.0 KB, free: 1080.9 MB)
16/03/16 15:21:26 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 15:21:26 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:21:26 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 15:21:26 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 15:21:26 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 15:21:26 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 15:21:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 15:21:26 INFO PythonRunner: Times: total = 140, boot = 140, init = 0, finish = 0
16/03/16 15:21:26 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 15:21:26 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 15:21:26 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 15:21:26 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 15:21:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 15:21:26 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 168 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'composition', 'None']
16/03/16 15:21:26 INFO PythonRunner: Times: total = 167, boot = 166, init = 0, finish = 1
16/03/16 15:21:26 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1245 bytes result sent to driver
16/03/16 15:21:26 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 193 ms on localhost (2/2)
16/03/16 15:21:26 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.338 s
16/03/16 15:21:26 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.533839 s
16/03/16 15:21:26 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 15:21:26 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 15:21:26 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 15:21:26 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:21:26 INFO DAGScheduler: Parents of final stage: List()
16/03/16 15:21:26 INFO DAGScheduler: Missing parents: List()
16/03/16 15:21:26 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 15:21:26 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18741, maxMem=1133452984
16/03/16 15:21:26 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1080.9 MB)
16/03/16 15:21:27 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24557, maxMem=1133452984
16/03/16 15:21:27 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1080.9 MB)
16/03/16 15:21:27 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:36706 (size: 3.3 KB, free: 1080.9 MB)
16/03/16 15:21:27 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 15:21:27 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:21:27 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 15:21:27 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 15:21:27 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 15:21:27 INFO PythonRunner: Times: total = 30, boot = -178, init = 208, finish = 0
16/03/16 15:21:27 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:36706 in memory (size: 3.0 KB, free: 1080.9 MB)
16/03/16 15:21:27 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 15:21:27 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2275 bytes)
16/03/16 15:21:27 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 15:21:27 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 100 ms on localhost (1/2)
16/03/16 15:21:27 INFO ContextCleaner: Cleaned accumulator 323
16/03/16 15:21:27 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:36706 in memory (size: 4.0 KB, free: 1080.9 MB)
16/03/16 15:21:27 INFO ContextCleaner: Cleaned accumulator 322
16/03/16 15:21:27 INFO PythonRunner: Times: total = 176, boot = 175, init = 1, finish = 0
16/03/16 15:21:27 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1314 bytes result sent to driver
16/03/16 15:21:27 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 189 ms on localhost (2/2)
16/03/16 15:21:27 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 15:21:27 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.263 s
16/03/16 15:21:27 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.552668 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 15:21:27 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 15:21:27 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 15:21:27 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 15:21:27 INFO MemoryStore: MemoryStore cleared
16/03/16 15:21:27 INFO BlockManager: BlockManager stopped
16/03/16 15:21:27 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 15:21:27 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 15:21:27 INFO SparkContext: Successfully stopped SparkContext
16/03/16 15:21:27 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 15:21:27 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 15:21:27 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'composition', u'None']
16/03/16 15:21:28 INFO SparkContext: Running Spark version 1.5.2
16/03/16 15:21:28 INFO SecurityManager: Changing view acls to: root
16/03/16 15:21:28 INFO SecurityManager: Changing modify acls to: root
16/03/16 15:21:28 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 15:21:28 INFO Slf4jLogger: Slf4jLogger started
16/03/16 15:21:28 INFO Remoting: Starting remoting
16/03/16 15:21:28 INFO Utils: Successfully started service 'sparkDriver' on port 42323.
16/03/16 15:21:28 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:42323]
16/03/16 15:21:28 INFO SparkEnv: Registering MapOutputTracker
16/03/16 15:21:28 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 15:21:28 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-896e0eec-4207-416d-a0a1-21bb4029411d
16/03/16 15:21:28 INFO MemoryStore: MemoryStore started with capacity 1082.7 MB
16/03/16 15:21:28 INFO HttpFileServer: HTTP File server directory is /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/httpd-6b74b615-749e-459a-be3b-59c9e522b527
16/03/16 15:21:28 INFO HttpServer: Starting HTTP Server
16/03/16 15:21:28 INFO Utils: Successfully started service 'HTTP file server' on port 35551.
16/03/16 15:21:28 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 15:21:28 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 15:21:28 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 15:21:28 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/userFiles-77287720-120b-46e6-839e-d4a564113628/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 15:21:28 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458121888574
16/03/16 15:21:28 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 15:21:28 INFO Executor: Starting executor ID driver on host localhost
16/03/16 15:21:28 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55901.
16/03/16 15:21:28 INFO NettyBlockTransferService: Server created on 55901
16/03/16 15:21:28 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 15:21:28 INFO BlockManagerMasterEndpoint: Registering block manager localhost:55901 with 1082.7 MB RAM, BlockManagerId(driver, localhost, 55901)
16/03/16 15:21:28 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): speech
16/03/16 15:21:28 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 15:21:28 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:21:28 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 15:21:28 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:21:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 15:21:28 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 15:21:28 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 15:21:28 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1135293235
16/03/16 15:21:28 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1082.7 MB)
16/03/16 15:21:28 INFO MemoryStore: ensureFreeSpace(4141) called with curMem=6568, maxMem=1135293235
16/03/16 15:21:28 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1082.7 MB)
16/03/16 15:21:28 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:55901 (size: 4.0 KB, free: 1082.7 MB)
16/03/16 15:21:28 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 15:21:28 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:21:28 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 15:21:28 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 15:21:28 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 15:21:28 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458121888574
16/03/16 15:21:28 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/userFiles-77287720-120b-46e6-839e-d4a564113628/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: area
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: issue
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: planning
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: permission
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: economy
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: composition
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: agency
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 15:21:36 INFO PythonRunner: Times: total = 7922, boot = 458, init = 360, finish = 7104
16/03/16 15:21:36 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 15:21:36 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 15:21:36 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 15:21:36 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8012 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: set
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: bend
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: giant
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: astatine
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: present
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('present.n.01') ; keyword:  speech  in syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= [u'present']
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: area
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): speech
mapFunction_Parents(): keyword: speech ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= speech ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
16/03/16 15:21:37 INFO PythonRunner: Times: total = 280, boot = 171, init = 1, finish = 108
16/03/16 15:21:37 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 15:21:37 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.333 s
16/03/16 15:21:37 INFO DAGScheduler: looking for newly runnable stages
16/03/16 15:21:37 INFO DAGScheduler: running: Set()
16/03/16 15:21:37 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 15:21:37 INFO DAGScheduler: failed: Set()
16/03/16 15:21:37 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 15:21:37 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 15:21:37 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10709, maxMem=1135293235
16/03/16 15:21:37 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1082.7 MB)
16/03/16 15:21:37 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 328 ms on localhost (2/2)
16/03/16 15:21:37 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 15:21:37 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15693, maxMem=1135293235
16/03/16 15:21:37 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1082.7 MB)
16/03/16 15:21:37 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:55901 (size: 3.0 KB, free: 1082.7 MB)
16/03/16 15:21:37 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 15:21:37 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:21:37 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 15:21:37 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 15:21:37 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 15:21:37 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 15:21:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 15:21:37 INFO PythonRunner: Times: total = 146, boot = 146, init = 0, finish = 0
16/03/16 15:21:37 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 15:21:37 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 15:21:37 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 15:21:37 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 15:21:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 15:21:37 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 180 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'present']
16/03/16 15:21:37 INFO PythonRunner: Times: total = 177, boot = 177, init = 0, finish = 0
16/03/16 15:21:37 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1241 bytes result sent to driver
16/03/16 15:21:37 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.357 s
16/03/16 15:21:37 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.725043 s
16/03/16 15:21:37 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 205 ms on localhost (2/2)
16/03/16 15:21:37 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 15:21:37 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 15:21:37 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 15:21:37 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:21:37 INFO DAGScheduler: Parents of final stage: List()
16/03/16 15:21:37 INFO DAGScheduler: Missing parents: List()
16/03/16 15:21:37 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 15:21:37 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18741, maxMem=1135293235
16/03/16 15:21:37 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1082.7 MB)
16/03/16 15:21:37 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24557, maxMem=1135293235
16/03/16 15:21:37 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1082.7 MB)
16/03/16 15:21:37 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:55901 (size: 3.3 KB, free: 1082.7 MB)
16/03/16 15:21:37 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 15:21:37 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:21:37 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 15:21:37 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 15:21:37 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 15:21:37 INFO PythonRunner: Times: total = 17, boot = -15, init = 32, finish = 0
16/03/16 15:21:37 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 15:21:37 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2271 bytes)
16/03/16 15:21:37 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 36 ms on localhost (1/2)
16/03/16 15:21:37 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 15:21:37 INFO PythonRunner: Times: total = 172, boot = 171, init = 0, finish = 1
16/03/16 15:21:37 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1310 bytes result sent to driver
16/03/16 15:21:37 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.219 s
16/03/16 15:21:37 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.240191 s
16/03/16 15:21:37 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 188 ms on localhost (2/2)
16/03/16 15:21:37 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 15:21:37 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 15:21:37 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 15:21:37 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 15:21:37 INFO MemoryStore: MemoryStore cleared
16/03/16 15:21:37 INFO BlockManager: BlockManager stopped
16/03/16 15:21:37 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 15:21:38 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 15:21:38 INFO SparkContext: Successfully stopped SparkContext
16/03/16 15:21:38 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 15:21:38 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 15:21:38 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'present']
16/03/16 15:21:38 INFO SparkContext: Running Spark version 1.5.2
16/03/16 15:21:38 INFO SecurityManager: Changing view acls to: root
16/03/16 15:21:38 INFO SecurityManager: Changing modify acls to: root
16/03/16 15:21:38 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 15:21:38 INFO Slf4jLogger: Slf4jLogger started
16/03/16 15:21:38 INFO Remoting: Starting remoting
16/03/16 15:21:38 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:39640]
16/03/16 15:21:38 INFO Utils: Successfully started service 'sparkDriver' on port 39640.
16/03/16 15:21:38 INFO SparkEnv: Registering MapOutputTracker
16/03/16 15:21:38 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 15:21:38 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-12459f77-d9d7-41e1-9174-36615ec4fb3a
16/03/16 15:21:38 INFO MemoryStore: MemoryStore started with capacity 1082.7 MB
16/03/16 15:21:39 INFO HttpFileServer: HTTP File server directory is /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/httpd-6f4b1be6-7309-444d-b240-6d21757f731b
16/03/16 15:21:39 INFO HttpServer: Starting HTTP Server
16/03/16 15:21:39 INFO Utils: Successfully started service 'HTTP file server' on port 52118.
16/03/16 15:21:39 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 15:21:39 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 15:21:39 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 15:21:39 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/userFiles-28be3872-bfbe-4bd8-a906-02b71f86039a/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 15:21:39 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458121899135
16/03/16 15:21:39 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 15:21:39 INFO Executor: Starting executor ID driver on host localhost
16/03/16 15:21:39 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42369.
16/03/16 15:21:39 INFO NettyBlockTransferService: Server created on 42369
16/03/16 15:21:39 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 15:21:39 INFO BlockManagerMasterEndpoint: Registering block manager localhost:42369 with 1082.7 MB RAM, BlockManagerId(driver, localhost, 42369)
16/03/16 15:21:39 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): geographical
16/03/16 15:21:39 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 15:21:39 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:21:39 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 15:21:39 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:21:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 15:21:39 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 15:21:39 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 15:21:39 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1135293235
16/03/16 15:21:39 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1082.7 MB)
16/03/16 15:21:39 INFO MemoryStore: ensureFreeSpace(4142) called with curMem=6568, maxMem=1135293235
16/03/16 15:21:39 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1082.7 MB)
16/03/16 15:21:39 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:42369 (size: 4.0 KB, free: 1082.7 MB)
16/03/16 15:21:39 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 15:21:39 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:21:39 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 15:21:39 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 15:21:39 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 15:21:39 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458121899135
16/03/16 15:21:39 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/userFiles-28be3872-bfbe-4bd8-a906-02b71f86039a/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: area
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  geographical  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: issue
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: planning
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: permission
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: economy
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: composition
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: agency
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
16/03/16 15:21:47 INFO PythonRunner: Times: total = 7694, boot = 471, init = 347, finish = 6876
16/03/16 15:21:47 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 15:21:47 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 15:21:47 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 15:21:47 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7783 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: set
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: bend
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: giant
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: astatine
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: present
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: area
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  geographical  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
16/03/16 15:21:47 INFO PythonRunner: Times: total = 270, boot = 164, init = 1, finish = 105
16/03/16 15:21:47 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 15:21:47 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.086 s
16/03/16 15:21:47 INFO DAGScheduler: looking for newly runnable stages
16/03/16 15:21:47 INFO DAGScheduler: running: Set()
16/03/16 15:21:47 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 15:21:47 INFO DAGScheduler: failed: Set()
16/03/16 15:21:47 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 15:21:47 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 15:21:47 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 315 ms on localhost (2/2)
16/03/16 15:21:47 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 15:21:47 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10710, maxMem=1135293235
16/03/16 15:21:47 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1082.7 MB)
16/03/16 15:21:47 INFO MemoryStore: ensureFreeSpace(3049) called with curMem=15694, maxMem=1135293235
16/03/16 15:21:47 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1082.7 MB)
16/03/16 15:21:47 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:42369 (size: 3.0 KB, free: 1082.7 MB)
16/03/16 15:21:47 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 15:21:47 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:21:47 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 15:21:47 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 15:21:47 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 15:21:47 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 15:21:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/16 15:21:47 INFO PythonRunner: Times: total = 150, boot = 149, init = 0, finish = 1
16/03/16 15:21:47 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 15:21:47 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 15:21:47 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 15:21:47 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 15:21:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/16 15:21:47 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 188 ms on localhost (1/2)
reduceFunction_Parents(): returns= [u'area', 'None', u'area']
16/03/16 15:21:47 INFO PythonRunner: Times: total = 188, boot = 187, init = 1, finish = 0
16/03/16 15:21:47 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1241 bytes result sent to driver
16/03/16 15:21:47 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 218 ms on localhost (2/2)
16/03/16 15:21:47 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.372 s
16/03/16 15:21:47 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.494892 s
16/03/16 15:21:47 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 15:21:47 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 15:21:47 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 15:21:47 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:21:47 INFO DAGScheduler: Parents of final stage: List()
16/03/16 15:21:47 INFO DAGScheduler: Missing parents: List()
16/03/16 15:21:47 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 15:21:47 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18743, maxMem=1135293235
16/03/16 15:21:47 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1082.7 MB)
16/03/16 15:21:47 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24559, maxMem=1135293235
16/03/16 15:21:47 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1082.7 MB)
16/03/16 15:21:47 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:42369 (size: 3.3 KB, free: 1082.7 MB)
16/03/16 15:21:47 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 15:21:47 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:21:47 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 15:21:47 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 15:21:47 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 15:21:47 INFO PythonRunner: Times: total = 81, boot = 81, init = 0, finish = 0
16/03/16 15:21:47 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 15:21:47 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2271 bytes)
16/03/16 15:21:47 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 97 ms on localhost (1/2)
16/03/16 15:21:47 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 15:21:48 INFO PythonRunner: Times: total = 170, boot = 170, init = 0, finish = 0
16/03/16 15:21:48 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1307 bytes result sent to driver
16/03/16 15:21:48 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 187 ms on localhost (2/2)
16/03/16 15:21:48 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 15:21:48 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.276 s
16/03/16 15:21:48 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.299923 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 15:21:48 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 15:21:48 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 15:21:48 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 15:21:48 INFO MemoryStore: MemoryStore cleared
16/03/16 15:21:48 INFO BlockManager: BlockManager stopped
16/03/16 15:21:48 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 15:21:48 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 15:21:48 INFO SparkContext: Successfully stopped SparkContext
16/03/16 15:21:48 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 15:21:48 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 15:21:48 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'area', u'None', u'area']
16/03/16 15:21:49 INFO SparkContext: Running Spark version 1.5.2
16/03/16 15:21:49 INFO SecurityManager: Changing view acls to: root
16/03/16 15:21:49 INFO SecurityManager: Changing modify acls to: root
16/03/16 15:21:49 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 15:21:49 INFO Slf4jLogger: Slf4jLogger started
16/03/16 15:21:49 INFO Remoting: Starting remoting
16/03/16 15:21:49 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:50442]
16/03/16 15:21:49 INFO Utils: Successfully started service 'sparkDriver' on port 50442.
16/03/16 15:21:49 INFO SparkEnv: Registering MapOutputTracker
16/03/16 15:21:49 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 15:21:49 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-3406da5e-4a2a-4f70-9217-23e158f611ed
16/03/16 15:21:49 INFO MemoryStore: MemoryStore started with capacity 1082.7 MB
16/03/16 15:21:49 INFO HttpFileServer: HTTP File server directory is /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/httpd-37341e0b-e302-4148-b0af-7ee86c125d42
16/03/16 15:21:49 INFO HttpServer: Starting HTTP Server
16/03/16 15:21:49 INFO Utils: Successfully started service 'HTTP file server' on port 51620.
16/03/16 15:21:49 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 15:21:49 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 15:21:49 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 15:21:49 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/userFiles-28af95b1-71fb-40ac-8413-3c71106fff31/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 15:21:49 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458121909419
16/03/16 15:21:49 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 15:21:49 INFO Executor: Starting executor ID driver on host localhost
16/03/16 15:21:49 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59504.
16/03/16 15:21:49 INFO NettyBlockTransferService: Server created on 59504
16/03/16 15:21:49 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 15:21:49 INFO BlockManagerMasterEndpoint: Registering block manager localhost:59504 with 1082.7 MB RAM, BlockManagerId(driver, localhost, 59504)
16/03/16 15:21:49 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): spatial
16/03/16 15:21:49 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 15:21:49 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:21:49 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 15:21:49 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:21:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 15:21:49 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 15:21:49 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 15:21:49 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1135293235
16/03/16 15:21:49 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1082.7 MB)
16/03/16 15:21:49 INFO MemoryStore: ensureFreeSpace(4141) called with curMem=6568, maxMem=1135293235
16/03/16 15:21:49 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1082.7 MB)
16/03/16 15:21:49 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:59504 (size: 4.0 KB, free: 1082.7 MB)
16/03/16 15:21:49 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 15:21:49 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:21:49 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 15:21:49 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 15:21:49 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 15:21:49 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458121909419
16/03/16 15:21:49 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/userFiles-28af95b1-71fb-40ac-8413-3c71106fff31/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: area
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: issue
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: planning
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: permission
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: economy
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: composition
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): adding to parents: syn =  Synset('composition.n.01') ; keyword:  spatial  in syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= [u'composition']
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: agency
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'composition']
16/03/16 15:21:57 INFO PythonRunner: Times: total = 7741, boot = 468, init = 348, finish = 6925
16/03/16 15:21:57 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 15:21:57 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 15:21:57 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 15:21:57 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7848 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: set
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: bend
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: giant
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: astatine
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: present
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: area
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): spatial
mapFunction_Parents(): keyword: spatial ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= spatial ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 15:21:57 INFO PythonRunner: Times: total = 243, boot = 141, init = 0, finish = 102
16/03/16 15:21:57 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 15:21:57 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 293 ms on localhost (2/2)
16/03/16 15:21:57 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 15:21:57 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.128 s
16/03/16 15:21:57 INFO DAGScheduler: looking for newly runnable stages
16/03/16 15:21:57 INFO DAGScheduler: running: Set()
16/03/16 15:21:57 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 15:21:57 INFO DAGScheduler: failed: Set()
16/03/16 15:21:57 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 15:21:57 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 15:21:57 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10709, maxMem=1135293235
16/03/16 15:21:57 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1082.7 MB)
16/03/16 15:21:57 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15693, maxMem=1135293235
16/03/16 15:21:57 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1082.7 MB)
16/03/16 15:21:57 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:59504 (size: 3.0 KB, free: 1082.7 MB)
16/03/16 15:21:57 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 15:21:57 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:21:57 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 15:21:57 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 15:21:57 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 15:21:57 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 15:21:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 15:21:57 INFO PythonRunner: Times: total = 122, boot = 121, init = 1, finish = 0
16/03/16 15:21:57 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 15:21:57 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 15:21:57 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 15:21:57 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 15:21:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
16/03/16 15:21:57 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 153 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'composition', 'None']
16/03/16 15:21:58 INFO PythonRunner: Times: total = 180, boot = 179, init = 0, finish = 1
16/03/16 15:21:58 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1245 bytes result sent to driver
16/03/16 15:21:58 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.338 s
16/03/16 15:21:58 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.508115 s
16/03/16 15:21:58 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 203 ms on localhost (2/2)
16/03/16 15:21:58 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 15:21:58 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 15:21:58 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 15:21:58 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:21:58 INFO DAGScheduler: Parents of final stage: List()
16/03/16 15:21:58 INFO DAGScheduler: Missing parents: List()
16/03/16 15:21:58 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 15:21:58 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18741, maxMem=1135293235
16/03/16 15:21:58 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1082.7 MB)
16/03/16 15:21:58 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24557, maxMem=1135293235
16/03/16 15:21:58 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1082.7 MB)
16/03/16 15:21:58 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:59504 (size: 3.3 KB, free: 1082.7 MB)
16/03/16 15:21:58 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 15:21:58 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:21:58 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 15:21:58 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 15:21:58 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 15:21:58 INFO PythonRunner: Times: total = 109, boot = 108, init = 0, finish = 1
16/03/16 15:21:58 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 15:21:58 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2275 bytes)
16/03/16 15:21:58 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 125 ms on localhost (1/2)
16/03/16 15:21:58 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 15:21:58 INFO PythonRunner: Times: total = 154, boot = 153, init = 1, finish = 0
16/03/16 15:21:58 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1314 bytes result sent to driver
16/03/16 15:21:58 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 171 ms on localhost (2/2)
16/03/16 15:21:58 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 15:21:58 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.295 s
16/03/16 15:21:58 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.310853 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 15:21:58 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 15:21:58 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 15:21:58 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 15:21:58 INFO MemoryStore: MemoryStore cleared
16/03/16 15:21:58 INFO BlockManager: BlockManager stopped
16/03/16 15:21:58 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 15:21:58 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 15:21:58 INFO SparkContext: Successfully stopped SparkContext
16/03/16 15:21:58 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 15:21:58 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 15:21:58 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'composition', u'None']
16/03/16 15:21:59 INFO SparkContext: Running Spark version 1.5.2
16/03/16 15:21:59 INFO SecurityManager: Changing view acls to: root
16/03/16 15:21:59 INFO SecurityManager: Changing modify acls to: root
16/03/16 15:21:59 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 15:21:59 INFO Slf4jLogger: Slf4jLogger started
16/03/16 15:21:59 INFO Remoting: Starting remoting
16/03/16 15:21:59 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:43916]
16/03/16 15:21:59 INFO Utils: Successfully started service 'sparkDriver' on port 43916.
16/03/16 15:21:59 INFO SparkEnv: Registering MapOutputTracker
16/03/16 15:21:59 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 15:21:59 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-e99e2167-13f8-4264-b56d-938f99b65b46
16/03/16 15:21:59 INFO MemoryStore: MemoryStore started with capacity 1082.7 MB
16/03/16 15:21:59 INFO HttpFileServer: HTTP File server directory is /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/httpd-7b4aa0bf-1e5b-4796-ba4f-1905e062606f
16/03/16 15:21:59 INFO HttpServer: Starting HTTP Server
16/03/16 15:21:59 INFO Utils: Successfully started service 'HTTP file server' on port 47459.
16/03/16 15:21:59 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 15:21:59 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 15:21:59 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 15:21:59 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/userFiles-67281e3a-6b09-4a52-8f33-01e935249c1f/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 15:21:59 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458121919769
16/03/16 15:21:59 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 15:21:59 INFO Executor: Starting executor ID driver on host localhost
16/03/16 15:21:59 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51788.
16/03/16 15:21:59 INFO NettyBlockTransferService: Server created on 51788
16/03/16 15:21:59 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 15:21:59 INFO BlockManagerMasterEndpoint: Registering block manager localhost:51788 with 1082.7 MB RAM, BlockManagerId(driver, localhost, 51788)
16/03/16 15:21:59 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): Nadu
16/03/16 15:21:59 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 15:21:59 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:21:59 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 15:21:59 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:21:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 15:21:59 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 15:21:59 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 15:21:59 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1135293235
16/03/16 15:21:59 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1082.7 MB)
16/03/16 15:21:59 INFO MemoryStore: ensureFreeSpace(4144) called with curMem=6568, maxMem=1135293235
16/03/16 15:21:59 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1082.7 MB)
16/03/16 15:21:59 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:51788 (size: 4.0 KB, free: 1082.7 MB)
16/03/16 15:21:59 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 15:21:59 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:21:59 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 15:21:59 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 15:21:59 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 15:21:59 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458121919769
16/03/16 15:21:59 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/userFiles-67281e3a-6b09-4a52-8f33-01e935249c1f/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: area
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: issue
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: planning
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: permission
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: economy
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: composition
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: agency
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): adding to parents: syn =  Synset('chennai.n.01') ; keyword:  Nadu  in syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= [u'Chennai']
reduceFunction_Parents(): returns= ['None', u'Chennai']
16/03/16 15:22:07 INFO PythonRunner: Times: total = 7887, boot = 467, init = 361, finish = 7059
16/03/16 15:22:07 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 15:22:07 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 15:22:07 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 15:22:07 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7987 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: set
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: bend
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: giant
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: astatine
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: present
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): adding to parents: syn =  Synset('chennai.n.01') ; keyword:  Nadu  in syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= [u'Chennai']
reduceFunction_Parents(): returns= ['None', u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: area
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'Chennai']
16/03/16 15:22:08 INFO PythonRunner: Times: total = 263, boot = 152, init = 0, finish = 111
16/03/16 15:22:08 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 15:22:08 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.275 s
16/03/16 15:22:08 INFO DAGScheduler: looking for newly runnable stages
16/03/16 15:22:08 INFO DAGScheduler: running: Set()
16/03/16 15:22:08 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 15:22:08 INFO DAGScheduler: failed: Set()
16/03/16 15:22:08 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 15:22:08 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 15:22:08 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10712, maxMem=1135293235
16/03/16 15:22:08 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 298 ms on localhost (2/2)
16/03/16 15:22:08 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1082.7 MB)
16/03/16 15:22:08 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 15:22:08 INFO MemoryStore: ensureFreeSpace(3046) called with curMem=15696, maxMem=1135293235
16/03/16 15:22:08 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1082.7 MB)
16/03/16 15:22:08 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:51788 (size: 3.0 KB, free: 1082.7 MB)
16/03/16 15:22:08 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 15:22:08 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:22:08 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 15:22:08 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 15:22:08 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 15:22:08 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 15:22:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 15:22:08 INFO PythonRunner: Times: total = 150, boot = 149, init = 1, finish = 0
16/03/16 15:22:08 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 15:22:08 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 15:22:08 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 15:22:08 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 15:22:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/16 15:22:08 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 173 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'Chennai', 'None', u'Chennai']
16/03/16 15:22:08 INFO PythonRunner: Times: total = 166, boot = 165, init = 0, finish = 1
16/03/16 15:22:08 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1255 bytes result sent to driver
16/03/16 15:22:08 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.348 s
16/03/16 15:22:08 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.654723 s
16/03/16 15:22:08 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 193 ms on localhost (2/2)
16/03/16 15:22:08 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 15:22:08 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 15:22:08 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 15:22:08 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:22:08 INFO DAGScheduler: Parents of final stage: List()
16/03/16 15:22:08 INFO DAGScheduler: Missing parents: List()
16/03/16 15:22:08 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 15:22:08 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18742, maxMem=1135293235
16/03/16 15:22:08 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1082.7 MB)
16/03/16 15:22:08 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=24558, maxMem=1135293235
16/03/16 15:22:08 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1082.7 MB)
16/03/16 15:22:08 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:51788 (size: 3.3 KB, free: 1082.7 MB)
16/03/16 15:22:08 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 15:22:08 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:22:08 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 15:22:08 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 15:22:08 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 15:22:08 INFO PythonRunner: Times: total = 139, boot = 139, init = 0, finish = 0
16/03/16 15:22:08 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 15:22:08 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2285 bytes)
16/03/16 15:22:08 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 166 ms on localhost (1/2)
16/03/16 15:22:08 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 15:22:09 INFO PythonRunner: Times: total = 260, boot = 259, init = 0, finish = 1
16/03/16 15:22:09 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1324 bytes result sent to driver
16/03/16 15:22:09 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.434 s
16/03/16 15:22:09 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 298 ms on localhost (2/2)
16/03/16 15:22:09 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.470127 s
16/03/16 15:22:09 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 15:22:09 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 15:22:09 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 15:22:09 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 15:22:09 INFO MemoryStore: MemoryStore cleared
16/03/16 15:22:09 INFO BlockManager: BlockManager stopped
16/03/16 15:22:09 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 15:22:09 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 15:22:09 INFO SparkContext: Successfully stopped SparkContext
16/03/16 15:22:09 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 15:22:09 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'Chennai', u'None', u'Chennai']
16/03/16 15:22:10 INFO SparkContext: Running Spark version 1.5.2
16/03/16 15:22:10 INFO SecurityManager: Changing view acls to: root
16/03/16 15:22:10 INFO SecurityManager: Changing modify acls to: root
16/03/16 15:22:10 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 15:22:10 INFO Slf4jLogger: Slf4jLogger started
16/03/16 15:22:10 INFO Remoting: Starting remoting
16/03/16 15:22:10 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:51043]
16/03/16 15:22:10 INFO Utils: Successfully started service 'sparkDriver' on port 51043.
16/03/16 15:22:10 INFO SparkEnv: Registering MapOutputTracker
16/03/16 15:22:10 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 15:22:10 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-6fc86b2b-1cd0-4d06-b4f9-00eb8ff255f8
16/03/16 15:22:10 INFO MemoryStore: MemoryStore started with capacity 1082.7 MB
16/03/16 15:22:10 INFO HttpFileServer: HTTP File server directory is /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/httpd-bd23a36d-82e1-4bba-bbe3-5fc34758f519
16/03/16 15:22:10 INFO HttpServer: Starting HTTP Server
16/03/16 15:22:10 INFO Utils: Successfully started service 'HTTP file server' on port 58895.
16/03/16 15:22:10 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 15:22:10 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 15:22:10 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 15:22:10 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/userFiles-5641804d-ac15-48ce-a43d-214c20406e77/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 15:22:10 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458121930459
16/03/16 15:22:10 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 15:22:10 INFO Executor: Starting executor ID driver on host localhost
16/03/16 15:22:10 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52672.
16/03/16 15:22:10 INFO NettyBlockTransferService: Server created on 52672
16/03/16 15:22:10 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 15:22:10 INFO BlockManagerMasterEndpoint: Registering block manager localhost:52672 with 1082.7 MB RAM, BlockManagerId(driver, localhost, 52672)
16/03/16 15:22:10 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): circular
16/03/16 15:22:10 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 15:22:10 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:22:10 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 15:22:10 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:22:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 15:22:10 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 15:22:10 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 15:22:10 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1135293235
16/03/16 15:22:10 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1082.7 MB)
16/03/16 15:22:10 INFO MemoryStore: ensureFreeSpace(4141) called with curMem=6568, maxMem=1135293235
16/03/16 15:22:10 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1082.7 MB)
16/03/16 15:22:10 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:52672 (size: 4.0 KB, free: 1082.7 MB)
16/03/16 15:22:10 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 15:22:10 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:22:10 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 15:22:10 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 15:22:10 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 15:22:10 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458121930459
16/03/16 15:22:10 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/userFiles-5641804d-ac15-48ce-a43d-214c20406e77/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: area
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: issue
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: planning
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: permission
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: economy
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: composition
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: agency
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 15:22:18 INFO PythonRunner: Times: total = 7823, boot = 467, init = 350, finish = 7006
16/03/16 15:22:18 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 15:22:18 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 15:22:18 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 15:22:18 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7928 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: set
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: bend
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): adding to parents: syn =  Synset('bend.n.01') ; keyword:  circular  in syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= [u'bend']
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: giant
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: astatine
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: present
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: area
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): circular
mapFunction_Parents(): keyword: circular ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= circular ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
16/03/16 15:22:18 INFO PythonRunner: Times: total = 287, boot = 181, init = 0, finish = 106
16/03/16 15:22:18 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 15:22:18 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 351 ms on localhost (2/2)
16/03/16 15:22:18 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 15:22:18 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.258 s
16/03/16 15:22:18 INFO DAGScheduler: looking for newly runnable stages
16/03/16 15:22:18 INFO DAGScheduler: running: Set()
16/03/16 15:22:18 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 15:22:18 INFO DAGScheduler: failed: Set()
16/03/16 15:22:18 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 15:22:18 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 15:22:18 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10709, maxMem=1135293235
16/03/16 15:22:18 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1082.7 MB)
16/03/16 15:22:18 INFO MemoryStore: ensureFreeSpace(3047) called with curMem=15693, maxMem=1135293235
16/03/16 15:22:18 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1082.7 MB)
16/03/16 15:22:18 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:52672 (size: 3.0 KB, free: 1082.7 MB)
16/03/16 15:22:18 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 15:22:18 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:22:18 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 15:22:18 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 15:22:18 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 15:22:18 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 15:22:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/16 15:22:19 INFO PythonRunner: Times: total = 128, boot = 127, init = 1, finish = 0
16/03/16 15:22:19 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 15:22:19 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 15:22:19 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 15:22:19 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 15:22:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/16 15:22:19 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 160 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'bend']
16/03/16 15:22:19 INFO PythonRunner: Times: total = 196, boot = 195, init = 0, finish = 1
16/03/16 15:22:19 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1230 bytes result sent to driver
16/03/16 15:22:19 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 212 ms on localhost (2/2)
16/03/16 15:22:19 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 15:22:19 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.354 s
16/03/16 15:22:19 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.666871 s
16/03/16 15:22:19 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 15:22:19 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 15:22:19 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:22:19 INFO DAGScheduler: Parents of final stage: List()
16/03/16 15:22:19 INFO DAGScheduler: Missing parents: List()
16/03/16 15:22:19 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 15:22:19 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18740, maxMem=1135293235
16/03/16 15:22:19 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1082.7 MB)
16/03/16 15:22:19 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24556, maxMem=1135293235
16/03/16 15:22:19 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1082.7 MB)
16/03/16 15:22:19 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:52672 (size: 3.3 KB, free: 1082.7 MB)
16/03/16 15:22:19 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 15:22:19 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:22:19 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 15:22:19 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 15:22:19 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 15:22:19 INFO PythonRunner: Times: total = 76, boot = 75, init = 1, finish = 0
16/03/16 15:22:19 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 15:22:19 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2260 bytes)
16/03/16 15:22:19 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 15:22:19 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 95 ms on localhost (1/2)
16/03/16 15:22:19 INFO PythonRunner: Times: total = 175, boot = 175, init = 0, finish = 0
16/03/16 15:22:19 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1296 bytes result sent to driver
16/03/16 15:22:19 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 190 ms on localhost (2/2)
16/03/16 15:22:19 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 15:22:19 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.279 s
16/03/16 15:22:19 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.298309 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 15:22:19 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 15:22:19 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 15:22:19 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 15:22:19 INFO MemoryStore: MemoryStore cleared
16/03/16 15:22:19 INFO BlockManager: BlockManager stopped
16/03/16 15:22:19 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 15:22:19 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 15:22:19 INFO SparkContext: Successfully stopped SparkContext
16/03/16 15:22:19 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 15:22:19 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 15:22:19 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'bend']
16/03/16 15:22:20 INFO SparkContext: Running Spark version 1.5.2
16/03/16 15:22:20 INFO SecurityManager: Changing view acls to: root
16/03/16 15:22:20 INFO SecurityManager: Changing modify acls to: root
16/03/16 15:22:20 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 15:22:20 INFO Slf4jLogger: Slf4jLogger started
16/03/16 15:22:20 INFO Remoting: Starting remoting
16/03/16 15:22:20 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:43958]
16/03/16 15:22:20 INFO Utils: Successfully started service 'sparkDriver' on port 43958.
16/03/16 15:22:20 INFO SparkEnv: Registering MapOutputTracker
16/03/16 15:22:20 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 15:22:20 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-e48a3acb-43b3-4e8b-b33a-9ebc83f15cad
16/03/16 15:22:20 INFO MemoryStore: MemoryStore started with capacity 1082.7 MB
16/03/16 15:22:20 INFO HttpFileServer: HTTP File server directory is /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/httpd-2de5e5fd-88ea-474d-abae-1d9774a9988c
16/03/16 15:22:20 INFO HttpServer: Starting HTTP Server
16/03/16 15:22:20 INFO Utils: Successfully started service 'HTTP file server' on port 60808.
16/03/16 15:22:20 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 15:22:20 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 15:22:20 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 15:22:20 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/userFiles-24919a7a-a120-4ffc-8288-f4a02e8f9032/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 15:22:20 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458121940978
16/03/16 15:22:21 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 15:22:21 INFO Executor: Starting executor ID driver on host localhost
16/03/16 15:22:21 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55963.
16/03/16 15:22:21 INFO NettyBlockTransferService: Server created on 55963
16/03/16 15:22:21 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 15:22:21 INFO BlockManagerMasterEndpoint: Registering block manager localhost:55963 with 1082.7 MB RAM, BlockManagerId(driver, localhost, 55963)
16/03/16 15:22:21 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): product
16/03/16 15:22:21 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 15:22:21 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:22:21 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 15:22:21 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:22:21 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 15:22:21 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 15:22:21 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 15:22:21 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1135293235
16/03/16 15:22:21 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1082.7 MB)
16/03/16 15:22:21 INFO MemoryStore: ensureFreeSpace(4141) called with curMem=6568, maxMem=1135293235
16/03/16 15:22:21 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1082.7 MB)
16/03/16 15:22:21 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:55963 (size: 4.0 KB, free: 1082.7 MB)
16/03/16 15:22:21 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 15:22:21 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:22:21 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 15:22:21 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 15:22:21 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 15:22:21 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458121940978
16/03/16 15:22:21 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/userFiles-24919a7a-a120-4ffc-8288-f4a02e8f9032/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: area
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: issue
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: planning
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: permission
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: economy
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: composition
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: agency
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 15:22:28 INFO PythonRunner: Times: total = 7753, boot = 473, init = 362, finish = 6918
16/03/16 15:22:28 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 15:22:28 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 15:22:28 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 15:22:28 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7822 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: set
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: bend
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: giant
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: astatine
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('astatine.n.01') ; keyword:  product  in syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= [u'astatine']
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: present
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: area
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
16/03/16 15:22:29 INFO PythonRunner: Times: total = 297, boot = 190, init = 0, finish = 107
16/03/16 15:22:29 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 15:22:29 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 342 ms on localhost (2/2)
16/03/16 15:22:29 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 15:22:29 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.156 s
16/03/16 15:22:29 INFO DAGScheduler: looking for newly runnable stages
16/03/16 15:22:29 INFO DAGScheduler: running: Set()
16/03/16 15:22:29 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 15:22:29 INFO DAGScheduler: failed: Set()
16/03/16 15:22:29 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 15:22:29 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 15:22:29 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10709, maxMem=1135293235
16/03/16 15:22:29 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1082.7 MB)
16/03/16 15:22:29 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15693, maxMem=1135293235
16/03/16 15:22:29 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1082.7 MB)
16/03/16 15:22:29 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:55963 (size: 3.0 KB, free: 1082.7 MB)
16/03/16 15:22:29 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 15:22:29 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:22:29 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 15:22:29 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 15:22:29 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 15:22:29 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 15:22:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 15:22:29 INFO PythonRunner: Times: total = 119, boot = 118, init = 1, finish = 0
16/03/16 15:22:29 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 15:22:29 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 15:22:29 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 15:22:29 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 15:22:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
16/03/16 15:22:29 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 161 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'astatine']
16/03/16 15:22:29 INFO PythonRunner: Times: total = 166, boot = 165, init = 0, finish = 1
16/03/16 15:22:29 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1242 bytes result sent to driver
16/03/16 15:22:29 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.313 s
16/03/16 15:22:29 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.517313 s
16/03/16 15:22:29 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 186 ms on localhost (2/2)
16/03/16 15:22:29 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 15:22:29 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 15:22:29 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 15:22:29 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:22:29 INFO DAGScheduler: Parents of final stage: List()
16/03/16 15:22:29 INFO DAGScheduler: Missing parents: List()
16/03/16 15:22:29 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 15:22:29 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18741, maxMem=1135293235
16/03/16 15:22:29 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1082.7 MB)
16/03/16 15:22:29 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24557, maxMem=1135293235
16/03/16 15:22:29 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1082.7 MB)
16/03/16 15:22:29 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:55963 (size: 3.3 KB, free: 1082.7 MB)
16/03/16 15:22:29 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 15:22:29 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:22:29 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 15:22:29 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 15:22:29 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 15:22:29 INFO PythonRunner: Times: total = 39, boot = 39, init = 0, finish = 0
16/03/16 15:22:29 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 15:22:29 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2272 bytes)
16/03/16 15:22:29 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 15:22:29 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 57 ms on localhost (1/2)
16/03/16 15:22:30 INFO PythonRunner: Times: total = 175, boot = 174, init = 1, finish = 0
16/03/16 15:22:30 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1311 bytes result sent to driver
16/03/16 15:22:30 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.236 s
16/03/16 15:22:30 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.274714 s
16/03/16 15:22:30 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 190 ms on localhost (2/2)
16/03/16 15:22:30 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 15:22:30 INFO BlockManagerInfo: Removed broadcast_2_piece0 on localhost:55963 in memory (size: 3.3 KB, free: 1082.7 MB)
16/03/16 15:22:30 INFO ContextCleaner: Cleaned accumulator 348
16/03/16 15:22:30 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:55963 in memory (size: 3.0 KB, free: 1082.7 MB)
16/03/16 15:22:30 INFO ContextCleaner: Cleaned accumulator 347
16/03/16 15:22:30 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:55963 in memory (size: 4.0 KB, free: 1082.7 MB)
16/03/16 15:22:30 INFO ContextCleaner: Cleaned accumulator 346
16/03/16 15:22:30 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 15:22:30 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 15:22:30 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 15:22:30 INFO MemoryStore: MemoryStore cleared
16/03/16 15:22:30 INFO BlockManager: BlockManager stopped
16/03/16 15:22:30 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 15:22:30 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 15:22:30 INFO SparkContext: Successfully stopped SparkContext
16/03/16 15:22:30 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 15:22:30 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 15:22:30 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'astatine']
16/03/16 15:22:31 INFO SparkContext: Running Spark version 1.5.2
16/03/16 15:22:31 INFO SecurityManager: Changing view acls to: root
16/03/16 15:22:31 INFO SecurityManager: Changing modify acls to: root
16/03/16 15:22:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 15:22:31 INFO Slf4jLogger: Slf4jLogger started
16/03/16 15:22:31 INFO Remoting: Starting remoting
16/03/16 15:22:31 INFO Utils: Successfully started service 'sparkDriver' on port 50783.
16/03/16 15:22:31 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:50783]
16/03/16 15:22:31 INFO SparkEnv: Registering MapOutputTracker
16/03/16 15:22:31 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 15:22:31 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-02688728-f831-4b96-896b-31457315b6a1
16/03/16 15:22:31 INFO MemoryStore: MemoryStore started with capacity 1072.7 MB
16/03/16 15:22:31 INFO HttpFileServer: HTTP File server directory is /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/httpd-4503fb5b-39fd-42e5-ae00-790f10c1b341
16/03/16 15:22:31 INFO HttpServer: Starting HTTP Server
16/03/16 15:22:31 INFO Utils: Successfully started service 'HTTP file server' on port 34534.
16/03/16 15:22:31 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 15:22:31 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 15:22:31 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 15:22:31 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/userFiles-a281abf0-37b7-4f52-a7be-8d5ef12653c3/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 15:22:31 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458121951400
16/03/16 15:22:31 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 15:22:31 INFO Executor: Starting executor ID driver on host localhost
16/03/16 15:22:31 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38021.
16/03/16 15:22:31 INFO NettyBlockTransferService: Server created on 38021
16/03/16 15:22:31 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 15:22:31 INFO BlockManagerMasterEndpoint: Registering block manager localhost:38021 with 1072.7 MB RAM, BlockManagerId(driver, localhost, 38021)
16/03/16 15:22:31 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): used
16/03/16 15:22:31 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 15:22:31 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:22:31 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 15:22:31 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:22:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 15:22:31 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 15:22:31 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 15:22:31 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1124817960
16/03/16 15:22:31 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1072.7 MB)
16/03/16 15:22:31 INFO MemoryStore: ensureFreeSpace(4141) called with curMem=6568, maxMem=1124817960
16/03/16 15:22:31 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1072.7 MB)
16/03/16 15:22:31 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:38021 (size: 4.0 KB, free: 1072.7 MB)
16/03/16 15:22:31 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 15:22:31 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:22:31 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 15:22:31 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 15:22:31 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 15:22:31 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458121951400
16/03/16 15:22:31 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/userFiles-a281abf0-37b7-4f52-a7be-8d5ef12653c3/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: area
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: issue
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: planning
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: permission
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: economy
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: composition
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: agency
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 15:22:39 INFO PythonRunner: Times: total = 7841, boot = 469, init = 358, finish = 7014
16/03/16 15:22:39 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 15:22:39 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 15:22:39 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 15:22:39 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7941 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: set
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): adding to parents: syn =  Synset('set.n.01') ; keyword:  used  in syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: bend
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: giant
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: astatine
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: present
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: area
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): used
mapFunction_Parents(): keyword: used ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= used ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
16/03/16 15:22:39 INFO PythonRunner: Times: total = 249, boot = 146, init = 0, finish = 103
16/03/16 15:22:39 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 15:22:39 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 284 ms on localhost (2/2)
16/03/16 15:22:39 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 15:22:39 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.222 s
16/03/16 15:22:39 INFO DAGScheduler: looking for newly runnable stages
16/03/16 15:22:39 INFO DAGScheduler: running: Set()
16/03/16 15:22:39 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 15:22:39 INFO DAGScheduler: failed: Set()
16/03/16 15:22:39 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 15:22:39 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 15:22:39 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10709, maxMem=1124817960
16/03/16 15:22:39 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1072.7 MB)
16/03/16 15:22:39 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15693, maxMem=1124817960
16/03/16 15:22:39 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1072.7 MB)
16/03/16 15:22:39 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:38021 (size: 3.0 KB, free: 1072.7 MB)
16/03/16 15:22:39 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 15:22:39 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:22:39 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 15:22:39 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 15:22:39 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 15:22:39 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 15:22:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/16 15:22:39 INFO PythonRunner: Times: total = 160, boot = 160, init = 0, finish = 0
16/03/16 15:22:39 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 15:22:39 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 15:22:39 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 15:22:39 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 15:22:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/16 15:22:39 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 199 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'set']
16/03/16 15:22:40 INFO PythonRunner: Times: total = 172, boot = 171, init = 0, finish = 1
16/03/16 15:22:40 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1229 bytes result sent to driver
16/03/16 15:22:40 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 201 ms on localhost (2/2)
16/03/16 15:22:40 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 15:22:40 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.368 s
16/03/16 15:22:40 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.621854 s
16/03/16 15:22:40 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 15:22:40 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 15:22:40 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:22:40 INFO DAGScheduler: Parents of final stage: List()
16/03/16 15:22:40 INFO DAGScheduler: Missing parents: List()
16/03/16 15:22:40 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 15:22:40 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18741, maxMem=1124817960
16/03/16 15:22:40 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1072.7 MB)
16/03/16 15:22:40 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24557, maxMem=1124817960
16/03/16 15:22:40 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1072.7 MB)
16/03/16 15:22:40 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:38021 (size: 3.3 KB, free: 1072.7 MB)
16/03/16 15:22:40 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 15:22:40 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:22:40 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 15:22:40 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 15:22:40 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 15:22:40 INFO PythonRunner: Times: total = 75, boot = 74, init = 0, finish = 1
16/03/16 15:22:40 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 15:22:40 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2259 bytes)
16/03/16 15:22:40 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 104 ms on localhost (1/2)
16/03/16 15:22:40 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 15:22:40 INFO PythonRunner: Times: total = 148, boot = 148, init = 0, finish = 0
16/03/16 15:22:40 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1295 bytes result sent to driver
16/03/16 15:22:40 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.261 s
16/03/16 15:22:40 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.307031 s
16/03/16 15:22:40 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 185 ms on localhost (2/2)
16/03/16 15:22:40 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 15:22:40 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 15:22:40 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 15:22:40 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 15:22:40 INFO MemoryStore: MemoryStore cleared
16/03/16 15:22:40 INFO BlockManager: BlockManager stopped
16/03/16 15:22:40 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 15:22:40 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 15:22:40 INFO SparkContext: Successfully stopped SparkContext
16/03/16 15:22:40 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 15:22:40 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 15:22:40 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'set']
16/03/16 15:22:41 INFO SparkContext: Running Spark version 1.5.2
16/03/16 15:22:41 INFO SecurityManager: Changing view acls to: root
16/03/16 15:22:41 INFO SecurityManager: Changing modify acls to: root
16/03/16 15:22:41 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 15:22:41 INFO Slf4jLogger: Slf4jLogger started
16/03/16 15:22:41 INFO Remoting: Starting remoting
16/03/16 15:22:41 INFO Utils: Successfully started service 'sparkDriver' on port 55129.
16/03/16 15:22:41 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:55129]
16/03/16 15:22:41 INFO SparkEnv: Registering MapOutputTracker
16/03/16 15:22:41 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 15:22:41 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-cdaa018a-bf29-47cd-a933-4bbe0b8fc0d0
16/03/16 15:22:41 INFO MemoryStore: MemoryStore started with capacity 1072.7 MB
16/03/16 15:22:41 INFO HttpFileServer: HTTP File server directory is /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/httpd-7238a9ae-6858-403b-8f20-3d9504bdd405
16/03/16 15:22:41 INFO HttpServer: Starting HTTP Server
16/03/16 15:22:41 INFO Utils: Successfully started service 'HTTP file server' on port 38116.
16/03/16 15:22:41 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 15:22:41 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 15:22:41 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 15:22:41 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/userFiles-9f9486ec-6b7a-41a5-91b0-f3f90bae2934/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 15:22:41 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458121961860
16/03/16 15:22:41 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 15:22:41 INFO Executor: Starting executor ID driver on host localhost
16/03/16 15:22:41 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 47725.
16/03/16 15:22:41 INFO NettyBlockTransferService: Server created on 47725
16/03/16 15:22:41 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 15:22:41 INFO BlockManagerMasterEndpoint: Registering block manager localhost:47725 with 1072.7 MB RAM, BlockManagerId(driver, localhost, 47725)
16/03/16 15:22:41 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): usually
16/03/16 15:22:42 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 15:22:42 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:22:42 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 15:22:42 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:22:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 15:22:42 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 15:22:42 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 15:22:42 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1124817960
16/03/16 15:22:42 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1072.7 MB)
16/03/16 15:22:42 INFO MemoryStore: ensureFreeSpace(4141) called with curMem=6568, maxMem=1124817960
16/03/16 15:22:42 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1072.7 MB)
16/03/16 15:22:42 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:47725 (size: 4.0 KB, free: 1072.7 MB)
16/03/16 15:22:42 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 15:22:42 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:22:42 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 15:22:42 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 15:22:42 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 15:22:42 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458121961860
16/03/16 15:22:42 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/userFiles-9f9486ec-6b7a-41a5-91b0-f3f90bae2934/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: area
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  usually  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: issue
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: planning
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: permission
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: economy
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: composition
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: agency
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
16/03/16 15:22:49 INFO PythonRunner: Times: total = 7850, boot = 471, init = 370, finish = 7009
16/03/16 15:22:49 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 15:22:49 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 15:22:49 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 15:22:49 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7941 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: set
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: bend
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: giant
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: astatine
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: present
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: area
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  usually  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
16/03/16 15:22:50 INFO PythonRunner: Times: total = 243, boot = 138, init = 1, finish = 104
16/03/16 15:22:50 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 15:22:50 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 280 ms on localhost (2/2)
16/03/16 15:22:50 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 15:22:50 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.222 s
16/03/16 15:22:50 INFO DAGScheduler: looking for newly runnable stages
16/03/16 15:22:50 INFO DAGScheduler: running: Set()
16/03/16 15:22:50 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 15:22:50 INFO DAGScheduler: failed: Set()
16/03/16 15:22:50 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 15:22:50 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 15:22:50 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10709, maxMem=1124817960
16/03/16 15:22:50 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1072.7 MB)
16/03/16 15:22:50 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15693, maxMem=1124817960
16/03/16 15:22:50 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1072.7 MB)
16/03/16 15:22:50 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:47725 (size: 3.0 KB, free: 1072.7 MB)
16/03/16 15:22:50 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 15:22:50 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:22:50 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 15:22:50 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 15:22:50 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 15:22:50 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 15:22:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 15:22:50 INFO PythonRunner: Times: total = 110, boot = 109, init = 1, finish = 0
16/03/16 15:22:50 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 15:22:50 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 15:22:50 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 15:22:50 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 15:22:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 15:22:50 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 151 ms on localhost (1/2)
reduceFunction_Parents(): returns= [u'area', 'None', u'area']
16/03/16 15:22:50 INFO PythonRunner: Times: total = 167, boot = 166, init = 0, finish = 1
16/03/16 15:22:50 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1241 bytes result sent to driver
16/03/16 15:22:50 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.312 s
16/03/16 15:22:50 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.595301 s
16/03/16 15:22:50 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 196 ms on localhost (2/2)
16/03/16 15:22:50 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 15:22:50 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 15:22:50 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 15:22:50 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:22:50 INFO DAGScheduler: Parents of final stage: List()
16/03/16 15:22:50 INFO DAGScheduler: Missing parents: List()
16/03/16 15:22:50 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 15:22:50 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18741, maxMem=1124817960
16/03/16 15:22:50 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1072.7 MB)
16/03/16 15:22:50 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24557, maxMem=1124817960
16/03/16 15:22:50 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1072.7 MB)
16/03/16 15:22:50 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:47725 (size: 3.3 KB, free: 1072.7 MB)
16/03/16 15:22:50 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 15:22:50 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:22:50 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 15:22:50 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 15:22:50 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 15:22:50 INFO PythonRunner: Times: total = 45, boot = 45, init = 0, finish = 0
16/03/16 15:22:50 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 15:22:50 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2271 bytes)
16/03/16 15:22:50 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 15:22:50 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 69 ms on localhost (1/2)
16/03/16 15:22:51 INFO PythonRunner: Times: total = 170, boot = 170, init = 0, finish = 0
16/03/16 15:22:51 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1307 bytes result sent to driver
16/03/16 15:22:51 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.237 s
16/03/16 15:22:51 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.275321 s
16/03/16 15:22:51 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 193 ms on localhost (2/2)
16/03/16 15:22:51 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 15:22:51 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 15:22:51 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 15:22:51 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 15:22:51 INFO MemoryStore: MemoryStore cleared
16/03/16 15:22:51 INFO BlockManager: BlockManager stopped
16/03/16 15:22:51 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 15:22:51 INFO SparkContext: Successfully stopped SparkContext
16/03/16 15:22:51 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 15:22:51 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 15:22:51 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 15:22:51 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'area', u'None', u'area']
16/03/16 15:22:52 INFO SparkContext: Running Spark version 1.5.2
16/03/16 15:22:52 INFO SecurityManager: Changing view acls to: root
16/03/16 15:22:52 INFO SecurityManager: Changing modify acls to: root
16/03/16 15:22:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 15:22:52 INFO Slf4jLogger: Slf4jLogger started
16/03/16 15:22:52 INFO Remoting: Starting remoting
16/03/16 15:22:52 INFO Utils: Successfully started service 'sparkDriver' on port 41864.
16/03/16 15:22:52 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:41864]
16/03/16 15:22:52 INFO SparkEnv: Registering MapOutputTracker
16/03/16 15:22:52 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 15:22:52 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-20163c5d-b2b1-49c4-9f8e-d97ae77bc816
16/03/16 15:22:52 INFO MemoryStore: MemoryStore started with capacity 1072.7 MB
16/03/16 15:22:52 INFO HttpFileServer: HTTP File server directory is /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/httpd-a595b267-d7ef-419c-b8d6-8f8a1686a2db
16/03/16 15:22:52 INFO HttpServer: Starting HTTP Server
16/03/16 15:22:52 INFO Utils: Successfully started service 'HTTP file server' on port 46893.
16/03/16 15:22:52 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 15:22:52 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 15:22:52 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 15:22:52 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/userFiles-f97188f1-5830-4e27-8b0a-fcfdc460f114/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 15:22:52 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458121972314
16/03/16 15:22:52 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 15:22:52 INFO Executor: Starting executor ID driver on host localhost
16/03/16 15:22:52 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49714.
16/03/16 15:22:52 INFO NettyBlockTransferService: Server created on 49714
16/03/16 15:22:52 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 15:22:52 INFO BlockManagerMasterEndpoint: Registering block manager localhost:49714 with 1072.7 MB RAM, BlockManagerId(driver, localhost, 49714)
16/03/16 15:22:52 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): moment
16/03/16 15:22:52 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 15:22:52 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:22:52 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 15:22:52 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:22:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 15:22:52 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 15:22:52 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 15:22:52 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1124817960
16/03/16 15:22:52 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1072.7 MB)
16/03/16 15:22:52 INFO MemoryStore: ensureFreeSpace(4141) called with curMem=6568, maxMem=1124817960
16/03/16 15:22:52 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1072.7 MB)
16/03/16 15:22:52 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:49714 (size: 4.0 KB, free: 1072.7 MB)
16/03/16 15:22:52 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 15:22:52 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:22:52 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 15:22:52 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 15:22:52 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 15:22:52 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458121972314
16/03/16 15:22:52 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/userFiles-f97188f1-5830-4e27-8b0a-fcfdc460f114/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: area
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: issue
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: planning
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: permission
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: economy
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: composition
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: agency
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 15:23:00 INFO PythonRunner: Times: total = 7943, boot = 509, init = 355, finish = 7079
16/03/16 15:23:00 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 15:23:00 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 15:23:00 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 15:23:00 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8053 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: set
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: bend
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: giant
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: astatine
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: present
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('present.n.01') ; keyword:  moment  in syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= [u'present']
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: area
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): moment
mapFunction_Parents(): keyword: moment ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= moment ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
16/03/16 15:23:00 INFO PythonRunner: Times: total = 249, boot = 143, init = 1, finish = 105
16/03/16 15:23:00 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 15:23:00 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 294 ms on localhost (2/2)
16/03/16 15:23:00 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.339 s
16/03/16 15:23:00 INFO DAGScheduler: looking for newly runnable stages
16/03/16 15:23:00 INFO DAGScheduler: running: Set()
16/03/16 15:23:00 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 15:23:00 INFO DAGScheduler: failed: Set()
16/03/16 15:23:00 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 15:23:00 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 15:23:00 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10709, maxMem=1124817960
16/03/16 15:23:00 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1072.7 MB)
16/03/16 15:23:00 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15693, maxMem=1124817960
16/03/16 15:23:00 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1072.7 MB)
16/03/16 15:23:00 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 15:23:00 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:49714 (size: 3.0 KB, free: 1072.7 MB)
16/03/16 15:23:00 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 15:23:00 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:23:00 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 15:23:00 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 15:23:00 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 15:23:00 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 15:23:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 15:23:00 INFO PythonRunner: Times: total = 157, boot = 156, init = 0, finish = 1
16/03/16 15:23:00 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 15:23:00 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 15:23:00 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 15:23:00 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 15:23:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
16/03/16 15:23:01 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 202 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'present']
16/03/16 15:23:01 INFO PythonRunner: Times: total = 281, boot = 276, init = 1, finish = 4
16/03/16 15:23:01 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1241 bytes result sent to driver
16/03/16 15:23:01 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 337 ms on localhost (2/2)
16/03/16 15:23:01 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.501 s
16/03/16 15:23:01 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 15:23:01 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.877844 s
16/03/16 15:23:01 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 15:23:01 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 15:23:01 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:23:01 INFO DAGScheduler: Parents of final stage: List()
16/03/16 15:23:01 INFO DAGScheduler: Missing parents: List()
16/03/16 15:23:01 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 15:23:01 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18741, maxMem=1124817960
16/03/16 15:23:01 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1072.7 MB)
16/03/16 15:23:01 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24557, maxMem=1124817960
16/03/16 15:23:01 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1072.7 MB)
16/03/16 15:23:01 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:49714 (size: 3.3 KB, free: 1072.7 MB)
16/03/16 15:23:01 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 15:23:01 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:23:01 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 15:23:01 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 15:23:01 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 15:23:01 INFO PythonRunner: Times: total = 155, boot = 154, init = 1, finish = 0
16/03/16 15:23:01 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 15:23:01 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2271 bytes)
16/03/16 15:23:01 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 171 ms on localhost (1/2)
16/03/16 15:23:01 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 15:23:01 INFO PythonRunner: Times: total = 208, boot = 208, init = 0, finish = 0
16/03/16 15:23:01 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1310 bytes result sent to driver
16/03/16 15:23:01 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 235 ms on localhost (2/2)
16/03/16 15:23:01 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 15:23:01 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.405 s
16/03/16 15:23:01 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.421928 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 15:23:02 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 15:23:02 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 15:23:02 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 15:23:02 INFO MemoryStore: MemoryStore cleared
16/03/16 15:23:02 INFO BlockManager: BlockManager stopped
16/03/16 15:23:02 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 15:23:02 INFO SparkContext: Successfully stopped SparkContext
16/03/16 15:23:02 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 15:23:02 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 15:23:02 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 15:23:02 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'present']
16/03/16 15:23:02 INFO SparkContext: Running Spark version 1.5.2
16/03/16 15:23:02 INFO SecurityManager: Changing view acls to: root
16/03/16 15:23:02 INFO SecurityManager: Changing modify acls to: root
16/03/16 15:23:02 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 15:23:03 INFO Slf4jLogger: Slf4jLogger started
16/03/16 15:23:03 INFO Remoting: Starting remoting
16/03/16 15:23:03 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:49471]
16/03/16 15:23:03 INFO Utils: Successfully started service 'sparkDriver' on port 49471.
16/03/16 15:23:03 INFO SparkEnv: Registering MapOutputTracker
16/03/16 15:23:03 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 15:23:03 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-968aaeba-bbc4-4a51-91bf-6229047d1cd9
16/03/16 15:23:03 INFO MemoryStore: MemoryStore started with capacity 1072.7 MB
16/03/16 15:23:03 INFO HttpFileServer: HTTP File server directory is /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/httpd-d73a53a5-ce75-4c62-9b4f-5be4d7dab860
16/03/16 15:23:03 INFO HttpServer: Starting HTTP Server
16/03/16 15:23:03 INFO Utils: Successfully started service 'HTTP file server' on port 47230.
16/03/16 15:23:03 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 15:23:03 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 15:23:03 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 15:23:03 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/userFiles-76544483-e476-4551-a5d4-bd26a420f909/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 15:23:03 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458121983249
16/03/16 15:23:03 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 15:23:03 INFO Executor: Starting executor ID driver on host localhost
16/03/16 15:23:03 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 32893.
16/03/16 15:23:03 INFO NettyBlockTransferService: Server created on 32893
16/03/16 15:23:03 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 15:23:03 INFO BlockManagerMasterEndpoint: Registering block manager localhost:32893 with 1072.7 MB RAM, BlockManagerId(driver, localhost, 32893)
16/03/16 15:23:03 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): purpose
16/03/16 15:23:03 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 15:23:03 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:23:03 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 15:23:03 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:23:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 15:23:03 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 15:23:03 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 15:23:03 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1124817960
16/03/16 15:23:03 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1072.7 MB)
16/03/16 15:23:03 INFO MemoryStore: ensureFreeSpace(4141) called with curMem=6568, maxMem=1124817960
16/03/16 15:23:03 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1072.7 MB)
16/03/16 15:23:03 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:32893 (size: 4.0 KB, free: 1072.7 MB)
16/03/16 15:23:03 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 15:23:03 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:23:03 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 15:23:03 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 15:23:03 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 15:23:03 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458121983249
16/03/16 15:23:03 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/userFiles-76544483-e476-4551-a5d4-bd26a420f909/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: area
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  purpose  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: issue
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: planning
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: permission
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: economy
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: composition
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: agency
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'area']
16/03/16 15:23:11 INFO PythonRunner: Times: total = 8164, boot = 594, init = 462, finish = 7108
16/03/16 15:23:11 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 15:23:11 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 15:23:11 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 15:23:11 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8296 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: set
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: bend
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: giant
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: astatine
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: present
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: area
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  purpose  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
16/03/16 15:23:11 INFO PythonRunner: Times: total = 302, boot = 185, init = 1, finish = 116
16/03/16 15:23:12 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 15:23:12 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.621 s
16/03/16 15:23:12 INFO DAGScheduler: looking for newly runnable stages
16/03/16 15:23:12 INFO DAGScheduler: running: Set()
16/03/16 15:23:12 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 15:23:12 INFO DAGScheduler: failed: Set()
16/03/16 15:23:12 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 15:23:12 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 15:23:12 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 331 ms on localhost (2/2)
16/03/16 15:23:12 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10709, maxMem=1124817960
16/03/16 15:23:12 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 15:23:12 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1072.7 MB)
16/03/16 15:23:12 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15693, maxMem=1124817960
16/03/16 15:23:12 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1072.7 MB)
16/03/16 15:23:12 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:32893 (size: 3.0 KB, free: 1072.7 MB)
16/03/16 15:23:12 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 15:23:12 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:23:12 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 15:23:12 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 15:23:12 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 15:23:12 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 15:23:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 15:23:12 INFO PythonRunner: Times: total = 147, boot = 146, init = 0, finish = 1
16/03/16 15:23:12 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 15:23:12 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 15:23:12 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 15:23:12 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 15:23:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/16 15:23:12 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 181 ms on localhost (1/2)
reduceFunction_Parents(): returns= [u'area', 'None', u'area']
16/03/16 15:23:12 INFO PythonRunner: Times: total = 165, boot = 164, init = 1, finish = 0
16/03/16 15:23:12 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1241 bytes result sent to driver
16/03/16 15:23:12 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 185 ms on localhost (2/2)
16/03/16 15:23:12 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 15:23:12 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.337 s
16/03/16 15:23:12 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.995888 s
16/03/16 15:23:12 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 15:23:12 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 15:23:12 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:23:12 INFO DAGScheduler: Parents of final stage: List()
16/03/16 15:23:12 INFO DAGScheduler: Missing parents: List()
16/03/16 15:23:12 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 15:23:12 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18741, maxMem=1124817960
16/03/16 15:23:12 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1072.7 MB)
16/03/16 15:23:12 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24557, maxMem=1124817960
16/03/16 15:23:12 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1072.7 MB)
16/03/16 15:23:12 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:32893 (size: 3.3 KB, free: 1072.7 MB)
16/03/16 15:23:12 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 15:23:12 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:23:12 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 15:23:12 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 15:23:12 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 15:23:12 INFO PythonRunner: Times: total = 96, boot = 96, init = 0, finish = 0
16/03/16 15:23:12 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 15:23:12 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2271 bytes)
16/03/16 15:23:12 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 119 ms on localhost (1/2)
16/03/16 15:23:12 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 15:23:12 INFO PythonRunner: Times: total = 156, boot = 155, init = 0, finish = 1
16/03/16 15:23:12 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1307 bytes result sent to driver
16/03/16 15:23:12 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 184 ms on localhost (2/2)
16/03/16 15:23:12 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 15:23:12 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.305 s
16/03/16 15:23:12 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.316127 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 15:23:12 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 15:23:12 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 15:23:12 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 15:23:12 INFO MemoryStore: MemoryStore cleared
16/03/16 15:23:12 INFO BlockManager: BlockManager stopped
16/03/16 15:23:12 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 15:23:12 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 15:23:12 INFO SparkContext: Successfully stopped SparkContext
16/03/16 15:23:12 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 15:23:12 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 15:23:12 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'area', u'None', u'area']
16/03/16 15:23:13 INFO SparkContext: Running Spark version 1.5.2
16/03/16 15:23:13 INFO SecurityManager: Changing view acls to: root
16/03/16 15:23:13 INFO SecurityManager: Changing modify acls to: root
16/03/16 15:23:13 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 15:23:13 INFO Slf4jLogger: Slf4jLogger started
16/03/16 15:23:13 INFO Remoting: Starting remoting
16/03/16 15:23:13 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:43008]
16/03/16 15:23:13 INFO Utils: Successfully started service 'sparkDriver' on port 43008.
16/03/16 15:23:13 INFO SparkEnv: Registering MapOutputTracker
16/03/16 15:23:13 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 15:23:13 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-bc28f5e9-cac7-4fb5-83ac-2caed80554b3
16/03/16 15:23:13 INFO MemoryStore: MemoryStore started with capacity 1072.7 MB
16/03/16 15:23:13 INFO HttpFileServer: HTTP File server directory is /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/httpd-7574e494-988a-420b-8a66-4a326397a84b
16/03/16 15:23:13 INFO HttpServer: Starting HTTP Server
16/03/16 15:23:14 INFO Utils: Successfully started service 'HTTP file server' on port 40552.
16/03/16 15:23:14 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 15:23:14 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 15:23:14 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 15:23:14 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/userFiles-e9f157c8-a701-4986-bd1f-714eeb352240/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 15:23:14 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458121994130
16/03/16 15:23:14 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 15:23:14 INFO Executor: Starting executor ID driver on host localhost
16/03/16 15:23:14 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37999.
16/03/16 15:23:14 INFO NettyBlockTransferService: Server created on 37999
16/03/16 15:23:14 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 15:23:14 INFO BlockManagerMasterEndpoint: Registering block manager localhost:37999 with 1072.7 MB RAM, BlockManagerId(driver, localhost, 37999)
16/03/16 15:23:14 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): segment
16/03/16 15:23:14 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 15:23:14 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:23:14 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 15:23:14 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:23:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 15:23:14 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 15:23:14 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 15:23:14 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1124817960
16/03/16 15:23:14 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1072.7 MB)
16/03/16 15:23:14 INFO MemoryStore: ensureFreeSpace(4141) called with curMem=6568, maxMem=1124817960
16/03/16 15:23:14 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1072.7 MB)
16/03/16 15:23:14 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:37999 (size: 4.0 KB, free: 1072.7 MB)
16/03/16 15:23:14 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 15:23:14 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:23:14 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 15:23:14 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 15:23:14 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 15:23:14 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458121994130
16/03/16 15:23:14 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/userFiles-e9f157c8-a701-4986-bd1f-714eeb352240/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: area
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: issue
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: planning
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: permission
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: economy
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: composition
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: agency
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 15:23:22 INFO PythonRunner: Times: total = 8134, boot = 474, init = 367, finish = 7293
16/03/16 15:23:22 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 15:23:22 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 15:23:22 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 15:23:22 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8250 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: set
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: bend
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): adding to parents: syn =  Synset('bend.n.01') ; keyword:  segment  in syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= [u'bend']
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: giant
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: astatine
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: present
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: area
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): segment
mapFunction_Parents(): keyword: segment ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= segment ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
16/03/16 15:23:22 INFO PythonRunner: Times: total = 264, boot = 164, init = 1, finish = 99
16/03/16 15:23:22 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 15:23:22 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.539 s
16/03/16 15:23:22 INFO DAGScheduler: looking for newly runnable stages
16/03/16 15:23:22 INFO DAGScheduler: running: Set()
16/03/16 15:23:22 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 15:23:22 INFO DAGScheduler: failed: Set()
16/03/16 15:23:22 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 15:23:22 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 15:23:22 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10709, maxMem=1124817960
16/03/16 15:23:22 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1072.7 MB)
16/03/16 15:23:22 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15693, maxMem=1124817960
16/03/16 15:23:22 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1072.7 MB)
16/03/16 15:23:22 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 299 ms on localhost (2/2)
16/03/16 15:23:22 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 15:23:22 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:37999 (size: 3.0 KB, free: 1072.7 MB)
16/03/16 15:23:22 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 15:23:22 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:23:22 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 15:23:22 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 15:23:22 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 15:23:22 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 15:23:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 15:23:23 INFO PythonRunner: Times: total = 169, boot = 168, init = 1, finish = 0
16/03/16 15:23:23 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 15:23:23 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 15:23:23 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 15:23:23 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 15:23:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
16/03/16 15:23:23 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 200 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'bend']
16/03/16 15:23:23 INFO PythonRunner: Times: total = 177, boot = 177, init = 0, finish = 0
16/03/16 15:23:23 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1230 bytes result sent to driver
16/03/16 15:23:23 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.383 s
16/03/16 15:23:23 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.971506 s
16/03/16 15:23:23 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 205 ms on localhost (2/2)
16/03/16 15:23:23 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 15:23:23 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 15:23:23 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 15:23:23 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:23:23 INFO DAGScheduler: Parents of final stage: List()
16/03/16 15:23:23 INFO DAGScheduler: Missing parents: List()
16/03/16 15:23:23 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 15:23:23 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18741, maxMem=1124817960
16/03/16 15:23:23 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1072.7 MB)
16/03/16 15:23:23 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24557, maxMem=1124817960
16/03/16 15:23:23 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1072.7 MB)
16/03/16 15:23:23 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:37999 (size: 3.3 KB, free: 1072.7 MB)
16/03/16 15:23:23 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 15:23:23 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:23:23 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 15:23:23 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 15:23:23 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 15:23:23 INFO PythonRunner: Times: total = 72, boot = 71, init = 1, finish = 0
16/03/16 15:23:23 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 15:23:23 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2260 bytes)
16/03/16 15:23:23 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 108 ms on localhost (1/2)
16/03/16 15:23:23 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 15:23:23 INFO PythonRunner: Times: total = 167, boot = 166, init = 1, finish = 0
16/03/16 15:23:23 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1296 bytes result sent to driver
16/03/16 15:23:23 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 191 ms on localhost (2/2)
16/03/16 15:23:23 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.263 s
16/03/16 15:23:23 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 15:23:23 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.306414 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 15:23:23 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 15:23:23 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 15:23:23 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 15:23:23 INFO MemoryStore: MemoryStore cleared
16/03/16 15:23:23 INFO BlockManager: BlockManager stopped
16/03/16 15:23:23 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 15:23:23 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 15:23:23 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 15:23:23 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 15:23:23 INFO SparkContext: Successfully stopped SparkContext
16/03/16 15:23:23 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'bend']
16/03/16 15:23:24 INFO SparkContext: Running Spark version 1.5.2
16/03/16 15:23:24 INFO SecurityManager: Changing view acls to: root
16/03/16 15:23:24 INFO SecurityManager: Changing modify acls to: root
16/03/16 15:23:24 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 15:23:24 INFO Slf4jLogger: Slf4jLogger started
16/03/16 15:23:24 INFO Remoting: Starting remoting
16/03/16 15:23:24 INFO Utils: Successfully started service 'sparkDriver' on port 52936.
16/03/16 15:23:24 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:52936]
16/03/16 15:23:24 INFO SparkEnv: Registering MapOutputTracker
16/03/16 15:23:24 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 15:23:24 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-42801648-d156-43c7-b0b0-1d8ef31377a6
16/03/16 15:23:24 INFO MemoryStore: MemoryStore started with capacity 1072.7 MB
16/03/16 15:23:24 INFO HttpFileServer: HTTP File server directory is /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/httpd-4cd15688-082b-4287-8efb-47fad917a290
16/03/16 15:23:24 INFO HttpServer: Starting HTTP Server
16/03/16 15:23:24 INFO Utils: Successfully started service 'HTTP file server' on port 47179.
16/03/16 15:23:24 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 15:23:24 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 15:23:24 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 15:23:24 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/userFiles-398a96e2-cd13-470a-bb2b-0c1a527039dc/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 15:23:24 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458122004967
16/03/16 15:23:24 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 15:23:24 INFO Executor: Starting executor ID driver on host localhost
16/03/16 15:23:25 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43229.
16/03/16 15:23:25 INFO NettyBlockTransferService: Server created on 43229
16/03/16 15:23:25 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 15:23:25 INFO BlockManagerMasterEndpoint: Registering block manager localhost:43229 with 1072.7 MB RAM, BlockManagerId(driver, localhost, 43229)
16/03/16 15:23:25 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): radioactive
16/03/16 15:23:25 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 15:23:25 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:23:25 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 15:23:25 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:23:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 15:23:25 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 15:23:25 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 15:23:25 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1124817960
16/03/16 15:23:25 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1072.7 MB)
16/03/16 15:23:25 INFO MemoryStore: ensureFreeSpace(4139) called with curMem=6568, maxMem=1124817960
16/03/16 15:23:25 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1072.7 MB)
16/03/16 15:23:25 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:43229 (size: 4.0 KB, free: 1072.7 MB)
16/03/16 15:23:25 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 15:23:25 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:23:25 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 15:23:25 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 15:23:25 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 15:23:25 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458122004967
16/03/16 15:23:25 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/userFiles-398a96e2-cd13-470a-bb2b-0c1a527039dc/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: area
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: issue
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: planning
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: permission
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: economy
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: composition
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: agency
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 15:23:33 INFO PythonRunner: Times: total = 7782, boot = 480, init = 362, finish = 6940
16/03/16 15:23:33 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 15:23:33 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 15:23:33 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: set
16/03/16 15:23:33 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8301 ms on localhost (1/2)
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: bend
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: giant
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: astatine
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('astatine.n.01') ; keyword:  radioactive  in syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= [u'astatine']
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: present
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: area
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): radioactive
mapFunction_Parents(): keyword: radioactive ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= radioactive ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
16/03/16 15:23:33 INFO PythonRunner: Times: total = 141, boot = -164, init = 194, finish = 111
16/03/16 15:23:33 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 15:23:33 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 550 ms on localhost (2/2)
16/03/16 15:23:33 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 15:23:33 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.452 s
16/03/16 15:23:33 INFO DAGScheduler: looking for newly runnable stages
16/03/16 15:23:33 INFO DAGScheduler: running: Set()
16/03/16 15:23:33 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 15:23:33 INFO DAGScheduler: failed: Set()
16/03/16 15:23:33 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 15:23:33 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 15:23:33 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10707, maxMem=1124817960
16/03/16 15:23:33 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1072.7 MB)
16/03/16 15:23:33 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15691, maxMem=1124817960
16/03/16 15:23:33 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1072.7 MB)
16/03/16 15:23:33 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:43229 (size: 3.0 KB, free: 1072.7 MB)
16/03/16 15:23:33 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 15:23:33 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:23:33 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 15:23:33 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 15:23:33 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 15:23:33 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 15:23:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/16 15:23:33 INFO PythonRunner: Times: total = 139, boot = 138, init = 1, finish = 0
16/03/16 15:23:33 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 15:23:33 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 15:23:33 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 15:23:33 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 15:23:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
16/03/16 15:23:33 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 154 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'astatine']
16/03/16 15:23:34 INFO PythonRunner: Times: total = 185, boot = 185, init = 0, finish = 0
16/03/16 15:23:34 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1242 bytes result sent to driver
16/03/16 15:23:34 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.363 s
16/03/16 15:23:34 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.843126 s
16/03/16 15:23:34 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 212 ms on localhost (2/2)
16/03/16 15:23:34 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 15:23:34 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 15:23:34 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 15:23:34 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:23:34 INFO DAGScheduler: Parents of final stage: List()
16/03/16 15:23:34 INFO DAGScheduler: Missing parents: List()
16/03/16 15:23:34 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 15:23:34 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18739, maxMem=1124817960
16/03/16 15:23:34 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1072.7 MB)
16/03/16 15:23:34 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24555, maxMem=1124817960
16/03/16 15:23:34 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1072.7 MB)
16/03/16 15:23:34 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:43229 (size: 3.3 KB, free: 1072.7 MB)
16/03/16 15:23:34 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 15:23:34 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:23:34 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 15:23:34 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 15:23:34 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 15:23:34 INFO PythonRunner: Times: total = 122, boot = 122, init = 0, finish = 0
16/03/16 15:23:34 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 15:23:34 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2272 bytes)
16/03/16 15:23:34 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 137 ms on localhost (1/2)
16/03/16 15:23:34 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 15:23:34 INFO PythonRunner: Times: total = 196, boot = 196, init = 0, finish = 0
16/03/16 15:23:34 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1311 bytes result sent to driver
16/03/16 15:23:34 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 219 ms on localhost (2/2)
16/03/16 15:23:34 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 15:23:34 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.346 s
16/03/16 15:23:34 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.371765 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 15:23:34 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 15:23:34 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 15:23:34 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 15:23:34 INFO MemoryStore: MemoryStore cleared
16/03/16 15:23:34 INFO BlockManager: BlockManager stopped
16/03/16 15:23:34 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 15:23:34 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 15:23:34 INFO SparkContext: Successfully stopped SparkContext
16/03/16 15:23:34 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 15:23:34 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 15:23:34 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'astatine']
16/03/16 15:23:35 INFO SparkContext: Running Spark version 1.5.2
16/03/16 15:23:35 INFO SecurityManager: Changing view acls to: root
16/03/16 15:23:35 INFO SecurityManager: Changing modify acls to: root
16/03/16 15:23:35 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 15:23:35 INFO Slf4jLogger: Slf4jLogger started
16/03/16 15:23:35 INFO Remoting: Starting remoting
16/03/16 15:23:35 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:48608]
16/03/16 15:23:35 INFO Utils: Successfully started service 'sparkDriver' on port 48608.
16/03/16 15:23:35 INFO SparkEnv: Registering MapOutputTracker
16/03/16 15:23:35 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 15:23:35 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-cccd358c-2282-4198-953b-788fb1eac572
16/03/16 15:23:35 INFO MemoryStore: MemoryStore started with capacity 1072.7 MB
16/03/16 15:23:35 INFO HttpFileServer: HTTP File server directory is /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/httpd-f56c34d3-33c6-48a9-9433-eb9ae042b23a
16/03/16 15:23:35 INFO HttpServer: Starting HTTP Server
16/03/16 15:23:35 INFO Utils: Successfully started service 'HTTP file server' on port 52101.
16/03/16 15:23:35 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 15:23:35 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 15:23:35 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 15:23:35 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/userFiles-d474fe2e-6eca-4c88-a361-aa6116d92a3c/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 15:23:35 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458122015840
16/03/16 15:23:35 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 15:23:35 INFO Executor: Starting executor ID driver on host localhost
16/03/16 15:23:35 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36382.
16/03/16 15:23:35 INFO NettyBlockTransferService: Server created on 36382
16/03/16 15:23:35 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 15:23:35 INFO BlockManagerMasterEndpoint: Registering block manager localhost:36382 with 1072.7 MB RAM, BlockManagerId(driver, localhost, 36382)
16/03/16 15:23:35 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): happening
16/03/16 15:23:36 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 15:23:36 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:23:36 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 15:23:36 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:23:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 15:23:36 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 15:23:36 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 15:23:36 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1124817960
16/03/16 15:23:36 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1072.7 MB)
16/03/16 15:23:36 INFO MemoryStore: ensureFreeSpace(4141) called with curMem=6568, maxMem=1124817960
16/03/16 15:23:36 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1072.7 MB)
16/03/16 15:23:36 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:36382 (size: 4.0 KB, free: 1072.7 MB)
16/03/16 15:23:36 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 15:23:36 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:23:36 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 15:23:36 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 15:23:36 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 15:23:36 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458122015840
16/03/16 15:23:36 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/userFiles-d474fe2e-6eca-4c88-a361-aa6116d92a3c/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: area
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: issue
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: planning
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: permission
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: economy
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: composition
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: agency
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 15:23:43 INFO PythonRunner: Times: total = 7881, boot = 534, init = 352, finish = 6995
16/03/16 15:23:44 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 15:23:44 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 15:23:44 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 15:23:44 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8004 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: set
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: bend
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: giant
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: astatine
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: present
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('present.n.01') ; keyword:  happening  in syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= [u'present']
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: area
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): happening
mapFunction_Parents(): keyword: happening ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= happening ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
16/03/16 15:23:44 INFO PythonRunner: Times: total = 258, boot = 155, init = 0, finish = 103
16/03/16 15:23:44 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 15:23:44 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.281 s
16/03/16 15:23:44 INFO DAGScheduler: looking for newly runnable stages
16/03/16 15:23:44 INFO DAGScheduler: running: Set()
16/03/16 15:23:44 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 15:23:44 INFO DAGScheduler: failed: Set()
16/03/16 15:23:44 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 15:23:44 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 15:23:44 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10709, maxMem=1124817960
16/03/16 15:23:44 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1072.7 MB)
16/03/16 15:23:44 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 306 ms on localhost (2/2)
16/03/16 15:23:44 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 15:23:44 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15693, maxMem=1124817960
16/03/16 15:23:44 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1072.7 MB)
16/03/16 15:23:44 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:36382 (size: 3.0 KB, free: 1072.7 MB)
16/03/16 15:23:44 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 15:23:44 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:23:44 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 15:23:44 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 15:23:44 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 15:23:44 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 15:23:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 15:23:44 INFO PythonRunner: Times: total = 99, boot = 98, init = 0, finish = 1
16/03/16 15:23:44 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 15:23:44 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 15:23:44 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 15:23:44 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 15:23:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
16/03/16 15:23:44 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 129 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'present']
16/03/16 15:23:44 INFO PythonRunner: Times: total = 158, boot = 157, init = 1, finish = 0
16/03/16 15:23:44 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1241 bytes result sent to driver
16/03/16 15:23:44 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.318 s
16/03/16 15:23:44 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.664029 s
16/03/16 15:23:44 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 198 ms on localhost (2/2)
16/03/16 15:23:44 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 15:23:44 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 15:23:44 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 15:23:44 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:23:44 INFO DAGScheduler: Parents of final stage: List()
16/03/16 15:23:44 INFO DAGScheduler: Missing parents: List()
16/03/16 15:23:44 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 15:23:44 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18741, maxMem=1124817960
16/03/16 15:23:44 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1072.7 MB)
16/03/16 15:23:44 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24557, maxMem=1124817960
16/03/16 15:23:44 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1072.7 MB)
16/03/16 15:23:44 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:36382 (size: 3.3 KB, free: 1072.7 MB)
16/03/16 15:23:44 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 15:23:44 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:23:44 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 15:23:44 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 15:23:44 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 15:23:44 INFO PythonRunner: Times: total = 26, boot = 23, init = 3, finish = 0
16/03/16 15:23:44 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 15:23:44 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2271 bytes)
16/03/16 15:23:44 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 52 ms on localhost (1/2)
16/03/16 15:23:44 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 15:23:45 INFO PythonRunner: Times: total = 140, boot = 140, init = 0, finish = 0
16/03/16 15:23:45 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1310 bytes result sent to driver
16/03/16 15:23:45 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.232 s
16/03/16 15:23:45 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.278950 s
16/03/16 15:23:45 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 197 ms on localhost (2/2)
16/03/16 15:23:45 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 15:23:45 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 15:23:45 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 15:23:45 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 15:23:45 INFO MemoryStore: MemoryStore cleared
16/03/16 15:23:45 INFO BlockManager: BlockManager stopped
16/03/16 15:23:45 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 15:23:45 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 15:23:45 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 15:23:45 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 15:23:45 INFO SparkContext: Successfully stopped SparkContext
16/03/16 15:23:45 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'present']
16/03/16 15:23:46 INFO SparkContext: Running Spark version 1.5.2
16/03/16 15:23:46 INFO SecurityManager: Changing view acls to: root
16/03/16 15:23:46 INFO SecurityManager: Changing modify acls to: root
16/03/16 15:23:46 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 15:23:46 INFO Slf4jLogger: Slf4jLogger started
16/03/16 15:23:46 INFO Remoting: Starting remoting
16/03/16 15:23:46 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:48142]
16/03/16 15:23:46 INFO Utils: Successfully started service 'sparkDriver' on port 48142.
16/03/16 15:23:46 INFO SparkEnv: Registering MapOutputTracker
16/03/16 15:23:46 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 15:23:46 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-bb1477fb-95a1-4dd8-82c4-72d4b2fca558
16/03/16 15:23:46 INFO MemoryStore: MemoryStore started with capacity 1072.7 MB
16/03/16 15:23:46 INFO HttpFileServer: HTTP File server directory is /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/httpd-5f7b164b-2ea6-49db-a0ca-e7a2bbb08cda
16/03/16 15:23:46 INFO HttpServer: Starting HTTP Server
16/03/16 15:23:46 INFO Utils: Successfully started service 'HTTP file server' on port 46922.
16/03/16 15:23:46 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 15:23:46 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 15:23:46 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 15:23:46 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/userFiles-7a115a14-5ab7-4559-8dcd-6fd64d7c31e0/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 15:23:46 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458122026383
16/03/16 15:23:46 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 15:23:46 INFO Executor: Starting executor ID driver on host localhost
16/03/16 15:23:46 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53929.
16/03/16 15:23:46 INFO NettyBlockTransferService: Server created on 53929
16/03/16 15:23:46 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 15:23:46 INFO BlockManagerMasterEndpoint: Registering block manager localhost:53929 with 1072.7 MB RAM, BlockManagerId(driver, localhost, 53929)
16/03/16 15:23:46 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): curve
16/03/16 15:23:46 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 15:23:46 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:23:46 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 15:23:46 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:23:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 15:23:46 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 15:23:46 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 15:23:46 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1124817960
16/03/16 15:23:46 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1072.7 MB)
16/03/16 15:23:46 INFO MemoryStore: ensureFreeSpace(4141) called with curMem=6568, maxMem=1124817960
16/03/16 15:23:46 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1072.7 MB)
16/03/16 15:23:46 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:53929 (size: 4.0 KB, free: 1072.7 MB)
16/03/16 15:23:46 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 15:23:46 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:23:46 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 15:23:46 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 15:23:46 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 15:23:46 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458122026383
16/03/16 15:23:46 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/userFiles-7a115a14-5ab7-4559-8dcd-6fd64d7c31e0/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: area
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: issue
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: planning
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: permission
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: economy
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: composition
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: agency
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 15:23:54 INFO PythonRunner: Times: total = 8194, boot = 470, init = 359, finish = 7365
16/03/16 15:23:54 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 15:23:54 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 15:23:54 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 15:23:54 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8301 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: set
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: bend
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): adding to parents: syn =  Synset('bend.n.01') ; keyword:  curve  in syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= [u'bend']
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: giant
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: astatine
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: present
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: area
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'bend']
16/03/16 15:23:55 INFO PythonRunner: Times: total = 263, boot = 163, init = 1, finish = 99
16/03/16 15:23:55 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 15:23:55 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.588 s
16/03/16 15:23:55 INFO DAGScheduler: looking for newly runnable stages
16/03/16 15:23:55 INFO DAGScheduler: running: Set()
16/03/16 15:23:55 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 15:23:55 INFO DAGScheduler: failed: Set()
16/03/16 15:23:55 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 15:23:55 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 15:23:55 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10709, maxMem=1124817960
16/03/16 15:23:55 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1072.7 MB)
16/03/16 15:23:55 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 308 ms on localhost (2/2)
16/03/16 15:23:55 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 15:23:55 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15693, maxMem=1124817960
16/03/16 15:23:55 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1072.7 MB)
16/03/16 15:23:55 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:53929 (size: 3.0 KB, free: 1072.7 MB)
16/03/16 15:23:55 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 15:23:55 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:23:55 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 15:23:55 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 15:23:55 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 15:23:55 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 15:23:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/16 15:23:55 INFO PythonRunner: Times: total = 148, boot = 148, init = 0, finish = 0
16/03/16 15:23:55 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 15:23:55 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 15:23:55 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 15:23:55 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 15:23:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/16 15:23:55 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 177 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'bend']
16/03/16 15:23:55 INFO PythonRunner: Times: total = 205, boot = 202, init = 0, finish = 3
16/03/16 15:23:55 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1230 bytes result sent to driver
16/03/16 15:23:55 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.396 s
16/03/16 15:23:55 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.028019 s
16/03/16 15:23:55 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 231 ms on localhost (2/2)
16/03/16 15:23:55 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 15:23:55 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 15:23:55 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 15:23:55 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:23:55 INFO DAGScheduler: Parents of final stage: List()
16/03/16 15:23:55 INFO DAGScheduler: Missing parents: List()
16/03/16 15:23:55 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 15:23:55 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18741, maxMem=1124817960
16/03/16 15:23:55 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1072.7 MB)
16/03/16 15:23:55 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24557, maxMem=1124817960
16/03/16 15:23:55 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1072.7 MB)
16/03/16 15:23:55 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:53929 (size: 3.3 KB, free: 1072.7 MB)
16/03/16 15:23:55 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 15:23:55 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:23:55 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 15:23:55 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 15:23:55 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 15:23:55 INFO PythonRunner: Times: total = 218, boot = 218, init = 0, finish = 0
16/03/16 15:23:55 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 15:23:55 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2260 bytes)
16/03/16 15:23:55 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 237 ms on localhost (1/2)
16/03/16 15:23:55 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 15:23:56 INFO PythonRunner: Times: total = 176, boot = 176, init = 0, finish = 0
16/03/16 15:23:56 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1296 bytes result sent to driver
16/03/16 15:23:56 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 198 ms on localhost (2/2)
16/03/16 15:23:56 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 15:23:56 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.422 s
16/03/16 15:23:56 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.442119 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 15:23:56 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 15:23:56 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 15:23:56 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 15:23:56 INFO MemoryStore: MemoryStore cleared
16/03/16 15:23:56 INFO BlockManager: BlockManager stopped
16/03/16 15:23:56 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 15:23:56 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 15:23:56 INFO SparkContext: Successfully stopped SparkContext
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'bend']
16/03/16 15:23:57 INFO SparkContext: Running Spark version 1.5.2
16/03/16 15:23:57 INFO SecurityManager: Changing view acls to: root
16/03/16 15:23:57 INFO SecurityManager: Changing modify acls to: root
16/03/16 15:23:57 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 15:23:57 INFO Slf4jLogger: Slf4jLogger started
16/03/16 15:23:57 INFO Remoting: Starting remoting
16/03/16 15:23:57 INFO Utils: Successfully started service 'sparkDriver' on port 39135.
16/03/16 15:23:57 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:39135]
16/03/16 15:23:57 INFO SparkEnv: Registering MapOutputTracker
16/03/16 15:23:57 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 15:23:57 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-fc62361e-29c9-457d-a2ae-06299a96c469
16/03/16 15:23:57 INFO MemoryStore: MemoryStore started with capacity 1072.7 MB
16/03/16 15:23:57 INFO HttpFileServer: HTTP File server directory is /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/httpd-e191d198-3789-4249-9745-fe1bd63dd677
16/03/16 15:23:57 INFO HttpServer: Starting HTTP Server
16/03/16 15:23:57 INFO Utils: Successfully started service 'HTTP file server' on port 41649.
16/03/16 15:23:57 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 15:23:57 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 15:23:57 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 15:23:57 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/userFiles-3280c3ab-e012-43e3-aecb-357a347ab947/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 15:23:57 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458122037401
16/03/16 15:23:57 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 15:23:57 INFO Executor: Starting executor ID driver on host localhost
16/03/16 15:23:57 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56550.
16/03/16 15:23:57 INFO NettyBlockTransferService: Server created on 56550
16/03/16 15:23:57 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 15:23:57 INFO BlockManagerMasterEndpoint: Registering block manager localhost:56550 with 1072.7 MB RAM, BlockManagerId(driver, localhost, 56550)
16/03/16 15:23:57 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): together
16/03/16 15:23:57 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 15:23:57 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:23:57 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 15:23:57 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:23:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 15:23:57 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 15:23:57 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 15:23:57 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1124817960
16/03/16 15:23:57 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1072.7 MB)
16/03/16 15:23:57 INFO MemoryStore: ensureFreeSpace(4141) called with curMem=6568, maxMem=1124817960
16/03/16 15:23:57 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1072.7 MB)
16/03/16 15:23:57 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:56550 (size: 4.0 KB, free: 1072.7 MB)
16/03/16 15:23:57 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 15:23:57 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:23:57 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 15:23:57 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 15:23:57 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 15:23:57 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458122037401
16/03/16 15:23:57 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/userFiles-3280c3ab-e012-43e3-aecb-357a347ab947/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: area
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: issue
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: planning
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: permission
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: economy
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: composition
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: agency
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 15:24:06 INFO PythonRunner: Times: total = 8502, boot = 474, init = 350, finish = 7678
16/03/16 15:24:06 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 15:24:06 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 15:24:06 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 15:24:06 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8589 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: set
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): adding to parents: syn =  Synset('set.n.01') ; keyword:  together  in syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: bend
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: giant
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: astatine
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: present
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: area
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'set']
16/03/16 15:24:06 INFO PythonRunner: Times: total = 377, boot = 235, init = 1, finish = 141
16/03/16 15:24:06 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 15:24:06 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 9.033 s
16/03/16 15:24:06 INFO DAGScheduler: looking for newly runnable stages
16/03/16 15:24:06 INFO DAGScheduler: running: Set()
16/03/16 15:24:06 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 15:24:06 INFO DAGScheduler: failed: Set()
16/03/16 15:24:06 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 15:24:06 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 15:24:06 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 456 ms on localhost (2/2)
16/03/16 15:24:06 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 15:24:06 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10709, maxMem=1124817960
16/03/16 15:24:06 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1072.7 MB)
16/03/16 15:24:06 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15693, maxMem=1124817960
16/03/16 15:24:06 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1072.7 MB)
16/03/16 15:24:06 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:56550 (size: 3.0 KB, free: 1072.7 MB)
16/03/16 15:24:06 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 15:24:06 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:24:06 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 15:24:06 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 15:24:06 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 15:24:06 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 15:24:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/16 15:24:06 INFO PythonRunner: Times: total = 197, boot = 196, init = 0, finish = 1
16/03/16 15:24:06 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 15:24:06 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 15:24:06 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 15:24:06 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 15:24:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
16/03/16 15:24:06 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 248 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'set']
16/03/16 15:24:07 INFO PythonRunner: Times: total = 240, boot = 239, init = 0, finish = 1
16/03/16 15:24:07 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1229 bytes result sent to driver
16/03/16 15:24:07 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 271 ms on localhost (2/2)
16/03/16 15:24:07 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.481 s
16/03/16 15:24:07 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 15:24:07 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.557984 s
16/03/16 15:24:07 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 15:24:07 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 15:24:07 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:24:07 INFO DAGScheduler: Parents of final stage: List()
16/03/16 15:24:07 INFO DAGScheduler: Missing parents: List()
16/03/16 15:24:07 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 15:24:07 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18741, maxMem=1124817960
16/03/16 15:24:07 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1072.7 MB)
16/03/16 15:24:07 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24557, maxMem=1124817960
16/03/16 15:24:07 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1072.7 MB)
16/03/16 15:24:07 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:56550 (size: 3.3 KB, free: 1072.7 MB)
16/03/16 15:24:07 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 15:24:07 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:24:07 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 15:24:07 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 15:24:07 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 15:24:07 INFO PythonRunner: Times: total = 134, boot = 134, init = 0, finish = 0
16/03/16 15:24:07 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 15:24:07 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2259 bytes)
16/03/16 15:24:07 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 152 ms on localhost (1/2)
16/03/16 15:24:07 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 15:24:07 INFO PythonRunner: Times: total = 216, boot = 215, init = 1, finish = 0
16/03/16 15:24:07 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1295 bytes result sent to driver
16/03/16 15:24:07 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 257 ms on localhost (2/2)
16/03/16 15:24:07 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 15:24:07 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.402 s
16/03/16 15:24:07 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.424962 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 15:24:07 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 15:24:07 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 15:24:07 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 15:24:07 INFO MemoryStore: MemoryStore cleared
16/03/16 15:24:07 INFO BlockManager: BlockManager stopped
16/03/16 15:24:07 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 15:24:07 INFO SparkContext: Successfully stopped SparkContext
16/03/16 15:24:07 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 15:24:07 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 15:24:07 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 15:24:07 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'set']
16/03/16 15:24:08 INFO SparkContext: Running Spark version 1.5.2
16/03/16 15:24:08 INFO SecurityManager: Changing view acls to: root
16/03/16 15:24:08 INFO SecurityManager: Changing modify acls to: root
16/03/16 15:24:08 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 15:24:08 INFO Slf4jLogger: Slf4jLogger started
16/03/16 15:24:08 INFO Remoting: Starting remoting
16/03/16 15:24:08 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:32890]
16/03/16 15:24:08 INFO Utils: Successfully started service 'sparkDriver' on port 32890.
16/03/16 15:24:08 INFO SparkEnv: Registering MapOutputTracker
16/03/16 15:24:08 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 15:24:08 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-f9154f5f-d898-4d22-befb-07a2984401a1
16/03/16 15:24:08 INFO MemoryStore: MemoryStore started with capacity 1072.7 MB
16/03/16 15:24:09 INFO HttpFileServer: HTTP File server directory is /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/httpd-4a73d868-1ffc-4ffd-a388-b50c0d9ca9ce
16/03/16 15:24:09 INFO HttpServer: Starting HTTP Server
16/03/16 15:24:09 INFO Utils: Successfully started service 'HTTP file server' on port 50321.
16/03/16 15:24:09 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 15:24:09 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 15:24:09 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 15:24:09 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/userFiles-6801c334-35cd-4c7b-911a-ae02a5092b77/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 15:24:09 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458122049204
16/03/16 15:24:09 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 15:24:09 INFO Executor: Starting executor ID driver on host localhost
16/03/16 15:24:09 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51720.
16/03/16 15:24:09 INFO NettyBlockTransferService: Server created on 51720
16/03/16 15:24:09 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 15:24:09 INFO BlockManagerMasterEndpoint: Registering block manager localhost:51720 with 1072.7 MB RAM, BlockManagerId(driver, localhost, 51720)
16/03/16 15:24:09 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): element
16/03/16 15:24:09 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 15:24:09 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:24:09 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 15:24:09 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:24:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 15:24:09 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 15:24:09 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 15:24:09 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1124817960
16/03/16 15:24:09 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1072.7 MB)
16/03/16 15:24:09 INFO MemoryStore: ensureFreeSpace(4141) called with curMem=6568, maxMem=1124817960
16/03/16 15:24:09 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1072.7 MB)
16/03/16 15:24:09 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:51720 (size: 4.0 KB, free: 1072.7 MB)
16/03/16 15:24:09 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 15:24:09 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:24:09 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 15:24:09 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 15:24:09 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 15:24:09 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458122049204
16/03/16 15:24:09 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/userFiles-6801c334-35cd-4c7b-911a-ae02a5092b77/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: area
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: issue
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: planning
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: permission
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: economy
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: composition
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: agency
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 15:24:18 INFO PythonRunner: Times: total = 8508, boot = 599, init = 499, finish = 7410
16/03/16 15:24:18 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 15:24:18 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 15:24:18 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 15:24:18 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8646 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: set
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: bend
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: giant
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: astatine
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('astatine.n.01') ; keyword:  element  in syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= [u'astatine']
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: present
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: area
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
16/03/16 15:24:18 INFO PythonRunner: Times: total = 331, boot = 216, init = 1, finish = 114
16/03/16 15:24:18 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 15:24:18 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.995 s
16/03/16 15:24:18 INFO DAGScheduler: looking for newly runnable stages
16/03/16 15:24:18 INFO DAGScheduler: running: Set()
16/03/16 15:24:18 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 15:24:18 INFO DAGScheduler: failed: Set()
16/03/16 15:24:18 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 15:24:18 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 15:24:18 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10709, maxMem=1124817960
16/03/16 15:24:18 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1072.7 MB)
16/03/16 15:24:18 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 370 ms on localhost (2/2)
16/03/16 15:24:18 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 15:24:18 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15693, maxMem=1124817960
16/03/16 15:24:18 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1072.7 MB)
16/03/16 15:24:18 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:51720 (size: 3.0 KB, free: 1072.7 MB)
16/03/16 15:24:18 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 15:24:18 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:24:18 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 15:24:18 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 15:24:18 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 15:24:18 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 15:24:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/16 15:24:18 INFO PythonRunner: Times: total = 206, boot = 205, init = 0, finish = 1
16/03/16 15:24:18 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 15:24:18 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 15:24:18 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 15:24:18 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 233 ms on localhost (1/2)
16/03/16 15:24:18 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 15:24:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
reduceFunction_Parents(): returns= ['None', 'None', u'astatine']
16/03/16 15:24:18 INFO PythonRunner: Times: total = 177, boot = 176, init = 0, finish = 1
16/03/16 15:24:18 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1242 bytes result sent to driver
16/03/16 15:24:18 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 222 ms on localhost (2/2)
16/03/16 15:24:18 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 15:24:18 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.449 s
16/03/16 15:24:18 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.499961 s
16/03/16 15:24:19 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 15:24:19 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 15:24:19 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:24:19 INFO DAGScheduler: Parents of final stage: List()
16/03/16 15:24:19 INFO DAGScheduler: Missing parents: List()
16/03/16 15:24:19 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 15:24:19 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18741, maxMem=1124817960
16/03/16 15:24:19 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1072.7 MB)
16/03/16 15:24:19 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24557, maxMem=1124817960
16/03/16 15:24:19 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1072.7 MB)
16/03/16 15:24:19 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:51720 (size: 3.3 KB, free: 1072.7 MB)
16/03/16 15:24:19 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 15:24:19 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:24:19 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 15:24:19 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 15:24:19 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 15:24:19 INFO PythonRunner: Times: total = 83, boot = 82, init = 1, finish = 0
16/03/16 15:24:19 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 15:24:19 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2272 bytes)
16/03/16 15:24:19 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 110 ms on localhost (1/2)
16/03/16 15:24:19 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 15:24:19 INFO PythonRunner: Times: total = 276, boot = 276, init = 0, finish = 0
16/03/16 15:24:19 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1311 bytes result sent to driver
16/03/16 15:24:19 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 312 ms on localhost (2/2)
16/03/16 15:24:19 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.402 s
16/03/16 15:24:19 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 15:24:19 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.433937 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 15:24:19 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 15:24:19 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 15:24:19 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 15:24:19 INFO MemoryStore: MemoryStore cleared
16/03/16 15:24:19 INFO BlockManager: BlockManager stopped
16/03/16 15:24:19 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 15:24:19 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 15:24:19 INFO SparkContext: Successfully stopped SparkContext
16/03/16 15:24:19 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 15:24:19 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 15:24:19 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'astatine']
16/03/16 15:24:20 INFO SparkContext: Running Spark version 1.5.2
16/03/16 15:24:20 INFO SecurityManager: Changing view acls to: root
16/03/16 15:24:20 INFO SecurityManager: Changing modify acls to: root
16/03/16 15:24:20 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 15:24:20 INFO Slf4jLogger: Slf4jLogger started
16/03/16 15:24:20 INFO Remoting: Starting remoting
16/03/16 15:24:20 INFO Utils: Successfully started service 'sparkDriver' on port 33036.
16/03/16 15:24:20 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:33036]
16/03/16 15:24:20 INFO SparkEnv: Registering MapOutputTracker
16/03/16 15:24:20 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 15:24:20 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-cb989ba8-fc93-469e-b44b-395dc53e540c
16/03/16 15:24:20 INFO MemoryStore: MemoryStore started with capacity 1072.7 MB
16/03/16 15:24:20 INFO HttpFileServer: HTTP File server directory is /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/httpd-1afaa28a-8d92-4466-a4ce-9ab006a07a42
16/03/16 15:24:20 INFO HttpServer: Starting HTTP Server
16/03/16 15:24:20 INFO Utils: Successfully started service 'HTTP file server' on port 44053.
16/03/16 15:24:20 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 15:24:20 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 15:24:20 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 15:24:20 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/userFiles-ab16da12-7dd9-41c7-8f6a-a5e1230fffdf/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 15:24:20 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458122060942
16/03/16 15:24:20 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 15:24:20 INFO Executor: Starting executor ID driver on host localhost
16/03/16 15:24:21 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50253.
16/03/16 15:24:21 INFO NettyBlockTransferService: Server created on 50253
16/03/16 15:24:21 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 15:24:21 INFO BlockManagerMasterEndpoint: Registering block manager localhost:50253 with 1072.7 MB RAM, BlockManagerId(driver, localhost, 50253)
16/03/16 15:24:21 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): person
16/03/16 15:24:21 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 15:24:21 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:24:21 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 15:24:21 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:24:21 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 15:24:21 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 15:24:21 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 15:24:21 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1124817960
16/03/16 15:24:21 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1072.7 MB)
16/03/16 15:24:21 INFO MemoryStore: ensureFreeSpace(4141) called with curMem=6568, maxMem=1124817960
16/03/16 15:24:21 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1072.7 MB)
16/03/16 15:24:21 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:50253 (size: 4.0 KB, free: 1072.7 MB)
16/03/16 15:24:21 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 15:24:21 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:24:21 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 15:24:21 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 15:24:21 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 15:24:21 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458122060942
16/03/16 15:24:21 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/userFiles-ab16da12-7dd9-41c7-8f6a-a5e1230fffdf/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: area
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: issue
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: planning
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: permission
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: economy
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: composition
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: agency
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 15:24:29 INFO PythonRunner: Times: total = 8384, boot = 527, init = 425, finish = 7432
16/03/16 15:24:29 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 15:24:29 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 15:24:29 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 15:24:29 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8493 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: set
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: bend
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: giant
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): adding to parents: syn =  Synset('colossus.n.02') ; keyword:  person  in syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= [u'giant']
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: astatine
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: present
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: area
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
16/03/16 15:24:30 INFO PythonRunner: Times: total = 365, boot = 256, init = 0, finish = 109
16/03/16 15:24:30 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 15:24:30 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.931 s
16/03/16 15:24:30 INFO DAGScheduler: looking for newly runnable stages
16/03/16 15:24:30 INFO DAGScheduler: running: Set()
16/03/16 15:24:30 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 15:24:30 INFO DAGScheduler: failed: Set()
16/03/16 15:24:30 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 15:24:30 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 15:24:30 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10709, maxMem=1124817960
16/03/16 15:24:30 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1072.7 MB)
16/03/16 15:24:30 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 446 ms on localhost (2/2)
16/03/16 15:24:30 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 15:24:30 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15693, maxMem=1124817960
16/03/16 15:24:30 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1072.7 MB)
16/03/16 15:24:30 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:50253 (size: 3.0 KB, free: 1072.7 MB)
16/03/16 15:24:30 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 15:24:30 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:24:30 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 15:24:30 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 15:24:30 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 15:24:30 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 15:24:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 15:24:30 INFO PythonRunner: Times: total = 134, boot = 134, init = 0, finish = 0
16/03/16 15:24:30 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 15:24:30 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 15:24:30 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 15:24:30 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 15:24:30 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 159 ms on localhost (1/2)
16/03/16 15:24:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
reduceFunction_Parents(): returns= ['None', 'None', u'giant']
16/03/16 15:24:30 INFO PythonRunner: Times: total = 177, boot = 176, init = 1, finish = 0
16/03/16 15:24:30 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1239 bytes result sent to driver
16/03/16 15:24:30 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 211 ms on localhost (2/2)
16/03/16 15:24:30 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 15:24:30 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.369 s
16/03/16 15:24:30 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.341112 s
16/03/16 15:24:30 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 15:24:30 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 15:24:30 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:24:30 INFO DAGScheduler: Parents of final stage: List()
16/03/16 15:24:30 INFO DAGScheduler: Missing parents: List()
16/03/16 15:24:30 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 15:24:30 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18741, maxMem=1124817960
16/03/16 15:24:30 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1072.7 MB)
16/03/16 15:24:30 INFO MemoryStore: ensureFreeSpace(3374) called with curMem=24557, maxMem=1124817960
16/03/16 15:24:30 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1072.7 MB)
16/03/16 15:24:30 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:50253 (size: 3.3 KB, free: 1072.7 MB)
16/03/16 15:24:30 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 15:24:30 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:24:30 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 15:24:30 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 15:24:30 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 15:24:30 INFO PythonRunner: Times: total = 12, boot = -29, init = 41, finish = 0
16/03/16 15:24:30 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 15:24:30 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2269 bytes)
16/03/16 15:24:30 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 15:24:30 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 70 ms on localhost (1/2)
16/03/16 15:24:30 INFO PythonRunner: Times: total = 201, boot = 201, init = 0, finish = 0
16/03/16 15:24:30 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1308 bytes result sent to driver
16/03/16 15:24:30 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 223 ms on localhost (2/2)
16/03/16 15:24:30 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 15:24:30 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.276 s
16/03/16 15:24:30 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.310352 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 15:24:31 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 15:24:31 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 15:24:31 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 15:24:31 INFO MemoryStore: MemoryStore cleared
16/03/16 15:24:31 INFO BlockManager: BlockManager stopped
16/03/16 15:24:31 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 15:24:31 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 15:24:31 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 15:24:31 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 15:24:31 INFO SparkContext: Successfully stopped SparkContext
16/03/16 15:24:31 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'giant']
16/03/16 15:24:32 INFO SparkContext: Running Spark version 1.5.2
16/03/16 15:24:32 INFO SecurityManager: Changing view acls to: root
16/03/16 15:24:32 INFO SecurityManager: Changing modify acls to: root
16/03/16 15:24:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 15:24:32 INFO Slf4jLogger: Slf4jLogger started
16/03/16 15:24:32 INFO Remoting: Starting remoting
16/03/16 15:24:32 INFO Utils: Successfully started service 'sparkDriver' on port 52819.
16/03/16 15:24:32 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:52819]
16/03/16 15:24:32 INFO SparkEnv: Registering MapOutputTracker
16/03/16 15:24:32 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 15:24:32 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-2ddd6684-4c4d-40fd-846e-b085655d921a
16/03/16 15:24:32 INFO MemoryStore: MemoryStore started with capacity 1072.7 MB
16/03/16 15:24:32 INFO HttpFileServer: HTTP File server directory is /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/httpd-263ddd03-5228-45a1-b56c-dd2f402be039
16/03/16 15:24:32 INFO HttpServer: Starting HTTP Server
16/03/16 15:24:32 INFO Utils: Successfully started service 'HTTP file server' on port 51383.
16/03/16 15:24:32 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 15:24:32 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 15:24:32 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 15:24:32 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/userFiles-2387d77f-b797-49fb-94d1-632ce8ca4063/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 15:24:32 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458122072867
16/03/16 15:24:32 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 15:24:32 INFO Executor: Starting executor ID driver on host localhost
16/03/16 15:24:32 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37141.
16/03/16 15:24:32 INFO NettyBlockTransferService: Server created on 37141
16/03/16 15:24:32 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 15:24:32 INFO BlockManagerMasterEndpoint: Registering block manager localhost:37141 with 1072.7 MB RAM, BlockManagerId(driver, localhost, 37141)
16/03/16 15:24:32 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): reputation
16/03/16 15:24:33 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 15:24:33 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:24:33 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 15:24:33 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:24:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 15:24:33 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 15:24:33 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 15:24:33 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1124817960
16/03/16 15:24:33 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1072.7 MB)
16/03/16 15:24:33 INFO MemoryStore: ensureFreeSpace(4141) called with curMem=6568, maxMem=1124817960
16/03/16 15:24:33 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1072.7 MB)
16/03/16 15:24:33 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:37141 (size: 4.0 KB, free: 1072.7 MB)
16/03/16 15:24:33 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 15:24:33 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:24:33 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 15:24:33 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 15:24:33 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 15:24:33 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458122072867
16/03/16 15:24:33 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/userFiles-2387d77f-b797-49fb-94d1-632ce8ca4063/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: area
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: issue
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: planning
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: permission
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: economy
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: composition
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: agency
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 15:24:42 INFO PythonRunner: Times: total = 9074, boot = 655, init = 455, finish = 7964
16/03/16 15:24:42 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 15:24:42 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 15:24:42 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 15:24:42 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9173 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: set
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: bend
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: giant
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): adding to parents: syn =  Synset('colossus.n.02') ; keyword:  reputation  in syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= [u'giant']
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: astatine
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: present
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: area
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
16/03/16 15:24:42 INFO PythonRunner: Times: total = 401, boot = 239, init = 0, finish = 162
16/03/16 15:24:42 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 15:24:42 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 9.607 s
16/03/16 15:24:42 INFO DAGScheduler: looking for newly runnable stages
16/03/16 15:24:42 INFO DAGScheduler: running: Set()
16/03/16 15:24:42 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 15:24:42 INFO DAGScheduler: failed: Set()
16/03/16 15:24:42 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 15:24:42 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 15:24:42 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10709, maxMem=1124817960
16/03/16 15:24:42 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1072.7 MB)
16/03/16 15:24:42 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15693, maxMem=1124817960
16/03/16 15:24:42 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1072.7 MB)
16/03/16 15:24:42 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 443 ms on localhost (2/2)
16/03/16 15:24:42 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 15:24:42 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:37141 (size: 3.0 KB, free: 1072.7 MB)
16/03/16 15:24:42 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 15:24:42 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:24:42 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 15:24:42 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 15:24:42 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 15:24:42 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 15:24:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 15:24:42 INFO PythonRunner: Times: total = 229, boot = 229, init = 0, finish = 0
16/03/16 15:24:42 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 15:24:43 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 15:24:43 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 15:24:43 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 15:24:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/16 15:24:43 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 274 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'giant']
16/03/16 15:24:43 INFO PythonRunner: Times: total = 241, boot = 240, init = 0, finish = 1
16/03/16 15:24:43 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1239 bytes result sent to driver
16/03/16 15:24:43 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.530 s
16/03/16 15:24:43 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 277 ms on localhost (2/2)
16/03/16 15:24:43 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 15:24:43 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 10.185919 s
16/03/16 15:24:43 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 15:24:43 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 15:24:43 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:24:43 INFO DAGScheduler: Parents of final stage: List()
16/03/16 15:24:43 INFO DAGScheduler: Missing parents: List()
16/03/16 15:24:43 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 15:24:43 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18741, maxMem=1124817960
16/03/16 15:24:43 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1072.7 MB)
16/03/16 15:24:43 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24557, maxMem=1124817960
16/03/16 15:24:43 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1072.7 MB)
16/03/16 15:24:43 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:37141 (size: 3.3 KB, free: 1072.7 MB)
16/03/16 15:24:43 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 15:24:43 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:24:43 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 15:24:43 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 15:24:43 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 15:24:43 INFO PythonRunner: Times: total = 34, boot = 33, init = 0, finish = 1
16/03/16 15:24:43 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 15:24:43 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2269 bytes)
16/03/16 15:24:43 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 74 ms on localhost (1/2)
16/03/16 15:24:43 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 15:24:43 INFO PythonRunner: Times: total = 208, boot = 208, init = 0, finish = 0
16/03/16 15:24:43 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1308 bytes result sent to driver
16/03/16 15:24:43 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 257 ms on localhost (2/2)
16/03/16 15:24:43 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.317 s
16/03/16 15:24:43 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.364420 s
16/03/16 15:24:43 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 15:24:43 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 15:24:43 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 15:24:44 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 15:24:44 INFO MemoryStore: MemoryStore cleared
16/03/16 15:24:44 INFO BlockManager: BlockManager stopped
16/03/16 15:24:44 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 15:24:44 INFO SparkContext: Successfully stopped SparkContext
16/03/16 15:24:44 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 15:24:44 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 15:24:44 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 15:24:44 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'giant']
16/03/16 15:24:44 INFO SparkContext: Running Spark version 1.5.2
16/03/16 15:24:44 INFO SecurityManager: Changing view acls to: root
16/03/16 15:24:44 INFO SecurityManager: Changing modify acls to: root
16/03/16 15:24:44 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 15:24:45 INFO Slf4jLogger: Slf4jLogger started
16/03/16 15:24:45 INFO Remoting: Starting remoting
16/03/16 15:24:45 INFO Utils: Successfully started service 'sparkDriver' on port 45696.
16/03/16 15:24:45 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:45696]
16/03/16 15:24:45 INFO SparkEnv: Registering MapOutputTracker
16/03/16 15:24:45 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 15:24:45 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-8554fef9-2830-47b9-a64f-01ffc8c189b1
16/03/16 15:24:45 INFO MemoryStore: MemoryStore started with capacity 1073.4 MB
16/03/16 15:24:45 INFO HttpFileServer: HTTP File server directory is /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/httpd-b565ca2d-8512-4bb5-88d2-92b0a67afe1f
16/03/16 15:24:45 INFO HttpServer: Starting HTTP Server
16/03/16 15:24:45 INFO Utils: Successfully started service 'HTTP file server' on port 53900.
16/03/16 15:24:45 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 15:24:45 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 15:24:45 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 15:24:45 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/userFiles-0e7c15f8-7e90-40ba-8cd9-858bc8e8ae37/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 15:24:45 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458122085410
16/03/16 15:24:45 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 15:24:45 INFO Executor: Starting executor ID driver on host localhost
16/03/16 15:24:45 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42458.
16/03/16 15:24:45 INFO NettyBlockTransferService: Server created on 42458
16/03/16 15:24:45 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 15:24:45 INFO BlockManagerMasterEndpoint: Registering block manager localhost:42458 with 1073.4 MB RAM, BlockManagerId(driver, localhost, 42458)
16/03/16 15:24:45 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): time
16/03/16 15:24:45 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 15:24:45 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:24:45 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 15:24:45 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:24:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 15:24:45 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 15:24:45 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 15:24:45 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1125525749
16/03/16 15:24:45 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1073.4 MB)
16/03/16 15:24:45 INFO MemoryStore: ensureFreeSpace(4141) called with curMem=6568, maxMem=1125525749
16/03/16 15:24:45 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1073.4 MB)
16/03/16 15:24:45 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:42458 (size: 4.0 KB, free: 1073.4 MB)
16/03/16 15:24:45 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 15:24:45 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:24:45 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 15:24:45 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 15:24:45 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 15:24:45 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458122085410
16/03/16 15:24:45 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/userFiles-0e7c15f8-7e90-40ba-8cd9-858bc8e8ae37/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: area
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: issue
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: planning
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: permission
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: economy
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: composition
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: agency
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 15:24:55 INFO PythonRunner: Times: total = 10056, boot = 593, init = 432, finish = 9031
16/03/16 15:24:55 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 15:24:55 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 15:24:55 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 15:24:55 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 10188 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: set
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: bend
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: giant
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: astatine
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: present
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('present.n.01') ; keyword:  time  in syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= [u'present']
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: area
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
16/03/16 15:24:56 INFO PythonRunner: Times: total = 344, boot = 227, init = 0, finish = 117
16/03/16 15:24:56 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 15:24:56 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 10.530 s
16/03/16 15:24:56 INFO DAGScheduler: looking for newly runnable stages
16/03/16 15:24:56 INFO DAGScheduler: running: Set()
16/03/16 15:24:56 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 15:24:56 INFO DAGScheduler: failed: Set()
16/03/16 15:24:56 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 15:24:56 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 15:24:56 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10709, maxMem=1125525749
16/03/16 15:24:56 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1073.4 MB)
16/03/16 15:24:56 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15693, maxMem=1125525749
16/03/16 15:24:56 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1073.4 MB)
16/03/16 15:24:56 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 373 ms on localhost (2/2)
16/03/16 15:24:56 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 15:24:56 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:42458 (size: 3.0 KB, free: 1073.4 MB)
16/03/16 15:24:56 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 15:24:56 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:24:56 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 15:24:56 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 15:24:56 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 15:24:56 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 15:24:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/16 15:24:56 INFO PythonRunner: Times: total = 215, boot = 214, init = 0, finish = 1
16/03/16 15:24:56 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 15:24:56 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 15:24:56 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 15:24:56 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 15:24:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 15:24:56 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 264 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'present']
16/03/16 15:24:56 INFO PythonRunner: Times: total = 245, boot = 244, init = 0, finish = 1
16/03/16 15:24:56 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1241 bytes result sent to driver
16/03/16 15:24:56 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.507 s
16/03/16 15:24:56 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 11.095564 s
16/03/16 15:24:56 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 268 ms on localhost (2/2)
16/03/16 15:24:56 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 15:24:56 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 15:24:56 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 15:24:56 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:24:56 INFO DAGScheduler: Parents of final stage: List()
16/03/16 15:24:56 INFO DAGScheduler: Missing parents: List()
16/03/16 15:24:56 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 15:24:56 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18741, maxMem=1125525749
16/03/16 15:24:56 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1073.4 MB)
16/03/16 15:24:56 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24557, maxMem=1125525749
16/03/16 15:24:56 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1073.4 MB)
16/03/16 15:24:56 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:42458 (size: 3.3 KB, free: 1073.4 MB)
16/03/16 15:24:56 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 15:24:56 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:24:56 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 15:24:56 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 15:24:56 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 15:24:57 INFO PythonRunner: Times: total = 164, boot = 163, init = 0, finish = 1
16/03/16 15:24:57 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 15:24:57 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2271 bytes)
16/03/16 15:24:57 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 182 ms on localhost (1/2)
16/03/16 15:24:57 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 15:24:57 INFO PythonRunner: Times: total = 302, boot = 300, init = 0, finish = 2
16/03/16 15:24:57 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1310 bytes result sent to driver
16/03/16 15:24:57 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.524 s
16/03/16 15:24:57 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.556307 s
16/03/16 15:24:57 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 362 ms on localhost (2/2)
16/03/16 15:24:57 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 15:24:57 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 15:24:57 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 15:24:57 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 15:24:57 INFO MemoryStore: MemoryStore cleared
16/03/16 15:24:57 INFO BlockManager: BlockManager stopped
16/03/16 15:24:57 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 15:24:57 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 15:24:57 INFO SparkContext: Successfully stopped SparkContext
16/03/16 15:24:57 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 15:24:57 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 15:24:57 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'present']
16/03/16 15:24:58 INFO SparkContext: Running Spark version 1.5.2
16/03/16 15:24:58 INFO SecurityManager: Changing view acls to: root
16/03/16 15:24:58 INFO SecurityManager: Changing modify acls to: root
16/03/16 15:24:58 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 15:24:58 INFO Slf4jLogger: Slf4jLogger started
16/03/16 15:24:58 INFO Remoting: Starting remoting
16/03/16 15:24:58 INFO Utils: Successfully started service 'sparkDriver' on port 37123.
16/03/16 15:24:58 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:37123]
16/03/16 15:24:58 INFO SparkEnv: Registering MapOutputTracker
16/03/16 15:24:58 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 15:24:58 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-1961c386-b3a1-4965-b1df-d55d3db4cf45
16/03/16 15:24:58 INFO MemoryStore: MemoryStore started with capacity 1073.4 MB
16/03/16 15:24:58 INFO HttpFileServer: HTTP File server directory is /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/httpd-f7fb1911-8185-4355-a42e-ea382d03d3a9
16/03/16 15:24:58 INFO HttpServer: Starting HTTP Server
16/03/16 15:24:58 INFO Utils: Successfully started service 'HTTP file server' on port 39695.
16/03/16 15:24:58 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 15:24:58 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 15:24:58 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 15:24:58 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/userFiles-893e3383-edaf-4bd7-9c28-4fce6ff3b592/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 15:24:58 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458122098918
16/03/16 15:24:59 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 15:24:59 INFO Executor: Starting executor ID driver on host localhost
16/03/16 15:24:59 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52327.
16/03/16 15:24:59 INFO NettyBlockTransferService: Server created on 52327
16/03/16 15:24:59 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 15:24:59 INFO BlockManagerMasterEndpoint: Registering block manager localhost:52327 with 1073.4 MB RAM, BlockManagerId(driver, localhost, 52327)
16/03/16 15:24:59 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): position
16/03/16 15:24:59 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 15:24:59 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:24:59 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 15:24:59 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:24:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 15:24:59 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 15:24:59 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 15:24:59 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1125525749
16/03/16 15:24:59 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1073.4 MB)
16/03/16 15:24:59 INFO MemoryStore: ensureFreeSpace(4141) called with curMem=6568, maxMem=1125525749
16/03/16 15:24:59 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1073.4 MB)
16/03/16 15:24:59 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:52327 (size: 4.0 KB, free: 1073.4 MB)
16/03/16 15:24:59 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 15:24:59 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:24:59 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 15:24:59 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 15:24:59 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 15:24:59 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458122098918
16/03/16 15:24:59 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/userFiles-893e3383-edaf-4bd7-9c28-4fce6ff3b592/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: area
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: issue
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: planning
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: permission
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: economy
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: composition
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: agency
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 15:25:07 INFO PythonRunner: Times: total = 8462, boot = 547, init = 466, finish = 7449
16/03/16 15:25:07 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 15:25:07 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 15:25:07 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 15:25:07 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8609 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: set
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: bend
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: giant
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: astatine
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: present
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): adding to parents: syn =  Synset('metropolitan.n.01') ; keyword:  position  in syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= [u'metropolitan']
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: area
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'metropolitan']
16/03/16 15:25:08 INFO PythonRunner: Times: total = 267, boot = 169, init = 0, finish = 98
16/03/16 15:25:08 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 15:25:08 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.854 s
16/03/16 15:25:08 INFO DAGScheduler: looking for newly runnable stages
16/03/16 15:25:08 INFO DAGScheduler: running: Set()
16/03/16 15:25:08 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 15:25:08 INFO DAGScheduler: failed: Set()
16/03/16 15:25:08 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 15:25:08 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 15:25:08 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10709, maxMem=1125525749
16/03/16 15:25:08 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1073.4 MB)
16/03/16 15:25:08 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15693, maxMem=1125525749
16/03/16 15:25:08 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1073.4 MB)
16/03/16 15:25:08 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 294 ms on localhost (2/2)
16/03/16 15:25:08 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 15:25:08 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:52327 (size: 3.0 KB, free: 1073.4 MB)
16/03/16 15:25:08 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 15:25:08 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:25:08 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 15:25:08 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 15:25:08 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 15:25:08 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 15:25:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/16 15:25:08 INFO PythonRunner: Times: total = 155, boot = 155, init = 0, finish = 0
16/03/16 15:25:08 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 15:25:08 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 15:25:08 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 15:25:08 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 15:25:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
16/03/16 15:25:08 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 186 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None', u'metropolitan']
16/03/16 15:25:08 INFO PythonRunner: Times: total = 175, boot = 174, init = 1, finish = 0
16/03/16 15:25:08 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1246 bytes result sent to driver
16/03/16 15:25:08 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 205 ms on localhost (2/2)
16/03/16 15:25:08 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 15:25:08 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.365 s
16/03/16 15:25:08 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 9.301693 s
16/03/16 15:25:08 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 15:25:08 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 15:25:08 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:25:08 INFO DAGScheduler: Parents of final stage: List()
16/03/16 15:25:08 INFO DAGScheduler: Missing parents: List()
16/03/16 15:25:08 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 15:25:08 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18741, maxMem=1125525749
16/03/16 15:25:08 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1073.4 MB)
16/03/16 15:25:08 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24557, maxMem=1125525749
16/03/16 15:25:08 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1073.4 MB)
16/03/16 15:25:08 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:52327 (size: 3.3 KB, free: 1073.4 MB)
16/03/16 15:25:08 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 15:25:08 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:25:08 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 15:25:08 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 15:25:08 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 15:25:08 INFO PythonRunner: Times: total = 71, boot = 70, init = 1, finish = 0
16/03/16 15:25:08 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 15:25:08 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2276 bytes)
16/03/16 15:25:08 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 88 ms on localhost (1/2)
16/03/16 15:25:08 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 15:25:08 INFO PythonRunner: Times: total = 211, boot = 211, init = 0, finish = 0
16/03/16 15:25:08 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1315 bytes result sent to driver
16/03/16 15:25:08 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.302 s
16/03/16 15:25:08 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.338068 s
16/03/16 15:25:08 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 230 ms on localhost (2/2)
16/03/16 15:25:08 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 15:25:09 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 15:25:09 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 15:25:09 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 15:25:09 INFO MemoryStore: MemoryStore cleared
16/03/16 15:25:09 INFO BlockManager: BlockManager stopped
16/03/16 15:25:09 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 15:25:09 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 15:25:09 INFO SparkContext: Successfully stopped SparkContext
16/03/16 15:25:09 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 15:25:09 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 15:25:09 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None', u'metropolitan']
16/03/16 15:25:09 INFO SparkContext: Running Spark version 1.5.2
16/03/16 15:25:09 INFO SecurityManager: Changing view acls to: root
16/03/16 15:25:09 INFO SecurityManager: Changing modify acls to: root
16/03/16 15:25:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 15:25:09 INFO Slf4jLogger: Slf4jLogger started
16/03/16 15:25:09 INFO Remoting: Starting remoting
16/03/16 15:25:10 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:44606]
16/03/16 15:25:10 INFO Utils: Successfully started service 'sparkDriver' on port 44606.
16/03/16 15:25:10 INFO SparkEnv: Registering MapOutputTracker
16/03/16 15:25:10 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 15:25:10 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-048eccfb-d3bc-4333-9181-03ae48e55528
16/03/16 15:25:10 INFO MemoryStore: MemoryStore started with capacity 1073.4 MB
16/03/16 15:25:10 INFO HttpFileServer: HTTP File server directory is /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/httpd-a089edf3-d714-454c-bd65-42027ac859d7
16/03/16 15:25:10 INFO HttpServer: Starting HTTP Server
16/03/16 15:25:10 INFO Utils: Successfully started service 'HTTP file server' on port 41805.
16/03/16 15:25:10 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 15:25:10 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 15:25:10 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 15:25:10 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/userFiles-6e6da838-d500-46e8-ab0c-f62fb7b1ce7e/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 15:25:10 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458122110210
16/03/16 15:25:10 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 15:25:10 INFO Executor: Starting executor ID driver on host localhost
16/03/16 15:25:10 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56459.
16/03/16 15:25:10 INFO NettyBlockTransferService: Server created on 56459
16/03/16 15:25:10 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 15:25:10 INFO BlockManagerMasterEndpoint: Registering block manager localhost:56459 with 1073.4 MB RAM, BlockManagerId(driver, localhost, 56459)
16/03/16 15:25:10 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): quantity
16/03/16 15:25:10 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 15:25:10 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:25:10 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 15:25:10 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:25:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 15:25:10 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 15:25:10 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 15:25:10 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=1125525749
16/03/16 15:25:10 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1073.4 MB)
16/03/16 15:25:10 INFO MemoryStore: ensureFreeSpace(4141) called with curMem=6568, maxMem=1125525749
16/03/16 15:25:10 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1073.4 MB)
16/03/16 15:25:10 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:56459 (size: 4.0 KB, free: 1073.4 MB)
16/03/16 15:25:10 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 15:25:10 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:25:10 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 15:25:10 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2352 bytes)
16/03/16 15:25:10 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 15:25:10 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458122110210
16/03/16 15:25:10 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/userFiles-6e6da838-d500-46e8-ab0c-f62fb7b1ce7e/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: area
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: issue
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'and', u'be', u'that', u'is', u'question', u'an', u'important', u'in', u'must', u'settled', u'dispute'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: planning
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'for', u'of', u'definite', u'an', u'course', u'program', u'act', u'action', u'formulating'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: permission
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'approval', u'something', u'do', u'to'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: economy
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'and', u'consumption', u'of', u'system', u'production', u'the', u'distribution'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: composition
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'and', u'from', u'of', u'in', u'arrangement', u'each', u'to', u'parts', u'resulting', u'spatial', u'relation', u'the', u'property', u'whole', u'other'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: agency
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'business', u'that', u'serves', u'other', u'businesses'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 15:25:18 INFO PythonRunner: Times: total = 7935, boot = 490, init = 354, finish = 7091
16/03/16 15:25:18 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 15:25:18 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2344 bytes)
16/03/16 15:25:18 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 15:25:18 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8025 ms on localhost (1/2)
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: set
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: bend
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: giant
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: astatine
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: present
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: area
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): quantity
mapFunction_Parents(): keyword: quantity ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= quantity ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/16 15:25:18 INFO PythonRunner: Times: total = 257, boot = 155, init = 0, finish = 102
16/03/16 15:25:18 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 15:25:18 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 8.311 s
16/03/16 15:25:18 INFO DAGScheduler: looking for newly runnable stages
16/03/16 15:25:18 INFO DAGScheduler: running: Set()
16/03/16 15:25:18 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 15:25:18 INFO DAGScheduler: failed: Set()
16/03/16 15:25:18 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 15:25:18 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which is now runnable
16/03/16 15:25:18 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10709, maxMem=1125525749
16/03/16 15:25:18 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1073.4 MB)
16/03/16 15:25:18 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15693, maxMem=1125525749
16/03/16 15:25:18 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1073.4 MB)
16/03/16 15:25:18 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:56459 (size: 3.0 KB, free: 1073.4 MB)
16/03/16 15:25:18 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 15:25:18 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:25:18 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 15:25:18 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 294 ms on localhost (2/2)
16/03/16 15:25:18 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 15:25:18 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 15:25:18 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 15:25:18 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 15:25:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 15:25:18 INFO PythonRunner: Times: total = 150, boot = 150, init = 0, finish = 0
16/03/16 15:25:18 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 15:25:18 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 15:25:18 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 15:25:18 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 15:25:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 15:25:18 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 197 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', 'None']
16/03/16 15:25:19 INFO PythonRunner: Times: total = 172, boot = 171, init = 1, finish = 0
16/03/16 15:25:19 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1227 bytes result sent to driver
16/03/16 15:25:19 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.364 s
16/03/16 15:25:19 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 8.696184 s
16/03/16 15:25:19 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 197 ms on localhost (2/2)
16/03/16 15:25:19 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 15:25:19 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207
16/03/16 15:25:19 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) with 2 output partitions
16/03/16 15:25:19 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:25:19 INFO DAGScheduler: Parents of final stage: List()
16/03/16 15:25:19 INFO DAGScheduler: Missing parents: List()
16/03/16 15:25:19 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207), which has no missing parents
16/03/16 15:25:19 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18741, maxMem=1125525749
16/03/16 15:25:19 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1073.4 MB)
16/03/16 15:25:19 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=24557, maxMem=1125525749
16/03/16 15:25:19 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1073.4 MB)
16/03/16 15:25:19 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:56459 (size: 3.3 KB, free: 1073.4 MB)
16/03/16 15:25:19 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 15:25:19 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207)
16/03/16 15:25:19 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 15:25:19 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 15:25:19 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 15:25:19 INFO PythonRunner: Times: total = 97, boot = 96, init = 1, finish = 0
16/03/16 15:25:19 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 15:25:19 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2257 bytes)
16/03/16 15:25:19 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 113 ms on localhost (1/2)
16/03/16 15:25:19 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 15:25:19 INFO PythonRunner: Times: total = 144, boot = 144, init = 0, finish = 0
16/03/16 15:25:19 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1296 bytes result sent to driver
16/03/16 15:25:19 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 173 ms on localhost (2/2)
16/03/16 15:25:19 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207) finished in 0.268 s
16/03/16 15:25:19 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 15:25:19 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:207, took 0.295136 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/03/16 15:25:19 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 15:25:19 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 15:25:19 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 15:25:19 INFO MemoryStore: MemoryStore cleared
16/03/16 15:25:19 INFO BlockManager: BlockManager stopped
16/03/16 15:25:19 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 15:25:19 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 15:25:19 INFO SparkContext: Successfully stopped SparkContext
16/03/16 15:25:19 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 15:25:19 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 15:25:19 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'None']
InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:freqterms1= [u'serving', u'Madras', u'Bengal', u'course', u'relation', u'geography', u'group', u'decay', u'program', u'Tamil', u'exceptional', u'Bay', u'formulating', u'serves', u'item', u'miles', u'unstable', u'including', u'people', u'series', u'Christianity', u'culture', u'meters', u'special', u'0.621371', u'Orthodox', u'definite', u'boundary', u'business', u'importance', u'equivalent', u'thorium', u'approval', u'providing', u'region', u'title', u'equal', u'length', u'resulting', u'act', u'action', u'whole', u'businesses', u'1000', u'formerly', u'period', u'highly', u'production', u'indefinite', u'unit', u'city', u'use', u'consumption', u'Eastern', u'stretch', u'archbishop', u'system', u'halogen', u'continuous', u'western', u'particular', u'given', u'kind', u'official', u'patriarch', u'Church', u'distribution', u'property', u'distinguished', u'metric', u'heaviest', u'purposes', u'general', u'something', u'bishop', u'things', u'belong', u'uranium', u'arrangement', u'parts', u'speech', u'geographical', u'spatial', u'Nadu', u'circular', u'product', u'used', u'usually', u'moment', u'purpose', u'segment', u'radioactive', u'happening', u'curve', u'together', u'element', u'person', u'reputation', u'time', u'position', u'quantity']
16/03/16 15:25:20 INFO SparkContext: Running Spark version 1.5.2
16/03/16 15:25:20 INFO SecurityManager: Changing view acls to: root
16/03/16 15:25:20 INFO SecurityManager: Changing modify acls to: root
16/03/16 15:25:20 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/16 15:25:20 INFO Slf4jLogger: Slf4jLogger started
16/03/16 15:25:20 INFO Remoting: Starting remoting
16/03/16 15:25:20 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:43822]
16/03/16 15:25:20 INFO Utils: Successfully started service 'sparkDriver' on port 43822.
16/03/16 15:25:20 INFO SparkEnv: Registering MapOutputTracker
16/03/16 15:25:20 INFO SparkEnv: Registering BlockManagerMaster
16/03/16 15:25:20 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-e1f91e83-b153-41a2-a076-1d69229eb9f0
16/03/16 15:25:20 INFO MemoryStore: MemoryStore started with capacity 1073.4 MB
16/03/16 15:25:20 INFO HttpFileServer: HTTP File server directory is /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/httpd-e7df6d71-e8de-4899-8376-6aef73d96a3e
16/03/16 15:25:20 INFO HttpServer: Starting HTTP Server
16/03/16 15:25:20 INFO Utils: Successfully started service 'HTTP file server' on port 48047.
16/03/16 15:25:20 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/16 15:25:20 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/16 15:25:20 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/16 15:25:20 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/userFiles-e448e712-546f-4e78-80bb-664a142d5fba/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/16 15:25:20 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458122120753
16/03/16 15:25:20 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/16 15:25:20 INFO Executor: Starting executor ID driver on host localhost
16/03/16 15:25:20 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35875.
16/03/16 15:25:20 INFO NettyBlockTransferService: Server created on 35875
16/03/16 15:25:20 INFO BlockManagerMaster: Trying to register BlockManager
16/03/16 15:25:20 INFO BlockManagerMasterEndpoint: Registering block manager localhost:35875 with 1073.4 MB RAM, BlockManagerId(driver, localhost, 35875)
16/03/16 15:25:20 INFO BlockManagerMaster: Registered BlockManager
Spark_MapReduce(): wordsatthislevel: [u'serving', u'Madras', u'Bengal', u'course', u'relation', u'geography', u'group', u'decay', u'program', u'Tamil', u'exceptional', u'Bay', u'formulating', u'serves', u'item', u'miles', u'unstable', u'including', u'people', u'series', u'Christianity', u'culture', u'meters', u'special', u'0.621371', u'Orthodox', u'definite', u'boundary', u'business', u'importance', u'equivalent', u'thorium', u'approval', u'providing', u'region', u'title', u'equal', u'length', u'resulting', u'act', u'action', u'whole', u'businesses', u'1000', u'formerly', u'period', u'highly', u'production', u'indefinite', u'unit', u'city', u'use', u'consumption', u'Eastern', u'stretch', u'archbishop', u'system', u'halogen', u'continuous', u'western', u'particular', u'given', u'kind', u'official', u'patriarch', u'Church', u'distribution', u'property', u'distinguished', u'metric', u'heaviest', u'purposes', u'general', u'something', u'bishop', u'things', u'belong', u'uranium', u'arrangement', u'parts', u'speech', u'geographical', u'spatial', u'Nadu', u'circular', u'product', u'used', u'usually', u'moment', u'purpose', u'segment', u'radioactive', u'happening', u'curve', u'together', u'element', u'person', u'reputation', u'time', u'position', u'quantity']
16/03/16 15:25:20 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230
16/03/16 15:25:20 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230)
16/03/16 15:25:20 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230) with 2 output partitions
16/03/16 15:25:20 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230)
16/03/16 15:25:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/16 15:25:20 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/16 15:25:20 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230), which has no missing parents
16/03/16 15:25:20 INFO MemoryStore: ensureFreeSpace(6552) called with curMem=0, maxMem=1125525749
16/03/16 15:25:20 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 1073.4 MB)
16/03/16 15:25:20 INFO MemoryStore: ensureFreeSpace(4132) called with curMem=6552, maxMem=1125525749
16/03/16 15:25:20 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1073.4 MB)
16/03/16 15:25:20 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:35875 (size: 4.0 KB, free: 1073.4 MB)
16/03/16 15:25:20 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/16 15:25:20 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230)
16/03/16 15:25:20 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/16 15:25:20 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2927 bytes)
16/03/16 15:25:20 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/16 15:25:20 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458122120753
16/03/16 15:25:20 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-99d1ae81-83b9-4f0f-91bf-70a2c6dbd18f/userFiles-e448e712-546f-4e78-80bb-664a142d5fba/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
mapFunction(): freqterms1: serving
mapFunction(): freqterms1: Madras
mapFunction(): freqterms1: Bengal
mapFunction(): freqterms1: course
mapFunction(): freqterms1: relation
mapFunction(): freqterms1: geography
mapFunction(): freqterms1: group
mapFunction(): freqterms1: decay
mapFunction(): freqterms1: program
mapFunction(): freqterms1: Tamil
mapFunction(): freqterms1: exceptional
mapFunction(): freqterms1: Bay
mapFunction(): freqterms1: formulating
mapFunction(): freqterms1: serves
mapFunction(): freqterms1: item
mapFunction(): freqterms1: miles
mapFunction(): freqterms1: unstable
mapFunction(): freqterms1: including
mapFunction(): freqterms1: people
mapFunction(): freqterms1: series
mapFunction(): freqterms1: Christianity
mapFunction(): freqterms1: culture
mapFunction(): freqterms1: meters
mapFunction(): freqterms1: special
mapFunction(): freqterms1: 0.621371
mapFunction(): freqterms1: Orthodox
mapFunction(): freqterms1: definite
mapFunction(): freqterms1: boundary
mapFunction(): freqterms1: business
mapFunction(): freqterms1: importance
mapFunction(): freqterms1: equivalent
mapFunction(): freqterms1: thorium
mapFunction(): freqterms1: approval
mapFunction(): freqterms1: providing
mapFunction(): freqterms1: region
mapFunction(): freqterms1: title
mapFunction(): freqterms1: equal
mapFunction(): freqterms1: length
mapFunction(): freqterms1: resulting
mapFunction(): freqterms1: act
mapFunction(): freqterms1: action
mapFunction(): freqterms1: whole
mapFunction(): freqterms1: businesses
mapFunction(): freqterms1: 1000
mapFunction(): freqterms1: formerly
mapFunction(): freqterms1: period
mapFunction(): freqterms1: highly
mapFunction(): freqterms1: production
mapFunction(): freqterms1: indefinite
mapFunction(): freqterms1: unit
16/03/16 15:25:29 INFO PythonRunner: Times: total = 8247, boot = 480, init = 351, finish = 7416
16/03/16 15:25:29 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1152 bytes result sent to driver
16/03/16 15:25:29 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2968 bytes)
16/03/16 15:25:29 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/16 15:25:29 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8346 ms on localhost (1/2)
mapFunction(): freqterms1: city
mapFunction(): freqterms1: use
mapFunction(): freqterms1: consumption
mapFunction(): freqterms1: Eastern
mapFunction(): freqterms1: stretch
mapFunction(): freqterms1: archbishop
mapFunction(): freqterms1: system
mapFunction(): freqterms1: halogen
mapFunction(): freqterms1: continuous
mapFunction(): freqterms1: western
mapFunction(): freqterms1: particular
mapFunction(): freqterms1: given
mapFunction(): freqterms1: kind
mapFunction(): freqterms1: official
mapFunction(): freqterms1: patriarch
mapFunction(): freqterms1: Church
mapFunction(): freqterms1: distribution
mapFunction(): freqterms1: property
mapFunction(): freqterms1: distinguished
mapFunction(): freqterms1: metric
mapFunction(): freqterms1: heaviest
mapFunction(): freqterms1: purposes
mapFunction(): freqterms1: general
mapFunction(): freqterms1: something
mapFunction(): freqterms1: bishop
mapFunction(): freqterms1: things
mapFunction(): freqterms1: belong
mapFunction(): freqterms1: uranium
mapFunction(): freqterms1: arrangement
mapFunction(): freqterms1: parts
mapFunction(): freqterms1: speech
mapFunction(): freqterms1: geographical
mapFunction(): freqterms1: spatial
mapFunction(): freqterms1: Nadu
mapFunction(): freqterms1: circular
mapFunction(): freqterms1: product
mapFunction(): freqterms1: used
mapFunction(): freqterms1: usually
mapFunction(): freqterms1: moment
mapFunction(): freqterms1: purpose
mapFunction(): freqterms1: segment
mapFunction(): freqterms1: radioactive
mapFunction(): freqterms1: happening
mapFunction(): freqterms1: curve
mapFunction(): freqterms1: together
mapFunction(): freqterms1: element
mapFunction(): freqterms1: person
mapFunction(): freqterms1: reputation
mapFunction(): freqterms1: time
mapFunction(): freqterms1: position
mapFunction(): freqterms1: quantity
16/03/16 15:25:30 INFO PythonRunner: Times: total = 779, boot = 217, init = 1, finish = 561
16/03/16 15:25:30 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1152 bytes result sent to driver
16/03/16 15:25:30 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230) finished in 9.155 s
16/03/16 15:25:30 INFO DAGScheduler: looking for newly runnable stages
16/03/16 15:25:30 INFO DAGScheduler: running: Set()
16/03/16 15:25:30 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/16 15:25:30 INFO DAGScheduler: failed: Set()
16/03/16 15:25:30 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/16 15:25:30 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230), which is now runnable
16/03/16 15:25:30 INFO MemoryStore: ensureFreeSpace(4976) called with curMem=10684, maxMem=1125525749
16/03/16 15:25:30 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1073.4 MB)
16/03/16 15:25:30 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 815 ms on localhost (2/2)
16/03/16 15:25:30 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/16 15:25:30 INFO MemoryStore: ensureFreeSpace(3040) called with curMem=15660, maxMem=1125525749
16/03/16 15:25:30 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 1073.4 MB)
16/03/16 15:25:30 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:35875 (size: 3.0 KB, free: 1073.4 MB)
16/03/16 15:25:30 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/16 15:25:30 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230)
16/03/16 15:25:30 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/16 15:25:30 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 15:25:30 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/16 15:25:30 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 15:25:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 15:25:30 INFO PythonRunner: Times: total = 157, boot = 156, init = 1, finish = 0
16/03/16 15:25:30 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1192 bytes result sent to driver
16/03/16 15:25:30 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/16 15:25:30 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/16 15:25:30 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/16 15:25:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/16 15:25:30 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 199 ms on localhost (1/2)
16/03/16 15:25:30 INFO PythonRunner: Times: total = 181, boot = 178, init = 0, finish = 3
16/03/16 15:25:30 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 10972 bytes result sent to driver
16/03/16 15:25:30 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 205 ms on localhost (2/2)
16/03/16 15:25:30 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/16 15:25:30 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230) finished in 0.376 s
16/03/16 15:25:30 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230, took 9.554320 s
16/03/16 15:25:30 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230
16/03/16 15:25:30 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230) with 2 output partitions
16/03/16 15:25:30 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230)
16/03/16 15:25:30 INFO DAGScheduler: Parents of final stage: List()
16/03/16 15:25:30 INFO DAGScheduler: Missing parents: List()
16/03/16 15:25:30 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230), which has no missing parents
16/03/16 15:25:30 INFO MemoryStore: ensureFreeSpace(5872) called with curMem=18700, maxMem=1125525749
16/03/16 15:25:30 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 1073.4 MB)
16/03/16 15:25:30 INFO MemoryStore: ensureFreeSpace(3416) called with curMem=24572, maxMem=1125525749
16/03/16 15:25:30 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 1073.4 MB)
16/03/16 15:25:30 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:35875 (size: 3.3 KB, free: 1073.4 MB)
16/03/16 15:25:30 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/16 15:25:30 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230)
16/03/16 15:25:30 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/16 15:25:30 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2222 bytes)
16/03/16 15:25:30 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/16 15:25:30 INFO PythonRunner: Times: total = 99, boot = 99, init = 0, finish = 0
16/03/16 15:25:30 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 942 bytes result sent to driver
16/03/16 15:25:30 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 11918 bytes)
16/03/16 15:25:30 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 125 ms on localhost (1/2)
16/03/16 15:25:30 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/16 15:25:30 INFO PythonRunner: Times: total = 143, boot = 141, init = 1, finish = 1
16/03/16 15:25:30 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 11279 bytes result sent to driver
16/03/16 15:25:30 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 193 ms on localhost (2/2)
16/03/16 15:25:30 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/16 15:25:30 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230) finished in 0.313 s
16/03/16 15:25:30 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:230, took 0.341209 s
Spark_MapReduce() - SparkSQL DataFrame query results:
Row(tokensatthislevel=[u'individual', u'quantity', u'food', u'drink', u'taken', u'part', u'meal', u'state', u'southeastern', u'India', u'Bay', u'Bengal', u'south', u'Andhra', u'Pradesh', u'formerly', u'Madras', u'region', u'whose', u'eastern', u'part', u'Bangladesh', u'whose', u'western', u'part', u'included', u'India', u'education', u'imparted', u'series', u'lessons', u'meetings', u'act', u'sexual', u'procreation', u'man', u'woman', u'man', u'penis', u'inserted', u'woman', u'vagina', u'excited', u'orgasm', u'ejaculation', u'occur', u'study', u'earth', u'surface', u'includes', u'people', u'responses', u'topography', u'climate', u'soil', u'vegetation', u'number', u'entities', u'members', u'considered', u'unit', u'gradual', u'decrease', u'stored', u'charge', u'current', u'series', u'steps', u'carried', u'goals', u'accomplished', u'member', u'mixed', u'Dravidian', u'Caucasian', u'people', u'southern', u'India', u'Sri', u'Lanka', u'deviating', u'widely', u'norm', u'physical', u'mental', u'ability', u'used', u'especially', u'children', u'normal', u'intelligence', u'indentation', u'shoreline', u'larger', u'cove', u'smaller', u'gulf', u'come', u'idea', u'plan', u'explanation', u'theory', u'principle', u'mental', u'effort', u'sports', u'stroke', u'puts', u'ball', u'play', u'distinct', u'part', u'specified', u'separately', u'group', u'things', u'could', u'enumerated', u'list', u'unit', u'length', u'equal', u'1,760', u'yards', u'5,280', u'feet', u'exactly', u'1609.344', u'meters', u'lacking', u'stability', u'fixity', u'firmness', u'part', u'made', u'plural', u'group', u'human', u'beings', u'men', u'women', u'children', u'collectively', u'similar', u'things', u'placed', u'order', u'happening', u'one', u'another', u'monotheistic', u'system', u'beliefs', u'practices', u'based', u'Old', u'Testament', u'teachings', u'Jesus', u'embodied', u'New', u'Testament', u'emphasizing', u'role', u'Jesus', u'savior', u'particular', u'society', u'particular', u'time', u'place', u'basic', u'unit', u'length', u'adopted', u'Systeme', u'International', u"d'Unites", u'approximately', u'1.094', u'yards', u'special', u'offering', u'usually', u'temporary', u'reduced', u'price', u'featured', u'advertising', u'pertaining', u'characteristic', u'Judaism', u'precise', u'explicit', u'clearly', u'defined', u'line', u'determining', u'limits', u'area', u'commercial', u'industrial', u'enterprise', u'people', u'constitute', u'prominent', u'status', u'person', u'thing', u'equal', u'another', u'value', u'measure', u'force', u'effect', u'significance', u'etc', u'soft', u'silvery-white', u'tetravalent', u'radioactive', u'metallic', u'element', u'isotope', u'232', u'used', u'power', u'source', u'nuclear', u'reactors', u'occurs', u'thorite', u'monazite', u'sands', u'feeling', u'liking', u'something', u'someone', u'good', u'give', u'something', u'useful', u'necessary', u'extended', u'spatial', u'location', u'something', u'heading', u'names', u'statute', u'legislative', u'bill', u'give', u'brief', u'summary', u'matters', u'deals', u'person', u'equal', u'standing', u'another', u'group', u'linear', u'extent', u'space', u'one', u'end', u'longest', u'dimension', u'something', u'fixed', u'place', u'issue', u'terminate', u'specified', u'way', u'state', u'etc', u'end', u'legal', u'document', u'codifying', u'result', u'deliberations', u'committee', u'society', u'legislative', u'body', u'military', u'engagement', u'something', u'including', u'component', u'elements', u'parts', u'commercial', u'industrial', u'enterprise', u'people', u'constitute', u'cardinal', u'number', u'product', u'10', u'100', u'previous', u'time', u'amount', u'time', u'high', u'degree', u'extent', u'favorably', u'much', u'respect', u'act', u'process', u'producing', u'something', u'vague', u'clearly', u'defined', u'stated', u'division', u'quantity', u'accepted', u'standard', u'measurement', u'exchange', u'large', u'densely', u'populated', u'urban', u'area', u'include', u'several', u'independent', u'administrative', u'districts', u'act', u'using', u'process', u'taking', u'food', u'body', u'mouth', u'eating', u'lying', u'toward', u'situated', u'east', u'large', u'unbroken', u'expanse', u'distance', u'bishop', u'highest', u'rank', u'instrumentality', u'combines', u'interrelated', u'interacting', u'artifacts', u'designed', u'work', u'coherent', u'entity', u'five', u'related', u'nonmetallic', u'elements', u'fluorine', u'chlorine', u'bromine', u'iodine', u'astatine', u'monovalent', u'readily', u'form', u'negative', u'ions', u'continuing', u'time', u'space', u'without', u'interruption', u'film', u'life', u'western', u'United', u'States', u'period', u'exploration', u'development', u'fact', u'part', u'opposed', u'general', u'assumption', u'taken', u'granted', u'category', u'things', u'distinguished', u'common', u'characteristic', u'quality', u'worker', u'holds', u'invested', u'office', u'man', u'older', u'higher', u'rank', u'one', u'groups', u'Christians', u'beliefs', u'forms', u'worship', u'statistics', u'arrangement', u'values', u'variable', u'showing', u'observed', u'theoretical', u'frequency', u'occurrence', u'something', u'owned', u'tangible', u'intangible', u'possession', u'owned', u'someone', u'mark', u'different', u'function', u'topological', u'space', u'gives', u'two', u'points', u'space', u'value', u'equal', u'distance', u'usually', u'describes', u'large', u'person', u'fat', u'large', u'frame', u'carry', u'anticipated', u'outcome', u'intended', u'guides', u'planned', u'actions', u'general', u'officer', u'highest', u'rank', u'senior', u'member', u'Christian', u'clergy', u'spiritual', u'administrative', u'authority', u'appointed', u'Christian', u'churches', u'oversee', u'priests', u'ministers', u'considered', u'churches', u'successors', u'twelve', u'Apostles', u'Christ', u'movable', u'possession', u'especially', u'articles', u'clothing', u'owned', u'possession', u'heavy', u'toxic', u'silvery-white', u'radioactive', u'metallic', u'element', u'occurs', u'many', u'isotopes', u'used', u'nuclear', u'fuels', u'nuclear', u'weapons', u'orderly', u'grouping', u'things', u'persons', u'considered', u'unit', u'result', u'arranging', u'something', u'less', u'whole', u'human', u'artifact', u'act', u'delivering', u'formal', u'spoken', u'communication', u'audience', u'relating', u'science', u'geography', u'pertaining', u'involving', u'nature', u'space', u'advertisement', u'usually', u'printed', u'page', u'leaflet', u'intended', u'wide', u'distribution', u'commodities', u'offered', u'sale', u'put', u'service', u'make', u'work', u'employ', u'particular', u'purpose', u'inherent', u'natural', u'purpose', u'normal', u'conditions', u'particular', u'point', u'time', u'anticipated', u'outcome', u'intended', u'guides', u'planned', u'actions', u'one', u'several', u'parts', u'pieces', u'fit', u'others', u'constitute', u'whole', u'object', u'exhibiting', u'caused', u'radioactivity', u'event', u'happens', u'trace', u'point', u'whose', u'direction', u'motion', u'changes', u'mentally', u'emotionally', u'stable', u'abstract', u'part', u'something', u'human', u'general', u'estimation', u'public', u'person', u'instance', u'single', u'occasion', u'event', u'particular', u'portion', u'space', u'occupied', u'something', u'concept', u'something', u'magnitude', u'represented', u'mathematical', u'expressions', u'constant', u'variable'])
16/03/16 15:25:31 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/16 15:25:31 INFO DAGScheduler: Stopping DAGScheduler
16/03/16 15:25:31 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/16 15:25:31 INFO MemoryStore: MemoryStore cleared
16/03/16 15:25:31 INFO BlockManager: BlockManager stopped
16/03/16 15:25:31 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/16 15:25:31 INFO SparkContext: Successfully stopped SparkContext
16/03/16 15:25:31 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/16 15:25:31 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/16 15:25:31 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/16 15:25:31 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:tokensofthislevel: [u'individual', u'quantity', u'food', u'drink', u'taken', u'part', u'meal', u'state', u'southeastern', u'India', u'Bay', u'Bengal', u'south', u'Andhra', u'Pradesh', u'formerly', u'Madras', u'region', u'whose', u'eastern', u'part', u'Bangladesh', u'whose', u'western', u'part', u'included', u'India', u'education', u'imparted', u'series', u'lessons', u'meetings', u'act', u'sexual', u'procreation', u'man', u'woman', u'man', u'penis', u'inserted', u'woman', u'vagina', u'excited', u'orgasm', u'ejaculation', u'occur', u'study', u'earth', u'surface', u'includes', u'people', u'responses', u'topography', u'climate', u'soil', u'vegetation', u'number', u'entities', u'members', u'considered', u'unit', u'gradual', u'decrease', u'stored', u'charge', u'current', u'series', u'steps', u'carried', u'goals', u'accomplished', u'member', u'mixed', u'Dravidian', u'Caucasian', u'people', u'southern', u'India', u'Sri', u'Lanka', u'deviating', u'widely', u'norm', u'physical', u'mental', u'ability', u'used', u'especially', u'children', u'normal', u'intelligence', u'indentation', u'shoreline', u'larger', u'cove', u'smaller', u'gulf', u'come', u'idea', u'plan', u'explanation', u'theory', u'principle', u'mental', u'effort', u'sports', u'stroke', u'puts', u'ball', u'play', u'distinct', u'part', u'specified', u'separately', u'group', u'things', u'could', u'enumerated', u'list', u'unit', u'length', u'equal', u'1,760', u'yards', u'5,280', u'feet', u'exactly', u'1609.344', u'meters', u'lacking', u'stability', u'fixity', u'firmness', u'part', u'made', u'plural', u'group', u'human', u'beings', u'men', u'women', u'children', u'collectively', u'similar', u'things', u'placed', u'order', u'happening', u'one', u'another', u'monotheistic', u'system', u'beliefs', u'practices', u'based', u'Old', u'Testament', u'teachings', u'Jesus', u'embodied', u'New', u'Testament', u'emphasizing', u'role', u'Jesus', u'savior', u'particular', u'society', u'particular', u'time', u'place', u'basic', u'unit', u'length', u'adopted', u'Systeme', u'International', u"d'Unites", u'approximately', u'1.094', u'yards', u'special', u'offering', u'usually', u'temporary', u'reduced', u'price', u'featured', u'advertising', u'pertaining', u'characteristic', u'Judaism', u'precise', u'explicit', u'clearly', u'defined', u'line', u'determining', u'limits', u'area', u'commercial', u'industrial', u'enterprise', u'people', u'constitute', u'prominent', u'status', u'person', u'thing', u'equal', u'another', u'value', u'measure', u'force', u'effect', u'significance', u'etc', u'soft', u'silvery-white', u'tetravalent', u'radioactive', u'metallic', u'element', u'isotope', u'232', u'used', u'power', u'source', u'nuclear', u'reactors', u'occurs', u'thorite', u'monazite', u'sands', u'feeling', u'liking', u'something', u'someone', u'good', u'give', u'something', u'useful', u'necessary', u'extended', u'spatial', u'location', u'something', u'heading', u'names', u'statute', u'legislative', u'bill', u'give', u'brief', u'summary', u'matters', u'deals', u'person', u'equal', u'standing', u'another', u'group', u'linear', u'extent', u'space', u'one', u'end', u'longest', u'dimension', u'something', u'fixed', u'place', u'issue', u'terminate', u'specified', u'way', u'state', u'etc', u'end', u'legal', u'document', u'codifying', u'result', u'deliberations', u'committee', u'society', u'legislative', u'body', u'military', u'engagement', u'something', u'including', u'component', u'elements', u'parts', u'commercial', u'industrial', u'enterprise', u'people', u'constitute', u'cardinal', u'number', u'product', u'10', u'100', u'previous', u'time', u'amount', u'time', u'high', u'degree', u'extent', u'favorably', u'much', u'respect', u'act', u'process', u'producing', u'something', u'vague', u'clearly', u'defined', u'stated', u'division', u'quantity', u'accepted', u'standard', u'measurement', u'exchange', u'large', u'densely', u'populated', u'urban', u'area', u'include', u'several', u'independent', u'administrative', u'districts', u'act', u'using', u'process', u'taking', u'food', u'body', u'mouth', u'eating', u'lying', u'toward', u'situated', u'east', u'large', u'unbroken', u'expanse', u'distance', u'bishop', u'highest', u'rank', u'instrumentality', u'combines', u'interrelated', u'interacting', u'artifacts', u'designed', u'work', u'coherent', u'entity', u'five', u'related', u'nonmetallic', u'elements', u'fluorine', u'chlorine', u'bromine', u'iodine', u'astatine', u'monovalent', u'readily', u'form', u'negative', u'ions', u'continuing', u'time', u'space', u'without', u'interruption', u'film', u'life', u'western', u'United', u'States', u'period', u'exploration', u'development', u'fact', u'part', u'opposed', u'general', u'assumption', u'taken', u'granted', u'category', u'things', u'distinguished', u'common', u'characteristic', u'quality', u'worker', u'holds', u'invested', u'office', u'man', u'older', u'higher', u'rank', u'one', u'groups', u'Christians', u'beliefs', u'forms', u'worship', u'statistics', u'arrangement', u'values', u'variable', u'showing', u'observed', u'theoretical', u'frequency', u'occurrence', u'something', u'owned', u'tangible', u'intangible', u'possession', u'owned', u'someone', u'mark', u'different', u'function', u'topological', u'space', u'gives', u'two', u'points', u'space', u'value', u'equal', u'distance', u'usually', u'describes', u'large', u'person', u'fat', u'large', u'frame', u'carry', u'anticipated', u'outcome', u'intended', u'guides', u'planned', u'actions', u'general', u'officer', u'highest', u'rank', u'senior', u'member', u'Christian', u'clergy', u'spiritual', u'administrative', u'authority', u'appointed', u'Christian', u'churches', u'oversee', u'priests', u'ministers', u'considered', u'churches', u'successors', u'twelve', u'Apostles', u'Christ', u'movable', u'possession', u'especially', u'articles', u'clothing', u'owned', u'possession', u'heavy', u'toxic', u'silvery-white', u'radioactive', u'metallic', u'element', u'occurs', u'many', u'isotopes', u'used', u'nuclear', u'fuels', u'nuclear', u'weapons', u'orderly', u'grouping', u'things', u'persons', u'considered', u'unit', u'result', u'arranging', u'something', u'less', u'whole', u'human', u'artifact', u'act', u'delivering', u'formal', u'spoken', u'communication', u'audience', u'relating', u'science', u'geography', u'pertaining', u'involving', u'nature', u'space', u'advertisement', u'usually', u'printed', u'page', u'leaflet', u'intended', u'wide', u'distribution', u'commodities', u'offered', u'sale', u'put', u'service', u'make', u'work', u'employ', u'particular', u'purpose', u'inherent', u'natural', u'purpose', u'normal', u'conditions', u'particular', u'point', u'time', u'anticipated', u'outcome', u'intended', u'guides', u'planned', u'actions', u'one', u'several', u'parts', u'pieces', u'fit', u'others', u'constitute', u'whole', u'object', u'exhibiting', u'caused', u'radioactivity', u'event', u'happens', u'trace', u'point', u'whose', u'direction', u'motion', u'changes', u'mentally', u'emotionally', u'stable', u'abstract', u'part', u'something', u'human', u'general', u'estimation', u'public', u'person', u'instance', u'single', u'occasion', u'event', u'particular', u'portion', u'space', u'occupied', u'something', u'concept', u'something', u'magnitude', u'represented', u'mathematical', u'expressions', u'constant', u'variable']
prevlevelsynsets: [Synset('helping.n.01'), Synset('tamil_nadu.n.01'), Synset('bengal.n.01'), Synset('course.n.01'), Synset('sexual_intercourse.n.01'), Synset('geography.n.01'), Synset('group.n.01'), Synset('decay.n.01'), Synset('plan.n.01'), Synset('tamil.n.01'), Synset('exceeding.s.01'), Synset('bay.n.01'), Synset('invent.v.01'), Synset('serve.n.01'), Synset('item.n.01'), Synset('mile.n.01'), Synset('unstable.a.01'), Synset('include.v.01'), Synset('people.n.01'), Synset('series.n.01'), Synset('christianity.n.01'), Synset('culture.n.01'), Synset('meter.n.01'), Synset('special.n.01'), Synset('orthodox.a.01'), Synset('definite.a.01'), Synset('boundary.n.01'), Synset('business.n.01'), Synset('importance.n.01'), Synset('equivalent.n.01'), Synset('thorium.n.01'), Synset('blessing.n.01'), Synset('supply.n.01'), Synset('region.n.01'), Synset('title.n.01'), Synset('peer.n.01'), Synset('length.n.01'), Synset('consequence.n.01'), Synset('act.n.01'), Synset('military_action.n.01'), Synset('whole.n.01'), Synset('business.n.01'), Synset('thousand.n.01'), Synset('once.r.01'), Synset('time_period.n.01'), Synset('highly.r.01'), Synset('production.n.01'), Synset('indefinite.a.01'), Synset('unit_of_measurement.n.01'), Synset('city.n.01'), Synset('use.n.01'), Synset('consumption.n.01'), Synset('eastern.s.01'), Synset('stretch.n.01'), Synset('archbishop.n.01'), Synset('system.n.01'), Synset('halogen.n.01'), Synset('continuous.a.01'), Synset('western.n.01'), Synset('particular.n.01'), Synset('given.n.01'), Synset('kind.n.01'), Synset('official.n.01'), Synset('patriarch.n.01'), Synset('church.n.01'), Synset('distribution.n.01'), Synset('property.n.01'), Synset('distinguish.v.01'), Synset('metric_function.n.01'), Synset('fleshy.s.01'), Synset('purpose.n.01'), Synset('general.n.01'), Synset('bishop.n.01'), Synset('things.n.01'), Synset('belong.v.01'), Synset('uranium.n.01'), Synset('agreement.n.04'), Synset('part.n.01'), Synset('address.n.01'), Synset('geographic.a.01'), Synset('spatial.a.01'), Synset('circular.n.01'), Synset('merchandise.n.01'), Synset('use.n.01'), Synset('normally.r.01'), Synset('moment.n.01'), Synset('purpose.n.01'), Synset('section.n.01'), Synset('radioactive.a.01'), Synset('happening.n.01'), Synset('curve.n.01'), Synset('together.s.01'), Synset('component.n.01'), Synset('person.n.01'), Synset('repute.n.01'), Synset('time.n.01'), Synset('position.n.01'), Synset('measure.n.02')]
defaultdict(<type 'list'>, {u'serving': [u'area', u'None', u'area'], u'Madras': [u'None', u'Chennai', u'None', u'Chennai'], u'Bengal': [u'None', u'Chennai', u'None', u'Chennai'], u'course': [u'None', u'planning', u'None'], u'relation': [u'None', u'composition', u'None'], u'geography': [u'area', u'None', u'area'], u'group': [u'None', u'set'], u'decay': [u'None', u'None', u'astatine'], u'halogen': [u'None', u'None', u'astatine'], u'Tamil': [u'None', u'Chennai', u'None', u'Chennai'], u'exceptional': [u'None', u'None', u'giant'], u'Bay': [u'None', u'Chennai', u'None', u'Chennai'], u'formulating': [u'None', u'planning', u'None'], u'serves': [u'None', u'agency', u'None'], u'item': [u'None', u'None'], u'miles': [u'None', u'kilometer', u'None', u'kilometer'], u'unstable': [u'None', u'None', u'astatine'], u'including': [u'None', u'None', u'present'], u'people': [u'area', u'None', u'area'], u'series': [u'None', u'None', u'astatine'], u'Christianity': [u'None', u'None', u'metropolitan'], u'culture': [u'area', u'None', u'area'], u'meters': [u'None', u'kilometer', u'None', u'kilometer'], u'special': [u'area', u'None', u'area'], u'0.621371': [u'None', u'kilometer', u'None', u'kilometer'], u'Orthodox': [u'None', u'None', u'metropolitan'], u'definite': [u'None', u'planning', u'None'], u'boundary': [u'area', u'None', u'area'], u'business': [u'None', u'agency', u'None'], u'importance': [u'None', u'None', u'giant'], u'equivalent': [u'None', u'None', u'metropolitan'], u'thorium': [u'None', u'None', u'astatine'], u'approval': [u'None', u'permission', u'None'], u'providing': [u'None', u'None'], u'region': [u'area', u'None', u'area'], u'title': [u'None', u'None', u'metropolitan'], u'equal': [u'None', u'kilometer', u'None', u'kilometer'], u'length': [u'None', u'kilometer', u'None', u'kilometer'], u'resulting': [u'None', u'composition', u'None'], u'act': [u'None', u'planning', u'None'], u'action': [u'None', u'planning', u'None'], u'whole': [u'None', u'composition', u'None'], u'businesses': [u'None', u'agency', u'None'], u'1000': [u'None', u'kilometer', u'None', u'kilometer'], u'formerly': [u'None', u'Chennai', u'None', u'Chennai'], u'period': [u'None', u'None', u'present'], u'highly': [u'None', u'None', u'astatine'], u'production': [u'None', u'economy', u'None'], u'indefinite': [u'area', u'None', u'area'], u'unit': [u'None', u'kilometer', u'None', u'kilometer'], u'city': [u'None', u'Chennai', u'None', u'Chennai'], u'use': [u'None', u'None'], u'consumption': [u'None', u'economy', u'None'], u'Eastern': [u'None', u'None', u'metropolitan'], u'stretch': [u'None', u'None', u'present'], u'archbishop': [u'None', u'None', u'metropolitan'], u'system': [u'None', u'economy', u'None'], u'program': [u'None', u'planning', u'None'], u'continuous': [u'None', u'None', u'present'], u'western': [u'None', u'None', u'metropolitan'], u'particular': [u'area', u'None', u'area'], u'given': [u'None', u'None', u'metropolitan'], u'kind': [u'None', u'set'], u'official': [u'None', u'None'], u'patriarch': [u'None', u'None', u'metropolitan'], u'Church': [u'None', u'None', u'metropolitan'], u'distribution': [u'None', u'economy', u'None'], u'property': [u'None', u'composition', u'None'], u'distinguished': [u'area', u'None', u'area'], u'metric': [u'None', u'kilometer', u'None', u'kilometer'], u'heaviest': [u'None', u'None', u'astatine'], u'purposes': [u'None', u'None'], u'general': [u'None', u'None'], u'something': [u'None', u'permission', u'None'], u'bishop': [u'None', u'None', u'metropolitan'], u'things': [u'None', u'set'], u'belong': [u'None', u'set'], u'uranium': [u'None', u'None', u'astatine'], u'arrangement': [u'None', u'composition', u'None'], u'parts': [u'None', u'composition', u'None'], u'speech': [u'None', u'None', u'present'], u'geographical': [u'area', u'None', u'area'], u'spatial': [u'None', u'composition', u'None'], u'Nadu': [u'None', u'Chennai', u'None', u'Chennai'], u'circular': [u'None', u'bend'], u'product': [u'None', u'None', u'astatine'], u'used': [u'None', u'set'], u'usually': [u'area', u'None', u'area'], u'moment': [u'None', u'None', u'present'], u'purpose': [u'area', u'None', u'area'], u'segment': [u'None', u'bend'], u'radioactive': [u'None', u'None', u'astatine'], u'happening': [u'None', u'None', u'present'], u'curve': [u'None', u'bend'], u'together': [u'None', u'set'], u'element': [u'None', u'None', u'astatine'], u'person': [u'None', u'None', u'giant'], u'reputation': [u'None', u'None', u'giant'], u'time': [u'None', u'None', u'present'], u'position': [u'None', u'None', u'metropolitan'], u'quantity': [u'None', u'None']})
ksynset= Synset('helping.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('helping.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('helping.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('tamil_nadu.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('tamil_nadu.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('tamil_nadu.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('tamil_nadu.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('bengal.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('bengal.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('bengal.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('bengal.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('course.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('course.n.01')
lsynset= Synset('planning.n.01')
ksynset= Synset('course.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('relation.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('relation.n.01')
lsynset= Synset('composition.n.01')
ksynset= Synset('relation.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('geography.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('geography.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('geography.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('group.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('group.n.01')
lsynset= Synset('set.n.01')
ksynset= Synset('decay.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('decay.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('decay.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('halogen.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('halogen.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('halogen.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('tamil.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('tamil.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('tamil.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('tamil.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('exceeding.s.01')
lsynset= Synset('none.n.01')
ksynset= Synset('exceeding.s.01')
lsynset= Synset('none.n.01')
ksynset= Synset('exceeding.s.01')
lsynset= Synset('giant.n.01')
ksynset= Synset('bay.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('bay.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('bay.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('bay.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('explicate.v.02')
lsynset= Synset('none.n.01')
ksynset= Synset('explicate.v.02')
lsynset= Synset('planning.n.01')
ksynset= Synset('explicate.v.02')
lsynset= Synset('none.n.01')
ksynset= Synset('serve.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('serve.n.01')
lsynset= Synset('agency.n.01')
ksynset= Synset('serve.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('item.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('item.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('mile.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('mile.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('mile.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('mile.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('unstable.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('unstable.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('unstable.a.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('include.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('include.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('include.v.01')
lsynset= Synset('present.n.01')
ksynset= Synset('people.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('people.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('people.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('series.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('series.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('series.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('christianity.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('christianity.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('christianity.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('culture.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('culture.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('culture.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('meter.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('meter.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('meter.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('meter.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('special.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('special.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('special.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('orthodox.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('orthodox.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('orthodox.a.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('definite.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('definite.a.01')
lsynset= Synset('planning.n.01')
ksynset= Synset('definite.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('boundary.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('boundary.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('boundary.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('business.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('business.n.01')
lsynset= Synset('agency.n.01')
ksynset= Synset('business.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('importance.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('importance.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('importance.n.01')
lsynset= Synset('giant.n.01')
ksynset= Synset('equivalent.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('equivalent.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('equivalent.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('thorium.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('thorium.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('thorium.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('blessing.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('blessing.n.01')
lsynset= Synset('permission.n.01')
ksynset= Synset('blessing.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('supply.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('supply.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('region.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('region.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('region.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('title.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('title.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('title.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('peer.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('peer.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('peer.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('peer.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('length.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('length.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('length.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('length.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('result.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('result.v.01')
lsynset= Synset('composition.n.01')
ksynset= Synset('result.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('act.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('act.n.01')
lsynset= Synset('planning.n.01')
ksynset= Synset('act.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('action.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('action.n.01')
lsynset= Synset('planning.n.01')
ksynset= Synset('action.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('whole.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('whole.n.01')
lsynset= Synset('composition.n.01')
ksynset= Synset('whole.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('business.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('business.n.01')
lsynset= Synset('agency.n.01')
ksynset= Synset('business.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('thousand.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('thousand.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('thousand.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('thousand.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('once.r.03')
lsynset= Synset('none.n.01')
ksynset= Synset('once.r.03')
lsynset= Synset('chennai.n.01')
ksynset= Synset('once.r.03')
lsynset= Synset('none.n.01')
ksynset= Synset('once.r.03')
lsynset= Synset('chennai.n.01')
ksynset= Synset('time_period.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('time_period.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('time_period.n.01')
lsynset= Synset('present.n.01')
ksynset= Synset('highly.r.01')
lsynset= Synset('none.n.01')
ksynset= Synset('highly.r.01')
lsynset= Synset('none.n.01')
ksynset= Synset('highly.r.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('production.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('production.n.01')
lsynset= Synset('economy.n.01')
ksynset= Synset('production.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('indefinite.a.01')
lsynset= Synset('area.n.01')
ksynset= Synset('indefinite.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('indefinite.a.01')
lsynset= Synset('area.n.01')
ksynset= Synset('unit_of_measurement.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('unit_of_measurement.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('unit_of_measurement.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('unit_of_measurement.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('city.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('city.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('city.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('city.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('use.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('use.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('consumption.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('consumption.n.01')
lsynset= Synset('economy.n.01')
ksynset= Synset('consumption.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('eastern.s.01')
lsynset= Synset('none.n.01')
ksynset= Synset('eastern.s.01')
lsynset= Synset('none.n.01')
ksynset= Synset('eastern.s.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('stretch.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('stretch.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('stretch.n.01')
lsynset= Synset('present.n.01')
ksynset= Synset('archbishop.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('archbishop.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('archbishop.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('system.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('system.n.01')
lsynset= Synset('economy.n.01')
ksynset= Synset('system.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('plan.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('plan.n.01')
lsynset= Synset('planning.n.01')
ksynset= Synset('plan.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('continuous.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('continuous.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('continuous.a.01')
lsynset= Synset('present.n.01')
ksynset= Synset('western.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('western.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('western.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('particular.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('particular.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('particular.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('given.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('given.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('given.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('kind.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('kind.n.01')
lsynset= Synset('set.n.01')
ksynset= Synset('official.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('official.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('patriarch.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('patriarch.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('patriarch.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('church.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('church.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('church.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('distribution.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('distribution.n.01')
lsynset= Synset('economy.n.01')
ksynset= Synset('distribution.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('property.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('property.n.01')
lsynset= Synset('composition.n.01')
ksynset= Synset('property.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('distinguish.v.01')
lsynset= Synset('area.n.01')
ksynset= Synset('distinguish.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('distinguish.v.01')
lsynset= Synset('area.n.01')
ksynset= Synset('metric_function.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('metric_function.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('metric_function.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('metric_function.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('heavy.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('heavy.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('heavy.a.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('purpose.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('purpose.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('general.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('general.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('bishop.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('bishop.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('bishop.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('things.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('things.n.01')
lsynset= Synset('set.n.01')
ksynset= Synset('belong.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('belong.v.01')
lsynset= Synset('set.n.01')
ksynset= Synset('uranium.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('uranium.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('uranium.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('agreement.n.04')
lsynset= Synset('none.n.01')
ksynset= Synset('agreement.n.04')
lsynset= Synset('composition.n.01')
ksynset= Synset('agreement.n.04')
lsynset= Synset('none.n.01')
ksynset= Synset('parts.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('parts.n.01')
lsynset= Synset('composition.n.01')
ksynset= Synset('parts.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('address.n.03')
lsynset= Synset('none.n.01')
ksynset= Synset('address.n.03')
lsynset= Synset('none.n.01')
ksynset= Synset('address.n.03')
lsynset= Synset('present.n.01')
ksynset= Synset('geographic.a.01')
lsynset= Synset('area.n.01')
ksynset= Synset('geographic.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('geographic.a.01')
lsynset= Synset('area.n.01')
ksynset= Synset('spatial.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('spatial.a.01')
lsynset= Synset('composition.n.01')
ksynset= Synset('spatial.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('circular.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('circular.n.01')
lsynset= Synset('bend.n.01')
ksynset= Synset('merchandise.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('merchandise.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('merchandise.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('use.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('use.v.01')
lsynset= Synset('set.n.01')
ksynset= Synset('normally.r.01')
lsynset= Synset('area.n.01')
ksynset= Synset('normally.r.01')
lsynset= Synset('none.n.01')
ksynset= Synset('normally.r.01')
lsynset= Synset('area.n.01')
ksynset= Synset('moment.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('moment.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('moment.n.01')
lsynset= Synset('present.n.01')
ksynset= Synset('purpose.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('purpose.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('purpose.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('section.n.04')
lsynset= Synset('none.n.01')
ksynset= Synset('section.n.04')
lsynset= Synset('bend.n.01')
ksynset= Synset('radioactive.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('radioactive.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('radioactive.a.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('happening.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('happening.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('happening.n.01')
lsynset= Synset('present.n.01')
ksynset= Synset('curve.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('curve.n.01')
lsynset= Synset('bend.n.01')
ksynset= Synset('together.s.01')
lsynset= Synset('none.n.01')
ksynset= Synset('together.s.01')
lsynset= Synset('set.n.01')
ksynset= Synset('component.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('component.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('component.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('person.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('person.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('person.n.01')
lsynset= Synset('giant.n.01')
ksynset= Synset('repute.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('repute.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('repute.n.01')
lsynset= Synset('giant.n.01')
ksynset= Synset('time.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('time.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('time.n.01')
lsynset= Synset('present.n.01')
ksynset= Synset('position.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('position.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('position.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('measure.n.02')
lsynset= Synset('none.n.01')
ksynset= Synset('measure.n.02')
lsynset= Synset('none.n.01')
Core number (sorted) : [(u'area', 13), (u'metropolitan', 12), (u'astatine', 11), (u'kilometer', 8), (u'present', 8), (u'Chennai', 7), (u'composition', 7), (u'planning', 6), (u'set', 6), (u'giant', 4), (u'economy', 4), (u'bend', 3), (u'agency', 3), (u'serving', 2), (u'Madras', 2), (u'Bengal', 2), (u'course', 2), (u'relation', 2), (u'geography', 2), (u'group', 2), (u'title', 2), (u'halogen', 2), (u'Tamil', 2), (u'permission', 2), (u'Bay', 2), (u'formulating', 2), (u'serves', 2), (u'miles', 2), (u'unstable', 2), (u'including', 2), (u'people', 2), (u'series', 2), (u'Christianity', 2), (u'culture', 2), (u'meters', 2), (u'special', 2), (u'0.621371', 2), (u'Orthodox', 2), (u'definite', 2), (u'boundary', 2), (u'business', 2), (u'importance', 2), (u'equivalent', 2), (u'thorium', 2), (u'approval', 2), (u'region', 2), (u'decay', 2), (u'equal', 2), (u'length', 2), (u'resulting', 2), (u'act', 2), (u'action', 2), (u'whole', 2), (u'businesses', 2), (u'1000', 2), (u'formerly', 2), (u'period', 2), (u'highly', 2), (u'production', 2), (u'indefinite', 2), (u'unit', 2), (u'city', 2), (u'given', 2), (u'consumption', 2), (u'stretch', 2), (u'archbishop', 2), (u'system', 2), (u'program', 2), (u'exceptional', 2), (u'continuous', 2), (u'western', 2), (u'particular', 2), (u'kind', 2), (u'patriarch', 2), (u'Eastern', 2), (u'Church', 2), (u'distribution', 2), (u'property', 2), (u'distinguished', 2), (u'something', 2), (u'metric', 2), (u'heaviest', 2), (u'bishop', 2), (u'things', 2), (u'belong', 2), (u'uranium', 2), (u'arrangement', 2), (u'parts', 2), (u'speech', 2), (u'geographical', 2), (u'spatial', 2), (u'Nadu', 2), (u'circular', 2), (u'product', 2), (u'used', 2), (u'usually', 2), (u'moment', 2), (u'purpose', 2), (u'segment', 2), (u'radioactive', 2), (u'happening', 2), (u'curve', 2), (u'together', 2), (u'element', 2), (u'person', 2), (u'reputation', 2), (u'time', 2), (u'position', 2), (u'item', 0), (u'None', 0), (u'use', 0), (u'providing', 0), (u'official', 0), (u'purposes', 0), (u'general', 0), (u'quantity', 0)]
=============================================================================================================
Unsupervised Classification based on top percentile Core numbers of the definition graph(subgraph of WordNet)
=============================================================================================================
This document belongs to class: area ,core number= 13
This document belongs to class: metropolitan ,core number= 12
This document belongs to class: astatine ,core number= 11
This document belongs to class: kilometer ,core number= 8
This document belongs to class: present ,core number= 8
This document belongs to class: Chennai ,core number= 7
This document belongs to class: composition ,core number= 7
This document belongs to class: planning ,core number= 6
This document belongs to class: set ,core number= 6
This document belongs to class: giant ,core number= 4
This document belongs to class: economy ,core number= 4
This document belongs to class: bend ,core number= 3
This document belongs to class: agency ,core number= 3
max_core_number 13
===================================================================
Page Rank of the vertices of RGO Definition Graph
===================================================================
[(u'area', 0.05964397617197671), (u'metropolitan', 0.05543677058743772), (u'astatine', 0.051229565002898755), (u'kilometer', 0.03860794824928188), (u'present', 0.03860794824928188), (u'Chennai', 0.034400742664742925), (u'composition', 0.034400742664742925), (u'planning', 0.030193537080203968), (u'set', 0.030193537080203968), (u'giant', 0.021779125911126046), (u'economy', 0.02177912591112604), (u'agency', 0.01757192032658708), (u'bend', 0.017571920326587075), (u'permission', 0.013364714742048119), (u'approval', 0.0070539063652396775), (u'something', 0.0070539063652396775), (u'serves', 0.006352705434483184), (u'business', 0.006352705434483184), (u'businesses', 0.006352705434483184), (u'circular', 0.006352705434483183), (u'segment', 0.006352705434483183), (u'curve', 0.006352705434483183), (u'importance', 0.006002104969104938), (u'production', 0.006002104969104938), (u'consumption', 0.006002104969104938), (u'system', 0.006002104969104938), (u'distribution', 0.006002104969104938), (u'exceptional', 0.006002104969104938), (u'person', 0.006002104969104938), (u'reputation', 0.006002104969104938), (u'course', 0.0056515045037266905), (u'group', 0.0056515045037266905), (u'program', 0.0056515045037266905), (u'formulating', 0.0056515045037266905), (u'definite', 0.0056515045037266905), (u'act', 0.0056515045037266905), (u'action', 0.0056515045037266905), (u'belong', 0.0056515045037266905), (u'kind', 0.0056515045037266905), (u'things', 0.0056515045037266905), (u'used', 0.0056515045037266905), (u'together', 0.0056515045037266905), (u'Madras', 0.005551332942190048), (u'Bengal', 0.005551332942190048), (u'relation', 0.005551332942190048), (u'Tamil', 0.005551332942190048), (u'Bay', 0.005551332942190048), (u'resulting', 0.005551332942190048), (u'whole', 0.005551332942190048), (u'formerly', 0.005551332942190048), (u'city', 0.005551332942190048), (u'property', 0.005551332942190048), (u'arrangement', 0.005551332942190048), (u'parts', 0.005551332942190048), (u'spatial', 0.005551332942190048), (u'Nadu', 0.005551332942190048), (u'miles', 0.0054762042710375675), (u'including', 0.0054762042710375675), (u'meters', 0.0054762042710375675), (u'0.621371', 0.0054762042710375675), (u'equal', 0.0054762042710375675), (u'length', 0.0054762042710375675), (u'1000', 0.0054762042710375675), (u'period', 0.0054762042710375675), (u'unit', 0.0054762042710375675), (u'stretch', 0.0054762042710375675), (u'continuous', 0.0054762042710375675), (u'metric', 0.0054762042710375675), (u'speech', 0.0054762042710375675), (u'moment', 0.0054762042710375675), (u'happening', 0.0054762042710375675), (u'time', 0.0054762042710375675), (u'unstable', 0.005332776807928284), (u'series', 0.005332776807928284), (u'thorium', 0.005332776807928284), (u'decay', 0.005332776807928284), (u'highly', 0.005332776807928284), (u'halogen', 0.005332776807928284), (u'heaviest', 0.005332776807928284), (u'uranium', 0.005332776807928284), (u'product', 0.005332776807928284), (u'radioactive', 0.005332776807928284), (u'element', 0.005332776807928284), (u'title', 0.005300904038348444), (u'Christianity', 0.005300904038348444), (u'Orthodox', 0.005300904038348444), (u'equivalent', 0.005300904038348444), (u'given', 0.005300904038348444), (u'archbishop', 0.005300904038348444), (u'western', 0.005300904038348444), (u'patriarch', 0.005300904038348444), (u'Eastern', 0.005300904038348444), (u'Church', 0.005300904038348444), (u'bishop', 0.005300904038348444), (u'position', 0.005300904038348444), (u'serving', 0.005273934771780889), (u'geography', 0.005273934771780889), (u'people', 0.005273934771780889), (u'culture', 0.005273934771780889), (u'special', 0.005273934771780889), (u'boundary', 0.005273934771780889), (u'region', 0.005273934771780889), (u'indefinite', 0.005273934771780889), (u'particular', 0.005273934771780889), (u'distinguished', 0.005273934771780889), (u'geographical', 0.005273934771780889), (u'usually', 0.005273934771780889), (u'purpose', 0.005273934771780889), (u'item', 0.001373626373626374), (u'None', 0.001373626373626374), (u'use', 0.001373626373626374), (u'providing', 0.001373626373626374), (u'official', 0.001373626373626374), (u'purposes', 0.001373626373626374), (u'general', 0.001373626373626374), (u'quantity', 0.001373626373626374)]
==========================================================================================================
Alternative Quantitative Intrinsic Merit  - connectivity of RGO Definition Graph - Mengers Theorem
==========================================================================================================
0
==========================================================================================================
Alternative Quantitative Intrinsic Merit  - Maxflow-Mincut of RGO Definition Graph - Minimum Edge Cut
==========================================================================================================
==========================================================================================================
Alternative Quantitative Intrinsic Merit  - Maxflow-Mincut of RGO Definition Graph - Stoer-Wagner
==========================================================================================================

