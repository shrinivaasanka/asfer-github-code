thmWithIntrinisicMerit_SparkMapReducer.py:186)
15/12/29 16:28:09 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
15/12/29 16:28:09 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
15/12/29 16:28:09 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
15/12/29 16:28:09 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
15/12/29 16:28:09 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/12/29 16:28:09 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
15/12/29 16:28:09 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/12/29 16:28:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
15/12/29 16:28:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
reduceFunction_Parents(): returns= [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:28:09 INFO PythonRunner: Times: total = 22, boot = -413, init = 434, finish = 1
15/12/29 16:28:09 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1360 bytes result sent to driver
15/12/29 16:28:09 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 50 ms on localhost (1/2)
15/12/29 16:28:10 INFO PythonRunner: Times: total = 271, boot = 270, init = 0, finish = 1
15/12/29 16:28:10 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
15/12/29 16:28:10 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186) finished in 0.275 s
15/12/29 16:28:10 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186, took 36.695673 s
15/12/29 16:28:10 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 287 ms on localhost (2/2)
15/12/29 16:28:10 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
15/12/29 16:28:10 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189
15/12/29 16:28:10 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189) with 2 output partitions
15/12/29 16:28:10 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189)
15/12/29 16:28:10 INFO DAGScheduler: Parents of final stage: List()
15/12/29 16:28:10 INFO DAGScheduler: Missing parents: List()
15/12/29 16:28:10 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189), which has no missing parents
15/12/29 16:28:10 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19729, maxMem=566938828
15/12/29 16:28:10 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 540.7 MB)
15/12/29 16:28:10 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=25545, maxMem=566938828
15/12/29 16:28:10 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 540.6 MB)
15/12/29 16:28:10 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:60131 (size: 3.3 KB, free: 540.7 MB)
15/12/29 16:28:10 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
15/12/29 16:28:10 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189)
15/12/29 16:28:10 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
15/12/29 16:28:10 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
15/12/29 16:28:10 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2441 bytes)
15/12/29 16:28:10 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
15/12/29 16:28:10 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
15/12/29 16:28:10 INFO PythonRunner: Times: total = 56, boot = -142, init = 198, finish = 0
15/12/29 16:28:10 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1422 bytes result sent to driver
15/12/29 16:28:10 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 76 ms on localhost (1/2)
15/12/29 16:28:10 INFO PythonRunner: Times: total = 240, boot = 240, init = 0, finish = 0
15/12/29 16:28:10 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
15/12/29 16:28:10 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 253 ms on localhost (2/2)
15/12/29 16:28:10 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
15/12/29 16:28:10 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189) finished in 0.236 s
15/12/29 16:28:10 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189, took 0.275009 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
15/12/29 16:28:10 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
15/12/29 16:28:10 INFO DAGScheduler: Stopping DAGScheduler
15/12/29 16:28:10 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
15/12/29 16:28:10 INFO MemoryStore: MemoryStore cleared
15/12/29 16:28:10 INFO BlockManager: BlockManager stopped
15/12/29 16:28:10 INFO BlockManagerMaster: BlockManagerMaster stopped
15/12/29 16:28:10 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
15/12/29 16:28:10 INFO SparkContext: Successfully stopped SparkContext
15/12/29 16:28:10 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
15/12/29 16:28:10 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
15/12/29 16:28:10 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:28:11 INFO SparkContext: Running Spark version 1.5.2
15/12/29 16:28:11 INFO SecurityManager: Changing view acls to: root
15/12/29 16:28:11 INFO SecurityManager: Changing modify acls to: root
15/12/29 16:28:11 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
15/12/29 16:28:11 INFO Slf4jLogger: Slf4jLogger started
15/12/29 16:28:11 INFO Remoting: Starting remoting
15/12/29 16:28:11 INFO Utils: Successfully started service 'sparkDriver' on port 35933.
15/12/29 16:28:11 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:35933]
15/12/29 16:28:11 INFO SparkEnv: Registering MapOutputTracker
15/12/29 16:28:11 INFO SparkEnv: Registering BlockManagerMaster
15/12/29 16:28:11 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-423394f8-bfd2-4b3d-b86a-868b6aef0169
15/12/29 16:28:11 INFO MemoryStore: MemoryStore started with capacity 540.7 MB
15/12/29 16:28:11 INFO HttpFileServer: HTTP File server directory is /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/httpd-5993b950-7f0d-4e24-a71d-76cecb33aca5
15/12/29 16:28:11 INFO HttpServer: Starting HTTP Server
15/12/29 16:28:11 INFO Utils: Successfully started service 'HTTP file server' on port 57428.
15/12/29 16:28:11 INFO SparkEnv: Registering OutputCommitCoordinator
15/12/29 16:28:12 INFO Utils: Successfully started service 'SparkUI' on port 4040.
15/12/29 16:28:12 INFO SparkUI: Started SparkUI at http://localhost:4040
15/12/29 16:28:12 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/userFiles-5181a3c1-6e70-4c11-b2ab-fe4fa379ba6f/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
15/12/29 16:28:12 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1451386692154
15/12/29 16:28:12 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
15/12/29 16:28:12 INFO Executor: Starting executor ID driver on host localhost
15/12/29 16:28:12 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33357.
15/12/29 16:28:12 INFO NettyBlockTransferService: Server created on 33357
15/12/29 16:28:12 INFO BlockManagerMaster: Trying to register BlockManager
15/12/29 16:28:12 INFO BlockManagerMasterEndpoint: Registering block manager localhost:33357 with 540.7 MB RAM, BlockManagerId(driver, localhost, 33357)
15/12/29 16:28:12 INFO BlockManagerMaster: Registered BlockManager
15/12/29 16:28:12 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186
15/12/29 16:28:12 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184)
15/12/29 16:28:12 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186) with 2 output partitions
15/12/29 16:28:12 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186)
15/12/29 16:28:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
15/12/29 16:28:12 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
15/12/29 16:28:12 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184), which has no missing parents
15/12/29 16:28:12 INFO MemoryStore: ensureFreeSpace(7120) called with curMem=0, maxMem=566938828
15/12/29 16:28:12 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 7.0 KB, free 540.7 MB)
15/12/29 16:28:12 INFO MemoryStore: ensureFreeSpace(4573) called with curMem=7120, maxMem=566938828
15/12/29 16:28:12 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.5 KB, free 540.7 MB)
15/12/29 16:28:12 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:33357 (size: 4.5 KB, free: 540.7 MB)
15/12/29 16:28:12 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
15/12/29 16:28:12 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184)
15/12/29 16:28:12 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
15/12/29 16:28:12 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2401 bytes)
15/12/29 16:28:12 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2424 bytes)
15/12/29 16:28:12 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
15/12/29 16:28:12 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1451386692154
15/12/29 16:28:12 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
15/12/29 16:28:12 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/userFiles-5181a3c1-6e70-4c11-b2ab-fe4fa379ba6f/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
*** Introductory Examples for the NLTK Book ***
Loading text1, ..., text9 and sent1, ..., sent9
Type the name of the text or sentence to view it.
Type: 'texts()' or 'sents()' to list the materials.
*** Introductory Examples for the NLTK Book ***
Loading text1, ..., text9 and sent1, ..., sent9
Type the name of the text or sentence to view it.
Type: 'texts()' or 'sents()' to list the materials.
text1: Moby Dick by Herman Melville 1851
text1: Moby Dick by Herman Melville 1851
text2: Sense and Sensibility by Jane Austen 1811
text2: Sense and Sensibility by Jane Austen 1811
text3: The Book of Genesis
text3: The Book of Genesis
text4: Inaugural Address Corpus
text4: Inaugural Address Corpus
text5: Chat Corpus
text5: Chat Corpus
text6: Monty Python and the Holy Grail
text6: Monty Python and the Holy Grail
text7: Wall Street Journal
text8: Personals Corpus
text7: Wall Street Journal
text9: The Man Who Was Thursday by G . K . Chesterton 1908
mapFunction_Parents(): keyword =  provided ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
text8: Personals Corpus
text9: The Man Who Was Thursday by G . K . Chesterton 1908
mapFunction_Parents(): keyword =  locomotive ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  powered ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  electricity ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  cars ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'coupled']
reduceFunction_Parents(): returns= [u'coupled']
mapFunction_Parents(): keyword =  coupled ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  railway ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'coupled']
mapFunction_Parents(): keyword =  together ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  car ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'coupled']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  drawn ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
15/12/29 16:28:48 INFO PythonRunner: Times: total = 36301, boot = 494, init = 27192, finish = 8615
15/12/29 16:28:48 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
15/12/29 16:28:48 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 36402 ms on localhost (1/2)
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  line ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'railway']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway']
mapFunction_Parents(): keyword =  public ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway']
mapFunction_Parents(): keyword =  transport ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'line', u'transport']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:28:49 INFO PythonRunner: Times: total = 36716, boot = 506, init = 27737, finish = 8473
15/12/29 16:28:49 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
15/12/29 16:28:49 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184) finished in 36.808 s
15/12/29 16:28:49 INFO DAGScheduler: looking for newly runnable stages
15/12/29 16:28:49 INFO DAGScheduler: running: Set()
15/12/29 16:28:49 INFO DAGScheduler: waiting: Set(ResultStage 1)
15/12/29 16:28:49 INFO DAGScheduler: failed: Set()
15/12/29 16:28:49 INFO DAGScheduler: Missing parents for ResultStage 1: List()
15/12/29 16:28:49 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186), which is now runnable
15/12/29 16:28:49 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11693, maxMem=566938828
15/12/29 16:28:49 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 540.7 MB)
15/12/29 16:28:49 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 36830 ms on localhost (2/2)
15/12/29 16:28:49 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
15/12/29 16:28:49 INFO MemoryStore: ensureFreeSpace(3054) called with curMem=16677, maxMem=566938828
15/12/29 16:28:49 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 540.7 MB)
15/12/29 16:28:49 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:33357 (size: 3.0 KB, free: 540.7 MB)
15/12/29 16:28:49 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
15/12/29 16:28:49 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186)
15/12/29 16:28:49 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
15/12/29 16:28:49 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
15/12/29 16:28:49 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
15/12/29 16:28:49 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
15/12/29 16:28:49 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/12/29 16:28:49 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
15/12/29 16:28:49 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/12/29 16:28:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
15/12/29 16:28:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
15/12/29 16:28:49 INFO PythonRunner: Times: total = 25, boot = -255, init = 280, finish = 0
15/12/29 16:28:49 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
15/12/29 16:28:49 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 44 ms on localhost (1/2)
reduceFunction_Parents(): returns= [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:28:49 INFO PythonRunner: Times: total = 183, boot = 182, init = 0, finish = 1
15/12/29 16:28:49 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1360 bytes result sent to driver
15/12/29 16:28:49 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 199 ms on localhost (2/2)
15/12/29 16:28:49 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
15/12/29 16:28:49 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186) finished in 0.201 s
15/12/29 16:28:49 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186, took 37.093770 s
15/12/29 16:28:49 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189
15/12/29 16:28:49 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189) with 2 output partitions
15/12/29 16:28:49 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189)
15/12/29 16:28:49 INFO DAGScheduler: Parents of final stage: List()
15/12/29 16:28:49 INFO DAGScheduler: Missing parents: List()
15/12/29 16:28:49 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189), which has no missing parents
15/12/29 16:28:49 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19731, maxMem=566938828
15/12/29 16:28:49 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 540.7 MB)
15/12/29 16:28:49 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25547, maxMem=566938828
15/12/29 16:28:49 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 540.6 MB)
15/12/29 16:28:49 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:33357 (size: 3.3 KB, free: 540.7 MB)
15/12/29 16:28:49 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
15/12/29 16:28:49 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189)
15/12/29 16:28:49 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
15/12/29 16:28:49 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
15/12/29 16:28:49 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2441 bytes)
15/12/29 16:28:49 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
15/12/29 16:28:49 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
15/12/29 16:28:49 INFO PythonRunner: Times: total = 121, boot = 120, init = 0, finish = 1
15/12/29 16:28:49 INFO PythonRunner: Times: total = 128, boot = 128, init = 0, finish = 0
15/12/29 16:28:49 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
15/12/29 16:28:49 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1422 bytes result sent to driver
15/12/29 16:28:49 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 139 ms on localhost (1/2)
15/12/29 16:28:49 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 141 ms on localhost (2/2)
15/12/29 16:28:49 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
15/12/29 16:28:49 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189) finished in 0.094 s
15/12/29 16:28:49 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189, took 0.192272 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
15/12/29 16:28:49 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
15/12/29 16:28:49 INFO DAGScheduler: Stopping DAGScheduler
15/12/29 16:28:49 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
15/12/29 16:28:49 INFO MemoryStore: MemoryStore cleared
15/12/29 16:28:49 INFO BlockManager: BlockManager stopped
15/12/29 16:28:49 INFO BlockManagerMaster: BlockManagerMaster stopped
15/12/29 16:28:49 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
15/12/29 16:28:49 INFO SparkContext: Successfully stopped SparkContext
15/12/29 16:28:49 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
15/12/29 16:28:49 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
15/12/29 16:28:49 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:28:50 INFO SparkContext: Running Spark version 1.5.2
15/12/29 16:28:50 INFO SecurityManager: Changing view acls to: root
15/12/29 16:28:50 INFO SecurityManager: Changing modify acls to: root
15/12/29 16:28:50 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
15/12/29 16:28:50 INFO Slf4jLogger: Slf4jLogger started
15/12/29 16:28:50 INFO Remoting: Starting remoting
15/12/29 16:28:50 INFO Utils: Successfully started service 'sparkDriver' on port 38351.
15/12/29 16:28:50 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:38351]
15/12/29 16:28:50 INFO SparkEnv: Registering MapOutputTracker
15/12/29 16:28:50 INFO SparkEnv: Registering BlockManagerMaster
15/12/29 16:28:50 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-f4d7c47e-0ce7-4ec5-a903-2926cf2d129a
15/12/29 16:28:50 INFO MemoryStore: MemoryStore started with capacity 540.7 MB
15/12/29 16:28:50 INFO HttpFileServer: HTTP File server directory is /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/httpd-15678946-dea0-4afa-84fa-a2e78c5100ff
15/12/29 16:28:50 INFO HttpServer: Starting HTTP Server
15/12/29 16:28:50 INFO Utils: Successfully started service 'HTTP file server' on port 44067.
15/12/29 16:28:50 INFO SparkEnv: Registering OutputCommitCoordinator
15/12/29 16:28:51 INFO Utils: Successfully started service 'SparkUI' on port 4040.
15/12/29 16:28:51 INFO SparkUI: Started SparkUI at http://localhost:4040
15/12/29 16:28:51 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/userFiles-d996855f-79d0-4f9b-9c3d-1ab611f51c17/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
15/12/29 16:28:51 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1451386731288
15/12/29 16:28:51 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
15/12/29 16:28:51 INFO Executor: Starting executor ID driver on host localhost
15/12/29 16:28:51 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50382.
15/12/29 16:28:51 INFO NettyBlockTransferService: Server created on 50382
15/12/29 16:28:51 INFO BlockManagerMaster: Trying to register BlockManager
15/12/29 16:28:51 INFO BlockManagerMasterEndpoint: Registering block manager localhost:50382 with 540.7 MB RAM, BlockManagerId(driver, localhost, 50382)
15/12/29 16:28:51 INFO BlockManagerMaster: Registered BlockManager
15/12/29 16:28:51 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186
15/12/29 16:28:51 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184)
15/12/29 16:28:51 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186) with 2 output partitions
15/12/29 16:28:51 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186)
15/12/29 16:28:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
15/12/29 16:28:51 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
15/12/29 16:28:51 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184), which has no missing parents
15/12/29 16:28:51 INFO MemoryStore: ensureFreeSpace(7120) called with curMem=0, maxMem=566938828
15/12/29 16:28:51 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 7.0 KB, free 540.7 MB)
15/12/29 16:28:51 INFO MemoryStore: ensureFreeSpace(4573) called with curMem=7120, maxMem=566938828
15/12/29 16:28:51 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.5 KB, free 540.7 MB)
15/12/29 16:28:51 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:50382 (size: 4.5 KB, free: 540.7 MB)
15/12/29 16:28:51 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
15/12/29 16:28:51 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184)
15/12/29 16:28:51 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
15/12/29 16:28:51 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2401 bytes)
15/12/29 16:28:51 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2424 bytes)
15/12/29 16:28:51 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
15/12/29 16:28:51 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1451386731288
15/12/29 16:28:51 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
15/12/29 16:28:51 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/userFiles-d996855f-79d0-4f9b-9c3d-1ab611f51c17/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
*** Introductory Examples for the NLTK Book ***
Loading text1, ..., text9 and sent1, ..., sent9
Type the name of the text or sentence to view it.
Type: 'texts()' or 'sents()' to list the materials.
*** Introductory Examples for the NLTK Book ***
Loading text1, ..., text9 and sent1, ..., sent9
Type the name of the text or sentence to view it.
Type: 'texts()' or 'sents()' to list the materials.
text1: Moby Dick by Herman Melville 1851
text1: Moby Dick by Herman Melville 1851
text2: Sense and Sensibility by Jane Austen 1811
text2: Sense and Sensibility by Jane Austen 1811
text3: The Book of Genesis
text3: The Book of Genesis
text4: Inaugural Address Corpus
text4: Inaugural Address Corpus
text5: Chat Corpus
text5: Chat Corpus
text6: Monty Python and the Holy Grail
text6: Monty Python and the Holy Grail
text7: Wall Street Journal
text7: Wall Street Journal
text8: Personals Corpus
text8: Personals Corpus
text9: The Man Who Was Thursday by G . K . Chesterton 1908
mapFunction_Parents(): keyword =  locomotive ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
text9: The Man Who Was Thursday by G . K . Chesterton 1908
mapFunction_Parents(): keyword =  provided ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  powered ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  electricity ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  railway ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  cars ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  car ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'coupled']
reduceFunction_Parents(): returns= [u'coupled']
mapFunction_Parents(): keyword =  coupled ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'coupled']
mapFunction_Parents(): keyword =  together ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  drawn ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'coupled']
15/12/29 16:29:30 INFO PythonRunner: Times: total = 38971, boot = 457, init = 30476, finish = 8038
15/12/29 16:29:30 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
15/12/29 16:29:30 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 39039 ms on localhost (1/2)
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  line ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'railway']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway']
mapFunction_Parents(): keyword =  public ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway']
mapFunction_Parents(): keyword =  transport ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'line', u'transport']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:29:30 INFO PythonRunner: Times: total = 39324, boot = 471, init = 30452, finish = 8401
15/12/29 16:29:30 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
15/12/29 16:29:30 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 39384 ms on localhost (2/2)
15/12/29 16:29:30 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184) finished in 39.390 s
15/12/29 16:29:30 INFO DAGScheduler: looking for newly runnable stages
15/12/29 16:29:30 INFO DAGScheduler: running: Set()
15/12/29 16:29:30 INFO DAGScheduler: waiting: Set(ResultStage 1)
15/12/29 16:29:30 INFO DAGScheduler: failed: Set()
15/12/29 16:29:30 INFO DAGScheduler: Missing parents for ResultStage 1: List()
15/12/29 16:29:30 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186), which is now runnable
15/12/29 16:29:30 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11693, maxMem=566938828
15/12/29 16:29:30 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 540.7 MB)
15/12/29 16:29:30 INFO MemoryStore: ensureFreeSpace(3054) called with curMem=16677, maxMem=566938828
15/12/29 16:29:30 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 540.7 MB)
15/12/29 16:29:30 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:50382 (size: 3.0 KB, free: 540.7 MB)
15/12/29 16:29:30 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
15/12/29 16:29:30 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186)
15/12/29 16:29:30 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
15/12/29 16:29:30 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
15/12/29 16:29:30 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
15/12/29 16:29:30 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
15/12/29 16:29:30 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
15/12/29 16:29:30 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/12/29 16:29:30 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
15/12/29 16:29:30 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/12/29 16:29:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
15/12/29 16:29:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
reduceFunction_Parents(): returns= [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:29:30 INFO PythonRunner: Times: total = 17, boot = -150, init = 167, finish = 0
15/12/29 16:29:30 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1360 bytes result sent to driver
15/12/29 16:29:30 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 51 ms on localhost (1/2)
15/12/29 16:29:31 INFO PythonRunner: Times: total = 247, boot = 246, init = 0, finish = 1
15/12/29 16:29:31 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
15/12/29 16:29:31 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186) finished in 0.268 s
15/12/29 16:29:31 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 266 ms on localhost (2/2)
15/12/29 16:29:31 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
15/12/29 16:29:31 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186, took 39.705649 s
15/12/29 16:29:31 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189
15/12/29 16:29:31 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189) with 2 output partitions
15/12/29 16:29:31 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189)
15/12/29 16:29:31 INFO DAGScheduler: Parents of final stage: List()
15/12/29 16:29:31 INFO DAGScheduler: Missing parents: List()
15/12/29 16:29:31 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189), which has no missing parents
15/12/29 16:29:31 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19731, maxMem=566938828
15/12/29 16:29:31 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 540.7 MB)
15/12/29 16:29:31 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25547, maxMem=566938828
15/12/29 16:29:31 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 540.6 MB)
15/12/29 16:29:31 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:50382 (size: 3.3 KB, free: 540.7 MB)
15/12/29 16:29:31 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
15/12/29 16:29:31 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189)
15/12/29 16:29:31 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
15/12/29 16:29:31 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
15/12/29 16:29:31 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2441 bytes)
15/12/29 16:29:31 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
15/12/29 16:29:31 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
15/12/29 16:29:31 INFO PythonRunner: Times: total = 47, boot = -113, init = 160, finish = 0
15/12/29 16:29:31 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
15/12/29 16:29:31 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 63 ms on localhost (1/2)
15/12/29 16:29:31 INFO PythonRunner: Times: total = 109, boot = 109, init = 0, finish = 0
15/12/29 16:29:31 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1422 bytes result sent to driver
15/12/29 16:29:31 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 123 ms on localhost (2/2)
15/12/29 16:29:31 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
15/12/29 16:29:31 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189) finished in 0.113 s
15/12/29 16:29:31 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189, took 0.177646 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
15/12/29 16:29:31 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
15/12/29 16:29:31 INFO DAGScheduler: Stopping DAGScheduler
15/12/29 16:29:31 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
15/12/29 16:29:31 INFO MemoryStore: MemoryStore cleared
15/12/29 16:29:31 INFO BlockManager: BlockManager stopped
15/12/29 16:29:31 INFO BlockManagerMaster: BlockManagerMaster stopped
15/12/29 16:29:31 INFO SparkContext: Successfully stopped SparkContext
15/12/29 16:29:31 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
15/12/29 16:29:31 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
15/12/29 16:29:31 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
15/12/29 16:29:31 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:29:32 INFO SparkContext: Running Spark version 1.5.2
15/12/29 16:29:32 INFO SecurityManager: Changing view acls to: root
15/12/29 16:29:32 INFO SecurityManager: Changing modify acls to: root
15/12/29 16:29:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
15/12/29 16:29:32 INFO Slf4jLogger: Slf4jLogger started
15/12/29 16:29:32 INFO Remoting: Starting remoting
15/12/29 16:29:32 INFO Utils: Successfully started service 'sparkDriver' on port 34574.
15/12/29 16:29:32 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:34574]
15/12/29 16:29:32 INFO SparkEnv: Registering MapOutputTracker
15/12/29 16:29:32 INFO SparkEnv: Registering BlockManagerMaster
15/12/29 16:29:32 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-e5de9f6f-27f6-4b39-862a-54a6b2acf257
15/12/29 16:29:32 INFO MemoryStore: MemoryStore started with capacity 540.7 MB
15/12/29 16:29:32 INFO HttpFileServer: HTTP File server directory is /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/httpd-216e501e-0b03-4b17-9be7-2e6f142a1030
15/12/29 16:29:32 INFO HttpServer: Starting HTTP Server
15/12/29 16:29:32 INFO Utils: Successfully started service 'HTTP file server' on port 42608.
15/12/29 16:29:32 INFO SparkEnv: Registering OutputCommitCoordinator
15/12/29 16:29:33 INFO Utils: Successfully started service 'SparkUI' on port 4040.
15/12/29 16:29:33 INFO SparkUI: Started SparkUI at http://localhost:4040
15/12/29 16:29:33 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/userFiles-6d4648c5-fe94-49f8-acf6-0e8f1ef23980/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
15/12/29 16:29:33 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1451386773298
15/12/29 16:29:33 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
15/12/29 16:29:33 INFO Executor: Starting executor ID driver on host localhost
15/12/29 16:29:33 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35711.
15/12/29 16:29:33 INFO NettyBlockTransferService: Server created on 35711
15/12/29 16:29:33 INFO BlockManagerMaster: Trying to register BlockManager
15/12/29 16:29:33 INFO BlockManagerMasterEndpoint: Registering block manager localhost:35711 with 540.7 MB RAM, BlockManagerId(driver, localhost, 35711)
15/12/29 16:29:33 INFO BlockManagerMaster: Registered BlockManager
15/12/29 16:29:33 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186
15/12/29 16:29:33 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184)
15/12/29 16:29:33 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186) with 2 output partitions
15/12/29 16:29:33 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186)
15/12/29 16:29:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
15/12/29 16:29:33 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
15/12/29 16:29:33 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184), which has no missing parents
15/12/29 16:29:33 INFO MemoryStore: ensureFreeSpace(7120) called with curMem=0, maxMem=566938828
15/12/29 16:29:33 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 7.0 KB, free 540.7 MB)
15/12/29 16:29:33 INFO MemoryStore: ensureFreeSpace(4573) called with curMem=7120, maxMem=566938828
15/12/29 16:29:33 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.5 KB, free 540.7 MB)
15/12/29 16:29:33 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:35711 (size: 4.5 KB, free: 540.7 MB)
15/12/29 16:29:33 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
15/12/29 16:29:33 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184)
15/12/29 16:29:33 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
15/12/29 16:29:33 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2401 bytes)
15/12/29 16:29:33 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2424 bytes)
15/12/29 16:29:33 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
15/12/29 16:29:33 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1451386773298
15/12/29 16:29:33 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
15/12/29 16:29:33 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/userFiles-6d4648c5-fe94-49f8-acf6-0e8f1ef23980/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
*** Introductory Examples for the NLTK Book ***
Loading text1, ..., text9 and sent1, ..., sent9
Type the name of the text or sentence to view it.
Type: 'texts()' or 'sents()' to list the materials.
*** Introductory Examples for the NLTK Book ***
Loading text1, ..., text9 and sent1, ..., sent9
Type the name of the text or sentence to view it.
Type: 'texts()' or 'sents()' to list the materials.
text1: Moby Dick by Herman Melville 1851
text1: Moby Dick by Herman Melville 1851
text2: Sense and Sensibility by Jane Austen 1811
text2: Sense and Sensibility by Jane Austen 1811
text3: The Book of Genesis
text3: The Book of Genesis
text4: Inaugural Address Corpus
text4: Inaugural Address Corpus
text5: Chat Corpus
text5: Chat Corpus
text6: Monty Python and the Holy Grail
text6: Monty Python and the Holy Grail
text7: Wall Street Journal
text8: Personals Corpus
text7: Wall Street Journal
text8: Personals Corpus
text9: The Man Who Was Thursday by G . K . Chesterton 1908
mapFunction_Parents(): keyword =  locomotive ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
text9: The Man Who Was Thursday by G . K . Chesterton 1908
mapFunction_Parents(): keyword =  provided ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  railway ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  car ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  drawn ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  line ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'railway']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway']
mapFunction_Parents(): keyword =  public ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway']
mapFunction_Parents(): keyword =  transport ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  powered ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'line', u'transport']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:30:10 INFO PythonRunner: Times: total = 36653, boot = 448, init = 28073, finish = 8132
15/12/29 16:30:10 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
15/12/29 16:30:10 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 36715 ms on localhost (1/2)
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  electricity ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  cars ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'coupled']
reduceFunction_Parents(): returns= [u'coupled']
mapFunction_Parents(): keyword =  coupled ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'coupled']
mapFunction_Parents(): keyword =  together ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'coupled']
15/12/29 16:30:10 INFO PythonRunner: Times: total = 37078, boot = 460, init = 28455, finish = 8163
15/12/29 16:30:10 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
15/12/29 16:30:10 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184) finished in 37.157 s
15/12/29 16:30:10 INFO DAGScheduler: looking for newly runnable stages
15/12/29 16:30:10 INFO DAGScheduler: running: Set()
15/12/29 16:30:10 INFO DAGScheduler: waiting: Set(ResultStage 1)
15/12/29 16:30:10 INFO DAGScheduler: failed: Set()
15/12/29 16:30:10 INFO DAGScheduler: Missing parents for ResultStage 1: List()
15/12/29 16:30:10 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186), which is now runnable
15/12/29 16:30:10 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11693, maxMem=566938828
15/12/29 16:30:10 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 540.7 MB)
15/12/29 16:30:10 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 37154 ms on localhost (2/2)
15/12/29 16:30:10 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
15/12/29 16:30:10 INFO MemoryStore: ensureFreeSpace(3053) called with curMem=16677, maxMem=566938828
15/12/29 16:30:10 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 540.7 MB)
15/12/29 16:30:10 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:35711 (size: 3.0 KB, free: 540.7 MB)
15/12/29 16:30:10 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
15/12/29 16:30:10 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186)
15/12/29 16:30:10 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
15/12/29 16:30:10 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
15/12/29 16:30:10 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
15/12/29 16:30:10 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
15/12/29 16:30:10 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
15/12/29 16:30:10 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/12/29 16:30:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
15/12/29 16:30:10 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/12/29 16:30:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
15/12/29 16:30:10 INFO PythonRunner: Times: total = 50, boot = -279, init = 329, finish = 0
15/12/29 16:30:10 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
15/12/29 16:30:10 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 106 ms on localhost (1/2)
reduceFunction_Parents(): returns= [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:30:10 INFO PythonRunner: Times: total = 203, boot = 202, init = 1, finish = 0
15/12/29 16:30:10 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1360 bytes result sent to driver
15/12/29 16:30:10 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 220 ms on localhost (2/2)
15/12/29 16:30:10 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
15/12/29 16:30:10 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186) finished in 0.216 s
15/12/29 16:30:10 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186, took 37.452651 s
15/12/29 16:30:11 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189
15/12/29 16:30:11 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189) with 2 output partitions
15/12/29 16:30:11 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189)
15/12/29 16:30:11 INFO DAGScheduler: Parents of final stage: List()
15/12/29 16:30:11 INFO DAGScheduler: Missing parents: List()
15/12/29 16:30:11 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189), which has no missing parents
15/12/29 16:30:11 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19730, maxMem=566938828
15/12/29 16:30:11 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 540.7 MB)
15/12/29 16:30:11 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=25546, maxMem=566938828
15/12/29 16:30:11 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 540.6 MB)
15/12/29 16:30:11 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:35711 (size: 3.3 KB, free: 540.7 MB)
15/12/29 16:30:11 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
15/12/29 16:30:11 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189)
15/12/29 16:30:11 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
15/12/29 16:30:11 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
15/12/29 16:30:11 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2441 bytes)
15/12/29 16:30:11 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
15/12/29 16:30:11 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
15/12/29 16:30:11 INFO PythonRunner: Times: total = 51, boot = 42, init = 0, finish = 9
15/12/29 16:30:11 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1422 bytes result sent to driver
15/12/29 16:30:11 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 74 ms on localhost (1/2)
15/12/29 16:30:11 INFO PythonRunner: Times: total = 137, boot = 137, init = 0, finish = 0
15/12/29 16:30:11 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
15/12/29 16:30:11 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 150 ms on localhost (2/2)
15/12/29 16:30:11 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
15/12/29 16:30:11 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189) finished in 0.151 s
15/12/29 16:30:11 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189, took 0.203275 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
15/12/29 16:30:11 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
15/12/29 16:30:11 INFO DAGScheduler: Stopping DAGScheduler
15/12/29 16:30:11 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
15/12/29 16:30:11 INFO MemoryStore: MemoryStore cleared
15/12/29 16:30:11 INFO BlockManager: BlockManager stopped
15/12/29 16:30:11 INFO BlockManagerMaster: BlockManagerMaster stopped
15/12/29 16:30:11 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
15/12/29 16:30:11 INFO SparkContext: Successfully stopped SparkContext
15/12/29 16:30:11 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
15/12/29 16:30:11 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
15/12/29 16:30:11 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:30:12 INFO SparkContext: Running Spark version 1.5.2
15/12/29 16:30:12 INFO SecurityManager: Changing view acls to: root
15/12/29 16:30:12 INFO SecurityManager: Changing modify acls to: root
15/12/29 16:30:12 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
15/12/29 16:30:12 INFO Slf4jLogger: Slf4jLogger started
15/12/29 16:30:12 INFO Remoting: Starting remoting
15/12/29 16:30:12 INFO Utils: Successfully started service 'sparkDriver' on port 56634.
15/12/29 16:30:12 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:56634]
15/12/29 16:30:12 INFO SparkEnv: Registering MapOutputTracker
15/12/29 16:30:12 INFO SparkEnv: Registering BlockManagerMaster
15/12/29 16:30:12 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-0e5d0d8f-b1ca-455b-95b2-ec1b30a0fcd1
15/12/29 16:30:12 INFO MemoryStore: MemoryStore started with capacity 541.2 MB
15/12/29 16:30:12 INFO HttpFileServer: HTTP File server directory is /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/httpd-8646be50-c93c-497c-8696-8af63a0de200
15/12/29 16:30:12 INFO HttpServer: Starting HTTP Server
15/12/29 16:30:12 INFO Utils: Successfully started service 'HTTP file server' on port 53546.
15/12/29 16:30:12 INFO SparkEnv: Registering OutputCommitCoordinator
15/12/29 16:30:12 INFO Utils: Successfully started service 'SparkUI' on port 4040.
15/12/29 16:30:12 INFO SparkUI: Started SparkUI at http://localhost:4040
15/12/29 16:30:12 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/userFiles-241639b4-bf1f-4100-8818-9b3af382930c/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
15/12/29 16:30:12 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1451386812911
15/12/29 16:30:12 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
15/12/29 16:30:12 INFO Executor: Starting executor ID driver on host localhost
15/12/29 16:30:12 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40185.
15/12/29 16:30:12 INFO NettyBlockTransferService: Server created on 40185
15/12/29 16:30:12 INFO BlockManagerMaster: Trying to register BlockManager
15/12/29 16:30:12 INFO BlockManagerMasterEndpoint: Registering block manager localhost:40185 with 541.2 MB RAM, BlockManagerId(driver, localhost, 40185)
15/12/29 16:30:12 INFO BlockManagerMaster: Registered BlockManager
15/12/29 16:30:13 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186
15/12/29 16:30:13 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184)
15/12/29 16:30:13 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186) with 2 output partitions
15/12/29 16:30:13 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186)
15/12/29 16:30:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
15/12/29 16:30:13 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
15/12/29 16:30:13 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184), which has no missing parents
15/12/29 16:30:13 INFO MemoryStore: ensureFreeSpace(7120) called with curMem=0, maxMem=567505059
15/12/29 16:30:13 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 7.0 KB, free 541.2 MB)
15/12/29 16:30:13 INFO MemoryStore: ensureFreeSpace(4573) called with curMem=7120, maxMem=567505059
15/12/29 16:30:13 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.5 KB, free 541.2 MB)
15/12/29 16:30:13 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:40185 (size: 4.5 KB, free: 541.2 MB)
15/12/29 16:30:13 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
15/12/29 16:30:13 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184)
15/12/29 16:30:13 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
15/12/29 16:30:13 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2401 bytes)
15/12/29 16:30:13 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2424 bytes)
15/12/29 16:30:13 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
15/12/29 16:30:13 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1451386812911
15/12/29 16:30:13 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
15/12/29 16:30:13 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/userFiles-241639b4-bf1f-4100-8818-9b3af382930c/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
*** Introductory Examples for the NLTK Book ***
Loading text1, ..., text9 and sent1, ..., sent9
Type the name of the text or sentence to view it.
Type: 'texts()' or 'sents()' to list the materials.
*** Introductory Examples for the NLTK Book ***
Loading text1, ..., text9 and sent1, ..., sent9
Type the name of the text or sentence to view it.
Type: 'texts()' or 'sents()' to list the materials.
text1: Moby Dick by Herman Melville 1851
text1: Moby Dick by Herman Melville 1851
text2: Sense and Sensibility by Jane Austen 1811
text2: Sense and Sensibility by Jane Austen 1811
text3: The Book of Genesis
text3: The Book of Genesis
text4: Inaugural Address Corpus
text4: Inaugural Address Corpus
text5: Chat Corpus
text6: Monty Python and the Holy Grail
text5: Chat Corpus
text6: Monty Python and the Holy Grail
text7: Wall Street Journal
text8: Personals Corpus
text7: Wall Street Journal
text9: The Man Who Was Thursday by G . K . Chesterton 1908
mapFunction_Parents(): keyword =  locomotive ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', text8: Personals Corpus
u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
text9: The Man Who Was Thursday by G . K . Chesterton 1908
mapFunction_Parents(): keyword =  provided ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  railway ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  car ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  drawn ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  line ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'railway']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway']
mapFunction_Parents(): keyword =  public ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  powered ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway']
mapFunction_Parents(): keyword =  transport ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  electricity ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'line', u'transport']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:30:49 INFO PythonRunner: Times: total = 36261, boot = 569, init = 27309, finish = 8383
15/12/29 16:30:49 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
15/12/29 16:30:49 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 36345 ms on localhost (1/2)
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  cars ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'coupled']
reduceFunction_Parents(): returns= [u'coupled']
mapFunction_Parents(): keyword =  coupled ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'coupled']
mapFunction_Parents(): keyword =  together ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'coupled']
15/12/29 16:30:49 INFO PythonRunner: Times: total = 36632, boot = 565, init = 27834, finish = 8233
15/12/29 16:30:49 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
15/12/29 16:30:49 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 36694 ms on localhost (2/2)
15/12/29 16:30:49 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
15/12/29 16:30:49 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184) finished in 36.700 s
15/12/29 16:30:49 INFO DAGScheduler: looking for newly runnable stages
15/12/29 16:30:49 INFO DAGScheduler: running: Set()
15/12/29 16:30:49 INFO DAGScheduler: waiting: Set(ResultStage 1)
15/12/29 16:30:49 INFO DAGScheduler: failed: Set()
15/12/29 16:30:49 INFO DAGScheduler: Missing parents for ResultStage 1: List()
15/12/29 16:30:49 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186), which is now runnable
15/12/29 16:30:49 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11693, maxMem=567505059
15/12/29 16:30:49 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 541.2 MB)
15/12/29 16:30:49 INFO MemoryStore: ensureFreeSpace(3054) called with curMem=16677, maxMem=567505059
15/12/29 16:30:49 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 541.2 MB)
15/12/29 16:30:49 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:40185 (size: 3.0 KB, free: 541.2 MB)
15/12/29 16:30:49 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
15/12/29 16:30:49 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186)
15/12/29 16:30:49 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
15/12/29 16:30:49 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
15/12/29 16:30:49 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
15/12/29 16:30:49 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
15/12/29 16:30:49 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
15/12/29 16:30:49 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/12/29 16:30:49 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/12/29 16:30:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
15/12/29 16:30:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
15/12/29 16:30:49 INFO PythonRunner: Times: total = 47, boot = -172, init = 219, finish = 0
15/12/29 16:30:49 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
15/12/29 16:30:49 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 71 ms on localhost (1/2)
reduceFunction_Parents(): returns= [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:30:50 INFO PythonRunner: Times: total = 288, boot = 286, init = 1, finish = 1
15/12/29 16:30:50 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1360 bytes result sent to driver
15/12/29 16:30:50 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 310 ms on localhost (2/2)
15/12/29 16:30:50 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
15/12/29 16:30:50 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186) finished in 0.319 s
15/12/29 16:30:50 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186, took 37.047910 s
15/12/29 16:30:50 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189
15/12/29 16:30:50 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189) with 2 output partitions
15/12/29 16:30:50 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189)
15/12/29 16:30:50 INFO DAGScheduler: Parents of final stage: List()
15/12/29 16:30:50 INFO DAGScheduler: Missing parents: List()
15/12/29 16:30:50 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189), which has no missing parents
15/12/29 16:30:50 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19731, maxMem=567505059
15/12/29 16:30:50 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 541.2 MB)
15/12/29 16:30:50 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25547, maxMem=567505059
15/12/29 16:30:50 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 541.2 MB)
15/12/29 16:30:50 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:40185 (size: 3.3 KB, free: 541.2 MB)
15/12/29 16:30:50 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
15/12/29 16:30:50 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189)
15/12/29 16:30:50 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
15/12/29 16:30:50 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
15/12/29 16:30:50 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2441 bytes)
15/12/29 16:30:50 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
15/12/29 16:30:50 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
15/12/29 16:30:50 INFO PythonRunner: Times: total = 56, boot = -88, init = 144, finish = 0
15/12/29 16:30:50 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
15/12/29 16:30:50 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 70 ms on localhost (1/2)
15/12/29 16:30:50 INFO PythonRunner: Times: total = 221, boot = 220, init = 1, finish = 0
15/12/29 16:30:50 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1422 bytes result sent to driver
15/12/29 16:30:50 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 234 ms on localhost (2/2)
15/12/29 16:30:50 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
15/12/29 16:30:50 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189) finished in 0.238 s
15/12/29 16:30:50 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189, took 0.256354 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
15/12/29 16:30:50 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
15/12/29 16:30:50 INFO DAGScheduler: Stopping DAGScheduler
15/12/29 16:30:50 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
15/12/29 16:30:50 INFO MemoryStore: MemoryStore cleared
15/12/29 16:30:50 INFO BlockManager: BlockManager stopped
15/12/29 16:30:50 INFO BlockManagerMaster: BlockManagerMaster stopped
15/12/29 16:30:50 INFO SparkContext: Successfully stopped SparkContext
15/12/29 16:30:50 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
15/12/29 16:30:50 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
15/12/29 16:30:50 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
15/12/29 16:30:50 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:30:51 INFO SparkContext: Running Spark version 1.5.2
15/12/29 16:30:51 INFO SecurityManager: Changing view acls to: root
15/12/29 16:30:51 INFO SecurityManager: Changing modify acls to: root
15/12/29 16:30:51 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
15/12/29 16:30:51 INFO Slf4jLogger: Slf4jLogger started
15/12/29 16:30:51 INFO Remoting: Starting remoting
15/12/29 16:30:51 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:52757]
15/12/29 16:30:51 INFO Utils: Successfully started service 'sparkDriver' on port 52757.
15/12/29 16:30:51 INFO SparkEnv: Registering MapOutputTracker
15/12/29 16:30:51 INFO SparkEnv: Registering BlockManagerMaster
15/12/29 16:30:51 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-3d924bc9-5316-4de5-93be-bb3b0ddd0be7
15/12/29 16:30:51 INFO MemoryStore: MemoryStore started with capacity 541.2 MB
15/12/29 16:30:51 INFO HttpFileServer: HTTP File server directory is /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/httpd-594b865b-13c8-49ba-9be1-9b40f2cfc52b
15/12/29 16:30:51 INFO HttpServer: Starting HTTP Server
15/12/29 16:30:51 INFO Utils: Successfully started service 'HTTP file server' on port 56789.
15/12/29 16:30:51 INFO SparkEnv: Registering OutputCommitCoordinator
15/12/29 16:30:52 INFO Utils: Successfully started service 'SparkUI' on port 4040.
15/12/29 16:30:52 INFO SparkUI: Started SparkUI at http://localhost:4040
15/12/29 16:30:52 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/userFiles-398765d8-ee05-4712-9ea0-2a3aa47f011f/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
15/12/29 16:30:52 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1451386852119
15/12/29 16:30:52 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
15/12/29 16:30:52 INFO Executor: Starting executor ID driver on host localhost
15/12/29 16:30:52 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43196.
15/12/29 16:30:52 INFO NettyBlockTransferService: Server created on 43196
15/12/29 16:30:52 INFO BlockManagerMaster: Trying to register BlockManager
15/12/29 16:30:52 INFO BlockManagerMasterEndpoint: Registering block manager localhost:43196 with 541.2 MB RAM, BlockManagerId(driver, localhost, 43196)
15/12/29 16:30:52 INFO BlockManagerMaster: Registered BlockManager
15/12/29 16:30:52 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186
15/12/29 16:30:52 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184)
15/12/29 16:30:52 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186) with 2 output partitions
15/12/29 16:30:52 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186)
15/12/29 16:30:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
15/12/29 16:30:52 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
15/12/29 16:30:52 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184), which has no missing parents
15/12/29 16:30:52 INFO MemoryStore: ensureFreeSpace(7120) called with curMem=0, maxMem=567505059
15/12/29 16:30:52 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 7.0 KB, free 541.2 MB)
15/12/29 16:30:52 INFO MemoryStore: ensureFreeSpace(4573) called with curMem=7120, maxMem=567505059
15/12/29 16:30:52 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.5 KB, free 541.2 MB)
15/12/29 16:30:52 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:43196 (size: 4.5 KB, free: 541.2 MB)
15/12/29 16:30:52 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
15/12/29 16:30:52 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184)
15/12/29 16:30:52 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
15/12/29 16:30:52 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2401 bytes)
15/12/29 16:30:52 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2424 bytes)
15/12/29 16:30:52 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
15/12/29 16:30:52 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1451386852119
15/12/29 16:30:52 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
15/12/29 16:30:52 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/userFiles-398765d8-ee05-4712-9ea0-2a3aa47f011f/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
*** Introductory Examples for the NLTK Book ***
Loading text1, ..., text9 and sent1, ..., sent9
Type the name of the text or sentence to view it.
Type: 'texts()' or 'sents()' to list the materials.
*** Introductory Examples for the NLTK Book ***
Loading text1, ..., text9 and sent1, ..., sent9
Type the name of the text or sentence to view it.
Type: 'texts()' or 'sents()' to list the materials.
text1: Moby Dick by Herman Melville 1851
text1: Moby Dick by Herman Melville 1851
text2: Sense and Sensibility by Jane Austen 1811
text3: The Book of Genesis
text2: Sense and Sensibility by Jane Austen 1811
text3: The Book of Genesis
text4: Inaugural Address Corpus
text4: Inaugural Address Corpus
text5: Chat Corpus
text6: Monty Python and the Holy Grail
text5: Chat Corpus
text6: Monty Python and the Holy Grail
text7: Wall Street Journal
text7: Wall Street Journal
text8: Personals Corpus
text8: Personals Corpus
text9: The Man Who Was Thursday by G . K . Chesterton 1908
mapFunction_Parents(): keyword =  locomotive ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
text9: The Man Who Was Thursday by G . K . Chesterton 1908
mapFunction_Parents(): keyword =  provided ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  railway ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  powered ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  car ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  electricity ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  drawn ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  cars ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  line ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'coupled']
reduceFunction_Parents(): returns= [u'coupled']
mapFunction_Parents(): keyword =  coupled ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'coupled']
mapFunction_Parents(): keyword =  together ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'railway']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway']
mapFunction_Parents(): keyword =  public ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'coupled']
15/12/29 16:31:29 INFO PythonRunner: Times: total = 37090, boot = 492, init = 28370, finish = 8228
15/12/29 16:31:29 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
15/12/29 16:31:29 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 37184 ms on localhost (1/2)
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway']
mapFunction_Parents(): keyword =  transport ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'line', u'transport']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:31:29 INFO PythonRunner: Times: total = 37265, boot = 485, init = 28311, finish = 8469
15/12/29 16:31:29 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
15/12/29 16:31:29 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 37370 ms on localhost (2/2)
15/12/29 16:31:29 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184) finished in 37.372 s
15/12/29 16:31:29 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
15/12/29 16:31:29 INFO DAGScheduler: looking for newly runnable stages
15/12/29 16:31:29 INFO DAGScheduler: running: Set()
15/12/29 16:31:29 INFO DAGScheduler: waiting: Set(ResultStage 1)
15/12/29 16:31:29 INFO DAGScheduler: failed: Set()
15/12/29 16:31:29 INFO DAGScheduler: Missing parents for ResultStage 1: List()
15/12/29 16:31:29 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186), which is now runnable
15/12/29 16:31:29 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11693, maxMem=567505059
15/12/29 16:31:29 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 541.2 MB)
15/12/29 16:31:29 INFO MemoryStore: ensureFreeSpace(3054) called with curMem=16677, maxMem=567505059
15/12/29 16:31:29 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 541.2 MB)
15/12/29 16:31:29 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:43196 (size: 3.0 KB, free: 541.2 MB)
15/12/29 16:31:29 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
15/12/29 16:31:29 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186)
15/12/29 16:31:29 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
15/12/29 16:31:29 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
15/12/29 16:31:29 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
15/12/29 16:31:29 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
15/12/29 16:31:29 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/12/29 16:31:29 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
15/12/29 16:31:29 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/12/29 16:31:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
15/12/29 16:31:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
reduceFunction_Parents(): returns= [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:31:29 INFO PythonRunner: Times: total = 92, boot = 91, init = 1, finish = 0
15/12/29 16:31:29 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1360 bytes result sent to driver
15/12/29 16:31:29 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 114 ms on localhost (1/2)
15/12/29 16:31:29 INFO PythonRunner: Times: total = 255, boot = 255, init = 0, finish = 0
15/12/29 16:31:29 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
15/12/29 16:31:29 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 271 ms on localhost (2/2)
15/12/29 16:31:29 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186) finished in 0.272 s
15/12/29 16:31:29 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186, took 37.700492 s
15/12/29 16:31:29 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
15/12/29 16:31:30 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189
15/12/29 16:31:30 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189) with 2 output partitions
15/12/29 16:31:30 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189)
15/12/29 16:31:30 INFO DAGScheduler: Parents of final stage: List()
15/12/29 16:31:30 INFO DAGScheduler: Missing parents: List()
15/12/29 16:31:30 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189), which has no missing parents
15/12/29 16:31:30 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19731, maxMem=567505059
15/12/29 16:31:30 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 541.2 MB)
15/12/29 16:31:30 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25547, maxMem=567505059
15/12/29 16:31:30 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 541.2 MB)
15/12/29 16:31:30 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:43196 (size: 3.3 KB, free: 541.2 MB)
15/12/29 16:31:30 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
15/12/29 16:31:30 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189)
15/12/29 16:31:30 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
15/12/29 16:31:30 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
15/12/29 16:31:30 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2441 bytes)
15/12/29 16:31:30 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
15/12/29 16:31:30 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
15/12/29 16:31:30 INFO PythonRunner: Times: total = 58, boot = 58, init = 0, finish = 0
15/12/29 16:31:30 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
15/12/29 16:31:30 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 69 ms on localhost (1/2)
15/12/29 16:31:30 INFO PythonRunner: Times: total = 226, boot = 226, init = 0, finish = 0
15/12/29 16:31:30 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1422 bytes result sent to driver
15/12/29 16:31:30 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 236 ms on localhost (2/2)
15/12/29 16:31:30 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
15/12/29 16:31:30 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189) finished in 0.228 s
15/12/29 16:31:30 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189, took 0.256408 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
15/12/29 16:31:30 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
15/12/29 16:31:30 INFO DAGScheduler: Stopping DAGScheduler
15/12/29 16:31:30 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
15/12/29 16:31:30 INFO MemoryStore: MemoryStore cleared
15/12/29 16:31:30 INFO BlockManager: BlockManager stopped
15/12/29 16:31:30 INFO BlockManagerMaster: BlockManagerMaster stopped
15/12/29 16:31:30 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
15/12/29 16:31:30 INFO SparkContext: Successfully stopped SparkContext
15/12/29 16:31:30 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
15/12/29 16:31:30 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
15/12/29 16:31:30 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:31:31 INFO SparkContext: Running Spark version 1.5.2
15/12/29 16:31:31 INFO SecurityManager: Changing view acls to: root
15/12/29 16:31:31 INFO SecurityManager: Changing modify acls to: root
15/12/29 16:31:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
15/12/29 16:31:31 INFO Slf4jLogger: Slf4jLogger started
15/12/29 16:31:31 INFO Remoting: Starting remoting
15/12/29 16:31:31 INFO Utils: Successfully started service 'sparkDriver' on port 54847.
15/12/29 16:31:31 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:54847]
15/12/29 16:31:31 INFO SparkEnv: Registering MapOutputTracker
15/12/29 16:31:31 INFO SparkEnv: Registering BlockManagerMaster
15/12/29 16:31:31 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-bcce70a2-6209-4ab7-8ba5-7e3f4b511ecc
15/12/29 16:31:31 INFO MemoryStore: MemoryStore started with capacity 541.2 MB
15/12/29 16:31:31 INFO HttpFileServer: HTTP File server directory is /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/httpd-12ca2c2e-aa8a-46e1-b315-98b13eebbfac
15/12/29 16:31:31 INFO HttpServer: Starting HTTP Server
15/12/29 16:31:31 INFO Utils: Successfully started service 'HTTP file server' on port 41108.
15/12/29 16:31:31 INFO SparkEnv: Registering OutputCommitCoordinator
15/12/29 16:31:31 INFO Utils: Successfully started service 'SparkUI' on port 4040.
15/12/29 16:31:31 INFO SparkUI: Started SparkUI at http://localhost:4040
15/12/29 16:31:32 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/userFiles-e0bd4d42-1251-4484-a9d6-1dda98dfc5e7/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
15/12/29 16:31:32 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1451386892018
15/12/29 16:31:32 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
15/12/29 16:31:32 INFO Executor: Starting executor ID driver on host localhost
15/12/29 16:31:32 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59934.
15/12/29 16:31:32 INFO NettyBlockTransferService: Server created on 59934
15/12/29 16:31:32 INFO BlockManagerMaster: Trying to register BlockManager
15/12/29 16:31:32 INFO BlockManagerMasterEndpoint: Registering block manager localhost:59934 with 541.2 MB RAM, BlockManagerId(driver, localhost, 59934)
15/12/29 16:31:32 INFO BlockManagerMaster: Registered BlockManager
15/12/29 16:31:32 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186
15/12/29 16:31:32 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184)
15/12/29 16:31:32 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186) with 2 output partitions
15/12/29 16:31:32 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186)
15/12/29 16:31:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
15/12/29 16:31:32 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
15/12/29 16:31:32 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184), which has no missing parents
15/12/29 16:31:32 INFO MemoryStore: ensureFreeSpace(7120) called with curMem=0, maxMem=567505059
15/12/29 16:31:32 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 7.0 KB, free 541.2 MB)
15/12/29 16:31:32 INFO MemoryStore: ensureFreeSpace(4573) called with curMem=7120, maxMem=567505059
15/12/29 16:31:32 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.5 KB, free 541.2 MB)
15/12/29 16:31:32 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:59934 (size: 4.5 KB, free: 541.2 MB)
15/12/29 16:31:32 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
15/12/29 16:31:32 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184)
15/12/29 16:31:32 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
15/12/29 16:31:32 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2401 bytes)
15/12/29 16:31:32 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2424 bytes)
15/12/29 16:31:32 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
15/12/29 16:31:32 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1451386892018
15/12/29 16:31:32 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
15/12/29 16:31:32 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/userFiles-e0bd4d42-1251-4484-a9d6-1dda98dfc5e7/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
*** Introductory Examples for the NLTK Book ***
Loading text1, ..., text9 and sent1, ..., sent9
Type the name of the text or sentence to view it.
Type: 'texts()' or 'sents()' to list the materials.
*** Introductory Examples for the NLTK Book ***
Loading text1, ..., text9 and sent1, ..., sent9
Type the name of the text or sentence to view it.
Type: 'texts()' or 'sents()' to list the materials.
text1: Moby Dick by Herman Melville 1851
text1: Moby Dick by Herman Melville 1851
text2: Sense and Sensibility by Jane Austen 1811
text3: The Book of Genesis
text2: Sense and Sensibility by Jane Austen 1811
text3: The Book of Genesis
text4: Inaugural Address Corpus
text4: Inaugural Address Corpus
text5: Chat Corpus
text6: Monty Python and the Holy Grail
text5: Chat Corpus
text6: Monty Python and the Holy Grail
text7: Wall Street Journal
text8: Personals Corpus
text9: The Man Who Was Thursday by G . K . Chesterton 1908
mapFunction_Parents(): keyword =  locomotive ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
text7: Wall Street Journal
text8: Personals Corpus
text9: The Man Who Was Thursday by G . K . Chesterton 1908
mapFunction_Parents(): keyword =  provided ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  railway ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  car ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  drawn ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  line ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'railway']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway']
mapFunction_Parents(): keyword =  public ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway']
mapFunction_Parents(): keyword =  transport ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'line', u'transport']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:32:07 INFO PythonRunner: Times: total = 34874, boot = 462, init = 26545, finish = 7867
15/12/29 16:32:07 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
15/12/29 16:32:07 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 34986 ms on localhost (1/2)
mapFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  powered ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  electricity ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  cars ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'coupled']
reduceFunction_Parents(): returns= [u'coupled']
mapFunction_Parents(): keyword =  coupled ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'coupled']
mapFunction_Parents(): keyword =  together ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'coupled']
15/12/29 16:32:10 INFO PythonRunner: Times: total = 38034, boot = 463, init = 29302, finish = 8269
15/12/29 16:32:10 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
15/12/29 16:32:10 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184) finished in 38.111 s
15/12/29 16:32:10 INFO DAGScheduler: looking for newly runnable stages
15/12/29 16:32:10 INFO DAGScheduler: running: Set()
15/12/29 16:32:10 INFO DAGScheduler: waiting: Set(ResultStage 1)
15/12/29 16:32:10 INFO DAGScheduler: failed: Set()
15/12/29 16:32:10 INFO DAGScheduler: Missing parents for ResultStage 1: List()
15/12/29 16:32:10 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186), which is now runnable
15/12/29 16:32:10 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11693, maxMem=567505059
15/12/29 16:32:10 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 541.2 MB)
15/12/29 16:32:10 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 38136 ms on localhost (2/2)
15/12/29 16:32:10 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
15/12/29 16:32:10 INFO MemoryStore: ensureFreeSpace(3054) called with curMem=16677, maxMem=567505059
15/12/29 16:32:10 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 541.2 MB)
15/12/29 16:32:10 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:59934 (size: 3.0 KB, free: 541.2 MB)
15/12/29 16:32:10 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
15/12/29 16:32:10 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186)
15/12/29 16:32:10 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
15/12/29 16:32:10 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
15/12/29 16:32:10 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
15/12/29 16:32:10 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
15/12/29 16:32:10 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
15/12/29 16:32:10 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/12/29 16:32:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
15/12/29 16:32:10 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/12/29 16:32:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
reduceFunction_Parents(): returns= [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:32:10 INFO PythonRunner: Times: total = 21, boot = -2944, init = 2964, finish = 1
15/12/29 16:32:10 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1360 bytes result sent to driver
15/12/29 16:32:10 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 73 ms on localhost (1/2)
15/12/29 16:32:10 INFO PythonRunner: Times: total = 249, boot = 248, init = 0, finish = 1
15/12/29 16:32:10 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
15/12/29 16:32:10 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 266 ms on localhost (2/2)
15/12/29 16:32:10 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186) finished in 0.207 s
15/12/29 16:32:10 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186, took 38.454020 s
15/12/29 16:32:10 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
15/12/29 16:32:10 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189
15/12/29 16:32:10 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189) with 2 output partitions
15/12/29 16:32:10 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189)
15/12/29 16:32:10 INFO DAGScheduler: Parents of final stage: List()
15/12/29 16:32:10 INFO DAGScheduler: Missing parents: List()
15/12/29 16:32:10 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189), which has no missing parents
15/12/29 16:32:10 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19731, maxMem=567505059
15/12/29 16:32:10 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 541.2 MB)
15/12/29 16:32:10 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25547, maxMem=567505059
15/12/29 16:32:10 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 541.2 MB)
15/12/29 16:32:10 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:59934 (size: 3.3 KB, free: 541.2 MB)
15/12/29 16:32:10 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
15/12/29 16:32:10 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189)
15/12/29 16:32:10 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
15/12/29 16:32:10 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
15/12/29 16:32:10 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2441 bytes)
15/12/29 16:32:10 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
15/12/29 16:32:10 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
15/12/29 16:32:10 INFO PythonRunner: Times: total = 69, boot = 3, init = 65, finish = 1
15/12/29 16:32:10 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1422 bytes result sent to driver
15/12/29 16:32:10 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 81 ms on localhost (1/2)
15/12/29 16:32:10 INFO PythonRunner: Times: total = 180, boot = 180, init = 0, finish = 0
15/12/29 16:32:10 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
15/12/29 16:32:10 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 192 ms on localhost (2/2)
15/12/29 16:32:10 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
15/12/29 16:32:10 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189) finished in 0.192 s
15/12/29 16:32:10 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189, took 0.222872 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
15/12/29 16:32:11 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
15/12/29 16:32:11 INFO DAGScheduler: Stopping DAGScheduler
15/12/29 16:32:11 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
15/12/29 16:32:11 INFO MemoryStore: MemoryStore cleared
15/12/29 16:32:11 INFO BlockManager: BlockManager stopped
15/12/29 16:32:11 INFO BlockManagerMaster: BlockManagerMaster stopped
15/12/29 16:32:11 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
15/12/29 16:32:11 INFO SparkContext: Successfully stopped SparkContext
15/12/29 16:32:11 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
15/12/29 16:32:11 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
15/12/29 16:32:11 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:32:11 INFO SparkContext: Running Spark version 1.5.2
15/12/29 16:32:11 INFO SecurityManager: Changing view acls to: root
15/12/29 16:32:11 INFO SecurityManager: Changing modify acls to: root
15/12/29 16:32:11 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
15/12/29 16:32:12 INFO Slf4jLogger: Slf4jLogger started
15/12/29 16:32:12 INFO Remoting: Starting remoting
15/12/29 16:32:12 INFO Utils: Successfully started service 'sparkDriver' on port 50085.
15/12/29 16:32:12 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:50085]
15/12/29 16:32:12 INFO SparkEnv: Registering MapOutputTracker
15/12/29 16:32:12 INFO SparkEnv: Registering BlockManagerMaster
15/12/29 16:32:12 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-d9e2b1f9-cc80-45c2-943c-2ffb20746db0
15/12/29 16:32:12 INFO MemoryStore: MemoryStore started with capacity 541.2 MB
15/12/29 16:32:12 INFO HttpFileServer: HTTP File server directory is /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/httpd-359e7b2f-3b93-4305-8046-7551edcd01b0
15/12/29 16:32:12 INFO HttpServer: Starting HTTP Server
15/12/29 16:32:12 INFO Utils: Successfully started service 'HTTP file server' on port 39070.
15/12/29 16:32:12 INFO SparkEnv: Registering OutputCommitCoordinator
15/12/29 16:32:12 INFO Utils: Successfully started service 'SparkUI' on port 4040.
15/12/29 16:32:12 INFO SparkUI: Started SparkUI at http://localhost:4040
15/12/29 16:32:12 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/userFiles-b4b16b18-7b8c-4507-83a1-1de87badf0c9/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
15/12/29 16:32:12 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1451386932418
15/12/29 16:32:12 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
15/12/29 16:32:12 INFO Executor: Starting executor ID driver on host localhost
15/12/29 16:32:12 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59150.
15/12/29 16:32:12 INFO NettyBlockTransferService: Server created on 59150
15/12/29 16:32:12 INFO BlockManagerMaster: Trying to register BlockManager
15/12/29 16:32:12 INFO BlockManagerMasterEndpoint: Registering block manager localhost:59150 with 541.2 MB RAM, BlockManagerId(driver, localhost, 59150)
15/12/29 16:32:12 INFO BlockManagerMaster: Registered BlockManager
15/12/29 16:32:12 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186
15/12/29 16:32:12 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184)
15/12/29 16:32:12 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186) with 2 output partitions
15/12/29 16:32:12 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186)
15/12/29 16:32:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
15/12/29 16:32:12 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
15/12/29 16:32:12 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184), which has no missing parents
15/12/29 16:32:12 INFO MemoryStore: ensureFreeSpace(7120) called with curMem=0, maxMem=567505059
15/12/29 16:32:12 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 7.0 KB, free 541.2 MB)
15/12/29 16:32:12 INFO MemoryStore: ensureFreeSpace(4573) called with curMem=7120, maxMem=567505059
15/12/29 16:32:12 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.5 KB, free 541.2 MB)
15/12/29 16:32:12 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:59150 (size: 4.5 KB, free: 541.2 MB)
15/12/29 16:32:12 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
15/12/29 16:32:12 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184)
15/12/29 16:32:12 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
15/12/29 16:32:12 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2401 bytes)
15/12/29 16:32:12 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2424 bytes)
15/12/29 16:32:12 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
15/12/29 16:32:12 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1451386932418
15/12/29 16:32:12 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/userFiles-b4b16b18-7b8c-4507-83a1-1de87badf0c9/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
15/12/29 16:32:12 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
*** Introductory Examples for the NLTK Book ***
Loading text1, ..., text9 and sent1, ..., sent9
Type the name of the text or sentence to view it.
Type: 'texts()' or 'sents()' to list the materials.
*** Introductory Examples for the NLTK Book ***
Loading text1, ..., text9 and sent1, ..., sent9
Type the name of the text or sentence to view it.
Type: 'texts()' or 'sents()' to list the materials.
text1: Moby Dick by Herman Melville 1851
text1: Moby Dick by Herman Melville 1851
text2: Sense and Sensibility by Jane Austen 1811
text3: The Book of Genesis
text2: Sense and Sensibility by Jane Austen 1811
text3: The Book of Genesis
text4: Inaugural Address Corpus
text4: Inaugural Address Corpus
text5: Chat Corpus
text6: Monty Python and the Holy Grail
text5: Chat Corpus
text6: Monty Python and the Holy Grail
text7: Wall Street Journal
text8: Personals Corpus
text9: The Man Who Was Thursday by G . K . Chesterton 1908
mapFunction_Parents(): keyword =  provided ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
text7: Wall Street Journal
text8: Personals Corpus
text9: The Man Who Was Thursday by G . K . Chesterton 1908
mapFunction_Parents(): keyword =  locomotive ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  powered ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  electricity ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  cars ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'coupled']
reduceFunction_Parents(): returns= [u'coupled']
mapFunction_Parents(): keyword =  coupled ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  railway ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'coupled']
mapFunction_Parents(): keyword =  together ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  car ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  drawn ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'coupled']
15/12/29 16:32:48 INFO PythonRunner: Times: total = 36219, boot = 447, init = 27509, finish = 8263
15/12/29 16:32:48 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
15/12/29 16:32:48 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 36292 ms on localhost (1/2)
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  line ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'railway']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway']
mapFunction_Parents(): keyword =  public ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway']
mapFunction_Parents(): keyword =  transport ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'line', u'transport']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:32:49 INFO PythonRunner: Times: total = 36593, boot = 444, init = 28072, finish = 8077
15/12/29 16:32:49 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
15/12/29 16:32:49 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184) finished in 36.659 s
15/12/29 16:32:49 INFO DAGScheduler: looking for newly runnable stages
15/12/29 16:32:49 INFO DAGScheduler: running: Set()
15/12/29 16:32:49 INFO DAGScheduler: waiting: Set(ResultStage 1)
15/12/29 16:32:49 INFO DAGScheduler: failed: Set()
15/12/29 16:32:49 INFO DAGScheduler: Missing parents for ResultStage 1: List()
15/12/29 16:32:49 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186), which is now runnable
15/12/29 16:32:49 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11693, maxMem=567505059
15/12/29 16:32:49 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 541.2 MB)
15/12/29 16:32:49 INFO MemoryStore: ensureFreeSpace(3054) called with curMem=16677, maxMem=567505059
15/12/29 16:32:49 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 541.2 MB)
15/12/29 16:32:49 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 36658 ms on localhost (2/2)
15/12/29 16:32:49 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
15/12/29 16:32:49 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:59150 (size: 3.0 KB, free: 541.2 MB)
15/12/29 16:32:49 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
15/12/29 16:32:49 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186)
15/12/29 16:32:49 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
15/12/29 16:32:49 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
15/12/29 16:32:49 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
15/12/29 16:32:49 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
15/12/29 16:32:49 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
15/12/29 16:32:49 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/12/29 16:32:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
15/12/29 16:32:49 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/12/29 16:32:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
15/12/29 16:32:49 INFO PythonRunner: Times: total = 16, boot = -161, init = 177, finish = 0
15/12/29 16:32:49 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
15/12/29 16:32:49 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 41 ms on localhost (1/2)
reduceFunction_Parents(): returns= [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:32:49 INFO PythonRunner: Times: total = 307, boot = 306, init = 0, finish = 1
15/12/29 16:32:49 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1360 bytes result sent to driver
15/12/29 16:32:49 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 319 ms on localhost (2/2)
15/12/29 16:32:49 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186) finished in 0.321 s
15/12/29 16:32:49 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186, took 37.005981 s
15/12/29 16:32:49 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
15/12/29 16:32:49 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189
15/12/29 16:32:49 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189) with 2 output partitions
15/12/29 16:32:49 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189)
15/12/29 16:32:49 INFO DAGScheduler: Parents of final stage: List()
15/12/29 16:32:49 INFO DAGScheduler: Missing parents: List()
15/12/29 16:32:49 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189), which has no missing parents
15/12/29 16:32:49 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19731, maxMem=567505059
15/12/29 16:32:49 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 541.2 MB)
15/12/29 16:32:49 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25547, maxMem=567505059
15/12/29 16:32:49 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 541.2 MB)
15/12/29 16:32:49 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:59150 (size: 3.3 KB, free: 541.2 MB)
15/12/29 16:32:49 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
15/12/29 16:32:49 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189)
15/12/29 16:32:49 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
15/12/29 16:32:49 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
15/12/29 16:32:49 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2441 bytes)
15/12/29 16:32:49 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
15/12/29 16:32:49 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
15/12/29 16:32:49 INFO PythonRunner: Times: total = 60, boot = -147, init = 207, finish = 0
15/12/29 16:32:49 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
15/12/29 16:32:49 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 80 ms on localhost (1/2)
15/12/29 16:32:49 INFO PythonRunner: Times: total = 165, boot = 163, init = 1, finish = 1
15/12/29 16:32:49 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1422 bytes result sent to driver
15/12/29 16:32:49 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 186 ms on localhost (2/2)
15/12/29 16:32:49 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
15/12/29 16:32:49 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189) finished in 0.188 s
15/12/29 16:32:49 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189, took 0.209661 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
15/12/29 16:32:49 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
15/12/29 16:32:49 INFO DAGScheduler: Stopping DAGScheduler
15/12/29 16:32:50 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
15/12/29 16:32:50 INFO MemoryStore: MemoryStore cleared
15/12/29 16:32:50 INFO BlockManager: BlockManager stopped
15/12/29 16:32:50 INFO BlockManagerMaster: BlockManagerMaster stopped
15/12/29 16:32:50 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
15/12/29 16:32:50 INFO SparkContext: Successfully stopped SparkContext
15/12/29 16:32:50 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
15/12/29 16:32:50 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
15/12/29 16:32:50 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:32:50 INFO SparkContext: Running Spark version 1.5.2
15/12/29 16:32:50 INFO SecurityManager: Changing view acls to: root
15/12/29 16:32:50 INFO SecurityManager: Changing modify acls to: root
15/12/29 16:32:50 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
15/12/29 16:32:50 INFO Slf4jLogger: Slf4jLogger started
15/12/29 16:32:50 INFO Remoting: Starting remoting
15/12/29 16:32:50 INFO Utils: Successfully started service 'sparkDriver' on port 39382.
15/12/29 16:32:50 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:39382]
15/12/29 16:32:50 INFO SparkEnv: Registering MapOutputTracker
15/12/29 16:32:50 INFO SparkEnv: Registering BlockManagerMaster
15/12/29 16:32:50 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-37e21f5c-8a97-46ed-a820-d9d56962dd5b
15/12/29 16:32:50 INFO MemoryStore: MemoryStore started with capacity 541.2 MB
15/12/29 16:32:50 INFO HttpFileServer: HTTP File server directory is /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/httpd-0f6c5a24-0942-4646-b318-bff5c301b8f5
15/12/29 16:32:50 INFO HttpServer: Starting HTTP Server
15/12/29 16:32:51 INFO Utils: Successfully started service 'HTTP file server' on port 50267.
15/12/29 16:32:51 INFO SparkEnv: Registering OutputCommitCoordinator
15/12/29 16:32:51 INFO Utils: Successfully started service 'SparkUI' on port 4040.
15/12/29 16:32:51 INFO SparkUI: Started SparkUI at http://localhost:4040
15/12/29 16:32:51 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/userFiles-98589965-1e40-47c4-a2ef-d2ce07a18d6d/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
15/12/29 16:32:51 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1451386971463
15/12/29 16:32:51 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
15/12/29 16:32:51 INFO Executor: Starting executor ID driver on host localhost
15/12/29 16:32:51 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54752.
15/12/29 16:32:51 INFO NettyBlockTransferService: Server created on 54752
15/12/29 16:32:51 INFO BlockManagerMaster: Trying to register BlockManager
15/12/29 16:32:51 INFO BlockManagerMasterEndpoint: Registering block manager localhost:54752 with 541.2 MB RAM, BlockManagerId(driver, localhost, 54752)
15/12/29 16:32:51 INFO BlockManagerMaster: Registered BlockManager
15/12/29 16:32:51 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186
15/12/29 16:32:51 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184)
15/12/29 16:32:51 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186) with 2 output partitions
15/12/29 16:32:51 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186)
15/12/29 16:32:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
15/12/29 16:32:51 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
15/12/29 16:32:51 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184), which has no missing parents
15/12/29 16:32:51 INFO MemoryStore: ensureFreeSpace(7120) called with curMem=0, maxMem=567505059
15/12/29 16:32:51 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 7.0 KB, free 541.2 MB)
15/12/29 16:32:51 INFO MemoryStore: ensureFreeSpace(4573) called with curMem=7120, maxMem=567505059
15/12/29 16:32:51 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.5 KB, free 541.2 MB)
15/12/29 16:32:51 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:54752 (size: 4.5 KB, free: 541.2 MB)
15/12/29 16:32:51 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
15/12/29 16:32:51 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184)
15/12/29 16:32:51 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
15/12/29 16:32:51 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2401 bytes)
15/12/29 16:32:51 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2424 bytes)
15/12/29 16:32:51 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
15/12/29 16:32:51 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1451386971463
15/12/29 16:32:51 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
15/12/29 16:32:51 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/userFiles-98589965-1e40-47c4-a2ef-d2ce07a18d6d/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
*** Introductory Examples for the NLTK Book ***
Loading text1, ..., text9 and sent1, ..., sent9
Type the name of the text or sentence to view it.
Type: 'texts()' or 'sents()' to list the materials.
*** Introductory Examples for the NLTK Book ***
Loading text1, ..., text9 and sent1, ..., sent9
Type the name of the text or sentence to view it.
Type: 'texts()' or 'sents()' to list the materials.
text1: Moby Dick by Herman Melville 1851
text1: Moby Dick by Herman Melville 1851
text2: Sense and Sensibility by Jane Austen 1811
text3: The Book of Genesis
text2: Sense and Sensibility by Jane Austen 1811
text3: The Book of Genesis
text4: Inaugural Address Corpus
text4: Inaugural Address Corpus
text5: Chat Corpus
text6: Monty Python and the Holy Grail
text5: Chat Corpus
text6: Monty Python and the Holy Grail
text7: Wall Street Journal
text8: Personals Corpus
text9: The Man Who Was Thursday by G . K . Chesterton 1908
mapFunction_Parents(): keyword =  locomotive ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
text7: Wall Street Journal
text8: Personals Corpus
text9: The Man Who Was Thursday by G . K . Chesterton 1908
mapFunction_Parents(): keyword =  provided ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  railway ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  car ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  drawn ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  line ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'railway']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway']
mapFunction_Parents(): keyword =  public ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway']
mapFunction_Parents(): keyword =  transport ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'line', u'transport']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:33:28 INFO PythonRunner: Times: total = 37161, boot = 468, init = 27823, finish = 8870
15/12/29 16:33:28 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
15/12/29 16:33:28 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 37261 ms on localhost (1/2)
mapFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  powered ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  electricity ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  cars ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'coupled']
reduceFunction_Parents(): returns= [u'coupled']
mapFunction_Parents(): keyword =  coupled ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'coupled']
mapFunction_Parents(): keyword =  together ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'coupled']
15/12/29 16:33:29 INFO PythonRunner: Times: total = 37696, boot = 471, init = 28705, finish = 8520
15/12/29 16:33:29 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
15/12/29 16:33:29 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184) finished in 37.753 s
15/12/29 16:33:29 INFO DAGScheduler: looking for newly runnable stages
15/12/29 16:33:29 INFO DAGScheduler: running: Set()
15/12/29 16:33:29 INFO DAGScheduler: waiting: Set(ResultStage 1)
15/12/29 16:33:29 INFO DAGScheduler: failed: Set()
15/12/29 16:33:29 INFO DAGScheduler: Missing parents for ResultStage 1: List()
15/12/29 16:33:29 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186), which is now runnable
15/12/29 16:33:29 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11693, maxMem=567505059
15/12/29 16:33:29 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 541.2 MB)
15/12/29 16:33:29 INFO MemoryStore: ensureFreeSpace(3054) called with curMem=16677, maxMem=567505059
15/12/29 16:33:29 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 541.2 MB)
15/12/29 16:33:29 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 37770 ms on localhost (2/2)
15/12/29 16:33:29 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
15/12/29 16:33:29 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:54752 (size: 3.0 KB, free: 541.2 MB)
15/12/29 16:33:29 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
15/12/29 16:33:29 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186)
15/12/29 16:33:29 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
15/12/29 16:33:29 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
15/12/29 16:33:29 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
15/12/29 16:33:29 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
15/12/29 16:33:29 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
15/12/29 16:33:29 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/12/29 16:33:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
15/12/29 16:33:29 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/12/29 16:33:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
reduceFunction_Parents(): returns= [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:33:29 INFO PythonRunner: Times: total = 22, boot = -228, init = 249, finish = 1
15/12/29 16:33:29 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1360 bytes result sent to driver
15/12/29 16:33:29 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 78 ms on localhost (1/2)
15/12/29 16:33:29 INFO PythonRunner: Times: total = 281, boot = 280, init = 1, finish = 0
15/12/29 16:33:29 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
15/12/29 16:33:29 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 304 ms on localhost (2/2)
15/12/29 16:33:29 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
15/12/29 16:33:29 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186) finished in 0.301 s
15/12/29 16:33:29 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186, took 38.100850 s
15/12/29 16:33:29 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189
15/12/29 16:33:29 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189) with 2 output partitions
15/12/29 16:33:29 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189)
15/12/29 16:33:29 INFO DAGScheduler: Parents of final stage: List()
15/12/29 16:33:29 INFO DAGScheduler: Missing parents: List()
15/12/29 16:33:29 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189), which has no missing parents
15/12/29 16:33:29 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19731, maxMem=567505059
15/12/29 16:33:29 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 541.2 MB)
15/12/29 16:33:29 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25547, maxMem=567505059
15/12/29 16:33:29 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 541.2 MB)
15/12/29 16:33:29 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:54752 (size: 3.3 KB, free: 541.2 MB)
15/12/29 16:33:29 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
15/12/29 16:33:29 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189)
15/12/29 16:33:29 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
15/12/29 16:33:29 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
15/12/29 16:33:29 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2441 bytes)
15/12/29 16:33:29 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
15/12/29 16:33:29 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
15/12/29 16:33:29 INFO PythonRunner: Times: total = 50, boot = -132, init = 182, finish = 0
15/12/29 16:33:29 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1422 bytes result sent to driver
15/12/29 16:33:29 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 73 ms on localhost (1/2)
15/12/29 16:33:30 INFO PythonRunner: Times: total = 171, boot = 170, init = 1, finish = 0
15/12/29 16:33:30 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
15/12/29 16:33:30 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 196 ms on localhost (2/2)
15/12/29 16:33:30 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
15/12/29 16:33:30 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189) finished in 0.196 s
15/12/29 16:33:30 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189, took 0.206953 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
15/12/29 16:33:30 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
15/12/29 16:33:30 INFO DAGScheduler: Stopping DAGScheduler
15/12/29 16:33:30 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
15/12/29 16:33:30 INFO MemoryStore: MemoryStore cleared
15/12/29 16:33:30 INFO BlockManager: BlockManager stopped
15/12/29 16:33:30 INFO BlockManagerMaster: BlockManagerMaster stopped
15/12/29 16:33:30 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
15/12/29 16:33:30 INFO SparkContext: Successfully stopped SparkContext
15/12/29 16:33:30 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
15/12/29 16:33:30 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
15/12/29 16:33:30 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:33:31 INFO SparkContext: Running Spark version 1.5.2
15/12/29 16:33:31 INFO SecurityManager: Changing view acls to: root
15/12/29 16:33:31 INFO SecurityManager: Changing modify acls to: root
15/12/29 16:33:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
15/12/29 16:33:31 INFO Slf4jLogger: Slf4jLogger started
15/12/29 16:33:31 INFO Remoting: Starting remoting
15/12/29 16:33:31 INFO Utils: Successfully started service 'sparkDriver' on port 37488.
15/12/29 16:33:31 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:37488]
15/12/29 16:33:31 INFO SparkEnv: Registering MapOutputTracker
15/12/29 16:33:31 INFO SparkEnv: Registering BlockManagerMaster
15/12/29 16:33:31 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-7239eacb-a0d4-4c74-906f-1e957c4f4e61
15/12/29 16:33:31 INFO MemoryStore: MemoryStore started with capacity 535.0 MB
15/12/29 16:33:31 INFO HttpFileServer: HTTP File server directory is /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/httpd-c3a376e2-b919-428f-b04b-60f4f92febb8
15/12/29 16:33:31 INFO HttpServer: Starting HTTP Server
15/12/29 16:33:31 INFO Utils: Successfully started service 'HTTP file server' on port 45547.
15/12/29 16:33:31 INFO SparkEnv: Registering OutputCommitCoordinator
15/12/29 16:33:31 INFO Utils: Successfully started service 'SparkUI' on port 4040.
15/12/29 16:33:31 INFO SparkUI: Started SparkUI at http://localhost:4040
15/12/29 16:33:31 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/userFiles-6682c5d2-bf86-4982-bca6-0afded2af626/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
15/12/29 16:33:31 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1451387011541
15/12/29 16:33:31 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
15/12/29 16:33:31 INFO Executor: Starting executor ID driver on host localhost
15/12/29 16:33:31 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52505.
15/12/29 16:33:31 INFO NettyBlockTransferService: Server created on 52505
15/12/29 16:33:31 INFO BlockManagerMaster: Trying to register BlockManager
15/12/29 16:33:31 INFO BlockManagerMasterEndpoint: Registering block manager localhost:52505 with 535.0 MB RAM, BlockManagerId(driver, localhost, 52505)
15/12/29 16:33:31 INFO BlockManagerMaster: Registered BlockManager
15/12/29 16:33:31 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186
15/12/29 16:33:31 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184)
15/12/29 16:33:31 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186) with 2 output partitions
15/12/29 16:33:31 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186)
15/12/29 16:33:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
15/12/29 16:33:31 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
15/12/29 16:33:31 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184), which has no missing parents
15/12/29 16:33:31 INFO MemoryStore: ensureFreeSpace(7120) called with curMem=0, maxMem=560993402
15/12/29 16:33:31 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 7.0 KB, free 535.0 MB)
15/12/29 16:33:31 INFO MemoryStore: ensureFreeSpace(4572) called with curMem=7120, maxMem=560993402
15/12/29 16:33:31 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.5 KB, free 535.0 MB)
15/12/29 16:33:31 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:52505 (size: 4.5 KB, free: 535.0 MB)
15/12/29 16:33:31 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
15/12/29 16:33:31 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184)
15/12/29 16:33:31 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
15/12/29 16:33:31 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2401 bytes)
15/12/29 16:33:31 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2424 bytes)
15/12/29 16:33:31 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
15/12/29 16:33:31 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1451387011541
15/12/29 16:33:31 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
15/12/29 16:33:31 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/userFiles-6682c5d2-bf86-4982-bca6-0afded2af626/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
*** Introductory Examples for the NLTK Book ***
Loading text1, ..., text9 and sent1, ..., sent9
Type the name of the text or sentence to view it.
Type: 'texts()' or 'sents()' to list the materials.
*** Introductory Examples for the NLTK Book ***
Loading text1, ..., text9 and sent1, ..., sent9
Type the name of the text or sentence to view it.
Type: 'texts()' or 'sents()' to list the materials.
text1: Moby Dick by Herman Melville 1851
text1: Moby Dick by Herman Melville 1851
text2: Sense and Sensibility by Jane Austen 1811
text2: Sense and Sensibility by Jane Austen 1811
text3: The Book of Genesis
text3: The Book of Genesis
text4: Inaugural Address Corpus
text4: Inaugural Address Corpus
text5: Chat Corpus
text6: Monty Python and the Holy Grail
text5: Chat Corpus
text6: Monty Python and the Holy Grail
text7: Wall Street Journal
text8: Personals Corpus
text9: The Man Who Was Thursday by G . K . Chesterton 1908
mapFunction_Parents(): keyword =  locomotive ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
text7: Wall Street Journal
text8: Personals Corpus
text9: The Man Who Was Thursday by G . K . Chesterton 1908
mapFunction_Parents(): keyword =  provided ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  railway ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  car ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  drawn ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  line ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  powered ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  electricity ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'railway']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway']
mapFunction_Parents(): keyword =  public ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  cars ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway']
mapFunction_Parents(): keyword =  transport ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'coupled']
reduceFunction_Parents(): returns= [u'coupled']
mapFunction_Parents(): keyword =  coupled ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'coupled']
mapFunction_Parents(): keyword =  together ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'line', u'transport']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:34:08 INFO PythonRunner: Times: total = 37053, boot = 489, init = 27737, finish = 8827
15/12/29 16:34:08 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
15/12/29 16:34:08 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 37137 ms on localhost (1/2)
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'coupled']
15/12/29 16:34:08 INFO PythonRunner: Times: total = 37156, boot = 487, init = 28624, finish = 8045
15/12/29 16:34:08 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
15/12/29 16:34:08 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184) finished in 37.257 s
15/12/29 16:34:08 INFO DAGScheduler: looking for newly runnable stages
15/12/29 16:34:08 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 37255 ms on localhost (2/2)
15/12/29 16:34:08 INFO DAGScheduler: running: Set()
15/12/29 16:34:08 INFO DAGScheduler: waiting: Set(ResultStage 1)
15/12/29 16:34:08 INFO DAGScheduler: failed: Set()
15/12/29 16:34:08 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
15/12/29 16:34:08 INFO DAGScheduler: Missing parents for ResultStage 1: List()
15/12/29 16:34:08 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186), which is now runnable
15/12/29 16:34:08 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11692, maxMem=560993402
15/12/29 16:34:08 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 535.0 MB)
15/12/29 16:34:08 INFO MemoryStore: ensureFreeSpace(3054) called with curMem=16676, maxMem=560993402
15/12/29 16:34:08 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 535.0 MB)
15/12/29 16:34:08 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:52505 (size: 3.0 KB, free: 535.0 MB)
15/12/29 16:34:08 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
15/12/29 16:34:08 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186)
15/12/29 16:34:08 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
15/12/29 16:34:08 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
15/12/29 16:34:08 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
15/12/29 16:34:08 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
15/12/29 16:34:08 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
15/12/29 16:34:08 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/12/29 16:34:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
15/12/29 16:34:08 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/12/29 16:34:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
15/12/29 16:34:09 INFO PythonRunner: Times: total = 162, boot = 162, init = 0, finish = 0
15/12/29 16:34:09 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
15/12/29 16:34:09 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 186 ms on localhost (1/2)
reduceFunction_Parents(): returns= [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:34:09 INFO PythonRunner: Times: total = 275, boot = 272, init = 0, finish = 3
15/12/29 16:34:09 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1360 bytes result sent to driver
15/12/29 16:34:09 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186) finished in 0.298 s
15/12/29 16:34:09 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186, took 37.583030 s
15/12/29 16:34:09 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 296 ms on localhost (2/2)
15/12/29 16:34:09 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
15/12/29 16:34:09 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189
15/12/29 16:34:09 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189) with 2 output partitions
15/12/29 16:34:09 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189)
15/12/29 16:34:09 INFO DAGScheduler: Parents of final stage: List()
15/12/29 16:34:09 INFO DAGScheduler: Missing parents: List()
15/12/29 16:34:09 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189), which has no missing parents
15/12/29 16:34:09 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19730, maxMem=560993402
15/12/29 16:34:09 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 535.0 MB)
15/12/29 16:34:09 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25546, maxMem=560993402
15/12/29 16:34:09 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 535.0 MB)
15/12/29 16:34:09 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:52505 (size: 3.3 KB, free: 535.0 MB)
15/12/29 16:34:09 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
15/12/29 16:34:09 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189)
15/12/29 16:34:09 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
15/12/29 16:34:09 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
15/12/29 16:34:09 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2441 bytes)
15/12/29 16:34:09 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
15/12/29 16:34:09 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
15/12/29 16:34:09 INFO PythonRunner: Times: total = 9, boot = -70, init = 79, finish = 0
15/12/29 16:34:09 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1422 bytes result sent to driver
15/12/29 16:34:09 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 52 ms on localhost (1/2)
15/12/29 16:34:09 INFO PythonRunner: Times: total = 218, boot = 218, init = 0, finish = 0
15/12/29 16:34:09 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
15/12/29 16:34:09 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 228 ms on localhost (2/2)
15/12/29 16:34:09 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
15/12/29 16:34:09 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189) finished in 0.228 s
15/12/29 16:34:09 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189, took 0.252113 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
15/12/29 16:34:09 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
15/12/29 16:34:09 INFO DAGScheduler: Stopping DAGScheduler
15/12/29 16:34:09 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
15/12/29 16:34:09 INFO MemoryStore: MemoryStore cleared
15/12/29 16:34:09 INFO BlockManager: BlockManager stopped
15/12/29 16:34:09 INFO BlockManagerMaster: BlockManagerMaster stopped
15/12/29 16:34:09 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
15/12/29 16:34:09 INFO SparkContext: Successfully stopped SparkContext
15/12/29 16:34:09 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
15/12/29 16:34:09 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
15/12/29 16:34:09 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:34:10 INFO SparkContext: Running Spark version 1.5.2
15/12/29 16:34:10 INFO SecurityManager: Changing view acls to: root
15/12/29 16:34:10 INFO SecurityManager: Changing modify acls to: root
15/12/29 16:34:10 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
15/12/29 16:34:10 INFO Slf4jLogger: Slf4jLogger started
15/12/29 16:34:10 INFO Remoting: Starting remoting
15/12/29 16:34:10 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:50724]
15/12/29 16:34:10 INFO Utils: Successfully started service 'sparkDriver' on port 50724.
15/12/29 16:34:10 INFO SparkEnv: Registering MapOutputTracker
15/12/29 16:34:10 INFO SparkEnv: Registering BlockManagerMaster
15/12/29 16:34:10 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-34b16663-5401-47b5-be68-c110833249ef
15/12/29 16:34:10 INFO MemoryStore: MemoryStore started with capacity 535.0 MB
15/12/29 16:34:10 INFO HttpFileServer: HTTP File server directory is /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/httpd-7fe9a05b-7d82-43dd-a6de-6c0db6869d32
15/12/29 16:34:10 INFO HttpServer: Starting HTTP Server
15/12/29 16:34:10 INFO Utils: Successfully started service 'HTTP file server' on port 38164.
15/12/29 16:34:10 INFO SparkEnv: Registering OutputCommitCoordinator
15/12/29 16:34:11 INFO Utils: Successfully started service 'SparkUI' on port 4040.
15/12/29 16:34:11 INFO SparkUI: Started SparkUI at http://localhost:4040
15/12/29 16:34:11 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/userFiles-acb7945b-e821-400f-b6e1-61810267afce/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
15/12/29 16:34:11 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1451387051293
15/12/29 16:34:11 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
15/12/29 16:34:11 INFO Executor: Starting executor ID driver on host localhost
15/12/29 16:34:11 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43602.
15/12/29 16:34:11 INFO NettyBlockTransferService: Server created on 43602
15/12/29 16:34:11 INFO BlockManagerMaster: Trying to register BlockManager
15/12/29 16:34:11 INFO BlockManagerMasterEndpoint: Registering block manager localhost:43602 with 535.0 MB RAM, BlockManagerId(driver, localhost, 43602)
15/12/29 16:34:11 INFO BlockManagerMaster: Registered BlockManager
15/12/29 16:34:11 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186
15/12/29 16:34:11 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184)
15/12/29 16:34:11 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186) with 2 output partitions
15/12/29 16:34:11 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186)
15/12/29 16:34:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
15/12/29 16:34:11 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
15/12/29 16:34:11 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184), which has no missing parents
15/12/29 16:34:11 INFO MemoryStore: ensureFreeSpace(7120) called with curMem=0, maxMem=560993402
15/12/29 16:34:11 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 7.0 KB, free 535.0 MB)
15/12/29 16:34:11 INFO MemoryStore: ensureFreeSpace(4573) called with curMem=7120, maxMem=560993402
15/12/29 16:34:11 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.5 KB, free 535.0 MB)
15/12/29 16:34:11 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:43602 (size: 4.5 KB, free: 535.0 MB)
15/12/29 16:34:11 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
15/12/29 16:34:11 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184)
15/12/29 16:34:11 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
15/12/29 16:34:11 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2401 bytes)
15/12/29 16:34:11 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2424 bytes)
15/12/29 16:34:11 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
15/12/29 16:34:11 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1451387051293
15/12/29 16:34:11 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
15/12/29 16:34:11 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/userFiles-acb7945b-e821-400f-b6e1-61810267afce/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
*** Introductory Examples for the NLTK Book ***
Loading text1, ..., text9 and sent1, ..., sent9
Type the name of the text or sentence to view it.
Type: 'texts()' or 'sents()' to list the materials.
*** Introductory Examples for the NLTK Book ***
Loading text1, ..., text9 and sent1, ..., sent9
Type the name of the text or sentence to view it.
Type: 'texts()' or 'sents()' to list the materials.
text1: Moby Dick by Herman Melville 1851
text1: Moby Dick by Herman Melville 1851
text2: Sense and Sensibility by Jane Austen 1811
text2: Sense and Sensibility by Jane Austen 1811
text3: The Book of Genesis
text3: The Book of Genesis
text4: Inaugural Address Corpus
text4: Inaugural Address Corpus
text5: Chat Corpus
text6: Monty Python and the Holy Grail
text5: Chat Corpus
text6: Monty Python and the Holy Grail
text7: Wall Street Journal
text8: Personals Corpus
text9: The Man Who Was Thursday by G . K . Chesterton 1908
mapFunction_Parents(): keyword =  provided ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
text7: Wall Street Journal
text8: Personals Corpus
text9: The Man Who Was Thursday by G . K . Chesterton 1908
mapFunction_Parents(): keyword =  locomotive ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  railway ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  car ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  powered ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  drawn ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  line ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  electricity ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'railway']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway']
mapFunction_Parents(): keyword =  public ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  cars ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'coupled']
reduceFunction_Parents(): returns= [u'coupled']
mapFunction_Parents(): keyword =  coupled ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway']
mapFunction_Parents(): keyword =  transport ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'coupled']
mapFunction_Parents(): keyword =  together ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'line', u'transport']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:34:48 INFO PythonRunner: Times: total = 36619, boot = 451, init = 28151, finish = 8017
15/12/29 16:34:48 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
15/12/29 16:34:48 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 36693 ms on localhost (1/2)
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'coupled']
15/12/29 16:34:48 INFO PythonRunner: Times: total = 36673, boot = 454, init = 27232, finish = 8987
15/12/29 16:34:48 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
15/12/29 16:34:48 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 36750 ms on localhost (2/2)
15/12/29 16:34:48 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184) finished in 36.750 s
15/12/29 16:34:48 INFO DAGScheduler: looking for newly runnable stages
15/12/29 16:34:48 INFO DAGScheduler: running: Set()
15/12/29 16:34:48 INFO DAGScheduler: waiting: Set(ResultStage 1)
15/12/29 16:34:48 INFO DAGScheduler: failed: Set()
15/12/29 16:34:48 INFO DAGScheduler: Missing parents for ResultStage 1: List()
15/12/29 16:34:48 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
15/12/29 16:34:48 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186), which is now runnable
15/12/29 16:34:48 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11693, maxMem=560993402
15/12/29 16:34:48 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 535.0 MB)
15/12/29 16:34:48 INFO MemoryStore: ensureFreeSpace(3054) called with curMem=16677, maxMem=560993402
15/12/29 16:34:48 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 535.0 MB)
15/12/29 16:34:48 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:43602 (size: 3.0 KB, free: 535.0 MB)
15/12/29 16:34:48 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
15/12/29 16:34:48 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186)
15/12/29 16:34:48 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
15/12/29 16:34:48 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
15/12/29 16:34:48 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
15/12/29 16:34:48 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
15/12/29 16:34:48 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
15/12/29 16:34:48 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/12/29 16:34:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
15/12/29 16:34:48 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/12/29 16:34:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
reduceFunction_Parents(): returns= [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:34:48 INFO PythonRunner: Times: total = 236, boot = 235, init = 1, finish = 0
15/12/29 16:34:48 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1360 bytes result sent to driver
15/12/29 16:34:48 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 255 ms on localhost (1/2)
15/12/29 16:34:48 INFO PythonRunner: Times: total = 290, boot = 290, init = 0, finish = 0
15/12/29 16:34:48 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
15/12/29 16:34:48 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186) finished in 0.293 s
15/12/29 16:34:48 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186, took 37.109622 s
15/12/29 16:34:48 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 312 ms on localhost (2/2)
15/12/29 16:34:48 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
15/12/29 16:34:48 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189
15/12/29 16:34:48 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189) with 2 output partitions
15/12/29 16:34:48 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189)
15/12/29 16:34:48 INFO DAGScheduler: Parents of final stage: List()
15/12/29 16:34:48 INFO DAGScheduler: Missing parents: List()
15/12/29 16:34:48 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189), which has no missing parents
15/12/29 16:34:48 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19731, maxMem=560993402
15/12/29 16:34:48 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 535.0 MB)
15/12/29 16:34:48 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25547, maxMem=560993402
15/12/29 16:34:48 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 535.0 MB)
15/12/29 16:34:48 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:43602 (size: 3.3 KB, free: 535.0 MB)
15/12/29 16:34:48 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
15/12/29 16:34:48 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189)
15/12/29 16:34:48 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
15/12/29 16:34:48 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
15/12/29 16:34:48 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2441 bytes)
15/12/29 16:34:48 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
15/12/29 16:34:48 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
15/12/29 16:34:48 INFO PythonRunner: Times: total = 74, boot = 74, init = 0, finish = 0
15/12/29 16:34:48 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1422 bytes result sent to driver
15/12/29 16:34:48 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 82 ms on localhost (1/2)
15/12/29 16:34:48 INFO PythonRunner: Times: total = 214, boot = 214, init = 0, finish = 0
15/12/29 16:34:48 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
15/12/29 16:34:48 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 221 ms on localhost (2/2)
15/12/29 16:34:48 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
15/12/29 16:34:48 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189) finished in 0.219 s
15/12/29 16:34:48 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189, took 0.237163 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
15/12/29 16:34:49 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
15/12/29 16:34:49 INFO DAGScheduler: Stopping DAGScheduler
15/12/29 16:34:49 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
15/12/29 16:34:49 INFO MemoryStore: MemoryStore cleared
15/12/29 16:34:49 INFO BlockManager: BlockManager stopped
15/12/29 16:34:49 INFO BlockManagerMaster: BlockManagerMaster stopped
15/12/29 16:34:49 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
15/12/29 16:34:49 INFO SparkContext: Successfully stopped SparkContext
15/12/29 16:34:49 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
15/12/29 16:34:49 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
15/12/29 16:34:49 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:34:49 INFO SparkContext: Running Spark version 1.5.2
15/12/29 16:34:49 INFO SecurityManager: Changing view acls to: root
15/12/29 16:34:49 INFO SecurityManager: Changing modify acls to: root
15/12/29 16:34:49 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
15/12/29 16:34:50 INFO Slf4jLogger: Slf4jLogger started
15/12/29 16:34:50 INFO Remoting: Starting remoting
15/12/29 16:34:50 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:40243]
15/12/29 16:34:50 INFO Utils: Successfully started service 'sparkDriver' on port 40243.
15/12/29 16:34:50 INFO SparkEnv: Registering MapOutputTracker
15/12/29 16:34:50 INFO SparkEnv: Registering BlockManagerMaster
15/12/29 16:34:50 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-03b3dc4a-bd23-4ce4-a82f-dd3c319e92f4
15/12/29 16:34:50 INFO MemoryStore: MemoryStore started with capacity 535.0 MB
15/12/29 16:34:50 INFO HttpFileServer: HTTP File server directory is /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/httpd-5c5ed778-83f4-4d40-a79a-b49e762dd337
15/12/29 16:34:50 INFO HttpServer: Starting HTTP Server
15/12/29 16:34:50 INFO Utils: Successfully started service 'HTTP file server' on port 57365.
15/12/29 16:34:50 INFO SparkEnv: Registering OutputCommitCoordinator
15/12/29 16:34:50 INFO Utils: Successfully started service 'SparkUI' on port 4040.
15/12/29 16:34:50 INFO SparkUI: Started SparkUI at http://localhost:4040
15/12/29 16:34:50 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/userFiles-d6abe38f-c93b-4530-ae25-a8ab9fb1be26/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
15/12/29 16:34:50 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1451387090530
15/12/29 16:34:50 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
15/12/29 16:34:50 INFO Executor: Starting executor ID driver on host localhost
15/12/29 16:34:50 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43540.
15/12/29 16:34:50 INFO NettyBlockTransferService: Server created on 43540
15/12/29 16:34:50 INFO BlockManagerMaster: Trying to register BlockManager
15/12/29 16:34:50 INFO BlockManagerMasterEndpoint: Registering block manager localhost:43540 with 535.0 MB RAM, BlockManagerId(driver, localhost, 43540)
15/12/29 16:34:50 INFO BlockManagerMaster: Registered BlockManager
15/12/29 16:34:50 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186
15/12/29 16:34:50 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184)
15/12/29 16:34:50 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186) with 2 output partitions
15/12/29 16:34:50 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186)
15/12/29 16:34:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
15/12/29 16:34:50 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
15/12/29 16:34:50 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184), which has no missing parents
15/12/29 16:34:50 INFO MemoryStore: ensureFreeSpace(7120) called with curMem=0, maxMem=560993402
15/12/29 16:34:50 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 7.0 KB, free 535.0 MB)
15/12/29 16:34:50 INFO MemoryStore: ensureFreeSpace(4573) called with curMem=7120, maxMem=560993402
15/12/29 16:34:50 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.5 KB, free 535.0 MB)
15/12/29 16:34:50 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:43540 (size: 4.5 KB, free: 535.0 MB)
15/12/29 16:34:50 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
15/12/29 16:34:50 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184)
15/12/29 16:34:50 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
15/12/29 16:34:50 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2401 bytes)
15/12/29 16:34:50 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2424 bytes)
15/12/29 16:34:50 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
15/12/29 16:34:50 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1451387090530
15/12/29 16:34:50 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
15/12/29 16:34:50 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/userFiles-d6abe38f-c93b-4530-ae25-a8ab9fb1be26/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
*** Introductory Examples for the NLTK Book ***
Loading text1, ..., text9 and sent1, ..., sent9
Type the name of the text or sentence to view it.
Type: 'texts()' or 'sents()' to list the materials.
*** Introductory Examples for the NLTK Book ***
Loading text1, ..., text9 and sent1, ..., sent9
Type the name of the text or sentence to view it.
Type: 'texts()' or 'sents()' to list the materials.
text1: Moby Dick by Herman Melville 1851
text1: Moby Dick by Herman Melville 1851
text2: Sense and Sensibility by Jane Austen 1811
text3: The Book of Genesis
text2: Sense and Sensibility by Jane Austen 1811
text3: The Book of Genesis
text4: Inaugural Address Corpus
text4: Inaugural Address Corpus
text5: Chat Corpus
text6: Monty Python and the Holy Grail
text5: Chat Corpus
text6: Monty Python and the Holy Grail
text7: Wall Street Journal
text8: Personals Corpus
text9: The Man Who Was Thursday by G . K . Chesterton 1908
mapFunction_Parents(): keyword =  provided ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
text7: Wall Street Journal
text8: Personals Corpus
text9: The Man Who Was Thursday by G . K . Chesterton 1908
mapFunction_Parents(): keyword =  locomotive ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  powered ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  electricity ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  cars ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'coupled']
reduceFunction_Parents(): returns= [u'coupled']
mapFunction_Parents(): keyword =  coupled ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'coupled']
mapFunction_Parents(): keyword =  together ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'coupled']
15/12/29 16:35:27 INFO PythonRunner: Times: total = 37161, boot = 452, init = 28722, finish = 7987
15/12/29 16:35:27 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
15/12/29 16:35:27 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 37236 ms on localhost (1/2)
mapFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  railway ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  car ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  drawn ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  line ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'railway']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway']
mapFunction_Parents(): keyword =  public ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway']
mapFunction_Parents(): keyword =  transport ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'line', u'transport']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:35:28 INFO PythonRunner: Times: total = 38145, boot = 452, init = 29375, finish = 8318
15/12/29 16:35:28 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
15/12/29 16:35:28 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184) finished in 38.212 s
15/12/29 16:35:28 INFO DAGScheduler: looking for newly runnable stages
15/12/29 16:35:28 INFO DAGScheduler: running: Set()
15/12/29 16:35:28 INFO DAGScheduler: waiting: Set(ResultStage 1)
15/12/29 16:35:28 INFO DAGScheduler: failed: Set()
15/12/29 16:35:28 INFO DAGScheduler: Missing parents for ResultStage 1: List()
15/12/29 16:35:28 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186), which is now runnable
15/12/29 16:35:28 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11693, maxMem=560993402
15/12/29 16:35:28 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 535.0 MB)
15/12/29 16:35:28 INFO MemoryStore: ensureFreeSpace(3054) called with curMem=16677, maxMem=560993402
15/12/29 16:35:28 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 535.0 MB)
15/12/29 16:35:28 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 38216 ms on localhost (2/2)
15/12/29 16:35:28 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
15/12/29 16:35:28 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:43540 (size: 3.0 KB, free: 535.0 MB)
15/12/29 16:35:28 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
15/12/29 16:35:28 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186)
15/12/29 16:35:28 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
15/12/29 16:35:28 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
15/12/29 16:35:28 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
15/12/29 16:35:28 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
15/12/29 16:35:28 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
15/12/29 16:35:28 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/12/29 16:35:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
15/12/29 16:35:28 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/12/29 16:35:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
15/12/29 16:35:28 INFO PythonRunner: Times: total = 34, boot = -782, init = 816, finish = 0
15/12/29 16:35:28 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
15/12/29 16:35:28 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 57 ms on localhost (1/2)
reduceFunction_Parents(): returns= [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:35:29 INFO PythonRunner: Times: total = 272, boot = 269, init = 0, finish = 3
15/12/29 16:35:29 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1360 bytes result sent to driver
15/12/29 16:35:29 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 296 ms on localhost (2/2)
15/12/29 16:35:29 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186) finished in 0.287 s
15/12/29 16:35:29 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
15/12/29 16:35:29 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186, took 38.552253 s
15/12/29 16:35:29 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189
15/12/29 16:35:29 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189) with 2 output partitions
15/12/29 16:35:29 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189)
15/12/29 16:35:29 INFO DAGScheduler: Parents of final stage: List()
15/12/29 16:35:29 INFO DAGScheduler: Missing parents: List()
15/12/29 16:35:29 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189), which has no missing parents
15/12/29 16:35:29 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19731, maxMem=560993402
15/12/29 16:35:29 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 535.0 MB)
15/12/29 16:35:29 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25547, maxMem=560993402
15/12/29 16:35:29 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 535.0 MB)
15/12/29 16:35:29 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:43540 (size: 3.3 KB, free: 535.0 MB)
15/12/29 16:35:29 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
15/12/29 16:35:29 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189)
15/12/29 16:35:29 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
15/12/29 16:35:29 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
15/12/29 16:35:29 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2441 bytes)
15/12/29 16:35:29 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
15/12/29 16:35:29 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
15/12/29 16:35:29 INFO PythonRunner: Times: total = 46, boot = -143, init = 189, finish = 0
15/12/29 16:35:29 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1422 bytes result sent to driver
15/12/29 16:35:29 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 73 ms on localhost (1/2)
15/12/29 16:35:29 INFO PythonRunner: Times: total = 170, boot = 169, init = 1, finish = 0
15/12/29 16:35:29 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
15/12/29 16:35:29 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 181 ms on localhost (2/2)
15/12/29 16:35:29 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
15/12/29 16:35:29 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189) finished in 0.168 s
15/12/29 16:35:29 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189, took 0.197532 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
15/12/29 16:35:29 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
15/12/29 16:35:29 INFO DAGScheduler: Stopping DAGScheduler
15/12/29 16:35:29 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
15/12/29 16:35:29 INFO MemoryStore: MemoryStore cleared
15/12/29 16:35:29 INFO BlockManager: BlockManager stopped
15/12/29 16:35:29 INFO BlockManagerMaster: BlockManagerMaster stopped
15/12/29 16:35:29 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
15/12/29 16:35:29 INFO SparkContext: Successfully stopped SparkContext
15/12/29 16:35:29 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
15/12/29 16:35:29 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
15/12/29 16:35:29 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:35:30 INFO SparkContext: Running Spark version 1.5.2
15/12/29 16:35:30 INFO SecurityManager: Changing view acls to: root
15/12/29 16:35:30 INFO SecurityManager: Changing modify acls to: root
15/12/29 16:35:30 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
15/12/29 16:35:30 INFO Slf4jLogger: Slf4jLogger started
15/12/29 16:35:30 INFO Remoting: Starting remoting
15/12/29 16:35:30 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:50557]
15/12/29 16:35:30 INFO Utils: Successfully started service 'sparkDriver' on port 50557.
15/12/29 16:35:30 INFO SparkEnv: Registering MapOutputTracker
15/12/29 16:35:30 INFO SparkEnv: Registering BlockManagerMaster
15/12/29 16:35:30 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-5fe5c667-daf5-4bd1-a28c-1accf865d317
15/12/29 16:35:30 INFO MemoryStore: MemoryStore started with capacity 535.0 MB
15/12/29 16:35:30 INFO HttpFileServer: HTTP File server directory is /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/httpd-538bf7c1-9fc3-4cf6-9643-483916d4d3ae
15/12/29 16:35:30 INFO HttpServer: Starting HTTP Server
15/12/29 16:35:30 INFO Utils: Successfully started service 'HTTP file server' on port 34649.
15/12/29 16:35:30 INFO SparkEnv: Registering OutputCommitCoordinator
15/12/29 16:35:31 INFO Utils: Successfully started service 'SparkUI' on port 4040.
15/12/29 16:35:31 INFO SparkUI: Started SparkUI at http://localhost:4040
15/12/29 16:35:31 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/userFiles-7130986f-2d82-49c4-b584-1a0811db672a/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
15/12/29 16:35:31 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1451387131152
15/12/29 16:35:31 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
15/12/29 16:35:31 INFO Executor: Starting executor ID driver on host localhost
15/12/29 16:35:31 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59780.
15/12/29 16:35:31 INFO NettyBlockTransferService: Server created on 59780
15/12/29 16:35:31 INFO BlockManagerMaster: Trying to register BlockManager
15/12/29 16:35:31 INFO BlockManagerMasterEndpoint: Registering block manager localhost:59780 with 535.0 MB RAM, BlockManagerId(driver, localhost, 59780)
15/12/29 16:35:31 INFO BlockManagerMaster: Registered BlockManager
15/12/29 16:35:31 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186
15/12/29 16:35:31 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184)
15/12/29 16:35:31 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186) with 2 output partitions
15/12/29 16:35:31 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186)
15/12/29 16:35:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
15/12/29 16:35:31 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
15/12/29 16:35:31 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184), which has no missing parents
15/12/29 16:35:31 INFO MemoryStore: ensureFreeSpace(7120) called with curMem=0, maxMem=560993402
15/12/29 16:35:31 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 7.0 KB, free 535.0 MB)
15/12/29 16:35:31 INFO MemoryStore: ensureFreeSpace(4573) called with curMem=7120, maxMem=560993402
15/12/29 16:35:31 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.5 KB, free 535.0 MB)
15/12/29 16:35:31 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:59780 (size: 4.5 KB, free: 535.0 MB)
15/12/29 16:35:31 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
15/12/29 16:35:31 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184)
15/12/29 16:35:31 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
15/12/29 16:35:31 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2401 bytes)
15/12/29 16:35:31 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2424 bytes)
15/12/29 16:35:31 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
15/12/29 16:35:31 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1451387131152
15/12/29 16:35:31 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
15/12/29 16:35:31 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/userFiles-7130986f-2d82-49c4-b584-1a0811db672a/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
*** Introductory Examples for the NLTK Book ***
Loading text1, ..., text9 and sent1, ..., sent9
Type the name of the text or sentence to view it.
Type: 'texts()' or 'sents()' to list the materials.
*** Introductory Examples for the NLTK Book ***
Loading text1, ..., text9 and sent1, ..., sent9
Type the name of the text or sentence to view it.
Type: 'texts()' or 'sents()' to list the materials.
text1: Moby Dick by Herman Melville 1851
text1: Moby Dick by Herman Melville 1851
text2: Sense and Sensibility by Jane Austen 1811
text2: Sense and Sensibility by Jane Austen 1811
text3: The Book of Genesis
text3: The Book of Genesis
text4: Inaugural Address Corpus
text4: Inaugural Address Corpus
text5: Chat Corpus
text6: Monty Python and the Holy Grail
text5: Chat Corpus
text6: Monty Python and the Holy Grail
text7: Wall Street Journal
text8: Personals Corpus
text7: Wall Street Journal
text8: Personals Corpus
text9: The Man Who Was Thursday by G . K . Chesterton 1908
mapFunction_Parents(): keyword =  provided ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
text9: The Man Who Was Thursday by G . K . Chesterton 1908
mapFunction_Parents(): keyword =  locomotive ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  railway ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  car ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  drawn ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  line ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'railway']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway']
mapFunction_Parents(): keyword =  public ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway']
mapFunction_Parents(): keyword =  transport ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'line', u'transport']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:36:07 INFO PythonRunner: Times: total = 36198, boot = 464, init = 27962, finish = 7772
15/12/29 16:36:07 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
15/12/29 16:36:07 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 36317 ms on localhost (1/2)
mapFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  powered ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  electricity ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  cars ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'coupled']
reduceFunction_Parents(): returns= [u'coupled']
mapFunction_Parents(): keyword =  coupled ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'coupled']
mapFunction_Parents(): keyword =  together ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'coupled']
15/12/29 16:36:08 INFO PythonRunner: Times: total = 36745, boot = 458, init = 27729, finish = 8558
15/12/29 16:36:08 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
15/12/29 16:36:08 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 36871 ms on localhost (2/2)
15/12/29 16:36:08 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
15/12/29 16:36:08 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184) finished in 36.866 s
15/12/29 16:36:08 INFO DAGScheduler: looking for newly runnable stages
15/12/29 16:36:08 INFO DAGScheduler: running: Set()
15/12/29 16:36:08 INFO DAGScheduler: waiting: Set(ResultStage 1)
15/12/29 16:36:08 INFO DAGScheduler: failed: Set()
15/12/29 16:36:08 INFO DAGScheduler: Missing parents for ResultStage 1: List()
15/12/29 16:36:08 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186), which is now runnable
15/12/29 16:36:08 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11693, maxMem=560993402
15/12/29 16:36:08 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 535.0 MB)
15/12/29 16:36:08 INFO MemoryStore: ensureFreeSpace(3054) called with curMem=16677, maxMem=560993402
15/12/29 16:36:08 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 535.0 MB)
15/12/29 16:36:08 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:59780 (size: 3.0 KB, free: 535.0 MB)
15/12/29 16:36:08 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
15/12/29 16:36:08 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186)
15/12/29 16:36:08 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
15/12/29 16:36:08 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
15/12/29 16:36:08 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
15/12/29 16:36:08 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
15/12/29 16:36:08 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/12/29 16:36:08 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
15/12/29 16:36:08 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/12/29 16:36:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
15/12/29 16:36:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
reduceFunction_Parents(): returns= [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:36:08 INFO PythonRunner: Times: total = 10, boot = -343, init = 353, finish = 0
15/12/29 16:36:08 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1360 bytes result sent to driver
15/12/29 16:36:08 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 55 ms on localhost (1/2)
15/12/29 16:36:08 INFO PythonRunner: Times: total = 263, boot = 263, init = 0, finish = 0
15/12/29 16:36:08 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
15/12/29 16:36:08 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186) finished in 0.269 s
15/12/29 16:36:08 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 278 ms on localhost (2/2)
15/12/29 16:36:08 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
15/12/29 16:36:08 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186, took 37.203091 s
15/12/29 16:36:08 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189
15/12/29 16:36:08 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189) with 2 output partitions
15/12/29 16:36:08 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189)
15/12/29 16:36:08 INFO DAGScheduler: Parents of final stage: List()
15/12/29 16:36:08 INFO DAGScheduler: Missing parents: List()
15/12/29 16:36:08 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189), which has no missing parents
15/12/29 16:36:08 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19731, maxMem=560993402
15/12/29 16:36:08 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 535.0 MB)
15/12/29 16:36:08 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25547, maxMem=560993402
15/12/29 16:36:08 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 535.0 MB)
15/12/29 16:36:08 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:59780 (size: 3.3 KB, free: 535.0 MB)
15/12/29 16:36:08 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
15/12/29 16:36:08 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189)
15/12/29 16:36:08 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
15/12/29 16:36:08 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
15/12/29 16:36:08 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2441 bytes)
15/12/29 16:36:08 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
15/12/29 16:36:08 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
15/12/29 16:36:08 INFO PythonRunner: Times: total = 61, boot = -160, init = 221, finish = 0
15/12/29 16:36:08 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1422 bytes result sent to driver
15/12/29 16:36:08 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 75 ms on localhost (1/2)
15/12/29 16:36:08 INFO PythonRunner: Times: total = 177, boot = 177, init = 0, finish = 0
15/12/29 16:36:08 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
15/12/29 16:36:08 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 187 ms on localhost (2/2)
15/12/29 16:36:08 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
15/12/29 16:36:08 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189) finished in 0.175 s
15/12/29 16:36:08 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189, took 0.216764 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
15/12/29 16:36:09 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
15/12/29 16:36:09 INFO DAGScheduler: Stopping DAGScheduler
15/12/29 16:36:09 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
15/12/29 16:36:09 INFO MemoryStore: MemoryStore cleared
15/12/29 16:36:09 INFO BlockManager: BlockManager stopped
15/12/29 16:36:09 INFO BlockManagerMaster: BlockManagerMaster stopped
15/12/29 16:36:09 INFO SparkContext: Successfully stopped SparkContext
15/12/29 16:36:09 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
15/12/29 16:36:09 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
15/12/29 16:36:09 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
15/12/29 16:36:09 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:36:09 INFO SparkContext: Running Spark version 1.5.2
15/12/29 16:36:09 INFO SecurityManager: Changing view acls to: root
15/12/29 16:36:09 INFO SecurityManager: Changing modify acls to: root
15/12/29 16:36:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
15/12/29 16:36:09 INFO Slf4jLogger: Slf4jLogger started
15/12/29 16:36:09 INFO Remoting: Starting remoting
15/12/29 16:36:10 INFO Utils: Successfully started service 'sparkDriver' on port 52427.
15/12/29 16:36:10 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:52427]
15/12/29 16:36:10 INFO SparkEnv: Registering MapOutputTracker
15/12/29 16:36:10 INFO SparkEnv: Registering BlockManagerMaster
15/12/29 16:36:10 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-f5cc6927-e878-404e-ab6e-e706b4667907
15/12/29 16:36:10 INFO MemoryStore: MemoryStore started with capacity 535.0 MB
15/12/29 16:36:10 INFO HttpFileServer: HTTP File server directory is /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/httpd-04f833c2-ebd7-482c-97ec-82ab4ab5efaa
15/12/29 16:36:10 INFO HttpServer: Starting HTTP Server
15/12/29 16:36:10 INFO Utils: Successfully started service 'HTTP file server' on port 33814.
15/12/29 16:36:10 INFO SparkEnv: Registering OutputCommitCoordinator
15/12/29 16:36:10 INFO Utils: Successfully started service 'SparkUI' on port 4040.
15/12/29 16:36:10 INFO SparkUI: Started SparkUI at http://localhost:4040
15/12/29 16:36:10 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/userFiles-784344b2-08a9-48b7-8b7f-8424fddfeb34/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
15/12/29 16:36:10 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1451387170536
15/12/29 16:36:10 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
15/12/29 16:36:10 INFO Executor: Starting executor ID driver on host localhost
15/12/29 16:36:10 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49336.
15/12/29 16:36:10 INFO NettyBlockTransferService: Server created on 49336
15/12/29 16:36:10 INFO BlockManagerMaster: Trying to register BlockManager
15/12/29 16:36:10 INFO BlockManagerMasterEndpoint: Registering block manager localhost:49336 with 535.0 MB RAM, BlockManagerId(driver, localhost, 49336)
15/12/29 16:36:10 INFO BlockManagerMaster: Registered BlockManager
15/12/29 16:36:10 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186
15/12/29 16:36:10 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184)
15/12/29 16:36:10 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186) with 2 output partitions
15/12/29 16:36:10 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186)
15/12/29 16:36:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
15/12/29 16:36:10 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
15/12/29 16:36:10 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184), which has no missing parents
15/12/29 16:36:10 INFO MemoryStore: ensureFreeSpace(7120) called with curMem=0, maxMem=560993402
15/12/29 16:36:10 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 7.0 KB, free 535.0 MB)
15/12/29 16:36:10 INFO MemoryStore: ensureFreeSpace(4573) called with curMem=7120, maxMem=560993402
15/12/29 16:36:10 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.5 KB, free 535.0 MB)
15/12/29 16:36:10 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:49336 (size: 4.5 KB, free: 535.0 MB)
15/12/29 16:36:10 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
15/12/29 16:36:10 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184)
15/12/29 16:36:10 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
15/12/29 16:36:10 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2401 bytes)
15/12/29 16:36:10 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2424 bytes)
15/12/29 16:36:10 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
15/12/29 16:36:10 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1451387170536
15/12/29 16:36:10 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
15/12/29 16:36:10 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/userFiles-784344b2-08a9-48b7-8b7f-8424fddfeb34/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
*** Introductory Examples for the NLTK Book ***
Loading text1, ..., text9 and sent1, ..., sent9
Type the name of the text or sentence to view it.
Type: 'texts()' or 'sents()' to list the materials.
*** Introductory Examples for the NLTK Book ***
Loading text1, ..., text9 and sent1, ..., sent9
Type the name of the text or sentence to view it.
Type: 'texts()' or 'sents()' to list the materials.
text1: Moby Dick by Herman Melville 1851
text1: Moby Dick by Herman Melville 1851
text2: Sense and Sensibility by Jane Austen 1811
text3: The Book of Genesis
text2: Sense and Sensibility by Jane Austen 1811
text3: The Book of Genesis
text4: Inaugural Address Corpus
text4: Inaugural Address Corpus
text5: Chat Corpus
text6: Monty Python and the Holy Grail
text5: Chat Corpus
text6: Monty Python and the Holy Grail
text7: Wall Street Journal
text8: Personals Corpus
text7: Wall Street Journal
text8: Personals Corpus
text9: The Man Who Was Thursday by G . K . Chesterton 1908
mapFunction_Parents(): keyword =  provided ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
text9: The Man Who Was Thursday by G . K . Chesterton 1908
mapFunction_Parents(): keyword =  locomotive ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  railway ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  car ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  drawn ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  line ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'railway']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway']
mapFunction_Parents(): keyword =  public ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  powered ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  electricity ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway']
mapFunction_Parents(): keyword =  transport ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  cars ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'line', u'transport']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:36:47 INFO PythonRunner: Times: total = 36514, boot = 470, init = 28081, finish = 7963
15/12/29 16:36:47 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
mapFunction_Parents(): returns= [u'coupled']
reduceFunction_Parents(): returns= [u'coupled']
mapFunction_Parents(): keyword =  coupled ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'coupled']
mapFunction_Parents(): keyword =  together ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
15/12/29 16:36:47 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 36905 ms on localhost (1/2)
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'coupled']
15/12/29 16:36:47 INFO PythonRunner: Times: total = 36923, boot = 476, init = 27700, finish = 8747
15/12/29 16:36:47 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
15/12/29 16:36:47 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184) finished in 37.034 s
15/12/29 16:36:47 INFO DAGScheduler: looking for newly runnable stages
15/12/29 16:36:47 INFO DAGScheduler: running: Set()
15/12/29 16:36:47 INFO DAGScheduler: waiting: Set(ResultStage 1)
15/12/29 16:36:47 INFO DAGScheduler: failed: Set()
15/12/29 16:36:47 INFO DAGScheduler: Missing parents for ResultStage 1: List()
15/12/29 16:36:47 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186), which is now runnable
15/12/29 16:36:47 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11693, maxMem=560993402
15/12/29 16:36:47 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 535.0 MB)
15/12/29 16:36:47 INFO MemoryStore: ensureFreeSpace(3054) called with curMem=16677, maxMem=560993402
15/12/29 16:36:47 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 535.0 MB)
15/12/29 16:36:47 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 37032 ms on localhost (2/2)
15/12/29 16:36:47 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
15/12/29 16:36:47 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:49336 (size: 3.0 KB, free: 535.0 MB)
15/12/29 16:36:47 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
15/12/29 16:36:47 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186)
15/12/29 16:36:47 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
15/12/29 16:36:47 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
15/12/29 16:36:47 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
15/12/29 16:36:47 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
15/12/29 16:36:47 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/12/29 16:36:47 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
15/12/29 16:36:47 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/12/29 16:36:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
15/12/29 16:36:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
reduceFunction_Parents(): returns= [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:36:47 INFO PythonRunner: Times: total = 26, boot = -48, init = 73, finish = 1
15/12/29 16:36:47 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1360 bytes result sent to driver
15/12/29 16:36:47 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 72 ms on localhost (1/2)
15/12/29 16:36:47 INFO PythonRunner: Times: total = 259, boot = 258, init = 0, finish = 1
15/12/29 16:36:47 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
15/12/29 16:36:47 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186) finished in 0.257 s
15/12/29 16:36:47 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 282 ms on localhost (2/2)
15/12/29 16:36:47 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
15/12/29 16:36:47 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186, took 37.341596 s
15/12/29 16:36:48 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189
15/12/29 16:36:48 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189) with 2 output partitions
15/12/29 16:36:48 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189)
15/12/29 16:36:48 INFO DAGScheduler: Parents of final stage: List()
15/12/29 16:36:48 INFO DAGScheduler: Missing parents: List()
15/12/29 16:36:48 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189), which has no missing parents
15/12/29 16:36:48 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19731, maxMem=560993402
15/12/29 16:36:48 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 535.0 MB)
15/12/29 16:36:48 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25547, maxMem=560993402
15/12/29 16:36:48 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 535.0 MB)
15/12/29 16:36:48 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:49336 (size: 3.3 KB, free: 535.0 MB)
15/12/29 16:36:48 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
15/12/29 16:36:48 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189)
15/12/29 16:36:48 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
15/12/29 16:36:48 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
15/12/29 16:36:48 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2441 bytes)
15/12/29 16:36:48 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
15/12/29 16:36:48 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
15/12/29 16:36:48 INFO PythonRunner: Times: total = 63, boot = -98, init = 161, finish = 0
15/12/29 16:36:48 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
15/12/29 16:36:48 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 78 ms on localhost (1/2)
15/12/29 16:36:48 INFO PythonRunner: Times: total = 239, boot = 238, init = 1, finish = 0
15/12/29 16:36:48 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1422 bytes result sent to driver
15/12/29 16:36:48 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 247 ms on localhost (2/2)
15/12/29 16:36:48 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
15/12/29 16:36:48 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189) finished in 0.246 s
15/12/29 16:36:48 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189, took 0.263040 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
15/12/29 16:36:48 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
15/12/29 16:36:48 INFO DAGScheduler: Stopping DAGScheduler
15/12/29 16:36:48 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
15/12/29 16:36:48 INFO MemoryStore: MemoryStore cleared
15/12/29 16:36:48 INFO BlockManager: BlockManager stopped
15/12/29 16:36:48 INFO BlockManagerMaster: BlockManagerMaster stopped
15/12/29 16:36:48 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
15/12/29 16:36:48 INFO SparkContext: Successfully stopped SparkContext
15/12/29 16:36:48 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
15/12/29 16:36:48 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:36:49 INFO SparkContext: Running Spark version 1.5.2
15/12/29 16:36:49 INFO SecurityManager: Changing view acls to: root
15/12/29 16:36:49 INFO SecurityManager: Changing modify acls to: root
15/12/29 16:36:49 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
15/12/29 16:36:49 INFO Slf4jLogger: Slf4jLogger started
15/12/29 16:36:49 INFO Remoting: Starting remoting
15/12/29 16:36:49 INFO Utils: Successfully started service 'sparkDriver' on port 37710.
15/12/29 16:36:49 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:37710]
15/12/29 16:36:49 INFO SparkEnv: Registering MapOutputTracker
15/12/29 16:36:49 INFO SparkEnv: Registering BlockManagerMaster
15/12/29 16:36:49 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-05d26d31-9371-47d4-9c8d-a597f7af8ec8
15/12/29 16:36:49 INFO MemoryStore: MemoryStore started with capacity 538.0 MB
15/12/29 16:36:49 INFO HttpFileServer: HTTP File server directory is /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/httpd-1b980545-a170-40bb-b9f8-eaf8688cdcbb
15/12/29 16:36:49 INFO HttpServer: Starting HTTP Server
15/12/29 16:36:49 INFO Utils: Successfully started service 'HTTP file server' on port 39786.
15/12/29 16:36:49 INFO SparkEnv: Registering OutputCommitCoordinator
15/12/29 16:36:49 INFO Utils: Successfully started service 'SparkUI' on port 4040.
15/12/29 16:36:49 INFO SparkUI: Started SparkUI at http://localhost:4040
15/12/29 16:36:49 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/userFiles-2cbc0e03-f702-41d9-88b3-c3829392a141/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
15/12/29 16:36:49 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1451387209957
15/12/29 16:36:49 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
15/12/29 16:36:49 INFO Executor: Starting executor ID driver on host localhost
15/12/29 16:36:50 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53867.
15/12/29 16:36:50 INFO NettyBlockTransferService: Server created on 53867
15/12/29 16:36:50 INFO BlockManagerMaster: Trying to register BlockManager
15/12/29 16:36:50 INFO BlockManagerMasterEndpoint: Registering block manager localhost:53867 with 538.0 MB RAM, BlockManagerId(driver, localhost, 53867)
15/12/29 16:36:50 INFO BlockManagerMaster: Registered BlockManager
15/12/29 16:36:50 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186
15/12/29 16:36:50 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184)
15/12/29 16:36:50 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186) with 2 output partitions
15/12/29 16:36:50 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186)
15/12/29 16:36:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
15/12/29 16:36:50 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
15/12/29 16:36:50 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184), which has no missing parents
15/12/29 16:36:50 INFO MemoryStore: ensureFreeSpace(7120) called with curMem=0, maxMem=564107673
15/12/29 16:36:50 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 7.0 KB, free 538.0 MB)
15/12/29 16:36:50 INFO MemoryStore: ensureFreeSpace(4573) called with curMem=7120, maxMem=564107673
15/12/29 16:36:50 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.5 KB, free 538.0 MB)
15/12/29 16:36:50 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:53867 (size: 4.5 KB, free: 538.0 MB)
15/12/29 16:36:50 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
15/12/29 16:36:50 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184)
15/12/29 16:36:50 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
15/12/29 16:36:50 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2401 bytes)
15/12/29 16:36:50 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2424 bytes)
15/12/29 16:36:50 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
15/12/29 16:36:50 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1451387209957
15/12/29 16:36:50 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
15/12/29 16:36:50 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/userFiles-2cbc0e03-f702-41d9-88b3-c3829392a141/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
*** Introductory Examples for the NLTK Book ***
Loading text1, ..., text9 and sent1, ..., sent9
Type the name of the text or sentence to view it.
Type: 'texts()' or 'sents()' to list the materials.
*** Introductory Examples for the NLTK Book ***
Loading text1, ..., text9 and sent1, ..., sent9
Type the name of the text or sentence to view it.
Type: 'texts()' or 'sents()' to list the materials.
text1: Moby Dick by Herman Melville 1851
text1: Moby Dick by Herman Melville 1851
text2: Sense and Sensibility by Jane Austen 1811
text3: The Book of Genesis
text2: Sense and Sensibility by Jane Austen 1811
text3: The Book of Genesis
text4: Inaugural Address Corpus
text4: Inaugural Address Corpus
text5: Chat Corpus
text6: Monty Python and the Holy Grail
text5: Chat Corpus
text6: Monty Python and the Holy Grail
text7: Wall Street Journal
text8: Personals Corpus
text9: The Man Who Was Thursday by G . K . Chesterton 1908
mapFunction_Parents(): keyword =  provided ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
text7: Wall Street Journal
text8: Personals Corpus
text9: The Man Who Was Thursday by G . K . Chesterton 1908
mapFunction_Parents(): keyword =  locomotive ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  powered ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  electricity ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  cars ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'coupled']
reduceFunction_Parents(): returns= [u'coupled']
mapFunction_Parents(): keyword =  coupled ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'coupled']
mapFunction_Parents(): keyword =  together ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'coupled']
15/12/29 16:37:25 INFO PythonRunner: Times: total = 35535, boot = 456, init = 27090, finish = 7989
15/12/29 16:37:25 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
15/12/29 16:37:25 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 35620 ms on localhost (1/2)
mapFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  railway ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  car ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  drawn ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  line ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'railway']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway']
mapFunction_Parents(): keyword =  public ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway']
mapFunction_Parents(): keyword =  transport ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'line', u'transport']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:37:27 INFO PythonRunner: Times: total = 37605, boot = 455, init = 28707, finish = 8443
15/12/29 16:37:27 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
15/12/29 16:37:27 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 37695 ms on localhost (2/2)
15/12/29 16:37:27 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
15/12/29 16:37:27 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184) finished in 37.695 s
15/12/29 16:37:27 INFO DAGScheduler: looking for newly runnable stages
15/12/29 16:37:27 INFO DAGScheduler: running: Set()
15/12/29 16:37:27 INFO DAGScheduler: waiting: Set(ResultStage 1)
15/12/29 16:37:27 INFO DAGScheduler: failed: Set()
15/12/29 16:37:27 INFO DAGScheduler: Missing parents for ResultStage 1: List()
15/12/29 16:37:27 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186), which is now runnable
15/12/29 16:37:27 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11693, maxMem=564107673
15/12/29 16:37:27 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 538.0 MB)
15/12/29 16:37:27 INFO MemoryStore: ensureFreeSpace(3054) called with curMem=16677, maxMem=564107673
15/12/29 16:37:27 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 538.0 MB)
15/12/29 16:37:27 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:53867 (size: 3.0 KB, free: 538.0 MB)
15/12/29 16:37:27 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
15/12/29 16:37:27 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186)
15/12/29 16:37:27 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
15/12/29 16:37:27 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
15/12/29 16:37:27 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
15/12/29 16:37:27 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
15/12/29 16:37:27 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
15/12/29 16:37:27 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/12/29 16:37:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
15/12/29 16:37:27 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/12/29 16:37:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
reduceFunction_Parents(): returns= [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:37:27 INFO PythonRunner: Times: total = 55, boot = -1865, init = 1919, finish = 1
15/12/29 16:37:27 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1360 bytes result sent to driver
15/12/29 16:37:27 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 138 ms on localhost (1/2)
15/12/29 16:37:28 INFO PythonRunner: Times: total = 246, boot = 246, init = 0, finish = 0
15/12/29 16:37:28 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
15/12/29 16:37:28 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 266 ms on localhost (2/2)
15/12/29 16:37:28 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
15/12/29 16:37:28 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186) finished in 0.271 s
15/12/29 16:37:28 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186, took 38.007729 s
15/12/29 16:37:28 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189
15/12/29 16:37:28 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189) with 2 output partitions
15/12/29 16:37:28 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189)
15/12/29 16:37:28 INFO DAGScheduler: Parents of final stage: List()
15/12/29 16:37:28 INFO DAGScheduler: Missing parents: List()
15/12/29 16:37:28 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189), which has no missing parents
15/12/29 16:37:28 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19731, maxMem=564107673
15/12/29 16:37:28 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 538.0 MB)
15/12/29 16:37:28 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25547, maxMem=564107673
15/12/29 16:37:28 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 537.9 MB)
15/12/29 16:37:28 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:53867 (size: 3.3 KB, free: 538.0 MB)
15/12/29 16:37:28 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
15/12/29 16:37:28 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189)
15/12/29 16:37:28 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
15/12/29 16:37:28 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
15/12/29 16:37:28 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2441 bytes)
15/12/29 16:37:28 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
15/12/29 16:37:28 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
15/12/29 16:37:28 INFO PythonRunner: Times: total = 84, boot = 83, init = 1, finish = 0
15/12/29 16:37:28 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1422 bytes result sent to driver
15/12/29 16:37:28 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 93 ms on localhost (1/2)
15/12/29 16:37:28 INFO PythonRunner: Times: total = 185, boot = 184, init = 0, finish = 1
15/12/29 16:37:28 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
15/12/29 16:37:28 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 195 ms on localhost (2/2)
15/12/29 16:37:28 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
15/12/29 16:37:28 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189) finished in 0.197 s
15/12/29 16:37:28 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189, took 0.219553 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
15/12/29 16:37:28 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
15/12/29 16:37:28 INFO DAGScheduler: Stopping DAGScheduler
15/12/29 16:37:28 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
15/12/29 16:37:28 INFO MemoryStore: MemoryStore cleared
15/12/29 16:37:28 INFO BlockManager: BlockManager stopped
15/12/29 16:37:28 INFO BlockManagerMaster: BlockManagerMaster stopped
15/12/29 16:37:28 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
15/12/29 16:37:28 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
15/12/29 16:37:28 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
15/12/29 16:37:28 INFO SparkContext: Successfully stopped SparkContext
15/12/29 16:37:28 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:37:29 INFO SparkContext: Running Spark version 1.5.2
15/12/29 16:37:29 INFO SecurityManager: Changing view acls to: root
15/12/29 16:37:29 INFO SecurityManager: Changing modify acls to: root
15/12/29 16:37:29 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
15/12/29 16:37:29 INFO Slf4jLogger: Slf4jLogger started
15/12/29 16:37:29 INFO Remoting: Starting remoting
15/12/29 16:37:29 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:44448]
15/12/29 16:37:29 INFO Utils: Successfully started service 'sparkDriver' on port 44448.
15/12/29 16:37:29 INFO SparkEnv: Registering MapOutputTracker
15/12/29 16:37:29 INFO SparkEnv: Registering BlockManagerMaster
15/12/29 16:37:29 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-7642368f-94bd-4839-919f-fdf2903185c8
15/12/29 16:37:29 INFO MemoryStore: MemoryStore started with capacity 538.0 MB
15/12/29 16:37:29 INFO HttpFileServer: HTTP File server directory is /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/httpd-04c0c173-3092-4325-ab6a-678b7dfd56c1
15/12/29 16:37:29 INFO HttpServer: Starting HTTP Server
15/12/29 16:37:29 INFO Utils: Successfully started service 'HTTP file server' on port 36528.
15/12/29 16:37:29 INFO SparkEnv: Registering OutputCommitCoordinator
15/12/29 16:37:30 INFO Utils: Successfully started service 'SparkUI' on port 4040.
15/12/29 16:37:30 INFO SparkUI: Started SparkUI at http://localhost:4040
15/12/29 16:37:30 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/userFiles-b2f518a7-4265-4a10-b880-e2ffcec60654/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
15/12/29 16:37:30 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1451387250070
15/12/29 16:37:30 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
15/12/29 16:37:30 INFO Executor: Starting executor ID driver on host localhost
15/12/29 16:37:30 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44624.
15/12/29 16:37:30 INFO NettyBlockTransferService: Server created on 44624
15/12/29 16:37:30 INFO BlockManagerMaster: Trying to register BlockManager
15/12/29 16:37:30 INFO BlockManagerMasterEndpoint: Registering block manager localhost:44624 with 538.0 MB RAM, BlockManagerId(driver, localhost, 44624)
15/12/29 16:37:30 INFO BlockManagerMaster: Registered BlockManager
15/12/29 16:37:30 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186
15/12/29 16:37:30 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184)
15/12/29 16:37:30 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186) with 2 output partitions
15/12/29 16:37:30 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186)
15/12/29 16:37:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
15/12/29 16:37:30 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
15/12/29 16:37:30 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184), which has no missing parents
15/12/29 16:37:30 INFO MemoryStore: ensureFreeSpace(7120) called with curMem=0, maxMem=564107673
15/12/29 16:37:30 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 7.0 KB, free 538.0 MB)
15/12/29 16:37:30 INFO MemoryStore: ensureFreeSpace(4576) called with curMem=7120, maxMem=564107673
15/12/29 16:37:30 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.5 KB, free 538.0 MB)
15/12/29 16:37:30 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:44624 (size: 4.5 KB, free: 538.0 MB)
15/12/29 16:37:30 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
15/12/29 16:37:30 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184)
15/12/29 16:37:30 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
15/12/29 16:37:30 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2401 bytes)
15/12/29 16:37:30 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2424 bytes)
15/12/29 16:37:30 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
15/12/29 16:37:30 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1451387250070
15/12/29 16:37:30 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
15/12/29 16:37:30 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/userFiles-b2f518a7-4265-4a10-b880-e2ffcec60654/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
*** Introductory Examples for the NLTK Book ***
Loading text1, ..., text9 and sent1, ..., sent9
Type the name of the text or sentence to view it.
Type: 'texts()' or 'sents()' to list the materials.
*** Introductory Examples for the NLTK Book ***
Loading text1, ..., text9 and sent1, ..., sent9
Type the name of the text or sentence to view it.
Type: 'texts()' or 'sents()' to list the materials.
text1: Moby Dick by Herman Melville 1851
text1: Moby Dick by Herman Melville 1851
text2: Sense and Sensibility by Jane Austen 1811
text2: Sense and Sensibility by Jane Austen 1811
text3: The Book of Genesis
text3: The Book of Genesis
text4: Inaugural Address Corpus
text4: Inaugural Address Corpus
text5: Chat Corpus
text6: Monty Python and the Holy Grail
text5: Chat Corpus
text6: Monty Python and the Holy Grail
text7: Wall Street Journal
text8: Personals Corpus
text7: Wall Street Journal
text8: Personals Corpus
text9: The Man Who Was Thursday by G . K . Chesterton 1908
mapFunction_Parents(): keyword =  locomotive ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
text9: The Man Who Was Thursday by G . K . Chesterton 1908
mapFunction_Parents(): keyword =  provided ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  railway ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  car ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  drawn ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  line ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'railway']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway']
mapFunction_Parents(): keyword =  public ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway']
mapFunction_Parents(): keyword =  transport ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'line', u'transport']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:38:06 INFO PythonRunner: Times: total = 36218, boot = 491, init = 27670, finish = 8057
15/12/29 16:38:06 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
15/12/29 16:38:06 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 36316 ms on localhost (1/2)
mapFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  powered ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  electricity ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  cars ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'coupled']
reduceFunction_Parents(): returns= [u'coupled']
mapFunction_Parents(): keyword =  coupled ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'coupled']
mapFunction_Parents(): keyword =  together ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'coupled']
15/12/29 16:38:07 INFO PythonRunner: Times: total = 36839, boot = 492, init = 28031, finish = 8316
15/12/29 16:38:07 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
15/12/29 16:38:07 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184) finished in 36.931 s
15/12/29 16:38:07 INFO DAGScheduler: looking for newly runnable stages
15/12/29 16:38:07 INFO DAGScheduler: running: Set()
15/12/29 16:38:07 INFO DAGScheduler: waiting: Set(ResultStage 1)
15/12/29 16:38:07 INFO DAGScheduler: failed: Set()
15/12/29 16:38:07 INFO DAGScheduler: Missing parents for ResultStage 1: List()
15/12/29 16:38:07 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186), which is now runnable
15/12/29 16:38:07 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11696, maxMem=564107673
15/12/29 16:38:07 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 538.0 MB)
15/12/29 16:38:07 INFO MemoryStore: ensureFreeSpace(3054) called with curMem=16680, maxMem=564107673
15/12/29 16:38:07 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 36940 ms on localhost (2/2)
15/12/29 16:38:07 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
15/12/29 16:38:07 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 538.0 MB)
15/12/29 16:38:07 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:44624 (size: 3.0 KB, free: 538.0 MB)
15/12/29 16:38:07 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
15/12/29 16:38:07 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186)
15/12/29 16:38:07 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
15/12/29 16:38:07 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
15/12/29 16:38:07 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
15/12/29 16:38:07 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
15/12/29 16:38:07 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
15/12/29 16:38:07 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/12/29 16:38:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
15/12/29 16:38:07 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/12/29 16:38:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
15/12/29 16:38:07 INFO PythonRunner: Times: total = 11, boot = -422, init = 433, finish = 0
15/12/29 16:38:07 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
15/12/29 16:38:07 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 74 ms on localhost (1/2)
reduceFunction_Parents(): returns= [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:38:07 INFO PythonRunner: Times: total = 264, boot = 263, init = 1, finish = 0
15/12/29 16:38:07 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1360 bytes result sent to driver
15/12/29 16:38:07 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 280 ms on localhost (2/2)
15/12/29 16:38:07 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
15/12/29 16:38:07 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186) finished in 0.278 s
15/12/29 16:38:07 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186, took 37.263727 s
15/12/29 16:38:07 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189
15/12/29 16:38:07 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189) with 2 output partitions
15/12/29 16:38:07 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189)
15/12/29 16:38:07 INFO DAGScheduler: Parents of final stage: List()
15/12/29 16:38:07 INFO DAGScheduler: Missing parents: List()
15/12/29 16:38:07 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189), which has no missing parents
15/12/29 16:38:07 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19734, maxMem=564107673
15/12/29 16:38:07 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 538.0 MB)
15/12/29 16:38:07 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25550, maxMem=564107673
15/12/29 16:38:07 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 537.9 MB)
15/12/29 16:38:07 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:44624 (size: 3.3 KB, free: 538.0 MB)
15/12/29 16:38:07 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
15/12/29 16:38:07 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189)
15/12/29 16:38:07 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
15/12/29 16:38:07 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
15/12/29 16:38:07 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2441 bytes)
15/12/29 16:38:07 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
15/12/29 16:38:07 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
15/12/29 16:38:07 INFO PythonRunner: Times: total = 155, boot = 154, init = 1, finish = 0
15/12/29 16:38:07 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
15/12/29 16:38:07 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 164 ms on localhost (1/2)
15/12/29 16:38:07 INFO PythonRunner: Times: total = 165, boot = 165, init = 0, finish = 0
15/12/29 16:38:07 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1422 bytes result sent to driver
15/12/29 16:38:07 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 188 ms on localhost (2/2)
15/12/29 16:38:07 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
15/12/29 16:38:07 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189) finished in 0.181 s
15/12/29 16:38:07 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189, took 0.228997 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
15/12/29 16:38:07 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
15/12/29 16:38:07 INFO DAGScheduler: Stopping DAGScheduler
15/12/29 16:38:07 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
15/12/29 16:38:07 INFO MemoryStore: MemoryStore cleared
15/12/29 16:38:07 INFO BlockManager: BlockManager stopped
15/12/29 16:38:07 INFO BlockManagerMaster: BlockManagerMaster stopped
15/12/29 16:38:07 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
15/12/29 16:38:08 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
15/12/29 16:38:08 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
15/12/29 16:38:08 INFO SparkContext: Successfully stopped SparkContext
15/12/29 16:38:08 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:38:08 INFO SparkContext: Running Spark version 1.5.2
15/12/29 16:38:08 INFO SecurityManager: Changing view acls to: root
15/12/29 16:38:08 INFO SecurityManager: Changing modify acls to: root
15/12/29 16:38:08 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
15/12/29 16:38:08 INFO Slf4jLogger: Slf4jLogger started
15/12/29 16:38:08 INFO Remoting: Starting remoting
15/12/29 16:38:08 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:51162]
15/12/29 16:38:08 INFO Utils: Successfully started service 'sparkDriver' on port 51162.
15/12/29 16:38:08 INFO SparkEnv: Registering MapOutputTracker
15/12/29 16:38:08 INFO SparkEnv: Registering BlockManagerMaster
15/12/29 16:38:08 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-8fe9e796-a084-4e69-9d47-3a2d469f1e37
15/12/29 16:38:08 INFO MemoryStore: MemoryStore started with capacity 538.0 MB
15/12/29 16:38:08 INFO HttpFileServer: HTTP File server directory is /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/httpd-c4b2ffb0-8e25-4671-8418-68a5dafcbbc1
15/12/29 16:38:08 INFO HttpServer: Starting HTTP Server
15/12/29 16:38:08 INFO Utils: Successfully started service 'HTTP file server' on port 39727.
15/12/29 16:38:08 INFO SparkEnv: Registering OutputCommitCoordinator
15/12/29 16:38:09 INFO Utils: Successfully started service 'SparkUI' on port 4040.
15/12/29 16:38:09 INFO SparkUI: Started SparkUI at http://localhost:4040
15/12/29 16:38:09 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/userFiles-98abf234-9201-4d67-9463-9c70731ea77b/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
15/12/29 16:38:09 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1451387289440
15/12/29 16:38:09 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
15/12/29 16:38:09 INFO Executor: Starting executor ID driver on host localhost
15/12/29 16:38:09 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56926.
15/12/29 16:38:09 INFO NettyBlockTransferService: Server created on 56926
15/12/29 16:38:09 INFO BlockManagerMaster: Trying to register BlockManager
15/12/29 16:38:09 INFO BlockManagerMasterEndpoint: Registering block manager localhost:56926 with 538.0 MB RAM, BlockManagerId(driver, localhost, 56926)
15/12/29 16:38:09 INFO BlockManagerMaster: Registered BlockManager
15/12/29 16:38:09 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186
15/12/29 16:38:09 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184)
15/12/29 16:38:09 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186) with 2 output partitions
15/12/29 16:38:09 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186)
15/12/29 16:38:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
15/12/29 16:38:09 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
15/12/29 16:38:09 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184), which has no missing parents
15/12/29 16:38:09 INFO MemoryStore: ensureFreeSpace(7120) called with curMem=0, maxMem=564107673
15/12/29 16:38:09 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 7.0 KB, free 538.0 MB)
15/12/29 16:38:09 INFO MemoryStore: ensureFreeSpace(4573) called with curMem=7120, maxMem=564107673
15/12/29 16:38:09 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.5 KB, free 538.0 MB)
15/12/29 16:38:09 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:56926 (size: 4.5 KB, free: 538.0 MB)
15/12/29 16:38:09 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
15/12/29 16:38:09 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184)
15/12/29 16:38:09 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
15/12/29 16:38:09 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2401 bytes)
15/12/29 16:38:09 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2424 bytes)
15/12/29 16:38:09 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
15/12/29 16:38:09 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1451387289440
15/12/29 16:38:09 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
15/12/29 16:38:09 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/userFiles-98abf234-9201-4d67-9463-9c70731ea77b/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
*** Introductory Examples for the NLTK Book ***
Loading text1, ..., text9 and sent1, ..., sent9
Type the name of the text or sentence to view it.
Type: 'texts()' or 'sents()' to list the materials.
*** Introductory Examples for the NLTK Book ***
Loading text1, ..., text9 and sent1, ..., sent9
Type the name of the text or sentence to view it.
Type: 'texts()' or 'sents()' to list the materials.
text1: Moby Dick by Herman Melville 1851
text1: Moby Dick by Herman Melville 1851
text2: Sense and Sensibility by Jane Austen 1811
text2: Sense and Sensibility by Jane Austen 1811
text3: The Book of Genesis
text3: The Book of Genesis
text4: Inaugural Address Corpus
text4: Inaugural Address Corpus
text5: Chat Corpus
text6: Monty Python and the Holy Grail
text5: Chat Corpus
text6: Monty Python and the Holy Grail
text7: Wall Street Journal
text8: Personals Corpus
text9: The Man Who Was Thursday by G . K . Chesterton 1908
mapFunction_Parents(): keyword =  provided ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
text7: Wall Street Journal
text8: Personals Corpus
text9: The Man Who Was Thursday by G . K . Chesterton 1908
mapFunction_Parents(): keyword =  locomotive ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  powered ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  electricity ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  cars ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'coupled']
reduceFunction_Parents(): returns= [u'coupled']
mapFunction_Parents(): keyword =  coupled ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  railway ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'coupled']
mapFunction_Parents(): keyword =  together ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  car ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  drawn ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'coupled']
15/12/29 16:38:45 INFO PythonRunner: Times: total = 35935, boot = 477, init = 27188, finish = 8270
15/12/29 16:38:45 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
15/12/29 16:38:45 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 36019 ms on localhost (1/2)
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  line ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'railway']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway']
mapFunction_Parents(): keyword =  public ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway']
mapFunction_Parents(): keyword =  transport ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'line', u'transport']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:38:45 INFO PythonRunner: Times: total = 36350, boot = 478, init = 27918, finish = 7954
15/12/29 16:38:45 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
15/12/29 16:38:46 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184) finished in 36.416 s
15/12/29 16:38:46 INFO DAGScheduler: looking for newly runnable stages
15/12/29 16:38:46 INFO DAGScheduler: running: Set()
15/12/29 16:38:46 INFO DAGScheduler: waiting: Set(ResultStage 1)
15/12/29 16:38:46 INFO DAGScheduler: failed: Set()
15/12/29 16:38:46 INFO DAGScheduler: Missing parents for ResultStage 1: List()
15/12/29 16:38:46 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186), which is now runnable
15/12/29 16:38:46 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11693, maxMem=564107673
15/12/29 16:38:46 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 538.0 MB)
15/12/29 16:38:46 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 36427 ms on localhost (2/2)
15/12/29 16:38:46 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
15/12/29 16:38:46 INFO MemoryStore: ensureFreeSpace(3054) called with curMem=16677, maxMem=564107673
15/12/29 16:38:46 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 538.0 MB)
15/12/29 16:38:46 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:56926 (size: 3.0 KB, free: 538.0 MB)
15/12/29 16:38:46 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
15/12/29 16:38:46 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186)
15/12/29 16:38:46 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
15/12/29 16:38:46 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
15/12/29 16:38:46 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
15/12/29 16:38:46 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
15/12/29 16:38:46 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
15/12/29 16:38:46 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/12/29 16:38:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
15/12/29 16:38:46 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/12/29 16:38:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
15/12/29 16:38:46 INFO PythonRunner: Times: total = 51, boot = -183, init = 234, finish = 0
15/12/29 16:38:46 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
15/12/29 16:38:46 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 78 ms on localhost (1/2)
reduceFunction_Parents(): returns= [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:38:46 INFO PythonRunner: Times: total = 197, boot = 196, init = 0, finish = 1
15/12/29 16:38:46 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1360 bytes result sent to driver
15/12/29 16:38:46 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 215 ms on localhost (2/2)
15/12/29 16:38:46 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
15/12/29 16:38:46 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186) finished in 0.208 s
15/12/29 16:38:46 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186, took 36.690671 s
15/12/29 16:38:46 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189
15/12/29 16:38:46 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189) with 2 output partitions
15/12/29 16:38:46 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189)
15/12/29 16:38:46 INFO DAGScheduler: Parents of final stage: List()
15/12/29 16:38:46 INFO DAGScheduler: Missing parents: List()
15/12/29 16:38:46 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189), which has no missing parents
15/12/29 16:38:46 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19731, maxMem=564107673
15/12/29 16:38:46 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 538.0 MB)
15/12/29 16:38:46 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25547, maxMem=564107673
15/12/29 16:38:46 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 537.9 MB)
15/12/29 16:38:46 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:56926 (size: 3.3 KB, free: 538.0 MB)
15/12/29 16:38:46 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
15/12/29 16:38:46 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189)
15/12/29 16:38:46 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
15/12/29 16:38:46 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
15/12/29 16:38:46 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2441 bytes)
15/12/29 16:38:46 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
15/12/29 16:38:46 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
15/12/29 16:38:46 INFO PythonRunner: Times: total = 58, boot = 58, init = 0, finish = 0
15/12/29 16:38:46 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
15/12/29 16:38:46 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 71 ms on localhost (1/2)
15/12/29 16:38:46 INFO PythonRunner: Times: total = 174, boot = 171, init = 1, finish = 2
15/12/29 16:38:46 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1422 bytes result sent to driver
15/12/29 16:38:46 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 187 ms on localhost (2/2)
15/12/29 16:38:46 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
15/12/29 16:38:46 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189) finished in 0.188 s
15/12/29 16:38:46 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189, took 0.205661 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
15/12/29 16:38:46 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
15/12/29 16:38:46 INFO DAGScheduler: Stopping DAGScheduler
15/12/29 16:38:46 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
15/12/29 16:38:46 INFO MemoryStore: MemoryStore cleared
15/12/29 16:38:46 INFO BlockManager: BlockManager stopped
15/12/29 16:38:46 INFO BlockManagerMaster: BlockManagerMaster stopped
15/12/29 16:38:46 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
15/12/29 16:38:46 INFO SparkContext: Successfully stopped SparkContext
15/12/29 16:38:46 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
15/12/29 16:38:46 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
15/12/29 16:38:46 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:38:47 INFO SparkContext: Running Spark version 1.5.2
15/12/29 16:38:47 INFO SecurityManager: Changing view acls to: root
15/12/29 16:38:47 INFO SecurityManager: Changing modify acls to: root
15/12/29 16:38:47 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
15/12/29 16:38:47 INFO Slf4jLogger: Slf4jLogger started
15/12/29 16:38:47 INFO Remoting: Starting remoting
15/12/29 16:38:47 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:37797]
15/12/29 16:38:47 INFO Utils: Successfully started service 'sparkDriver' on port 37797.
15/12/29 16:38:47 INFO SparkEnv: Registering MapOutputTracker
15/12/29 16:38:47 INFO SparkEnv: Registering BlockManagerMaster
15/12/29 16:38:47 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-634d3a14-25ea-4111-9917-f0295f5d7959
15/12/29 16:38:47 INFO MemoryStore: MemoryStore started with capacity 538.0 MB
15/12/29 16:38:47 INFO HttpFileServer: HTTP File server directory is /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/httpd-408717bf-17ff-474c-8d8c-cec61bd59a12
15/12/29 16:38:47 INFO HttpServer: Starting HTTP Server
15/12/29 16:38:47 INFO Utils: Successfully started service 'HTTP file server' on port 47328.
15/12/29 16:38:47 INFO SparkEnv: Registering OutputCommitCoordinator
15/12/29 16:38:48 INFO Utils: Successfully started service 'SparkUI' on port 4040.
15/12/29 16:38:48 INFO SparkUI: Started SparkUI at http://localhost:4040
15/12/29 16:38:48 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/userFiles-ef3fffe1-353b-4a6c-9fdc-547b41161870/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
15/12/29 16:38:48 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1451387328144
15/12/29 16:38:48 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
15/12/29 16:38:48 INFO Executor: Starting executor ID driver on host localhost
15/12/29 16:38:48 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37098.
15/12/29 16:38:48 INFO NettyBlockTransferService: Server created on 37098
15/12/29 16:38:48 INFO BlockManagerMaster: Trying to register BlockManager
15/12/29 16:38:48 INFO BlockManagerMasterEndpoint: Registering block manager localhost:37098 with 538.0 MB RAM, BlockManagerId(driver, localhost, 37098)
15/12/29 16:38:48 INFO BlockManagerMaster: Registered BlockManager
15/12/29 16:38:48 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186
15/12/29 16:38:48 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184)
15/12/29 16:38:48 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186) with 2 output partitions
15/12/29 16:38:48 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186)
15/12/29 16:38:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
15/12/29 16:38:48 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
15/12/29 16:38:48 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184), which has no missing parents
15/12/29 16:38:48 INFO MemoryStore: ensureFreeSpace(7120) called with curMem=0, maxMem=564107673
15/12/29 16:38:48 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 7.0 KB, free 538.0 MB)
15/12/29 16:38:48 INFO MemoryStore: ensureFreeSpace(4573) called with curMem=7120, maxMem=564107673
15/12/29 16:38:48 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.5 KB, free 538.0 MB)
15/12/29 16:38:48 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:37098 (size: 4.5 KB, free: 538.0 MB)
15/12/29 16:38:48 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
15/12/29 16:38:48 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184)
15/12/29 16:38:48 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
15/12/29 16:38:48 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2401 bytes)
15/12/29 16:38:48 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2424 bytes)
15/12/29 16:38:48 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
15/12/29 16:38:48 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1451387328144
15/12/29 16:38:48 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
15/12/29 16:38:48 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/userFiles-ef3fffe1-353b-4a6c-9fdc-547b41161870/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
*** Introductory Examples for the NLTK Book ***
Loading text1, ..., text9 and sent1, ..., sent9
Type the name of the text or sentence to view it.
Type: 'texts()' or 'sents()' to list the materials.
*** Introductory Examples for the NLTK Book ***
Loading text1, ..., text9 and sent1, ..., sent9
Type the name of the text or sentence to view it.
Type: 'texts()' or 'sents()' to list the materials.
text1: Moby Dick by Herman Melville 1851
text1: Moby Dick by Herman Melville 1851
text2: Sense and Sensibility by Jane Austen 1811
text2: Sense and Sensibility by Jane Austen 1811
text3: The Book of Genesis
text3: The Book of Genesis
text4: Inaugural Address Corpus
text4: Inaugural Address Corpus
text5: Chat Corpus
text6: Monty Python and the Holy Grail
text5: Chat Corpus
text6: Monty Python and the Holy Grail
text7: Wall Street Journal
text8: Personals Corpus
text7: Wall Street Journal
text8: Personals Corpus
text9: The Man Who Was Thursday by G . K . Chesterton 1908
mapFunction_Parents(): keyword =  provided ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
text9: The Man Who Was Thursday by G . K . Chesterton 1908
mapFunction_Parents(): keyword =  locomotive ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  powered ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  electricity ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  cars ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'coupled']
reduceFunction_Parents(): returns= [u'coupled']
mapFunction_Parents(): keyword =  coupled ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'coupled']
mapFunction_Parents(): keyword =  together ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'coupled']
15/12/29 16:39:24 INFO PythonRunner: Times: total = 36290, boot = 461, init = 27743, finish = 8086
15/12/29 16:39:24 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
15/12/29 16:39:24 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 36383 ms on localhost (1/2)
mapFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  railway ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  car ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  drawn ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  line ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'railway']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway']
mapFunction_Parents(): keyword =  public ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway']
mapFunction_Parents(): keyword =  transport ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'line', u'transport']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:39:25 INFO PythonRunner: Times: total = 36881, boot = 454, init = 28161, finish = 8266
15/12/29 16:39:25 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
15/12/29 16:39:25 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184) finished in 36.936 s
15/12/29 16:39:25 INFO DAGScheduler: looking for newly runnable stages
15/12/29 16:39:25 INFO DAGScheduler: running: Set()
15/12/29 16:39:25 INFO DAGScheduler: waiting: Set(ResultStage 1)
15/12/29 16:39:25 INFO DAGScheduler: failed: Set()
15/12/29 16:39:25 INFO DAGScheduler: Missing parents for ResultStage 1: List()
15/12/29 16:39:25 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186), which is now runnable
15/12/29 16:39:25 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11693, maxMem=564107673
15/12/29 16:39:25 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 538.0 MB)
15/12/29 16:39:25 INFO MemoryStore: ensureFreeSpace(3054) called with curMem=16677, maxMem=564107673
15/12/29 16:39:25 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 538.0 MB)
15/12/29 16:39:25 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 36948 ms on localhost (2/2)
15/12/29 16:39:25 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:37098 (size: 3.0 KB, free: 538.0 MB)
15/12/29 16:39:25 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
15/12/29 16:39:25 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
15/12/29 16:39:25 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186)
15/12/29 16:39:25 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
15/12/29 16:39:25 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
15/12/29 16:39:25 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
15/12/29 16:39:25 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
15/12/29 16:39:25 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
15/12/29 16:39:25 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/12/29 16:39:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
15/12/29 16:39:25 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/12/29 16:39:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
15/12/29 16:39:25 INFO PythonRunner: Times: total = 11, boot = -352, init = 362, finish = 1
15/12/29 16:39:25 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
15/12/29 16:39:25 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 67 ms on localhost (1/2)
reduceFunction_Parents(): returns= [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:39:25 INFO PythonRunner: Times: total = 282, boot = 279, init = 0, finish = 3
15/12/29 16:39:25 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1360 bytes result sent to driver
15/12/29 16:39:25 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186) finished in 0.306 s
15/12/29 16:39:25 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 298 ms on localhost (2/2)
15/12/29 16:39:25 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
15/12/29 16:39:25 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186, took 37.290007 s
15/12/29 16:39:25 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189
15/12/29 16:39:25 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189) with 2 output partitions
15/12/29 16:39:25 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189)
15/12/29 16:39:25 INFO DAGScheduler: Parents of final stage: List()
15/12/29 16:39:25 INFO DAGScheduler: Missing parents: List()
15/12/29 16:39:25 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189), which has no missing parents
15/12/29 16:39:25 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19731, maxMem=564107673
15/12/29 16:39:25 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 538.0 MB)
15/12/29 16:39:25 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25547, maxMem=564107673
15/12/29 16:39:25 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 537.9 MB)
15/12/29 16:39:25 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:37098 (size: 3.3 KB, free: 538.0 MB)
15/12/29 16:39:25 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
15/12/29 16:39:25 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189)
15/12/29 16:39:25 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
15/12/29 16:39:25 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
15/12/29 16:39:25 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2441 bytes)
15/12/29 16:39:25 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
15/12/29 16:39:25 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
15/12/29 16:39:25 INFO PythonRunner: Times: total = 64, boot = -177, init = 241, finish = 0
15/12/29 16:39:25 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
15/12/29 16:39:25 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 85 ms on localhost (1/2)
15/12/29 16:39:25 INFO PythonRunner: Times: total = 93, boot = 93, init = 0, finish = 0
15/12/29 16:39:25 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1422 bytes result sent to driver
15/12/29 16:39:25 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 121 ms on localhost (2/2)
15/12/29 16:39:25 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
15/12/29 16:39:25 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189) finished in 0.088 s
15/12/29 16:39:25 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189, took 0.160677 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
15/12/29 16:39:25 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
15/12/29 16:39:25 INFO DAGScheduler: Stopping DAGScheduler
15/12/29 16:39:26 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
15/12/29 16:39:26 INFO MemoryStore: MemoryStore cleared
15/12/29 16:39:26 INFO BlockManager: BlockManager stopped
15/12/29 16:39:26 INFO BlockManagerMaster: BlockManagerMaster stopped
15/12/29 16:39:26 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
15/12/29 16:39:26 INFO SparkContext: Successfully stopped SparkContext
15/12/29 16:39:26 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
15/12/29 16:39:26 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
15/12/29 16:39:26 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:39:26 INFO SparkContext: Running Spark version 1.5.2
15/12/29 16:39:26 INFO SecurityManager: Changing view acls to: root
15/12/29 16:39:26 INFO SecurityManager: Changing modify acls to: root
15/12/29 16:39:26 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
15/12/29 16:39:26 INFO Slf4jLogger: Slf4jLogger started
15/12/29 16:39:26 INFO Remoting: Starting remoting
15/12/29 16:39:26 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:51280]
15/12/29 16:39:26 INFO Utils: Successfully started service 'sparkDriver' on port 51280.
15/12/29 16:39:26 INFO SparkEnv: Registering MapOutputTracker
15/12/29 16:39:26 INFO SparkEnv: Registering BlockManagerMaster
15/12/29 16:39:26 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-ba996c61-1e1b-4b71-9310-89c07455eaa6
15/12/29 16:39:26 INFO MemoryStore: MemoryStore started with capacity 538.0 MB
15/12/29 16:39:26 INFO HttpFileServer: HTTP File server directory is /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/httpd-8dd96924-74e9-4b7e-9afb-aac942e8efa2
15/12/29 16:39:26 INFO HttpServer: Starting HTTP Server
15/12/29 16:39:27 INFO Utils: Successfully started service 'HTTP file server' on port 54445.
15/12/29 16:39:27 INFO SparkEnv: Registering OutputCommitCoordinator
15/12/29 16:39:27 INFO Utils: Successfully started service 'SparkUI' on port 4040.
15/12/29 16:39:27 INFO SparkUI: Started SparkUI at http://localhost:4040
15/12/29 16:39:27 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/userFiles-e2406d5a-4cbe-42fc-97af-3086c7814831/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
15/12/29 16:39:27 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1451387367334
15/12/29 16:39:27 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
15/12/29 16:39:27 INFO Executor: Starting executor ID driver on host localhost
15/12/29 16:39:27 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52468.
15/12/29 16:39:27 INFO NettyBlockTransferService: Server created on 52468
15/12/29 16:39:27 INFO BlockManagerMaster: Trying to register BlockManager
15/12/29 16:39:27 INFO BlockManagerMasterEndpoint: Registering block manager localhost:52468 with 538.0 MB RAM, BlockManagerId(driver, localhost, 52468)
15/12/29 16:39:27 INFO BlockManagerMaster: Registered BlockManager
15/12/29 16:39:27 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186
15/12/29 16:39:27 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184)
15/12/29 16:39:27 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186) with 2 output partitions
15/12/29 16:39:27 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186)
15/12/29 16:39:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
15/12/29 16:39:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
15/12/29 16:39:27 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184), which has no missing parents
15/12/29 16:39:27 INFO MemoryStore: ensureFreeSpace(7120) called with curMem=0, maxMem=564107673
15/12/29 16:39:27 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 7.0 KB, free 538.0 MB)
15/12/29 16:39:27 INFO MemoryStore: ensureFreeSpace(4573) called with curMem=7120, maxMem=564107673
15/12/29 16:39:27 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.5 KB, free 538.0 MB)
15/12/29 16:39:27 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:52468 (size: 4.5 KB, free: 538.0 MB)
15/12/29 16:39:27 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
15/12/29 16:39:27 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184)
15/12/29 16:39:27 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
15/12/29 16:39:27 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2401 bytes)
15/12/29 16:39:27 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2424 bytes)
15/12/29 16:39:27 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
15/12/29 16:39:27 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1451387367334
15/12/29 16:39:27 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
15/12/29 16:39:27 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/userFiles-e2406d5a-4cbe-42fc-97af-3086c7814831/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
*** Introductory Examples for the NLTK Book ***
Loading text1, ..., text9 and sent1, ..., sent9
Type the name of the text or sentence to view it.
Type: 'texts()' or 'sents()' to list the materials.
*** Introductory Examples for the NLTK Book ***
Loading text1, ..., text9 and sent1, ..., sent9
Type the name of the text or sentence to view it.
Type: 'texts()' or 'sents()' to list the materials.
text1: Moby Dick by Herman Melville 1851
text1: Moby Dick by Herman Melville 1851
text2: Sense and Sensibility by Jane Austen 1811
text2: Sense and Sensibility by Jane Austen 1811
text3: The Book of Genesis
text3: The Book of Genesis
text4: Inaugural Address Corpus
text4: Inaugural Address Corpus
text5: Chat Corpus
text6: Monty Python and the Holy Grail
text5: Chat Corpus
text6: Monty Python and the Holy Grail
text7: Wall Street Journal
text8: Personals Corpus
text7: Wall Street Journal
text8: Personals Corpus
text9: The Man Who Was Thursday by G . K . Chesterton 1908
mapFunction_Parents(): keyword =  locomotive ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
text9: The Man Who Was Thursday by G . K . Chesterton 1908
mapFunction_Parents(): keyword =  provided ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  railway ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  car ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  drawn ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  line ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'railway']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway']
mapFunction_Parents(): keyword =  public ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway']
mapFunction_Parents(): keyword =  transport ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  powered ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'line', u'transport']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:40:03 INFO PythonRunner: Times: total = 36292, boot = 453, init = 27622, finish = 8217
15/12/29 16:40:03 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
15/12/29 16:40:03 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 36353 ms on localhost (1/2)
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  electricity ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  cars ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'coupled']
reduceFunction_Parents(): returns= [u'coupled']
mapFunction_Parents(): keyword =  coupled ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'coupled']
mapFunction_Parents(): keyword =  together ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'coupled']
15/12/29 16:40:04 INFO PythonRunner: Times: total = 36803, boot = 447, init = 27651, finish = 8705
15/12/29 16:40:04 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
15/12/29 16:40:04 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 36865 ms on localhost (2/2)
15/12/29 16:40:04 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
15/12/29 16:40:04 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184) finished in 36.881 s
15/12/29 16:40:04 INFO DAGScheduler: looking for newly runnable stages
15/12/29 16:40:04 INFO DAGScheduler: running: Set()
15/12/29 16:40:04 INFO DAGScheduler: waiting: Set(ResultStage 1)
15/12/29 16:40:04 INFO DAGScheduler: failed: Set()
15/12/29 16:40:04 INFO DAGScheduler: Missing parents for ResultStage 1: List()
15/12/29 16:40:04 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186), which is now runnable
15/12/29 16:40:04 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11693, maxMem=564107673
15/12/29 16:40:04 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 538.0 MB)
15/12/29 16:40:04 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16677, maxMem=564107673
15/12/29 16:40:04 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 538.0 MB)
15/12/29 16:40:04 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:52468 (size: 3.0 KB, free: 538.0 MB)
15/12/29 16:40:04 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
15/12/29 16:40:04 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186)
15/12/29 16:40:04 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
15/12/29 16:40:04 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
15/12/29 16:40:04 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
15/12/29 16:40:04 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
15/12/29 16:40:04 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
15/12/29 16:40:04 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/12/29 16:40:04 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/12/29 16:40:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
15/12/29 16:40:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
15/12/29 16:40:04 INFO PythonRunner: Times: total = 15, boot = -319, init = 334, finish = 0
15/12/29 16:40:04 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
15/12/29 16:40:04 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 61 ms on localhost (1/2)
reduceFunction_Parents(): returns= [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:40:04 INFO PythonRunner: Times: total = 249, boot = 247, init = 1, finish = 1
15/12/29 16:40:04 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1360 bytes result sent to driver
15/12/29 16:40:04 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 262 ms on localhost (2/2)
15/12/29 16:40:04 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
15/12/29 16:40:04 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186) finished in 0.266 s
15/12/29 16:40:04 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186, took 37.324074 s
15/12/29 16:40:04 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189
15/12/29 16:40:04 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189) with 2 output partitions
15/12/29 16:40:04 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189)
15/12/29 16:40:04 INFO DAGScheduler: Parents of final stage: List()
15/12/29 16:40:04 INFO DAGScheduler: Missing parents: List()
15/12/29 16:40:04 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189), which has no missing parents
15/12/29 16:40:04 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19732, maxMem=564107673
15/12/29 16:40:04 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 538.0 MB)
15/12/29 16:40:04 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25548, maxMem=564107673
15/12/29 16:40:04 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 537.9 MB)
15/12/29 16:40:04 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:52468 (size: 3.3 KB, free: 538.0 MB)
15/12/29 16:40:04 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
15/12/29 16:40:04 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189)
15/12/29 16:40:04 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
15/12/29 16:40:04 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
15/12/29 16:40:04 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2441 bytes)
15/12/29 16:40:04 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
15/12/29 16:40:04 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
15/12/29 16:40:05 INFO PythonRunner: Times: total = 47, boot = -75, init = 122, finish = 0
15/12/29 16:40:05 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
15/12/29 16:40:05 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 72 ms on localhost (1/2)
15/12/29 16:40:05 INFO PythonRunner: Times: total = 85, boot = 84, init = 1, finish = 0
15/12/29 16:40:05 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1422 bytes result sent to driver
15/12/29 16:40:05 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 98 ms on localhost (2/2)
15/12/29 16:40:05 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
15/12/29 16:40:05 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189) finished in 0.100 s
15/12/29 16:40:05 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189, took 0.136001 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
15/12/29 16:40:05 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
15/12/29 16:40:05 INFO DAGScheduler: Stopping DAGScheduler
15/12/29 16:40:05 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
15/12/29 16:40:05 INFO MemoryStore: MemoryStore cleared
15/12/29 16:40:05 INFO BlockManager: BlockManager stopped
15/12/29 16:40:05 INFO BlockManagerMaster: BlockManagerMaster stopped
15/12/29 16:40:05 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
15/12/29 16:40:05 INFO SparkContext: Successfully stopped SparkContext
15/12/29 16:40:05 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
15/12/29 16:40:05 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
15/12/29 16:40:05 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:40:06 INFO SparkContext: Running Spark version 1.5.2
15/12/29 16:40:06 INFO SecurityManager: Changing view acls to: root
15/12/29 16:40:06 INFO SecurityManager: Changing modify acls to: root
15/12/29 16:40:06 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
15/12/29 16:40:06 INFO Slf4jLogger: Slf4jLogger started
15/12/29 16:40:06 INFO Remoting: Starting remoting
15/12/29 16:40:06 INFO Utils: Successfully started service 'sparkDriver' on port 48596.
15/12/29 16:40:06 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:48596]
15/12/29 16:40:06 INFO SparkEnv: Registering MapOutputTracker
15/12/29 16:40:06 INFO SparkEnv: Registering BlockManagerMaster
15/12/29 16:40:06 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-435abac2-a8f1-495a-8744-393acdea6416
15/12/29 16:40:06 INFO MemoryStore: MemoryStore started with capacity 532.8 MB
15/12/29 16:40:06 INFO HttpFileServer: HTTP File server directory is /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/httpd-7e2fd18d-0437-423d-b40f-9ec037cb0797
15/12/29 16:40:06 INFO HttpServer: Starting HTTP Server
15/12/29 16:40:06 INFO Utils: Successfully started service 'HTTP file server' on port 44197.
15/12/29 16:40:06 INFO SparkEnv: Registering OutputCommitCoordinator
15/12/29 16:40:06 INFO Utils: Successfully started service 'SparkUI' on port 4040.
15/12/29 16:40:06 INFO SparkUI: Started SparkUI at http://localhost:4040
15/12/29 16:40:06 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/userFiles-19fb4f01-c1f4-4961-a552-a745a45b97a0/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
15/12/29 16:40:06 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1451387406678
15/12/29 16:40:06 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
15/12/29 16:40:06 INFO Executor: Starting executor ID driver on host localhost
15/12/29 16:40:06 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34054.
15/12/29 16:40:06 INFO NettyBlockTransferService: Server created on 34054
15/12/29 16:40:06 INFO BlockManagerMaster: Trying to register BlockManager
15/12/29 16:40:06 INFO BlockManagerMasterEndpoint: Registering block manager localhost:34054 with 532.8 MB RAM, BlockManagerId(driver, localhost, 34054)
15/12/29 16:40:06 INFO BlockManagerMaster: Registered BlockManager
15/12/29 16:40:06 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186
15/12/29 16:40:06 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184)
15/12/29 16:40:06 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186) with 2 output partitions
15/12/29 16:40:06 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186)
15/12/29 16:40:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
15/12/29 16:40:06 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
15/12/29 16:40:06 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184), which has no missing parents
15/12/29 16:40:06 INFO MemoryStore: ensureFreeSpace(7120) called with curMem=0, maxMem=558728478
15/12/29 16:40:06 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 7.0 KB, free 532.8 MB)
15/12/29 16:40:06 INFO MemoryStore: ensureFreeSpace(4573) called with curMem=7120, maxMem=558728478
15/12/29 16:40:06 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.5 KB, free 532.8 MB)
15/12/29 16:40:06 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:34054 (size: 4.5 KB, free: 532.8 MB)
15/12/29 16:40:06 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
15/12/29 16:40:06 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184)
15/12/29 16:40:06 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
15/12/29 16:40:06 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2401 bytes)
15/12/29 16:40:06 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2424 bytes)
15/12/29 16:40:06 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
15/12/29 16:40:06 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1451387406678
15/12/29 16:40:06 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
15/12/29 16:40:06 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/userFiles-19fb4f01-c1f4-4961-a552-a745a45b97a0/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
*** Introductory Examples for the NLTK Book ***
Loading text1, ..., text9 and sent1, ..., sent9
Type the name of the text or sentence to view it.
Type: 'texts()' or 'sents()' to list the materials.
*** Introductory Examples for the NLTK Book ***
Loading text1, ..., text9 and sent1, ..., sent9
Type the name of the text or sentence to view it.
Type: 'texts()' or 'sents()' to list the materials.
text1: Moby Dick by Herman Melville 1851
text1: Moby Dick by Herman Melville 1851
text2: Sense and Sensibility by Jane Austen 1811
text2: Sense and Sensibility by Jane Austen 1811
text3: The Book of Genesis
text3: The Book of Genesis
text4: Inaugural Address Corpus
text4: Inaugural Address Corpus
text5: Chat Corpus
text6: Monty Python and the Holy Grail
text5: Chat Corpus
text6: Monty Python and the Holy Grail
text7: Wall Street Journal
text8: Personals Corpus
text9: The Man Who Was Thursday by G . K . Chesterton 1908
mapFunction_Parents(): keyword =  locomotive ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
text7: Wall Street Journal
text8: Personals Corpus
text9: The Man Who Was Thursday by G . K . Chesterton 1908
mapFunction_Parents(): keyword =  provided ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  railway ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  car ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  drawn ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  line ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'railway']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway']
mapFunction_Parents(): keyword =  public ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway']
mapFunction_Parents(): keyword =  transport ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'line', u'transport']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:40:42 INFO PythonRunner: Times: total = 35742, boot = 503, init = 27014, finish = 8225
15/12/29 16:40:42 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
15/12/29 16:40:42 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 35821 ms on localhost (1/2)
mapFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  powered ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  electricity ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  cars ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'coupled']
reduceFunction_Parents(): returns= [u'coupled']
mapFunction_Parents(): keyword =  coupled ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'coupled']
mapFunction_Parents(): keyword =  together ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'coupled']
15/12/29 16:40:44 INFO PythonRunner: Times: total = 37871, boot = 504, init = 28842, finish = 8525
15/12/29 16:40:44 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
15/12/29 16:40:44 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184) finished in 37.948 s
15/12/29 16:40:44 INFO DAGScheduler: looking for newly runnable stages
15/12/29 16:40:44 INFO DAGScheduler: running: Set()
15/12/29 16:40:44 INFO DAGScheduler: waiting: Set(ResultStage 1)
15/12/29 16:40:44 INFO DAGScheduler: failed: Set()
15/12/29 16:40:44 INFO DAGScheduler: Missing parents for ResultStage 1: List()
15/12/29 16:40:44 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186), which is now runnable
15/12/29 16:40:44 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 37956 ms on localhost (2/2)
15/12/29 16:40:44 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
15/12/29 16:40:44 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11693, maxMem=558728478
15/12/29 16:40:44 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 532.8 MB)
15/12/29 16:40:44 INFO MemoryStore: ensureFreeSpace(3054) called with curMem=16677, maxMem=558728478
15/12/29 16:40:44 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 532.8 MB)
15/12/29 16:40:44 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:34054 (size: 3.0 KB, free: 532.8 MB)
15/12/29 16:40:44 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
15/12/29 16:40:44 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186)
15/12/29 16:40:44 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
15/12/29 16:40:44 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
15/12/29 16:40:44 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
15/12/29 16:40:44 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
15/12/29 16:40:44 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
15/12/29 16:40:44 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/12/29 16:40:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
15/12/29 16:40:44 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/12/29 16:40:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
reduceFunction_Parents(): returns= [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:40:44 INFO PythonRunner: Times: total = 20, boot = -1894, init = 1914, finish = 0
15/12/29 16:40:44 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1360 bytes result sent to driver
15/12/29 16:40:44 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 55 ms on localhost (1/2)
15/12/29 16:40:45 INFO PythonRunner: Times: total = 281, boot = 280, init = 0, finish = 1
15/12/29 16:40:45 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
15/12/29 16:40:45 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 294 ms on localhost (2/2)
15/12/29 16:40:45 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186) finished in 0.295 s
15/12/29 16:40:45 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
15/12/29 16:40:45 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186, took 38.287069 s
15/12/29 16:40:45 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189
15/12/29 16:40:45 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189) with 2 output partitions
15/12/29 16:40:45 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189)
15/12/29 16:40:45 INFO DAGScheduler: Parents of final stage: List()
15/12/29 16:40:45 INFO DAGScheduler: Missing parents: List()
15/12/29 16:40:45 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189), which has no missing parents
15/12/29 16:40:45 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19731, maxMem=558728478
15/12/29 16:40:45 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 532.8 MB)
15/12/29 16:40:45 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25547, maxMem=558728478
15/12/29 16:40:45 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 532.8 MB)
15/12/29 16:40:45 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:34054 (size: 3.3 KB, free: 532.8 MB)
15/12/29 16:40:45 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
15/12/29 16:40:45 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189)
15/12/29 16:40:45 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
15/12/29 16:40:45 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
15/12/29 16:40:45 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2441 bytes)
15/12/29 16:40:45 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
15/12/29 16:40:45 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
15/12/29 16:40:45 INFO PythonRunner: Times: total = 73, boot = -126, init = 199, finish = 0
15/12/29 16:40:45 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
15/12/29 16:40:45 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 80 ms on localhost (1/2)
15/12/29 16:40:45 INFO PythonRunner: Times: total = 186, boot = 185, init = 1, finish = 0
15/12/29 16:40:45 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1422 bytes result sent to driver
15/12/29 16:40:45 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 199 ms on localhost (2/2)
15/12/29 16:40:45 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
15/12/29 16:40:45 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189) finished in 0.201 s
15/12/29 16:40:45 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189, took 0.220385 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
15/12/29 16:40:45 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
15/12/29 16:40:45 INFO DAGScheduler: Stopping DAGScheduler
15/12/29 16:40:45 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
15/12/29 16:40:45 INFO MemoryStore: MemoryStore cleared
15/12/29 16:40:45 INFO BlockManager: BlockManager stopped
15/12/29 16:40:45 INFO BlockManagerMaster: BlockManagerMaster stopped
15/12/29 16:40:45 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
15/12/29 16:40:45 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
15/12/29 16:40:45 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
15/12/29 16:40:45 INFO SparkContext: Successfully stopped SparkContext
15/12/29 16:40:45 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:40:46 INFO SparkContext: Running Spark version 1.5.2
15/12/29 16:40:46 INFO SecurityManager: Changing view acls to: root
15/12/29 16:40:46 INFO SecurityManager: Changing modify acls to: root
15/12/29 16:40:46 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
15/12/29 16:40:46 INFO Slf4jLogger: Slf4jLogger started
15/12/29 16:40:46 INFO Remoting: Starting remoting
15/12/29 16:40:46 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:36105]
15/12/29 16:40:46 INFO Utils: Successfully started service 'sparkDriver' on port 36105.
15/12/29 16:40:46 INFO SparkEnv: Registering MapOutputTracker
15/12/29 16:40:46 INFO SparkEnv: Registering BlockManagerMaster
15/12/29 16:40:46 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-7c66193a-ed03-4b49-8083-a15d734cbb39
15/12/29 16:40:46 INFO MemoryStore: MemoryStore started with capacity 532.8 MB
15/12/29 16:40:46 INFO HttpFileServer: HTTP File server directory is /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/httpd-f695fa7e-1583-4c51-aac4-2b8165bd9259
15/12/29 16:40:46 INFO HttpServer: Starting HTTP Server
15/12/29 16:40:46 INFO Utils: Successfully started service 'HTTP file server' on port 42931.
15/12/29 16:40:46 INFO SparkEnv: Registering OutputCommitCoordinator
15/12/29 16:40:46 INFO Utils: Successfully started service 'SparkUI' on port 4040.
15/12/29 16:40:46 INFO SparkUI: Started SparkUI at http://localhost:4040
15/12/29 16:40:46 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/userFiles-c884be59-0a19-4a82-bbac-4f71527c17d4/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
15/12/29 16:40:46 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1451387446968
15/12/29 16:40:47 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
15/12/29 16:40:47 INFO Executor: Starting executor ID driver on host localhost
15/12/29 16:40:47 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34861.
15/12/29 16:40:47 INFO NettyBlockTransferService: Server created on 34861
15/12/29 16:40:47 INFO BlockManagerMaster: Trying to register BlockManager
15/12/29 16:40:47 INFO BlockManagerMasterEndpoint: Registering block manager localhost:34861 with 532.8 MB RAM, BlockManagerId(driver, localhost, 34861)
15/12/29 16:40:47 INFO BlockManagerMaster: Registered BlockManager
15/12/29 16:40:47 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186
15/12/29 16:40:47 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184)
15/12/29 16:40:47 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186) with 2 output partitions
15/12/29 16:40:47 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186)
15/12/29 16:40:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
15/12/29 16:40:47 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
15/12/29 16:40:47 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184), which has no missing parents
15/12/29 16:40:47 INFO MemoryStore: ensureFreeSpace(7120) called with curMem=0, maxMem=558728478
15/12/29 16:40:47 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 7.0 KB, free 532.8 MB)
15/12/29 16:40:47 INFO MemoryStore: ensureFreeSpace(4573) called with curMem=7120, maxMem=558728478
15/12/29 16:40:47 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.5 KB, free 532.8 MB)
15/12/29 16:40:47 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:34861 (size: 4.5 KB, free: 532.8 MB)
15/12/29 16:40:47 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
15/12/29 16:40:47 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184)
15/12/29 16:40:47 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
15/12/29 16:40:47 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2401 bytes)
15/12/29 16:40:47 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2424 bytes)
15/12/29 16:40:47 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
15/12/29 16:40:47 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1451387446968
15/12/29 16:40:47 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
15/12/29 16:40:47 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/userFiles-c884be59-0a19-4a82-bbac-4f71527c17d4/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
*** Introductory Examples for the NLTK Book ***
Loading text1, ..., text9 and sent1, ..., sent9
Type the name of the text or sentence to view it.
Type: 'texts()' or 'sents()' to list the materials.
*** Introductory Examples for the NLTK Book ***
Loading text1, ..., text9 and sent1, ..., sent9
Type the name of the text or sentence to view it.
Type: 'texts()' or 'sents()' to list the materials.
text1: Moby Dick by Herman Melville 1851
text1: Moby Dick by Herman Melville 1851
text2: Sense and Sensibility by Jane Austen 1811
text3: The Book of Genesis
text2: Sense and Sensibility by Jane Austen 1811
text3: The Book of Genesis
text4: Inaugural Address Corpus
text4: Inaugural Address Corpus
text5: Chat Corpus
text6: Monty Python and the Holy Grail
text5: Chat Corpus
text6: Monty Python and the Holy Grail
text7: Wall Street Journal
text8: Personals Corpus
text9: The Man Who Was Thursday by G . K . Chesterton 1908
mapFunction_Parents(): keyword =  locomotive ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
text7: Wall Street Journal
text8: Personals Corpus
text9: The Man Who Was Thursday by G . K . Chesterton 1908
mapFunction_Parents(): keyword =  provided ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  railway ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  car ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  drawn ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  line ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  powered ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  electricity ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'railway']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway']
mapFunction_Parents(): keyword =  public ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  cars ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway']
mapFunction_Parents(): keyword =  transport ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'coupled']
reduceFunction_Parents(): returns= [u'coupled']
mapFunction_Parents(): keyword =  coupled ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'coupled']
mapFunction_Parents(): keyword =  together ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'line', u'transport']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:41:24 INFO PythonRunner: Times: total = 37732, boot = 457, init = 27610, finish = 9665
15/12/29 16:41:24 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
15/12/29 16:41:24 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 37804 ms on localhost (1/2)
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'coupled']
15/12/29 16:41:25 INFO PythonRunner: Times: total = 37859, boot = 468, init = 28903, finish = 8488
15/12/29 16:41:25 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
15/12/29 16:41:25 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 37937 ms on localhost (2/2)
15/12/29 16:41:25 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
15/12/29 16:41:25 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184) finished in 37.930 s
15/12/29 16:41:25 INFO DAGScheduler: looking for newly runnable stages
15/12/29 16:41:25 INFO DAGScheduler: running: Set()
15/12/29 16:41:25 INFO DAGScheduler: waiting: Set(ResultStage 1)
15/12/29 16:41:25 INFO DAGScheduler: failed: Set()
15/12/29 16:41:25 INFO DAGScheduler: Missing parents for ResultStage 1: List()
15/12/29 16:41:25 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186), which is now runnable
15/12/29 16:41:25 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11693, maxMem=558728478
15/12/29 16:41:25 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 532.8 MB)
15/12/29 16:41:25 INFO MemoryStore: ensureFreeSpace(3054) called with curMem=16677, maxMem=558728478
15/12/29 16:41:25 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 532.8 MB)
15/12/29 16:41:25 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:34861 (size: 3.0 KB, free: 532.8 MB)
15/12/29 16:41:25 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
15/12/29 16:41:25 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186)
15/12/29 16:41:25 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
15/12/29 16:41:25 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
15/12/29 16:41:25 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
15/12/29 16:41:25 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
15/12/29 16:41:25 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
15/12/29 16:41:25 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/12/29 16:41:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
15/12/29 16:41:25 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/12/29 16:41:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
15/12/29 16:41:25 INFO PythonRunner: Times: total = 202, boot = 202, init = 0, finish = 0
15/12/29 16:41:25 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
15/12/29 16:41:25 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 217 ms on localhost (1/2)
reduceFunction_Parents(): returns= [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:41:25 INFO PythonRunner: Times: total = 277, boot = 276, init = 1, finish = 0
15/12/29 16:41:25 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1360 bytes result sent to driver
15/12/29 16:41:25 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 310 ms on localhost (2/2)
15/12/29 16:41:25 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
15/12/29 16:41:25 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186) finished in 0.313 s
15/12/29 16:41:25 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186, took 38.290891 s
15/12/29 16:41:25 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189
15/12/29 16:41:25 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189) with 2 output partitions
15/12/29 16:41:25 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189)
15/12/29 16:41:25 INFO DAGScheduler: Parents of final stage: List()
15/12/29 16:41:25 INFO DAGScheduler: Missing parents: List()
15/12/29 16:41:25 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189), which has no missing parents
15/12/29 16:41:25 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19731, maxMem=558728478
15/12/29 16:41:25 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 532.8 MB)
15/12/29 16:41:25 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25547, maxMem=558728478
15/12/29 16:41:25 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 532.8 MB)
15/12/29 16:41:25 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:34861 (size: 3.3 KB, free: 532.8 MB)
15/12/29 16:41:25 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
15/12/29 16:41:25 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189)
15/12/29 16:41:25 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
15/12/29 16:41:25 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
15/12/29 16:41:25 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2441 bytes)
15/12/29 16:41:25 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
15/12/29 16:41:25 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
15/12/29 16:41:25 INFO PythonRunner: Times: total = 159, boot = 159, init = 0, finish = 0
15/12/29 16:41:25 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
15/12/29 16:41:25 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 166 ms on localhost (1/2)
15/12/29 16:41:25 INFO PythonRunner: Times: total = 203, boot = 202, init = 1, finish = 0
15/12/29 16:41:25 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1422 bytes result sent to driver
15/12/29 16:41:25 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 214 ms on localhost (2/2)
15/12/29 16:41:25 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
15/12/29 16:41:25 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189) finished in 0.205 s
15/12/29 16:41:25 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189, took 0.246256 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
15/12/29 16:41:25 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
15/12/29 16:41:25 INFO DAGScheduler: Stopping DAGScheduler
15/12/29 16:41:25 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
15/12/29 16:41:25 INFO MemoryStore: MemoryStore cleared
15/12/29 16:41:25 INFO BlockManager: BlockManager stopped
15/12/29 16:41:25 INFO BlockManagerMaster: BlockManagerMaster stopped
15/12/29 16:41:25 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
15/12/29 16:41:25 INFO SparkContext: Successfully stopped SparkContext
15/12/29 16:41:25 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
15/12/29 16:41:25 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
15/12/29 16:41:26 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:41:26 INFO SparkContext: Running Spark version 1.5.2
15/12/29 16:41:26 INFO SecurityManager: Changing view acls to: root
15/12/29 16:41:26 INFO SecurityManager: Changing modify acls to: root
15/12/29 16:41:26 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
15/12/29 16:41:26 INFO Slf4jLogger: Slf4jLogger started
15/12/29 16:41:26 INFO Remoting: Starting remoting
15/12/29 16:41:26 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:41728]
15/12/29 16:41:26 INFO Utils: Successfully started service 'sparkDriver' on port 41728.
15/12/29 16:41:26 INFO SparkEnv: Registering MapOutputTracker
15/12/29 16:41:26 INFO SparkEnv: Registering BlockManagerMaster
15/12/29 16:41:26 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-9236ab2a-4358-48e1-a677-3dad1c436f02
15/12/29 16:41:26 INFO MemoryStore: MemoryStore started with capacity 532.8 MB
15/12/29 16:41:26 INFO HttpFileServer: HTTP File server directory is /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/httpd-e7ca8349-11d9-43d1-b485-3f845274fd2c
15/12/29 16:41:26 INFO HttpServer: Starting HTTP Server
15/12/29 16:41:26 INFO Utils: Successfully started service 'HTTP file server' on port 46233.
15/12/29 16:41:26 INFO SparkEnv: Registering OutputCommitCoordinator
15/12/29 16:41:27 INFO Utils: Successfully started service 'SparkUI' on port 4040.
15/12/29 16:41:27 INFO SparkUI: Started SparkUI at http://localhost:4040
15/12/29 16:41:27 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/userFiles-8f9a61bd-97ae-4bcc-8721-19ccb5149f6d/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
15/12/29 16:41:27 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1451387487398
15/12/29 16:41:27 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
15/12/29 16:41:27 INFO Executor: Starting executor ID driver on host localhost
15/12/29 16:41:27 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39644.
15/12/29 16:41:27 INFO NettyBlockTransferService: Server created on 39644
15/12/29 16:41:27 INFO BlockManagerMaster: Trying to register BlockManager
15/12/29 16:41:27 INFO BlockManagerMasterEndpoint: Registering block manager localhost:39644 with 532.8 MB RAM, BlockManagerId(driver, localhost, 39644)
15/12/29 16:41:27 INFO BlockManagerMaster: Registered BlockManager
15/12/29 16:41:27 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186
15/12/29 16:41:27 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184)
15/12/29 16:41:27 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186) with 2 output partitions
15/12/29 16:41:27 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186)
15/12/29 16:41:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
15/12/29 16:41:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
15/12/29 16:41:27 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184), which has no missing parents
15/12/29 16:41:27 INFO MemoryStore: ensureFreeSpace(7120) called with curMem=0, maxMem=558728478
15/12/29 16:41:27 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 7.0 KB, free 532.8 MB)
15/12/29 16:41:27 INFO MemoryStore: ensureFreeSpace(4572) called with curMem=7120, maxMem=558728478
15/12/29 16:41:27 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.5 KB, free 532.8 MB)
15/12/29 16:41:27 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:39644 (size: 4.5 KB, free: 532.8 MB)
15/12/29 16:41:27 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
15/12/29 16:41:27 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184)
15/12/29 16:41:27 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
15/12/29 16:41:27 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2401 bytes)
15/12/29 16:41:27 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2424 bytes)
15/12/29 16:41:27 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
15/12/29 16:41:27 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1451387487398
15/12/29 16:41:27 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
15/12/29 16:41:27 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/userFiles-8f9a61bd-97ae-4bcc-8721-19ccb5149f6d/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
*** Introductory Examples for the NLTK Book ***
Loading text1, ..., text9 and sent1, ..., sent9
Type the name of the text or sentence to view it.
Type: 'texts()' or 'sents()' to list the materials.
*** Introductory Examples for the NLTK Book ***
Loading text1, ..., text9 and sent1, ..., sent9
Type the name of the text or sentence to view it.
Type: 'texts()' or 'sents()' to list the materials.
text1: Moby Dick by Herman Melville 1851
text1: Moby Dick by Herman Melville 1851
text2: Sense and Sensibility by Jane Austen 1811
text3: The Book of Genesis
text2: Sense and Sensibility by Jane Austen 1811
text3: The Book of Genesis
text4: Inaugural Address Corpus
text4: Inaugural Address Corpus
text5: Chat Corpus
text6: Monty Python and the Holy Grail
text5: Chat Corpus
text6: Monty Python and the Holy Grail
text7: Wall Street Journal
text8: Personals Corpus
text9: The Man Who Was Thursday by G . K . Chesterton 1908
mapFunction_Parents(): keyword =  provided ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
text7: Wall Street Journal
text8: Personals Corpus
text9: The Man Who Was Thursday by G . K . Chesterton 1908
mapFunction_Parents(): keyword =  locomotive ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  powered ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  electricity ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  cars ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'coupled']
reduceFunction_Parents(): returns= [u'coupled']
mapFunction_Parents(): keyword =  coupled ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  railway ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  car ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'coupled']
mapFunction_Parents(): keyword =  together ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  drawn ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  line ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'coupled']
15/12/29 16:42:03 INFO PythonRunner: Times: total = 36363, boot = 457, init = 27215, finish = 8691
15/12/29 16:42:03 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
15/12/29 16:42:03 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 36426 ms on localhost (1/2)
mapFunction_Parents(): returns= [u'railway']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway']
mapFunction_Parents(): keyword =  public ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway']
mapFunction_Parents(): keyword =  transport ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'line', u'transport']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:42:04 INFO PythonRunner: Times: total = 36713, boot = 460, init = 28104, finish = 8149
15/12/29 16:42:04 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
15/12/29 16:42:04 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184) finished in 36.786 s
15/12/29 16:42:04 INFO DAGScheduler: looking for newly runnable stages
15/12/29 16:42:04 INFO DAGScheduler: running: Set()
15/12/29 16:42:04 INFO DAGScheduler: waiting: Set(ResultStage 1)
15/12/29 16:42:04 INFO DAGScheduler: failed: Set()
15/12/29 16:42:04 INFO DAGScheduler: Missing parents for ResultStage 1: List()
15/12/29 16:42:04 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186), which is now runnable
15/12/29 16:42:04 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11692, maxMem=558728478
15/12/29 16:42:04 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 532.8 MB)
15/12/29 16:42:04 INFO MemoryStore: ensureFreeSpace(3053) called with curMem=16676, maxMem=558728478
15/12/29 16:42:04 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 532.8 MB)
15/12/29 16:42:04 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 36787 ms on localhost (2/2)
15/12/29 16:42:04 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
15/12/29 16:42:04 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:39644 (size: 3.0 KB, free: 532.8 MB)
15/12/29 16:42:04 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
15/12/29 16:42:04 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186)
15/12/29 16:42:04 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
15/12/29 16:42:04 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
15/12/29 16:42:04 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
15/12/29 16:42:04 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
15/12/29 16:42:04 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
15/12/29 16:42:04 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/12/29 16:42:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
15/12/29 16:42:04 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/12/29 16:42:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
reduceFunction_Parents(): returns= [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:42:04 INFO PythonRunner: Times: total = 37, boot = -167, init = 204, finish = 0
15/12/29 16:42:04 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1360 bytes result sent to driver
15/12/29 16:42:04 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 63 ms on localhost (1/2)
15/12/29 16:42:04 INFO PythonRunner: Times: total = 268, boot = 267, init = 1, finish = 0
15/12/29 16:42:04 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
15/12/29 16:42:04 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186) finished in 0.281 s
15/12/29 16:42:04 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186, took 37.107331 s
15/12/29 16:42:04 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 286 ms on localhost (2/2)
15/12/29 16:42:04 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
15/12/29 16:42:04 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189
15/12/29 16:42:04 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189) with 2 output partitions
15/12/29 16:42:04 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189)
15/12/29 16:42:04 INFO DAGScheduler: Parents of final stage: List()
15/12/29 16:42:04 INFO DAGScheduler: Missing parents: List()
15/12/29 16:42:04 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189), which has no missing parents
15/12/29 16:42:04 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19729, maxMem=558728478
15/12/29 16:42:04 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 532.8 MB)
15/12/29 16:42:04 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25545, maxMem=558728478
15/12/29 16:42:04 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 532.8 MB)
15/12/29 16:42:04 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:39644 (size: 3.3 KB, free: 532.8 MB)
15/12/29 16:42:04 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
15/12/29 16:42:04 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189)
15/12/29 16:42:04 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
15/12/29 16:42:04 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
15/12/29 16:42:04 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2441 bytes)
15/12/29 16:42:04 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
15/12/29 16:42:04 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
15/12/29 16:42:04 INFO PythonRunner: Times: total = 62, boot = -122, init = 184, finish = 0
15/12/29 16:42:04 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
15/12/29 16:42:04 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 77 ms on localhost (1/2)
15/12/29 16:42:04 INFO PythonRunner: Times: total = 182, boot = 182, init = 0, finish = 0
15/12/29 16:42:04 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1422 bytes result sent to driver
15/12/29 16:42:04 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 202 ms on localhost (2/2)
15/12/29 16:42:04 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
15/12/29 16:42:04 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189) finished in 0.178 s
15/12/29 16:42:04 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189, took 0.237219 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
15/12/29 16:42:05 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
15/12/29 16:42:05 INFO DAGScheduler: Stopping DAGScheduler
15/12/29 16:42:05 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
15/12/29 16:42:05 INFO MemoryStore: MemoryStore cleared
15/12/29 16:42:05 INFO BlockManager: BlockManager stopped
15/12/29 16:42:05 INFO BlockManagerMaster: BlockManagerMaster stopped
15/12/29 16:42:05 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
15/12/29 16:42:05 INFO SparkContext: Successfully stopped SparkContext
15/12/29 16:42:05 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
15/12/29 16:42:05 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
15/12/29 16:42:05 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:42:05 INFO SparkContext: Running Spark version 1.5.2
15/12/29 16:42:05 INFO SecurityManager: Changing view acls to: root
15/12/29 16:42:05 INFO SecurityManager: Changing modify acls to: root
15/12/29 16:42:05 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
15/12/29 16:42:05 INFO Slf4jLogger: Slf4jLogger started
15/12/29 16:42:05 INFO Remoting: Starting remoting
15/12/29 16:42:06 INFO Utils: Successfully started service 'sparkDriver' on port 58036.
15/12/29 16:42:06 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:58036]
15/12/29 16:42:06 INFO SparkEnv: Registering MapOutputTracker
15/12/29 16:42:06 INFO SparkEnv: Registering BlockManagerMaster
15/12/29 16:42:06 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-ae7855a0-8977-4c00-922c-15881c576eb2
15/12/29 16:42:06 INFO MemoryStore: MemoryStore started with capacity 532.8 MB
15/12/29 16:42:06 INFO HttpFileServer: HTTP File server directory is /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/httpd-f0f839a5-b3be-4049-9e63-a3f8ae52cb68
15/12/29 16:42:06 INFO HttpServer: Starting HTTP Server
15/12/29 16:42:06 INFO Utils: Successfully started service 'HTTP file server' on port 44179.
15/12/29 16:42:06 INFO SparkEnv: Registering OutputCommitCoordinator
15/12/29 16:42:06 INFO Utils: Successfully started service 'SparkUI' on port 4040.
15/12/29 16:42:06 INFO SparkUI: Started SparkUI at http://localhost:4040
15/12/29 16:42:06 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/userFiles-c551aa44-a794-4f4e-9ebe-271f77f44b31/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
15/12/29 16:42:06 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1451387526830
15/12/29 16:42:06 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
15/12/29 16:42:06 INFO Executor: Starting executor ID driver on host localhost
15/12/29 16:42:06 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33168.
15/12/29 16:42:06 INFO NettyBlockTransferService: Server created on 33168
15/12/29 16:42:06 INFO BlockManagerMaster: Trying to register BlockManager
15/12/29 16:42:06 INFO BlockManagerMasterEndpoint: Registering block manager localhost:33168 with 532.8 MB RAM, BlockManagerId(driver, localhost, 33168)
15/12/29 16:42:06 INFO BlockManagerMaster: Registered BlockManager
15/12/29 16:42:06 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186
15/12/29 16:42:06 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184)
15/12/29 16:42:06 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186) with 2 output partitions
15/12/29 16:42:06 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186)
15/12/29 16:42:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
15/12/29 16:42:06 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
15/12/29 16:42:06 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184), which has no missing parents
15/12/29 16:42:06 INFO MemoryStore: ensureFreeSpace(7120) called with curMem=0, maxMem=558728478
15/12/29 16:42:06 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 7.0 KB, free 532.8 MB)
15/12/29 16:42:06 INFO MemoryStore: ensureFreeSpace(4573) called with curMem=7120, maxMem=558728478
15/12/29 16:42:06 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.5 KB, free 532.8 MB)
15/12/29 16:42:06 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:33168 (size: 4.5 KB, free: 532.8 MB)
15/12/29 16:42:06 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
15/12/29 16:42:06 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184)
15/12/29 16:42:06 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
15/12/29 16:42:06 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2401 bytes)
15/12/29 16:42:06 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2424 bytes)
15/12/29 16:42:06 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
15/12/29 16:42:06 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1451387526830
15/12/29 16:42:06 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
15/12/29 16:42:07 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/userFiles-c551aa44-a794-4f4e-9ebe-271f77f44b31/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
*** Introductory Examples for the NLTK Book ***
Loading text1, ..., text9 and sent1, ..., sent9
Type the name of the text or sentence to view it.
Type: 'texts()' or 'sents()' to list the materials.
*** Introductory Examples for the NLTK Book ***
Loading text1, ..., text9 and sent1, ..., sent9
Type the name of the text or sentence to view it.
Type: 'texts()' or 'sents()' to list the materials.
text1: Moby Dick by Herman Melville 1851
text1: Moby Dick by Herman Melville 1851
text2: Sense and Sensibility by Jane Austen 1811
text2: Sense and Sensibility by Jane Austen 1811
text3: The Book of Genesis
text3: The Book of Genesis
text4: Inaugural Address Corpus
text4: Inaugural Address Corpus
text5: Chat Corpus
text6: Monty Python and the Holy Grail
text5: Chat Corpus
text6: Monty Python and the Holy Grail
text7: Wall Street Journal
text8: Personals Corpus
text9: The Man Who Was Thursday by G . K . Chesterton 1908
mapFunction_Parents(): keyword =  provided ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
text7: Wall Street Journal
text8: Personals Corpus
text9: The Man Who Was Thursday by G . K . Chesterton 1908
mapFunction_Parents(): keyword =  locomotive ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  powered ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  electricity ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  cars ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'coupled']
reduceFunction_Parents(): returns= [u'coupled']
mapFunction_Parents(): keyword =  coupled ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'coupled']
mapFunction_Parents(): keyword =  together ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'coupled']
15/12/29 16:42:42 INFO PythonRunner: Times: total = 35878, boot = 461, init = 27471, finish = 7946
15/12/29 16:42:42 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
15/12/29 16:42:42 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 35968 ms on localhost (1/2)
mapFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  railway ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  car ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  drawn ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  line ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'railway']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway']
mapFunction_Parents(): keyword =  public ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway']
mapFunction_Parents(): keyword =  transport ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'line', u'transport']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:42:45 INFO PythonRunner: Times: total = 38061, boot = 460, init = 29179, finish = 8422
15/12/29 16:42:45 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
15/12/29 16:42:45 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 38133 ms on localhost (2/2)
15/12/29 16:42:45 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
15/12/29 16:42:45 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184) finished in 38.132 s
15/12/29 16:42:45 INFO DAGScheduler: looking for newly runnable stages
15/12/29 16:42:45 INFO DAGScheduler: running: Set()
15/12/29 16:42:45 INFO DAGScheduler: waiting: Set(ResultStage 1)
15/12/29 16:42:45 INFO DAGScheduler: failed: Set()
15/12/29 16:42:45 INFO DAGScheduler: Missing parents for ResultStage 1: List()
15/12/29 16:42:45 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186), which is now runnable
15/12/29 16:42:45 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11693, maxMem=558728478
15/12/29 16:42:45 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 532.8 MB)
15/12/29 16:42:45 INFO MemoryStore: ensureFreeSpace(3054) called with curMem=16677, maxMem=558728478
15/12/29 16:42:45 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 532.8 MB)
15/12/29 16:42:45 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:33168 (size: 3.0 KB, free: 532.8 MB)
15/12/29 16:42:45 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
15/12/29 16:42:45 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186)
15/12/29 16:42:45 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
15/12/29 16:42:45 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
15/12/29 16:42:45 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
15/12/29 16:42:45 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
15/12/29 16:42:45 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
15/12/29 16:42:45 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/12/29 16:42:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
15/12/29 16:42:45 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/12/29 16:42:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
reduceFunction_Parents(): returns= [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:42:45 INFO PythonRunner: Times: total = 35, boot = -1994, init = 2028, finish = 1
15/12/29 16:42:45 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1360 bytes result sent to driver
15/12/29 16:42:45 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 111 ms on localhost (1/2)
15/12/29 16:42:45 INFO PythonRunner: Times: total = 341, boot = 341, init = 0, finish = 0
15/12/29 16:42:45 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
15/12/29 16:42:45 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186) finished in 0.347 s
15/12/29 16:42:45 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186, took 38.516214 s
15/12/29 16:42:45 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 353 ms on localhost (2/2)
15/12/29 16:42:45 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
15/12/29 16:42:45 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189
15/12/29 16:42:45 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189) with 2 output partitions
15/12/29 16:42:45 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189)
15/12/29 16:42:45 INFO DAGScheduler: Parents of final stage: List()
15/12/29 16:42:45 INFO DAGScheduler: Missing parents: List()
15/12/29 16:42:45 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189), which has no missing parents
15/12/29 16:42:45 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19731, maxMem=558728478
15/12/29 16:42:45 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 532.8 MB)
15/12/29 16:42:45 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25547, maxMem=558728478
15/12/29 16:42:45 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 532.8 MB)
15/12/29 16:42:45 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:33168 (size: 3.3 KB, free: 532.8 MB)
15/12/29 16:42:45 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
15/12/29 16:42:45 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189)
15/12/29 16:42:45 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
15/12/29 16:42:45 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
15/12/29 16:42:45 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2441 bytes)
15/12/29 16:42:45 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
15/12/29 16:42:45 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
15/12/29 16:42:45 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:33168 in memory (size: 3.0 KB, free: 532.8 MB)
15/12/29 16:42:45 INFO ContextCleaner: Cleaned accumulator 179
15/12/29 16:42:45 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:33168 in memory (size: 4.5 KB, free: 532.8 MB)
15/12/29 16:42:45 INFO ContextCleaner: Cleaned accumulator 178
15/12/29 16:42:45 INFO PythonRunner: Times: total = 11, boot = -198, init = 209, finish = 0
15/12/29 16:42:45 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
15/12/29 16:42:45 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 59 ms on localhost (1/2)
15/12/29 16:42:45 INFO PythonRunner: Times: total = 45, boot = -491, init = 536, finish = 0
15/12/29 16:42:45 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1422 bytes result sent to driver
15/12/29 16:42:45 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 102 ms on localhost (2/2)
15/12/29 16:42:45 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
15/12/29 16:42:45 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189) finished in 0.102 s
15/12/29 16:42:45 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189, took 0.412719 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
15/12/29 16:42:46 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
15/12/29 16:42:46 INFO DAGScheduler: Stopping DAGScheduler
15/12/29 16:42:46 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
15/12/29 16:42:46 INFO MemoryStore: MemoryStore cleared
15/12/29 16:42:46 INFO BlockManager: BlockManager stopped
15/12/29 16:42:46 INFO BlockManagerMaster: BlockManagerMaster stopped
15/12/29 16:42:46 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
15/12/29 16:42:46 INFO SparkContext: Successfully stopped SparkContext
15/12/29 16:42:46 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
15/12/29 16:42:46 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
15/12/29 16:42:46 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:42:47 INFO SparkContext: Running Spark version 1.5.2
15/12/29 16:42:47 INFO SecurityManager: Changing view acls to: root
15/12/29 16:42:47 INFO SecurityManager: Changing modify acls to: root
15/12/29 16:42:47 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
15/12/29 16:42:47 INFO Slf4jLogger: Slf4jLogger started
15/12/29 16:42:47 INFO Remoting: Starting remoting
15/12/29 16:42:47 INFO Utils: Successfully started service 'sparkDriver' on port 37173.
15/12/29 16:42:47 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:37173]
15/12/29 16:42:47 INFO SparkEnv: Registering MapOutputTracker
15/12/29 16:42:47 INFO SparkEnv: Registering BlockManagerMaster
15/12/29 16:42:47 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-96ca9880-585e-49c8-8ef5-ecc7725cef3d
15/12/29 16:42:47 INFO MemoryStore: MemoryStore started with capacity 531.5 MB
15/12/29 16:42:47 INFO HttpFileServer: HTTP File server directory is /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/httpd-dbd76fa5-2b0c-4f29-8a84-79bf6d0c6a39
15/12/29 16:42:47 INFO HttpServer: Starting HTTP Server
15/12/29 16:42:47 INFO Utils: Successfully started service 'HTTP file server' on port 47381.
15/12/29 16:42:47 INFO SparkEnv: Registering OutputCommitCoordinator
15/12/29 16:42:47 INFO Utils: Successfully started service 'SparkUI' on port 4040.
15/12/29 16:42:47 INFO SparkUI: Started SparkUI at http://localhost:4040
15/12/29 16:42:47 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/userFiles-474865c6-94bd-424a-b275-df6e6bec8831/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
15/12/29 16:42:47 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1451387567574
15/12/29 16:42:47 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
15/12/29 16:42:47 INFO Executor: Starting executor ID driver on host localhost
15/12/29 16:42:47 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60213.
15/12/29 16:42:47 INFO NettyBlockTransferService: Server created on 60213
15/12/29 16:42:47 INFO BlockManagerMaster: Trying to register BlockManager
15/12/29 16:42:47 INFO BlockManagerMasterEndpoint: Registering block manager localhost:60213 with 531.5 MB RAM, BlockManagerId(driver, localhost, 60213)
15/12/29 16:42:47 INFO BlockManagerMaster: Registered BlockManager
15/12/29 16:42:47 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186
15/12/29 16:42:47 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184)
15/12/29 16:42:47 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186) with 2 output partitions
15/12/29 16:42:47 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186)
15/12/29 16:42:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
15/12/29 16:42:47 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
15/12/29 16:42:47 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184), which has no missing parents
15/12/29 16:42:47 INFO MemoryStore: ensureFreeSpace(7120) called with curMem=0, maxMem=557312901
15/12/29 16:42:47 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 7.0 KB, free 531.5 MB)
15/12/29 16:42:47 INFO MemoryStore: ensureFreeSpace(4573) called with curMem=7120, maxMem=557312901
15/12/29 16:42:47 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.5 KB, free 531.5 MB)
15/12/29 16:42:47 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:60213 (size: 4.5 KB, free: 531.5 MB)
15/12/29 16:42:47 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
15/12/29 16:42:47 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184)
15/12/29 16:42:47 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
15/12/29 16:42:47 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2401 bytes)
15/12/29 16:42:47 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2424 bytes)
15/12/29 16:42:47 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
15/12/29 16:42:47 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1451387567574
15/12/29 16:42:47 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
15/12/29 16:42:47 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/userFiles-474865c6-94bd-424a-b275-df6e6bec8831/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
*** Introductory Examples for the NLTK Book ****** Introductory Examples for the NLTK Book ***
Loading text1, ..., text9 and sent1, ..., sent9
Type the name of the text or sentence to view it.
Type: 'texts()' or 'sents()' to list the materials.

Loading text1, ..., text9 and sent1, ..., sent9
Type the name of the text or sentence to view it.
Type: 'texts()' or 'sents()' to list the materials.
text1: Moby Dick by Herman Melville 1851
text1: Moby Dick by Herman Melville 1851
text2: Sense and Sensibility by Jane Austen 1811
text2: Sense and Sensibility by Jane Austen 1811
text3: The Book of Genesis
text3: The Book of Genesis
text4: Inaugural Address Corpus
text4: Inaugural Address Corpus
text5: Chat Corpus
text5: Chat Corpus
text6: Monty Python and the Holy Grail
text6: Monty Python and the Holy Grail
text7: Wall Street Journal
text8: Personals Corpus
text7: Wall Street Journal
text8: Personals Corpus
text9: The Man Who Was Thursday by G . K . Chesterton 1908
mapFunction_Parents(): keyword =  provided ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
text9: The Man Who Was Thursday by G . K . Chesterton 1908
mapFunction_Parents(): keyword =  locomotive ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  railway ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  powered ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  car ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  electricity ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  cars ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  drawn ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'coupled']
reduceFunction_Parents(): returns= [u'coupled']
mapFunction_Parents(): keyword =  coupled ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  line ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'coupled']
mapFunction_Parents(): keyword =  together ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'coupled']
mapFunction_Parents(): returns= [u'railway']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway']
mapFunction_Parents(): keyword =  public ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
15/12/29 16:43:25 INFO PythonRunner: Times: total = 37985, boot = 1628, init = 28295, finish = 8062
15/12/29 16:43:25 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
15/12/29 16:43:25 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 38058 ms on localhost (1/2)
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway']
mapFunction_Parents(): keyword =  transport ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'line', u'transport']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:43:26 INFO PythonRunner: Times: total = 38250, boot = 1627, init = 28303, finish = 8320
15/12/29 16:43:26 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
15/12/29 16:43:26 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184) finished in 38.347 s
15/12/29 16:43:26 INFO DAGScheduler: looking for newly runnable stages
15/12/29 16:43:26 INFO DAGScheduler: running: Set()
15/12/29 16:43:26 INFO DAGScheduler: waiting: Set(ResultStage 1)
15/12/29 16:43:26 INFO DAGScheduler: failed: Set()
15/12/29 16:43:26 INFO DAGScheduler: Missing parents for ResultStage 1: List()
15/12/29 16:43:26 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186), which is now runnable
15/12/29 16:43:26 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11693, maxMem=557312901
15/12/29 16:43:26 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 531.5 MB)
15/12/29 16:43:26 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 38340 ms on localhost (2/2)
15/12/29 16:43:26 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
15/12/29 16:43:26 INFO MemoryStore: ensureFreeSpace(3053) called with curMem=16677, maxMem=557312901
15/12/29 16:43:26 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 531.5 MB)
15/12/29 16:43:26 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:60213 (size: 3.0 KB, free: 531.5 MB)
15/12/29 16:43:26 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
15/12/29 16:43:26 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186)
15/12/29 16:43:26 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
15/12/29 16:43:26 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
15/12/29 16:43:26 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
15/12/29 16:43:26 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
15/12/29 16:43:26 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/12/29 16:43:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
15/12/29 16:43:26 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
15/12/29 16:43:26 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/12/29 16:43:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
reduceFunction_Parents(): returns= [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:43:26 INFO PythonRunner: Times: total = 80, boot = 53, init = 22, finish = 5
15/12/29 16:43:26 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1360 bytes result sent to driver
15/12/29 16:43:26 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 97 ms on localhost (1/2)
15/12/29 16:43:26 INFO PythonRunner: Times: total = 221, boot = 221, init = 0, finish = 0
15/12/29 16:43:26 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
15/12/29 16:43:26 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186) finished in 0.227 s
15/12/29 16:43:26 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186, took 38.611038 s
15/12/29 16:43:26 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 239 ms on localhost (2/2)
15/12/29 16:43:26 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
15/12/29 16:43:26 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189
15/12/29 16:43:26 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189) with 2 output partitions
15/12/29 16:43:26 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189)
15/12/29 16:43:26 INFO DAGScheduler: Parents of final stage: List()
15/12/29 16:43:26 INFO DAGScheduler: Missing parents: List()
15/12/29 16:43:26 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189), which has no missing parents
15/12/29 16:43:26 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19730, maxMem=557312901
15/12/29 16:43:26 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 531.5 MB)
15/12/29 16:43:26 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25546, maxMem=557312901
15/12/29 16:43:26 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 531.5 MB)
15/12/29 16:43:26 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:60213 (size: 3.3 KB, free: 531.5 MB)
15/12/29 16:43:26 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
15/12/29 16:43:26 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189)
15/12/29 16:43:26 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
15/12/29 16:43:26 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
15/12/29 16:43:26 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2441 bytes)
15/12/29 16:43:26 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
15/12/29 16:43:26 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
15/12/29 16:43:26 INFO PythonRunner: Times: total = 83, boot = 83, init = 0, finish = 0
15/12/29 16:43:26 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1422 bytes result sent to driver
15/12/29 16:43:26 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 93 ms on localhost (1/2)
15/12/29 16:43:26 INFO PythonRunner: Times: total = 97, boot = 97, init = 0, finish = 0
15/12/29 16:43:26 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
15/12/29 16:43:26 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 104 ms on localhost (2/2)
15/12/29 16:43:26 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
15/12/29 16:43:26 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189) finished in 0.094 s
15/12/29 16:43:26 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189, took 0.132510 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
15/12/29 16:43:26 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
15/12/29 16:43:26 INFO DAGScheduler: Stopping DAGScheduler
15/12/29 16:43:26 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
15/12/29 16:43:26 INFO MemoryStore: MemoryStore cleared
15/12/29 16:43:26 INFO BlockManager: BlockManager stopped
15/12/29 16:43:26 INFO BlockManagerMaster: BlockManagerMaster stopped
15/12/29 16:43:26 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
15/12/29 16:43:26 INFO SparkContext: Successfully stopped SparkContext
15/12/29 16:43:26 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
15/12/29 16:43:26 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
15/12/29 16:43:26 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:43:27 INFO SparkContext: Running Spark version 1.5.2
15/12/29 16:43:27 INFO SecurityManager: Changing view acls to: root
15/12/29 16:43:27 INFO SecurityManager: Changing modify acls to: root
15/12/29 16:43:27 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
15/12/29 16:43:27 INFO Slf4jLogger: Slf4jLogger started
15/12/29 16:43:27 INFO Remoting: Starting remoting
15/12/29 16:43:27 INFO Utils: Successfully started service 'sparkDriver' on port 51127.
15/12/29 16:43:27 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:51127]
15/12/29 16:43:27 INFO SparkEnv: Registering MapOutputTracker
15/12/29 16:43:27 INFO SparkEnv: Registering BlockManagerMaster
15/12/29 16:43:27 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-e6c12cf2-f064-43f3-b55a-d2e35289e893
15/12/29 16:43:27 INFO MemoryStore: MemoryStore started with capacity 531.5 MB
15/12/29 16:43:27 INFO HttpFileServer: HTTP File server directory is /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/httpd-fdd5908c-5214-4348-9c19-2b4665d5663e
15/12/29 16:43:27 INFO HttpServer: Starting HTTP Server
15/12/29 16:43:27 INFO Utils: Successfully started service 'HTTP file server' on port 44885.
15/12/29 16:43:27 INFO SparkEnv: Registering OutputCommitCoordinator
15/12/29 16:43:28 INFO Utils: Successfully started service 'SparkUI' on port 4040.
15/12/29 16:43:28 INFO SparkUI: Started SparkUI at http://localhost:4040
15/12/29 16:43:28 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/userFiles-8860fae6-245f-4429-b14f-6da46e62d757/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
15/12/29 16:43:28 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1451387608217
15/12/29 16:43:28 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
15/12/29 16:43:28 INFO Executor: Starting executor ID driver on host localhost
15/12/29 16:43:28 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53345.
15/12/29 16:43:28 INFO NettyBlockTransferService: Server created on 53345
15/12/29 16:43:28 INFO BlockManagerMaster: Trying to register BlockManager
15/12/29 16:43:28 INFO BlockManagerMasterEndpoint: Registering block manager localhost:53345 with 531.5 MB RAM, BlockManagerId(driver, localhost, 53345)
15/12/29 16:43:28 INFO BlockManagerMaster: Registered BlockManager
15/12/29 16:43:28 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186
15/12/29 16:43:28 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184)
15/12/29 16:43:28 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186) with 2 output partitions
15/12/29 16:43:28 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186)
15/12/29 16:43:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
15/12/29 16:43:28 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
15/12/29 16:43:28 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184), which has no missing parents
15/12/29 16:43:28 INFO MemoryStore: ensureFreeSpace(7120) called with curMem=0, maxMem=557312901
15/12/29 16:43:28 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 7.0 KB, free 531.5 MB)
15/12/29 16:43:28 INFO MemoryStore: ensureFreeSpace(4573) called with curMem=7120, maxMem=557312901
15/12/29 16:43:28 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.5 KB, free 531.5 MB)
15/12/29 16:43:28 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:53345 (size: 4.5 KB, free: 531.5 MB)
15/12/29 16:43:28 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
15/12/29 16:43:28 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184)
15/12/29 16:43:28 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
15/12/29 16:43:28 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2401 bytes)
15/12/29 16:43:28 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2424 bytes)
15/12/29 16:43:28 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
15/12/29 16:43:28 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1451387608217
15/12/29 16:43:28 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
15/12/29 16:43:28 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/userFiles-8860fae6-245f-4429-b14f-6da46e62d757/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
*** Introductory Examples for the NLTK Book ***
Loading text1, ..., text9 and sent1, ..., sent9
Type the name of the text or sentence to view it.
Type: 'texts()' or 'sents()' to list the materials.
*** Introductory Examples for the NLTK Book ***
Loading text1, ..., text9 and sent1, ..., sent9
Type the name of the text or sentence to view it.
Type: 'texts()' or 'sents()' to list the materials.
text1: Moby Dick by Herman Melville 1851
text1: Moby Dick by Herman Melville 1851
text2: Sense and Sensibility by Jane Austen 1811
text3: The Book of Genesis
text2: Sense and Sensibility by Jane Austen 1811
text3: The Book of Genesis
text4: Inaugural Address Corpus
text4: Inaugural Address Corpus
text5: Chat Corpus
text6: Monty Python and the Holy Grail
text5: Chat Corpus
text6: Monty Python and the Holy Grail
text7: Wall Street Journal
text8: Personals Corpus
text9: The Man Who Was Thursday by G . K . Chesterton 1908
mapFunction_Parents(): keyword =  provided ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
text7: Wall Street Journal
text8: Personals Corpus
text9: The Man Who Was Thursday by G . K . Chesterton 1908
mapFunction_Parents(): keyword =  locomotive ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  powered ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  electricity ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  cars ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'coupled']
reduceFunction_Parents(): returns= [u'coupled']
mapFunction_Parents(): keyword =  coupled ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'coupled']
mapFunction_Parents(): keyword =  together ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'coupled']
15/12/29 16:44:04 INFO PythonRunner: Times: total = 36018, boot = 457, init = 26612, finish = 8949
15/12/29 16:44:04 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
15/12/29 16:44:04 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 36088 ms on localhost (1/2)
mapFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  railway ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  car ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  drawn ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  line ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'railway']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway']
mapFunction_Parents(): keyword =  public ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway']
mapFunction_Parents(): keyword =  transport ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'line', u'transport']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:44:05 INFO PythonRunner: Times: total = 37511, boot = 453, init = 28986, finish = 8072
15/12/29 16:44:05 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
15/12/29 16:44:05 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184) finished in 37.571 s
15/12/29 16:44:05 INFO DAGScheduler: looking for newly runnable stages
15/12/29 16:44:05 INFO DAGScheduler: running: Set()
15/12/29 16:44:05 INFO DAGScheduler: waiting: Set(ResultStage 1)
15/12/29 16:44:05 INFO DAGScheduler: failed: Set()
15/12/29 16:44:05 INFO DAGScheduler: Missing parents for ResultStage 1: List()
15/12/29 16:44:05 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186), which is now runnable
15/12/29 16:44:05 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11693, maxMem=557312901
15/12/29 16:44:05 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 531.5 MB)
15/12/29 16:44:05 INFO MemoryStore: ensureFreeSpace(3054) called with curMem=16677, maxMem=557312901
15/12/29 16:44:05 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 531.5 MB)
15/12/29 16:44:05 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:53345 (size: 3.0 KB, free: 531.5 MB)
15/12/29 16:44:05 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 37568 ms on localhost (2/2)
15/12/29 16:44:05 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
15/12/29 16:44:05 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
15/12/29 16:44:05 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186)
15/12/29 16:44:05 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
15/12/29 16:44:05 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
15/12/29 16:44:05 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
15/12/29 16:44:05 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
15/12/29 16:44:05 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
15/12/29 16:44:05 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/12/29 16:44:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
15/12/29 16:44:05 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/12/29 16:44:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
15/12/29 16:44:06 INFO PythonRunner: Times: total = 39, boot = -1278, init = 1316, finish = 1
15/12/29 16:44:06 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
15/12/29 16:44:06 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 71 ms on localhost (1/2)
reduceFunction_Parents(): returns= [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']15/12/29 16:44:06 INFO PythonRunner: Times: total = 226, boot = 225, init = 0, finish = 1

15/12/29 16:44:06 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1360 bytes result sent to driver
15/12/29 16:44:06 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 249 ms on localhost (2/2)
15/12/29 16:44:06 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186) finished in 0.238 s
15/12/29 16:44:06 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
15/12/29 16:44:06 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186, took 37.861757 s
15/12/29 16:44:06 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189
15/12/29 16:44:06 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189) with 2 output partitions
15/12/29 16:44:06 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189)
15/12/29 16:44:06 INFO DAGScheduler: Parents of final stage: List()
15/12/29 16:44:06 INFO DAGScheduler: Missing parents: List()
15/12/29 16:44:06 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189), which has no missing parents
15/12/29 16:44:06 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19731, maxMem=557312901
15/12/29 16:44:06 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 531.5 MB)
15/12/29 16:44:06 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25547, maxMem=557312901
15/12/29 16:44:06 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 531.5 MB)
15/12/29 16:44:06 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:53345 (size: 3.3 KB, free: 531.5 MB)
15/12/29 16:44:06 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
15/12/29 16:44:06 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189)
15/12/29 16:44:06 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
15/12/29 16:44:06 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
15/12/29 16:44:06 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2441 bytes)
15/12/29 16:44:06 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
15/12/29 16:44:06 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
15/12/29 16:44:06 INFO PythonRunner: Times: total = 76, boot = 76, init = 0, finish = 0
15/12/29 16:44:06 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
15/12/29 16:44:06 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 83 ms on localhost (1/2)
15/12/29 16:44:06 INFO PythonRunner: Times: total = 242, boot = 242, init = 0, finish = 0
15/12/29 16:44:06 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1422 bytes result sent to driver
15/12/29 16:44:06 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 251 ms on localhost (2/2)
15/12/29 16:44:06 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
15/12/29 16:44:06 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189) finished in 0.251 s
15/12/29 16:44:06 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189, took 0.274700 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
15/12/29 16:44:06 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
15/12/29 16:44:06 INFO DAGScheduler: Stopping DAGScheduler
15/12/29 16:44:06 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
15/12/29 16:44:06 INFO MemoryStore: MemoryStore cleared
15/12/29 16:44:06 INFO BlockManager: BlockManager stopped
15/12/29 16:44:06 INFO BlockManagerMaster: BlockManagerMaster stopped
15/12/29 16:44:06 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
15/12/29 16:44:06 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
15/12/29 16:44:06 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
15/12/29 16:44:06 INFO SparkContext: Successfully stopped SparkContext
15/12/29 16:44:06 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:44:07 INFO SparkContext: Running Spark version 1.5.2
15/12/29 16:44:07 INFO SecurityManager: Changing view acls to: root
15/12/29 16:44:07 INFO SecurityManager: Changing modify acls to: root
15/12/29 16:44:07 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
15/12/29 16:44:07 INFO Slf4jLogger: Slf4jLogger started
15/12/29 16:44:07 INFO Remoting: Starting remoting
15/12/29 16:44:07 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:50527]
15/12/29 16:44:07 INFO Utils: Successfully started service 'sparkDriver' on port 50527.
15/12/29 16:44:07 INFO SparkEnv: Registering MapOutputTracker
15/12/29 16:44:07 INFO SparkEnv: Registering BlockManagerMaster
15/12/29 16:44:07 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-dd49b787-5455-45d4-9745-5698f4662e42
15/12/29 16:44:07 INFO MemoryStore: MemoryStore started with capacity 531.5 MB
15/12/29 16:44:07 INFO HttpFileServer: HTTP File server directory is /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/httpd-0c4e5cbb-72ee-4045-8ff5-ad3a44efb8e0
15/12/29 16:44:07 INFO HttpServer: Starting HTTP Server
15/12/29 16:44:07 INFO Utils: Successfully started service 'HTTP file server' on port 35386.
15/12/29 16:44:07 INFO SparkEnv: Registering OutputCommitCoordinator
15/12/29 16:44:08 INFO Utils: Successfully started service 'SparkUI' on port 4040.
15/12/29 16:44:08 INFO SparkUI: Started SparkUI at http://localhost:4040
15/12/29 16:44:08 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/userFiles-907d2c12-2c8d-4516-bb0a-a9623a41fa00/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
15/12/29 16:44:08 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1451387648191
15/12/29 16:44:08 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
15/12/29 16:44:08 INFO Executor: Starting executor ID driver on host localhost
15/12/29 16:44:08 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37190.
15/12/29 16:44:08 INFO NettyBlockTransferService: Server created on 37190
15/12/29 16:44:08 INFO BlockManagerMaster: Trying to register BlockManager
15/12/29 16:44:08 INFO BlockManagerMasterEndpoint: Registering block manager localhost:37190 with 531.5 MB RAM, BlockManagerId(driver, localhost, 37190)
15/12/29 16:44:08 INFO BlockManagerMaster: Registered BlockManager
15/12/29 16:44:08 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186
15/12/29 16:44:08 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184)
15/12/29 16:44:08 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186) with 2 output partitions
15/12/29 16:44:08 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186)
15/12/29 16:44:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
15/12/29 16:44:08 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
15/12/29 16:44:08 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184), which has no missing parents
15/12/29 16:44:08 INFO MemoryStore: ensureFreeSpace(7120) called with curMem=0, maxMem=557312901
15/12/29 16:44:08 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 7.0 KB, free 531.5 MB)
15/12/29 16:44:08 INFO MemoryStore: ensureFreeSpace(4573) called with curMem=7120, maxMem=557312901
15/12/29 16:44:08 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.5 KB, free 531.5 MB)
15/12/29 16:44:08 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:37190 (size: 4.5 KB, free: 531.5 MB)
15/12/29 16:44:08 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
15/12/29 16:44:08 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184)
15/12/29 16:44:08 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
15/12/29 16:44:08 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2401 bytes)
15/12/29 16:44:08 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2424 bytes)
15/12/29 16:44:08 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
15/12/29 16:44:08 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1451387648191
15/12/29 16:44:08 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
15/12/29 16:44:08 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/userFiles-907d2c12-2c8d-4516-bb0a-a9623a41fa00/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
*** Introductory Examples for the NLTK Book ***
Loading text1, ..., text9 and sent1, ..., sent9
Type the name of the text or sentence to view it.
Type: 'texts()' or 'sents()' to list the materials.
*** Introductory Examples for the NLTK Book ***
Loading text1, ..., text9 and sent1, ..., sent9
Type the name of the text or sentence to view it.
Type: 'texts()' or 'sents()' to list the materials.
text1: Moby Dick by Herman Melville 1851
text1: Moby Dick by Herman Melville 1851
text2: Sense and Sensibility by Jane Austen 1811
text2: Sense and Sensibility by Jane Austen 1811
text3: The Book of Genesis
text3: The Book of Genesis
text4: Inaugural Address Corpus
text4: Inaugural Address Corpus
text5: Chat Corpus
text6: Monty Python and the Holy Grail
text5: Chat Corpus
text6: Monty Python and the Holy Grail
text7: Wall Street Journal
text8: Personals Corpus
text9: The Man Who Was Thursday by G . K . Chesterton 1908
mapFunction_Parents(): keyword =  locomotive ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
text7: Wall Street Journal
text8: Personals Corpus
text9: The Man Who Was Thursday by G . K . Chesterton 1908
mapFunction_Parents(): keyword =  provided ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  railway ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  car ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  drawn ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  line ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'railway']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway']
mapFunction_Parents(): keyword =  public ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway']
mapFunction_Parents(): keyword =  transport ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'line', u'transport']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:44:43 INFO PythonRunner: Times: total = 34900, boot = 457, init = 26577, finish = 7866
15/12/29 16:44:43 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
15/12/29 16:44:43 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 34980 ms on localhost (1/2)
mapFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  powered ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  electricity ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  cars ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'coupled']
reduceFunction_Parents(): returns= [u'coupled']
mapFunction_Parents(): keyword =  coupled ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'coupled']
mapFunction_Parents(): keyword =  together ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'coupled']
15/12/29 16:44:46 INFO PythonRunner: Times: total = 37633, boot = 467, init = 29075, finish = 8091
15/12/29 16:44:46 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
15/12/29 16:44:46 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 37710 ms on localhost (2/2)
15/12/29 16:44:46 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
15/12/29 16:44:46 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184) finished in 37.714 s
15/12/29 16:44:46 INFO DAGScheduler: looking for newly runnable stages
15/12/29 16:44:46 INFO DAGScheduler: running: Set()
15/12/29 16:44:46 INFO DAGScheduler: waiting: Set(ResultStage 1)
15/12/29 16:44:46 INFO DAGScheduler: failed: Set()
15/12/29 16:44:46 INFO DAGScheduler: Missing parents for ResultStage 1: List()
15/12/29 16:44:46 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186), which is now runnable
15/12/29 16:44:46 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11693, maxMem=557312901
15/12/29 16:44:46 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 531.5 MB)
15/12/29 16:44:46 INFO MemoryStore: ensureFreeSpace(3054) called with curMem=16677, maxMem=557312901
15/12/29 16:44:46 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 531.5 MB)
15/12/29 16:44:46 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:37190 (size: 3.0 KB, free: 531.5 MB)
15/12/29 16:44:46 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
15/12/29 16:44:46 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186)
15/12/29 16:44:46 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
15/12/29 16:44:46 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
15/12/29 16:44:46 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
15/12/29 16:44:46 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
15/12/29 16:44:46 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
15/12/29 16:44:46 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/12/29 16:44:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
15/12/29 16:44:46 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/12/29 16:44:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
15/12/29 16:44:46 INFO PythonRunner: Times: total = 55, boot = -2533, init = 2588, finish = 0
15/12/29 16:44:46 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
15/12/29 16:44:46 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 73 ms on localhost (1/2)
reduceFunction_Parents(): returns= [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:44:46 INFO PythonRunner: Times: total = 278, boot = 275, init = 0, finish = 3
15/12/29 16:44:46 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1360 bytes result sent to driver
15/12/29 16:44:46 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186) finished in 0.294 s
15/12/29 16:44:46 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186, took 38.039981 s
15/12/29 16:44:46 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 293 ms on localhost (2/2)
15/12/29 16:44:46 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
15/12/29 16:44:46 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189
15/12/29 16:44:46 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189) with 2 output partitions
15/12/29 16:44:46 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189)
15/12/29 16:44:46 INFO DAGScheduler: Parents of final stage: List()
15/12/29 16:44:46 INFO DAGScheduler: Missing parents: List()
15/12/29 16:44:46 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189), which has no missing parents
15/12/29 16:44:46 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19731, maxMem=557312901
15/12/29 16:44:46 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 531.5 MB)
15/12/29 16:44:46 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25547, maxMem=557312901
15/12/29 16:44:46 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 531.5 MB)
15/12/29 16:44:46 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:37190 (size: 3.3 KB, free: 531.5 MB)
15/12/29 16:44:46 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
15/12/29 16:44:46 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189)
15/12/29 16:44:46 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
15/12/29 16:44:46 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
15/12/29 16:44:46 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2441 bytes)
15/12/29 16:44:46 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
15/12/29 16:44:46 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
15/12/29 16:44:46 INFO PythonRunner: Times: total = 66, boot = -137, init = 203, finish = 0
15/12/29 16:44:46 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1422 bytes result sent to driver
15/12/29 16:44:46 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 86 ms on localhost (1/2)
15/12/29 16:44:46 INFO PythonRunner: Times: total = 208, boot = 208, init = 0, finish = 0
15/12/29 16:44:46 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
15/12/29 16:44:46 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 222 ms on localhost (2/2)
15/12/29 16:44:46 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189) finished in 0.218 s
15/12/29 16:44:46 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
15/12/29 16:44:46 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189, took 0.246747 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
15/12/29 16:44:46 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
15/12/29 16:44:46 INFO DAGScheduler: Stopping DAGScheduler
15/12/29 16:44:46 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
15/12/29 16:44:46 INFO MemoryStore: MemoryStore cleared
15/12/29 16:44:46 INFO BlockManager: BlockManager stopped
15/12/29 16:44:46 INFO BlockManagerMaster: BlockManagerMaster stopped
15/12/29 16:44:46 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
15/12/29 16:44:46 INFO SparkContext: Successfully stopped SparkContext
15/12/29 16:44:46 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
15/12/29 16:44:46 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
15/12/29 16:44:46 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:44:47 INFO SparkContext: Running Spark version 1.5.2
15/12/29 16:44:47 INFO SecurityManager: Changing view acls to: root
15/12/29 16:44:47 INFO SecurityManager: Changing modify acls to: root
15/12/29 16:44:47 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
15/12/29 16:44:47 INFO Slf4jLogger: Slf4jLogger started
15/12/29 16:44:47 INFO Remoting: Starting remoting
15/12/29 16:44:47 INFO Utils: Successfully started service 'sparkDriver' on port 46845.
15/12/29 16:44:47 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:46845]
15/12/29 16:44:47 INFO SparkEnv: Registering MapOutputTracker
15/12/29 16:44:47 INFO SparkEnv: Registering BlockManagerMaster
15/12/29 16:44:47 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-b4dd09f1-f56a-4581-8005-95fd374a0ddf
15/12/29 16:44:47 INFO MemoryStore: MemoryStore started with capacity 531.5 MB
15/12/29 16:44:47 INFO HttpFileServer: HTTP File server directory is /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/httpd-fe3e85fd-8a6d-4f6d-8403-bd0644692ebe
15/12/29 16:44:47 INFO HttpServer: Starting HTTP Server
15/12/29 16:44:47 INFO Utils: Successfully started service 'HTTP file server' on port 59444.
15/12/29 16:44:47 INFO SparkEnv: Registering OutputCommitCoordinator
15/12/29 16:44:48 INFO Utils: Successfully started service 'SparkUI' on port 4040.
15/12/29 16:44:48 INFO SparkUI: Started SparkUI at http://localhost:4040
15/12/29 16:44:48 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/userFiles-c3b952c3-4248-4c00-b08d-450cdcb830b8/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
15/12/29 16:44:48 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1451387688322
15/12/29 16:44:48 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
15/12/29 16:44:48 INFO Executor: Starting executor ID driver on host localhost
15/12/29 16:44:48 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45108.
15/12/29 16:44:48 INFO NettyBlockTransferService: Server created on 45108
15/12/29 16:44:48 INFO BlockManagerMaster: Trying to register BlockManager
15/12/29 16:44:48 INFO BlockManagerMasterEndpoint: Registering block manager localhost:45108 with 531.5 MB RAM, BlockManagerId(driver, localhost, 45108)
15/12/29 16:44:48 INFO BlockManagerMaster: Registered BlockManager
15/12/29 16:44:48 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186
15/12/29 16:44:48 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184)
15/12/29 16:44:48 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186) with 2 output partitions
15/12/29 16:44:48 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186)
15/12/29 16:44:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
15/12/29 16:44:48 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
15/12/29 16:44:48 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184), which has no missing parents
15/12/29 16:44:48 INFO MemoryStore: ensureFreeSpace(7120) called with curMem=0, maxMem=557312901
15/12/29 16:44:48 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 7.0 KB, free 531.5 MB)
15/12/29 16:44:48 INFO MemoryStore: ensureFreeSpace(4573) called with curMem=7120, maxMem=557312901
15/12/29 16:44:48 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.5 KB, free 531.5 MB)
15/12/29 16:44:48 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:45108 (size: 4.5 KB, free: 531.5 MB)
15/12/29 16:44:48 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
15/12/29 16:44:48 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184)
15/12/29 16:44:48 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
15/12/29 16:44:48 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2401 bytes)
15/12/29 16:44:48 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2424 bytes)
15/12/29 16:44:48 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
15/12/29 16:44:48 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1451387688322
15/12/29 16:44:48 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
15/12/29 16:44:48 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/userFiles-c3b952c3-4248-4c00-b08d-450cdcb830b8/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
*** Introductory Examples for the NLTK Book ***
Loading text1, ..., text9 and sent1, ..., sent9
Type the name of the text or sentence to view it.
Type: 'texts()' or 'sents()' to list the materials.
*** Introductory Examples for the NLTK Book ***
Loading text1, ..., text9 and sent1, ..., sent9
Type the name of the text or sentence to view it.
Type: 'texts()' or 'sents()' to list the materials.
text1: Moby Dick by Herman Melville 1851
text1: Moby Dick by Herman Melville 1851
text2: Sense and Sensibility by Jane Austen 1811
text2: Sense and Sensibility by Jane Austen 1811
text3: The Book of Genesis
text3: The Book of Genesis
text4: Inaugural Address Corpus
text4: Inaugural Address Corpus
text5: Chat Corpus
text6: Monty Python and the Holy Grail
text5: Chat Corpus
text6: Monty Python and the Holy Grail
text7: Wall Street Journal
text8: Personals Corpus
text9: The Man Who Was Thursday by G . K . Chesterton 1908
mapFunction_Parents(): keyword =  locomotive ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
text7: Wall Street Journal
text8: Personals Corpus
text9: The Man Who Was Thursday by G . K . Chesterton 1908
mapFunction_Parents(): keyword =  provided ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  railway ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  car ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  drawn ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  line ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'railway']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway']
mapFunction_Parents(): keyword =  public ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway']
mapFunction_Parents(): keyword =  transport ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'line', u'transport']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:45:23 INFO PythonRunner: Times: total = 34899, boot = 455, init = 26505, finish = 7939
15/12/29 16:45:23 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
15/12/29 16:45:23 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 34974 ms on localhost (1/2)
mapFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  powered ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  electricity ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  cars ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'coupled']
reduceFunction_Parents(): returns= [u'coupled']
mapFunction_Parents(): keyword =  coupled ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'coupled']
mapFunction_Parents(): keyword =  together ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'coupled']
15/12/29 16:45:25 INFO PythonRunner: Times: total = 36926, boot = 460, init = 28244, finish = 8222
15/12/29 16:45:25 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
15/12/29 16:45:25 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184) finished in 36.986 s
15/12/29 16:45:25 INFO DAGScheduler: looking for newly runnable stages
15/12/29 16:45:25 INFO DAGScheduler: running: Set()
15/12/29 16:45:25 INFO DAGScheduler: waiting: Set(ResultStage 1)
15/12/29 16:45:25 INFO DAGScheduler: failed: Set()
15/12/29 16:45:25 INFO DAGScheduler: Missing parents for ResultStage 1: List()
15/12/29 16:45:25 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186), which is now runnable
15/12/29 16:45:25 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11693, maxMem=557312901
15/12/29 16:45:25 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 531.5 MB)
15/12/29 16:45:25 INFO MemoryStore: ensureFreeSpace(3054) called with curMem=16677, maxMem=557312901
15/12/29 16:45:25 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 36985 ms on localhost (2/2)
15/12/29 16:45:25 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
15/12/29 16:45:25 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 531.5 MB)
15/12/29 16:45:25 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:45108 (size: 3.0 KB, free: 531.5 MB)
15/12/29 16:45:25 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
15/12/29 16:45:25 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186)
15/12/29 16:45:25 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
15/12/29 16:45:25 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
15/12/29 16:45:25 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
15/12/29 16:45:25 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
15/12/29 16:45:25 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/12/29 16:45:25 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
15/12/29 16:45:25 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/12/29 16:45:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
15/12/29 16:45:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
reduceFunction_Parents(): returns= [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:45:25 INFO PythonRunner: Times: total = 38, boot = -1833, init = 1871, finish = 0
15/12/29 16:45:25 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1360 bytes result sent to driver
15/12/29 16:45:25 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 61 ms on localhost (1/2)
15/12/29 16:45:25 INFO PythonRunner: Times: total = 228, boot = 227, init = 0, finish = 1
15/12/29 16:45:25 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
15/12/29 16:45:25 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186) finished in 0.238 s
15/12/29 16:45:25 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 247 ms on localhost (2/2)
15/12/29 16:45:25 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
15/12/29 16:45:25 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186, took 37.286814 s
15/12/29 16:45:25 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189
15/12/29 16:45:25 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189) with 2 output partitions
15/12/29 16:45:25 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189)
15/12/29 16:45:25 INFO DAGScheduler: Parents of final stage: List()
15/12/29 16:45:25 INFO DAGScheduler: Missing parents: List()
15/12/29 16:45:25 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189), which has no missing parents
15/12/29 16:45:25 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19731, maxMem=557312901
15/12/29 16:45:25 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 531.5 MB)
15/12/29 16:45:25 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25547, maxMem=557312901
15/12/29 16:45:25 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 531.5 MB)
15/12/29 16:45:25 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:45108 (size: 3.3 KB, free: 531.5 MB)
15/12/29 16:45:25 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
15/12/29 16:45:25 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189)
15/12/29 16:45:25 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
15/12/29 16:45:25 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
15/12/29 16:45:25 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2441 bytes)
15/12/29 16:45:25 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
15/12/29 16:45:25 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
15/12/29 16:45:25 INFO PythonRunner: Times: total = 54, boot = -18, init = 72, finish = 0
15/12/29 16:45:25 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
15/12/29 16:45:25 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 64 ms on localhost (1/2)
15/12/29 16:45:25 INFO PythonRunner: Times: total = 102, boot = 102, init = 0, finish = 0
15/12/29 16:45:25 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1422 bytes result sent to driver
15/12/29 16:45:25 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 115 ms on localhost (2/2)
15/12/29 16:45:25 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
15/12/29 16:45:25 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189) finished in 0.117 s
15/12/29 16:45:25 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189, took 0.138648 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
15/12/29 16:45:26 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
15/12/29 16:45:26 INFO DAGScheduler: Stopping DAGScheduler
15/12/29 16:45:26 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
15/12/29 16:45:26 INFO MemoryStore: MemoryStore cleared
15/12/29 16:45:26 INFO BlockManager: BlockManager stopped
15/12/29 16:45:26 INFO BlockManagerMaster: BlockManagerMaster stopped
15/12/29 16:45:26 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
15/12/29 16:45:26 INFO SparkContext: Successfully stopped SparkContext
15/12/29 16:45:26 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
15/12/29 16:45:26 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
15/12/29 16:45:26 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:45:27 INFO SparkContext: Running Spark version 1.5.2
15/12/29 16:45:27 INFO SecurityManager: Changing view acls to: root
15/12/29 16:45:27 INFO SecurityManager: Changing modify acls to: root
15/12/29 16:45:27 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
15/12/29 16:45:27 INFO Slf4jLogger: Slf4jLogger started
15/12/29 16:45:27 INFO Remoting: Starting remoting
15/12/29 16:45:27 INFO Utils: Successfully started service 'sparkDriver' on port 49244.
15/12/29 16:45:27 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:49244]
15/12/29 16:45:27 INFO SparkEnv: Registering MapOutputTracker
15/12/29 16:45:27 INFO SparkEnv: Registering BlockManagerMaster
15/12/29 16:45:27 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-de7e9c63-0e9b-48a6-9166-bfba9a4de3b4
15/12/29 16:45:27 INFO MemoryStore: MemoryStore started with capacity 531.5 MB
15/12/29 16:45:27 INFO HttpFileServer: HTTP File server directory is /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/httpd-ad96318b-a313-4100-8c97-dccffef99a66
15/12/29 16:45:27 INFO HttpServer: Starting HTTP Server
15/12/29 16:45:27 INFO Utils: Successfully started service 'HTTP file server' on port 48275.
15/12/29 16:45:27 INFO SparkEnv: Registering OutputCommitCoordinator
15/12/29 16:45:27 INFO Utils: Successfully started service 'SparkUI' on port 4040.
15/12/29 16:45:27 INFO SparkUI: Started SparkUI at http://localhost:4040
15/12/29 16:45:27 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/userFiles-43d2c3d3-8ffb-4f29-a817-248bd6a03a76/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
15/12/29 16:45:27 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1451387727898
15/12/29 16:45:27 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
15/12/29 16:45:27 INFO Executor: Starting executor ID driver on host localhost
15/12/29 16:45:27 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53867.
15/12/29 16:45:27 INFO NettyBlockTransferService: Server created on 53867
15/12/29 16:45:27 INFO BlockManagerMaster: Trying to register BlockManager
15/12/29 16:45:27 INFO BlockManagerMasterEndpoint: Registering block manager localhost:53867 with 531.5 MB RAM, BlockManagerId(driver, localhost, 53867)
15/12/29 16:45:27 INFO BlockManagerMaster: Registered BlockManager
15/12/29 16:45:28 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186
15/12/29 16:45:28 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184)
15/12/29 16:45:28 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186) with 2 output partitions
15/12/29 16:45:28 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186)
15/12/29 16:45:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
15/12/29 16:45:28 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
15/12/29 16:45:28 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184), which has no missing parents
15/12/29 16:45:28 INFO MemoryStore: ensureFreeSpace(7120) called with curMem=0, maxMem=557312901
15/12/29 16:45:28 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 7.0 KB, free 531.5 MB)
15/12/29 16:45:28 INFO MemoryStore: ensureFreeSpace(4573) called with curMem=7120, maxMem=557312901
15/12/29 16:45:28 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.5 KB, free 531.5 MB)
15/12/29 16:45:28 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:53867 (size: 4.5 KB, free: 531.5 MB)
15/12/29 16:45:28 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
15/12/29 16:45:28 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184)
15/12/29 16:45:28 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
15/12/29 16:45:28 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2401 bytes)
15/12/29 16:45:28 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2424 bytes)
15/12/29 16:45:28 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
15/12/29 16:45:28 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1451387727898
15/12/29 16:45:28 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
15/12/29 16:45:28 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/userFiles-43d2c3d3-8ffb-4f29-a817-248bd6a03a76/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
*** Introductory Examples for the NLTK Book ***
Loading text1, ..., text9 and sent1, ..., sent9
Type the name of the text or sentence to view it.
Type: 'texts()' or 'sents()' to list the materials.
*** Introductory Examples for the NLTK Book ***
Loading text1, ..., text9 and sent1, ..., sent9
Type the name of the text or sentence to view it.
Type: 'texts()' or 'sents()' to list the materials.
text1: Moby Dick by Herman Melville 1851
text1: Moby Dick by Herman Melville 1851
text2: Sense and Sensibility by Jane Austen 1811
text2: Sense and Sensibility by Jane Austen 1811
text3: The Book of Genesis
text3: The Book of Genesis
text4: Inaugural Address Corpus
text4: Inaugural Address Corpus
text5: Chat Corpus
text6: Monty Python and the Holy Grail
text5: Chat Corpus
text6: Monty Python and the Holy Grail
text7: Wall Street Journal
text8: Personals Corpus
text9: The Man Who Was Thursday by G . K . Chesterton 1908
mapFunction_Parents(): keyword =  locomotive ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
text7: Wall Street Journal
text8: Personals Corpus
text9: The Man Who Was Thursday by G . K . Chesterton 1908
mapFunction_Parents(): keyword =  provided ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  railway ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  car ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  drawn ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  line ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'railway']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway']
mapFunction_Parents(): keyword =  public ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway']
mapFunction_Parents(): keyword =  transport ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'line', u'transport']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:46:04 INFO PythonRunner: Times: total = 36057, boot = 459, init = 27493, finish = 8105
15/12/29 16:46:04 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
15/12/29 16:46:04 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 36137 ms on localhost (1/2)
mapFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  powered ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  electricity ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  cars ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'coupled']
reduceFunction_Parents(): returns= [u'coupled']
mapFunction_Parents(): keyword =  coupled ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'coupled']
mapFunction_Parents(): keyword =  together ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'coupled']
15/12/29 16:46:05 INFO PythonRunner: Times: total = 37677, boot = 456, init = 28875, finish = 8346
15/12/29 16:46:05 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
15/12/29 16:46:05 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184) finished in 37.740 s
15/12/29 16:46:05 INFO DAGScheduler: looking for newly runnable stages
15/12/29 16:46:05 INFO DAGScheduler: running: Set()
15/12/29 16:46:05 INFO DAGScheduler: waiting: Set(ResultStage 1)
15/12/29 16:46:05 INFO DAGScheduler: failed: Set()
15/12/29 16:46:05 INFO DAGScheduler: Missing parents for ResultStage 1: List()
15/12/29 16:46:05 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186), which is now runnable
15/12/29 16:46:05 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11693, maxMem=557312901
15/12/29 16:46:05 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 531.5 MB)
15/12/29 16:46:05 INFO MemoryStore: ensureFreeSpace(3054) called with curMem=16677, maxMem=557312901
15/12/29 16:46:05 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 37737 ms on localhost (2/2)
15/12/29 16:46:05 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
15/12/29 16:46:05 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 531.5 MB)
15/12/29 16:46:05 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:53867 (size: 3.0 KB, free: 531.5 MB)
15/12/29 16:46:05 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
15/12/29 16:46:05 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186)
15/12/29 16:46:05 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
15/12/29 16:46:05 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
15/12/29 16:46:05 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
15/12/29 16:46:05 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
15/12/29 16:46:05 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
15/12/29 16:46:05 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/12/29 16:46:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
15/12/29 16:46:05 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/12/29 16:46:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
15/12/29 16:46:05 INFO PythonRunner: Times: total = 66, boot = -1392, init = 1457, finish = 1
15/12/29 16:46:05 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1360 bytes result sent to driver
reduceFunction_Parents(): returns= [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:46:05 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 96 ms on localhost (1/2)
15/12/29 16:46:06 INFO PythonRunner: Times: total = 239, boot = 238, init = 0, finish = 1
15/12/29 16:46:06 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
15/12/29 16:46:06 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 261 ms on localhost (2/2)
15/12/29 16:46:06 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186) finished in 0.261 s
15/12/29 16:46:06 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
15/12/29 16:46:06 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186, took 38.040352 s
15/12/29 16:46:06 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189
15/12/29 16:46:06 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189) with 2 output partitions
15/12/29 16:46:06 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189)
15/12/29 16:46:06 INFO DAGScheduler: Parents of final stage: List()
15/12/29 16:46:06 INFO DAGScheduler: Missing parents: List()
15/12/29 16:46:06 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189), which has no missing parents
15/12/29 16:46:06 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19731, maxMem=557312901
15/12/29 16:46:06 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 531.5 MB)
15/12/29 16:46:06 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25547, maxMem=557312901
15/12/29 16:46:06 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 531.5 MB)
15/12/29 16:46:06 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:53867 (size: 3.3 KB, free: 531.5 MB)
15/12/29 16:46:06 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
15/12/29 16:46:06 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189)
15/12/29 16:46:06 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
15/12/29 16:46:06 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
15/12/29 16:46:06 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2441 bytes)
15/12/29 16:46:06 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
15/12/29 16:46:06 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
15/12/29 16:46:06 INFO PythonRunner: Times: total = 119, boot = 119, init = 0, finish = 0
15/12/29 16:46:06 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
15/12/29 16:46:06 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 135 ms on localhost (1/2)
15/12/29 16:46:06 INFO PythonRunner: Times: total = 148, boot = 148, init = 0, finish = 0
15/12/29 16:46:06 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1422 bytes result sent to driver
15/12/29 16:46:06 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 159 ms on localhost (2/2)
15/12/29 16:46:06 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
15/12/29 16:46:06 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189) finished in 0.160 s
15/12/29 16:46:06 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189, took 0.199625 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
15/12/29 16:46:06 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
15/12/29 16:46:06 INFO DAGScheduler: Stopping DAGScheduler
15/12/29 16:46:06 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
15/12/29 16:46:06 INFO MemoryStore: MemoryStore cleared
15/12/29 16:46:06 INFO BlockManager: BlockManager stopped
15/12/29 16:46:06 INFO BlockManagerMaster: BlockManagerMaster stopped
15/12/29 16:46:06 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
15/12/29 16:46:06 INFO SparkContext: Successfully stopped SparkContext
15/12/29 16:46:06 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
15/12/29 16:46:06 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
15/12/29 16:46:06 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:46:07 INFO SparkContext: Running Spark version 1.5.2
15/12/29 16:46:07 INFO SecurityManager: Changing view acls to: root
15/12/29 16:46:07 INFO SecurityManager: Changing modify acls to: root
15/12/29 16:46:07 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
15/12/29 16:46:07 INFO Slf4jLogger: Slf4jLogger started
15/12/29 16:46:07 INFO Remoting: Starting remoting
15/12/29 16:46:07 INFO Utils: Successfully started service 'sparkDriver' on port 51509.
15/12/29 16:46:07 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:51509]
15/12/29 16:46:07 INFO SparkEnv: Registering MapOutputTracker
15/12/29 16:46:07 INFO SparkEnv: Registering BlockManagerMaster
15/12/29 16:46:07 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-f5798966-88e4-4c6f-9d95-124eff86f6d7
15/12/29 16:46:07 INFO MemoryStore: MemoryStore started with capacity 534.1 MB
15/12/29 16:46:07 INFO HttpFileServer: HTTP File server directory is /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/httpd-ddb86c88-6d7e-49f9-a4b1-0625597acc61
15/12/29 16:46:07 INFO HttpServer: Starting HTTP Server
15/12/29 16:46:07 INFO Utils: Successfully started service 'HTTP file server' on port 42626.
15/12/29 16:46:07 INFO SparkEnv: Registering OutputCommitCoordinator
15/12/29 16:46:07 INFO Utils: Successfully started service 'SparkUI' on port 4040.
15/12/29 16:46:07 INFO SparkUI: Started SparkUI at http://localhost:4040
15/12/29 16:46:07 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/userFiles-0572e3c8-0435-4164-ac26-459e5033f37d/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
15/12/29 16:46:07 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1451387767971
15/12/29 16:46:07 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
15/12/29 16:46:07 INFO Executor: Starting executor ID driver on host localhost
15/12/29 16:46:08 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53514.
15/12/29 16:46:08 INFO NettyBlockTransferService: Server created on 53514
15/12/29 16:46:08 INFO BlockManagerMaster: Trying to register BlockManager
15/12/29 16:46:08 INFO BlockManagerMasterEndpoint: Registering block manager localhost:53514 with 534.1 MB RAM, BlockManagerId(driver, localhost, 53514)
15/12/29 16:46:08 INFO BlockManagerMaster: Registered BlockManager
15/12/29 16:46:08 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186
15/12/29 16:46:08 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184)
15/12/29 16:46:08 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186) with 2 output partitions
15/12/29 16:46:08 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186)
15/12/29 16:46:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
15/12/29 16:46:08 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
15/12/29 16:46:08 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184), which has no missing parents
15/12/29 16:46:08 INFO MemoryStore: ensureFreeSpace(7120) called with curMem=0, maxMem=560002498
15/12/29 16:46:08 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 7.0 KB, free 534.1 MB)
15/12/29 16:46:08 INFO MemoryStore: ensureFreeSpace(4573) called with curMem=7120, maxMem=560002498
15/12/29 16:46:08 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.5 KB, free 534.0 MB)
15/12/29 16:46:08 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:53514 (size: 4.5 KB, free: 534.1 MB)
15/12/29 16:46:08 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
15/12/29 16:46:08 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184)
15/12/29 16:46:08 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
15/12/29 16:46:08 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2401 bytes)
15/12/29 16:46:08 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2424 bytes)
15/12/29 16:46:08 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
15/12/29 16:46:08 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1451387767971
15/12/29 16:46:08 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
15/12/29 16:46:08 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/userFiles-0572e3c8-0435-4164-ac26-459e5033f37d/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
*** Introductory Examples for the NLTK Book ***
Loading text1, ..., text9 and sent1, ..., sent9
Type the name of the text or sentence to view it.
Type: 'texts()' or 'sents()' to list the materials.
*** Introductory Examples for the NLTK Book ***
Loading text1, ..., text9 and sent1, ..., sent9
Type the name of the text or sentence to view it.
Type: 'texts()' or 'sents()' to list the materials.
text1: Moby Dick by Herman Melville 1851
text1: Moby Dick by Herman Melville 1851
text2: Sense and Sensibility by Jane Austen 1811
text2: Sense and Sensibility by Jane Austen 1811
text3: The Book of Genesis
text3: The Book of Genesis
text4: Inaugural Address Corpus
text4: Inaugural Address Corpus
text5: Chat Corpus
text6: Monty Python and the Holy Grail
text5: Chat Corpus
text6: Monty Python and the Holy Grail
text7: Wall Street Journal
text8: Personals Corpus
text9: The Man Who Was Thursday by G . K . Chesterton 1908
mapFunction_Parents(): keyword =  provided ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
text7: Wall Street Journal
text8: Personals Corpus
text9: The Man Who Was Thursday by G . K . Chesterton 1908
mapFunction_Parents(): keyword =  locomotive ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  powered ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  electricity ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  cars ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'coupled']
reduceFunction_Parents(): returns= [u'coupled']
mapFunction_Parents(): keyword =  coupled ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'coupled']
mapFunction_Parents(): keyword =  together ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'coupled']
15/12/29 16:46:44 INFO PythonRunner: Times: total = 35913, boot = 461, init = 27304, finish = 8148
15/12/29 16:46:44 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
15/12/29 16:46:44 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 36003 ms on localhost (1/2)
mapFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  railway ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  car ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  drawn ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  line ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'railway']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway']
mapFunction_Parents(): keyword =  public ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway']
mapFunction_Parents(): keyword =  transport ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'line', u'transport']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:46:45 INFO PythonRunner: Times: total = 37326, boot = 462, init = 28473, finish = 8391
15/12/29 16:46:45 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
15/12/29 16:46:45 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184) finished in 37.392 s
15/12/29 16:46:45 INFO DAGScheduler: looking for newly runnable stages
15/12/29 16:46:45 INFO DAGScheduler: running: Set()
15/12/29 16:46:45 INFO DAGScheduler: waiting: Set(ResultStage 1)
15/12/29 16:46:45 INFO DAGScheduler: failed: Set()
15/12/29 16:46:45 INFO DAGScheduler: Missing parents for ResultStage 1: List()
15/12/29 16:46:45 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186), which is now runnable
15/12/29 16:46:45 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11693, maxMem=560002498
15/12/29 16:46:45 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 534.0 MB)
15/12/29 16:46:45 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 37388 ms on localhost (2/2)
15/12/29 16:46:45 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
15/12/29 16:46:45 INFO MemoryStore: ensureFreeSpace(3054) called with curMem=16677, maxMem=560002498
15/12/29 16:46:45 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 534.0 MB)
15/12/29 16:46:45 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:53514 (size: 3.0 KB, free: 534.1 MB)
15/12/29 16:46:45 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
15/12/29 16:46:45 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186)
15/12/29 16:46:45 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
15/12/29 16:46:45 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
15/12/29 16:46:45 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
15/12/29 16:46:45 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
15/12/29 16:46:45 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
15/12/29 16:46:45 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/12/29 16:46:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
15/12/29 16:46:45 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/12/29 16:46:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
15/12/29 16:46:45 INFO PythonRunner: Times: total = 22, boot = -1200, init = 1222, finish = 0
15/12/29 16:46:45 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
15/12/29 16:46:45 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 64 ms on localhost (1/2)
reduceFunction_Parents(): returns= [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:46:45 INFO PythonRunner: Times: total = 214, boot = 213, init = 1, finish = 0
15/12/29 16:46:45 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1360 bytes result sent to driver
15/12/29 16:46:45 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 235 ms on localhost (2/2)
15/12/29 16:46:45 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
15/12/29 16:46:45 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186) finished in 0.237 s
15/12/29 16:46:45 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186, took 37.674182 s
15/12/29 16:46:45 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189
15/12/29 16:46:45 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189) with 2 output partitions
15/12/29 16:46:45 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189)
15/12/29 16:46:45 INFO DAGScheduler: Parents of final stage: List()
15/12/29 16:46:45 INFO DAGScheduler: Missing parents: List()
15/12/29 16:46:45 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189), which has no missing parents
15/12/29 16:46:45 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19731, maxMem=560002498
15/12/29 16:46:45 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 534.0 MB)
15/12/29 16:46:45 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25547, maxMem=560002498
15/12/29 16:46:45 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 534.0 MB)
15/12/29 16:46:45 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:53514 (size: 3.3 KB, free: 534.0 MB)
15/12/29 16:46:45 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
15/12/29 16:46:45 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189)
15/12/29 16:46:45 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
15/12/29 16:46:45 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
15/12/29 16:46:45 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2441 bytes)
15/12/29 16:46:45 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
15/12/29 16:46:45 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
15/12/29 16:46:46 INFO PythonRunner: Times: total = 73, boot = 73, init = 0, finish = 0
15/12/29 16:46:46 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
15/12/29 16:46:46 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 79 ms on localhost (1/2)
15/12/29 16:46:46 INFO PythonRunner: Times: total = 129, boot = 129, init = 0, finish = 0
15/12/29 16:46:46 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1422 bytes result sent to driver
15/12/29 16:46:46 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 142 ms on localhost (2/2)
15/12/29 16:46:46 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
15/12/29 16:46:46 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189) finished in 0.143 s
15/12/29 16:46:46 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189, took 0.175130 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
15/12/29 16:46:46 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
15/12/29 16:46:46 INFO DAGScheduler: Stopping DAGScheduler
15/12/29 16:46:46 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
15/12/29 16:46:46 INFO MemoryStore: MemoryStore cleared
15/12/29 16:46:46 INFO BlockManager: BlockManager stopped
15/12/29 16:46:46 INFO BlockManagerMaster: BlockManagerMaster stopped
15/12/29 16:46:46 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
15/12/29 16:46:46 INFO SparkContext: Successfully stopped SparkContext
15/12/29 16:46:46 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
15/12/29 16:46:46 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
15/12/29 16:46:46 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:46:47 INFO SparkContext: Running Spark version 1.5.2
15/12/29 16:46:47 INFO SecurityManager: Changing view acls to: root
15/12/29 16:46:47 INFO SecurityManager: Changing modify acls to: root
15/12/29 16:46:47 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
15/12/29 16:46:47 INFO Slf4jLogger: Slf4jLogger started
15/12/29 16:46:47 INFO Remoting: Starting remoting
15/12/29 16:46:47 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:47852]
15/12/29 16:46:47 INFO Utils: Successfully started service 'sparkDriver' on port 47852.
15/12/29 16:46:47 INFO SparkEnv: Registering MapOutputTracker
15/12/29 16:46:47 INFO SparkEnv: Registering BlockManagerMaster
15/12/29 16:46:47 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-465e5799-281e-413e-910d-663acc5edd7f
15/12/29 16:46:47 INFO MemoryStore: MemoryStore started with capacity 534.1 MB
15/12/29 16:46:47 INFO HttpFileServer: HTTP File server directory is /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/httpd-182190b0-aeb3-4b14-b151-856aa09b6acc
15/12/29 16:46:47 INFO HttpServer: Starting HTTP Server
15/12/29 16:46:47 INFO Utils: Successfully started service 'HTTP file server' on port 45102.
15/12/29 16:46:47 INFO SparkEnv: Registering OutputCommitCoordinator
15/12/29 16:46:47 INFO Utils: Successfully started service 'SparkUI' on port 4040.
15/12/29 16:46:47 INFO SparkUI: Started SparkUI at http://localhost:4040
15/12/29 16:46:47 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/userFiles-fccd9f50-757c-4a3a-b840-dd1dcf0ad819/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
15/12/29 16:46:47 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1451387807894
15/12/29 16:46:47 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
15/12/29 16:46:47 INFO Executor: Starting executor ID driver on host localhost
15/12/29 16:46:47 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33107.
15/12/29 16:46:47 INFO NettyBlockTransferService: Server created on 33107
15/12/29 16:46:47 INFO BlockManagerMaster: Trying to register BlockManager
15/12/29 16:46:47 INFO BlockManagerMasterEndpoint: Registering block manager localhost:33107 with 534.1 MB RAM, BlockManagerId(driver, localhost, 33107)
15/12/29 16:46:47 INFO BlockManagerMaster: Registered BlockManager
15/12/29 16:46:48 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186
15/12/29 16:46:48 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184)
15/12/29 16:46:48 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186) with 2 output partitions
15/12/29 16:46:48 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186)
15/12/29 16:46:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
15/12/29 16:46:48 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
15/12/29 16:46:48 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184), which has no missing parents
15/12/29 16:46:48 INFO MemoryStore: ensureFreeSpace(7120) called with curMem=0, maxMem=560002498
15/12/29 16:46:48 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 7.0 KB, free 534.1 MB)
15/12/29 16:46:48 INFO MemoryStore: ensureFreeSpace(4573) called with curMem=7120, maxMem=560002498
15/12/29 16:46:48 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.5 KB, free 534.0 MB)
15/12/29 16:46:48 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:33107 (size: 4.5 KB, free: 534.1 MB)
15/12/29 16:46:48 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
15/12/29 16:46:48 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184)
15/12/29 16:46:48 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
15/12/29 16:46:48 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2401 bytes)
15/12/29 16:46:48 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2424 bytes)
15/12/29 16:46:48 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
15/12/29 16:46:48 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1451387807894
15/12/29 16:46:48 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
15/12/29 16:46:48 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/userFiles-fccd9f50-757c-4a3a-b840-dd1dcf0ad819/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
*** Introductory Examples for the NLTK Book ***
Loading text1, ..., text9 and sent1, ..., sent9
Type the name of the text or sentence to view it.
Type: 'texts()' or 'sents()' to list the materials.
*** Introductory Examples for the NLTK Book ***
Loading text1, ..., text9 and sent1, ..., sent9
Type the name of the text or sentence to view it.
Type: 'texts()' or 'sents()' to list the materials.
text1: Moby Dick by Herman Melville 1851
text1: Moby Dick by Herman Melville 1851
text2: Sense and Sensibility by Jane Austen 1811
text2: Sense and Sensibility by Jane Austen 1811
text3: The Book of Genesis
text3: The Book of Genesis
text4: Inaugural Address Corpus
text4: Inaugural Address Corpus
text5: Chat Corpus
text6: Monty Python and the Holy Grail
text5: Chat Corpus
text6: Monty Python and the Holy Grail
text7: Wall Street Journal
text8: Personals Corpus
text7: Wall Street Journal
text8: Personals Corpus
text9: The Man Who Was Thursday by G . K . Chesterton 1908
mapFunction_Parents(): keyword =  locomotive ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
text9: The Man Who Was Thursday by G . K . Chesterton 1908
mapFunction_Parents(): keyword =  provided ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  railway ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  powered ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  car ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  electricity ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  cars ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  drawn ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'coupled']
reduceFunction_Parents(): returns= [u'coupled']
mapFunction_Parents(): keyword =  coupled ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  line ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'coupled']
mapFunction_Parents(): keyword =  together ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'railway']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway']
mapFunction_Parents(): keyword =  public ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'coupled']
15/12/29 16:47:35 INFO PythonRunner: Times: total = 47290, boot = 462, init = 35980, finish = 10848
15/12/29 16:47:35 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
15/12/29 16:47:35 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 47386 ms on localhost (1/2)
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway']
mapFunction_Parents(): keyword =  transport ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'line', u'transport']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:47:35 INFO PythonRunner: Times: total = 47646, boot = 464, init = 35787, finish = 11395
15/12/29 16:47:35 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
15/12/29 16:47:35 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184) finished in 47.729 s
15/12/29 16:47:35 INFO DAGScheduler: looking for newly runnable stages
15/12/29 16:47:35 INFO DAGScheduler: running: Set()
15/12/29 16:47:35 INFO DAGScheduler: waiting: Set(ResultStage 1)
15/12/29 16:47:35 INFO DAGScheduler: failed: Set()
15/12/29 16:47:35 INFO DAGScheduler: Missing parents for ResultStage 1: List()
15/12/29 16:47:35 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186), which is now runnable
15/12/29 16:47:35 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11693, maxMem=560002498
15/12/29 16:47:35 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 534.0 MB)
15/12/29 16:47:35 INFO MemoryStore: ensureFreeSpace(3054) called with curMem=16677, maxMem=560002498
15/12/29 16:47:35 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 534.0 MB)
15/12/29 16:47:35 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 47731 ms on localhost (2/2)
15/12/29 16:47:35 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
15/12/29 16:47:35 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:33107 (size: 3.0 KB, free: 534.1 MB)
15/12/29 16:47:35 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
15/12/29 16:47:35 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186)
15/12/29 16:47:35 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
15/12/29 16:47:35 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
15/12/29 16:47:35 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
15/12/29 16:47:35 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
15/12/29 16:47:35 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
15/12/29 16:47:35 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/12/29 16:47:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
15/12/29 16:47:35 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/12/29 16:47:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
reduceFunction_Parents(): returns= [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:47:36 INFO PythonRunner: Times: total = 202, boot = 195, init = 1, finish = 6
15/12/29 16:47:36 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1360 bytes result sent to driver
15/12/29 16:47:36 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 231 ms on localhost (1/2)
15/12/29 16:47:36 INFO PythonRunner: Times: total = 409, boot = 408, init = 1, finish = 0
15/12/29 16:47:36 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
15/12/29 16:47:36 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186) finished in 0.430 s
15/12/29 16:47:36 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186, took 48.213019 s
15/12/29 16:47:36 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 440 ms on localhost (2/2)
15/12/29 16:47:36 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
15/12/29 16:47:36 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189
15/12/29 16:47:36 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189) with 2 output partitions
15/12/29 16:47:36 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189)
15/12/29 16:47:36 INFO DAGScheduler: Parents of final stage: List()
15/12/29 16:47:36 INFO DAGScheduler: Missing parents: List()
15/12/29 16:47:36 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189), which has no missing parents
15/12/29 16:47:36 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19731, maxMem=560002498
15/12/29 16:47:36 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 534.0 MB)
15/12/29 16:47:36 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25547, maxMem=560002498
15/12/29 16:47:36 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 534.0 MB)
15/12/29 16:47:36 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:33107 (size: 3.3 KB, free: 534.0 MB)
15/12/29 16:47:36 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
15/12/29 16:47:36 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189)
15/12/29 16:47:36 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
15/12/29 16:47:36 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
15/12/29 16:47:36 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2441 bytes)
15/12/29 16:47:36 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
15/12/29 16:47:36 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
15/12/29 16:47:36 INFO PythonRunner: Times: total = 119, boot = 119, init = 0, finish = 0
15/12/29 16:47:36 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
15/12/29 16:47:36 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 129 ms on localhost (1/2)
15/12/29 16:47:36 INFO PythonRunner: Times: total = 476, boot = 476, init = 0, finish = 0
15/12/29 16:47:36 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1422 bytes result sent to driver
15/12/29 16:47:36 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 488 ms on localhost (2/2)
15/12/29 16:47:36 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
15/12/29 16:47:36 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189) finished in 0.490 s
15/12/29 16:47:36 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189, took 0.508206 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
15/12/29 16:47:37 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
15/12/29 16:47:37 INFO DAGScheduler: Stopping DAGScheduler
15/12/29 16:47:37 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
15/12/29 16:47:37 INFO MemoryStore: MemoryStore cleared
15/12/29 16:47:37 INFO BlockManager: BlockManager stopped
15/12/29 16:47:37 INFO BlockManagerMaster: BlockManagerMaster stopped
15/12/29 16:47:37 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
15/12/29 16:47:37 INFO SparkContext: Successfully stopped SparkContext
15/12/29 16:47:37 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
15/12/29 16:47:37 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:47:38 INFO SparkContext: Running Spark version 1.5.2
15/12/29 16:47:38 INFO SecurityManager: Changing view acls to: root
15/12/29 16:47:38 INFO SecurityManager: Changing modify acls to: root
15/12/29 16:47:38 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
15/12/29 16:47:38 INFO Slf4jLogger: Slf4jLogger started
15/12/29 16:47:38 INFO Remoting: Starting remoting
15/12/29 16:47:38 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:45625]
15/12/29 16:47:38 INFO Utils: Successfully started service 'sparkDriver' on port 45625.
15/12/29 16:47:38 INFO SparkEnv: Registering MapOutputTracker
15/12/29 16:47:38 INFO SparkEnv: Registering BlockManagerMaster
15/12/29 16:47:38 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-cab10b42-47a1-453c-a483-5eb3b3c639b5
15/12/29 16:47:38 INFO MemoryStore: MemoryStore started with capacity 534.1 MB
15/12/29 16:47:38 INFO HttpFileServer: HTTP File server directory is /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/httpd-bd69e796-2f72-4605-9dc8-968bf1c54560
15/12/29 16:47:38 INFO HttpServer: Starting HTTP Server
15/12/29 16:47:38 INFO Utils: Successfully started service 'HTTP file server' on port 43021.
15/12/29 16:47:38 INFO SparkEnv: Registering OutputCommitCoordinator
15/12/29 16:47:38 INFO Utils: Successfully started service 'SparkUI' on port 4040.
15/12/29 16:47:38 INFO SparkUI: Started SparkUI at http://localhost:4040
15/12/29 16:47:39 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/userFiles-bdf17935-e183-4d84-b963-867d015cd98c/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
15/12/29 16:47:39 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1451387859009
15/12/29 16:47:39 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
15/12/29 16:47:39 INFO Executor: Starting executor ID driver on host localhost
15/12/29 16:47:39 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45554.
15/12/29 16:47:39 INFO NettyBlockTransferService: Server created on 45554
15/12/29 16:47:39 INFO BlockManagerMaster: Trying to register BlockManager
15/12/29 16:47:39 INFO BlockManagerMasterEndpoint: Registering block manager localhost:45554 with 534.1 MB RAM, BlockManagerId(driver, localhost, 45554)
15/12/29 16:47:39 INFO BlockManagerMaster: Registered BlockManager
15/12/29 16:47:39 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186
15/12/29 16:47:39 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184)
15/12/29 16:47:39 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186) with 2 output partitions
15/12/29 16:47:39 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186)
15/12/29 16:47:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
15/12/29 16:47:39 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
15/12/29 16:47:39 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184), which has no missing parents
15/12/29 16:47:39 INFO MemoryStore: ensureFreeSpace(7120) called with curMem=0, maxMem=560002498
15/12/29 16:47:39 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 7.0 KB, free 534.1 MB)
15/12/29 16:47:39 INFO MemoryStore: ensureFreeSpace(4573) called with curMem=7120, maxMem=560002498
15/12/29 16:47:39 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.5 KB, free 534.0 MB)
15/12/29 16:47:39 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:45554 (size: 4.5 KB, free: 534.1 MB)
15/12/29 16:47:39 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
15/12/29 16:47:39 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184)
15/12/29 16:47:39 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
15/12/29 16:47:39 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2401 bytes)
15/12/29 16:47:39 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2424 bytes)
15/12/29 16:47:39 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
15/12/29 16:47:39 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1451387859009
15/12/29 16:47:39 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
15/12/29 16:47:39 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/userFiles-bdf17935-e183-4d84-b963-867d015cd98c/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
*** Introductory Examples for the NLTK Book ***
Loading text1, ..., text9 and sent1, ..., sent9
Type the name of the text or sentence to view it.
Type: 'texts()' or 'sents()' to list the materials.
*** Introductory Examples for the NLTK Book ***
Loading text1, ..., text9 and sent1, ..., sent9
Type the name of the text or sentence to view it.
Type: 'texts()' or 'sents()' to list the materials.
text1: Moby Dick by Herman Melville 1851
text1: Moby Dick by Herman Melville 1851
text2: Sense and Sensibility by Jane Austen 1811
text2: Sense and Sensibility by Jane Austen 1811
text3: The Book of Genesis
text3: The Book of Genesis
text4: Inaugural Address Corpus
text4: Inaugural Address Corpus
text5: Chat Corpus
text6: Monty Python and the Holy Grail
text5: Chat Corpus
text6: Monty Python and the Holy Grail
text7: Wall Street Journal
text8: Personals Corpus
text7: Wall Street Journal
text8: Personals Corpus
text9: The Man Who Was Thursday by G . K . Chesterton 1908
mapFunction_Parents(): keyword =  provided ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
text9: The Man Who Was Thursday by G . K . Chesterton 1908
mapFunction_Parents(): keyword =  locomotive ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  railway ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  car ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  drawn ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car']
mapFunction_Parents(): keyword =  line ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'railway']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway']
mapFunction_Parents(): keyword =  public ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway']
mapFunction_Parents(): keyword =  transport ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  powered ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'line', u'transport']
reduceFunction_Parents(): returns= [u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:48:22 INFO PythonRunner: Times: total = 43390, boot = 546, init = 33411, finish = 9433
15/12/29 16:48:22 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
15/12/29 16:48:22 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 43512 ms on localhost (1/2)
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  electricity ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
mapFunction_Parents(): keyword =  cars ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= [u'coupled']
reduceFunction_Parents(): returns= [u'coupled']
mapFunction_Parents(): keyword =  coupled ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'coupled']
mapFunction_Parents(): keyword =  together ;prevleveltokens: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'coupled']
15/12/29 16:48:23 INFO PythonRunner: Times: total = 43875, boot = 550, init = 33046, finish = 10279
15/12/29 16:48:23 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
15/12/29 16:48:23 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:184) finished in 43.991 s
15/12/29 16:48:23 INFO DAGScheduler: looking for newly runnable stages
15/12/29 16:48:23 INFO DAGScheduler: running: Set()
15/12/29 16:48:23 INFO DAGScheduler: waiting: Set(ResultStage 1)
15/12/29 16:48:23 INFO DAGScheduler: failed: Set()
15/12/29 16:48:23 INFO DAGScheduler: Missing parents for ResultStage 1: List()
15/12/29 16:48:23 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186), which is now runnable
15/12/29 16:48:23 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11693, maxMem=560002498
15/12/29 16:48:23 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 534.0 MB)
15/12/29 16:48:23 INFO MemoryStore: ensureFreeSpace(3054) called with curMem=16677, maxMem=560002498
15/12/29 16:48:23 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 534.0 MB)
15/12/29 16:48:23 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 43999 ms on localhost (2/2)
15/12/29 16:48:23 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
15/12/29 16:48:23 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:45554 (size: 3.0 KB, free: 534.1 MB)
15/12/29 16:48:23 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
15/12/29 16:48:23 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186)
15/12/29 16:48:23 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
15/12/29 16:48:23 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
15/12/29 16:48:23 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
15/12/29 16:48:23 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
15/12/29 16:48:23 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
15/12/29 16:48:23 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/12/29 16:48:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
15/12/29 16:48:23 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/12/29 16:48:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
15/12/29 16:48:23 INFO PythonRunner: Times: total = 40, boot = -266, init = 306, finish = 0
15/12/29 16:48:23 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
15/12/29 16:48:23 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 71 ms on localhost (1/2)
reduceFunction_Parents(): returns= [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
15/12/29 16:48:23 INFO PythonRunner: Times: total = 249, boot = 248, init = 1, finish = 0
15/12/29 16:48:23 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1360 bytes result sent to driver
15/12/29 16:48:23 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186) finished in 0.257 s
15/12/29 16:48:23 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:186, took 44.307233 s
15/12/29 16:48:23 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 273 ms on localhost (2/2)
15/12/29 16:48:23 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
15/12/29 16:48:23 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189
15/12/29 16:48:23 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189) with 2 output partitions
15/12/29 16:48:23 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189)
15/12/29 16:48:23 INFO DAGScheduler: Parents of final stage: List()
15/12/29 16:48:23 INFO DAGScheduler: Missing parents: List()
15/12/29 16:48:23 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189), which has no missing parents
15/12/29 16:48:23 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19731, maxMem=560002498
15/12/29 16:48:23 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 534.0 MB)
15/12/29 16:48:23 INFO MemoryStore: ensureFreeSpace(3375) called with curMem=25547, maxMem=560002498
15/12/29 16:48:23 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 534.0 MB)
15/12/29 16:48:23 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:45554 (size: 3.3 KB, free: 534.0 MB)
15/12/29 16:48:23 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
15/12/29 16:48:23 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189)
15/12/29 16:48:23 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
15/12/29 16:48:23 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
15/12/29 16:48:23 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2441 bytes)
15/12/29 16:48:23 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
15/12/29 16:48:23 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
15/12/29 16:48:23 INFO PythonRunner: Times: total = 59, boot = 2, init = 57, finish = 0
15/12/29 16:48:23 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
15/12/29 16:48:23 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 82 ms on localhost (1/2)
15/12/29 16:48:23 INFO PythonRunner: Times: total = 263, boot = 262, init = 0, finish = 1
15/12/29 16:48:23 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1422 bytes result sent to driver
15/12/29 16:48:23 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 275 ms on localhost (2/2)
15/12/29 16:48:23 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
15/12/29 16:48:23 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189) finished in 0.262 s
15/12/29 16:48:23 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:189, took 0.296167 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
15/12/29 16:48:24 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
15/12/29 16:48:24 INFO DAGScheduler: Stopping DAGScheduler
15/12/29 16:48:24 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
15/12/29 16:48:24 INFO MemoryStore: MemoryStore cleared
15/12/29 16:48:24 INFO BlockManager: BlockManager stopped
15/12/29 16:48:24 INFO BlockManagerMaster: BlockManagerMaster stopped
15/12/29 16:48:24 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
15/12/29 16:48:24 INFO SparkContext: Successfully stopped SparkContext
15/12/29 16:48:24 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
15/12/29 16:48:24 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
15/12/29 16:48:24 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']
InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:freqterms1= [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
15/12/29 16:48:24 INFO SparkContext: Running Spark version 1.5.2
15/12/29 16:48:24 INFO SecurityManager: Changing view acls to: root
15/12/29 16:48:24 INFO SecurityManager: Changing modify acls to: root
15/12/29 16:48:24 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
15/12/29 16:48:24 INFO Slf4jLogger: Slf4jLogger started
15/12/29 16:48:24 INFO Remoting: Starting remoting
15/12/29 16:48:25 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:55910]
15/12/29 16:48:25 INFO Utils: Successfully started service 'sparkDriver' on port 55910.
15/12/29 16:48:25 INFO SparkEnv: Registering MapOutputTracker
15/12/29 16:48:25 INFO SparkEnv: Registering BlockManagerMaster
15/12/29 16:48:25 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-69e5278d-f1f2-4d1a-a6ca-34bdf0e01b27
15/12/29 16:48:25 INFO MemoryStore: MemoryStore started with capacity 534.1 MB
15/12/29 16:48:25 INFO HttpFileServer: HTTP File server directory is /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/httpd-f117d503-fa22-4fc3-86ad-07d995690daf
15/12/29 16:48:25 INFO HttpServer: Starting HTTP Server
15/12/29 16:48:25 INFO Utils: Successfully started service 'HTTP file server' on port 42270.
15/12/29 16:48:25 INFO SparkEnv: Registering OutputCommitCoordinator
15/12/29 16:48:26 INFO Utils: Successfully started service 'SparkUI' on port 4040.
15/12/29 16:48:26 INFO SparkUI: Started SparkUI at http://localhost:4040
15/12/29 16:48:26 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/userFiles-27c62543-6450-4e8e-92e7-40152067cb8d/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
15/12/29 16:48:26 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1451387906355
15/12/29 16:48:26 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
15/12/29 16:48:26 INFO Executor: Starting executor ID driver on host localhost
15/12/29 16:48:26 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36530.
15/12/29 16:48:26 INFO NettyBlockTransferService: Server created on 36530
15/12/29 16:48:26 INFO BlockManagerMaster: Trying to register BlockManager
15/12/29 16:48:26 INFO BlockManagerMasterEndpoint: Registering block manager localhost:36530 with 534.1 MB RAM, BlockManagerId(driver, localhost, 36530)
15/12/29 16:48:26 INFO BlockManagerMaster: Registered BlockManager
Spark_MapReduce(): wordsatthislevel: [u'provided', u'powered', u'electricity', u'cars', u'coupled', u'together', u'locomotive', u'railway', u'car', u'drawn', u'line', u'public', u'transport']
15/12/29 16:48:26 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:140
15/12/29 16:48:26 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:132)
15/12/29 16:48:26 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:140) with 2 output partitions
15/12/29 16:48:26 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:140)
15/12/29 16:48:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
15/12/29 16:48:26 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
15/12/29 16:48:26 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:132), which has no missing parents
15/12/29 16:48:26 INFO MemoryStore: ensureFreeSpace(6552) called with curMem=0, maxMem=560002498
15/12/29 16:48:26 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 534.1 MB)
15/12/29 16:48:26 INFO MemoryStore: ensureFreeSpace(4139) called with curMem=6552, maxMem=560002498
15/12/29 16:48:26 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 534.0 MB)
15/12/29 16:48:26 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:36530 (size: 4.0 KB, free: 534.1 MB)
15/12/29 16:48:26 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
15/12/29 16:48:26 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:132)
15/12/29 16:48:26 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
15/12/29 16:48:26 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2401 bytes)
15/12/29 16:48:26 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2424 bytes)
15/12/29 16:48:26 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
15/12/29 16:48:26 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1451387906355
15/12/29 16:48:26 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
15/12/29 16:48:26 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/userFiles-27c62543-6450-4e8e-92e7-40152067cb8d/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
*** Introductory Examples for the NLTK Book ***
Loading text1, ..., text9 and sent1, ..., sent9
Type the name of the text or sentence to view it.
Type: 'texts()' or 'sents()' to list the materials.
*** Introductory Examples for the NLTK Book ***
Loading text1, ..., text9 and sent1, ..., sent9
Type the name of the text or sentence to view it.
Type: 'texts()' or 'sents()' to list the materials.
text1: Moby Dick by Herman Melville 1851
text1: Moby Dick by Herman Melville 1851
text2: Sense and Sensibility by Jane Austen 1811
text2: Sense and Sensibility by Jane Austen 1811
text3: The Book of Genesis
text3: The Book of Genesis
text4: Inaugural Address Corpus
text4: Inaugural Address Corpus
text5: Chat Corpus
text6: Monty Python and the Holy Grail
text5: Chat Corpus
text6: Monty Python and the Holy Grail
text7: Wall Street Journal
text8: Personals Corpus
text9: The Man Who Was Thursday by G . K . Chesterton 1908
mapFunction(): freqterms1: locomotive
text7: Wall Street Journal
text8: Personals Corpus
text9: The Man Who Was Thursday by G . K . Chesterton 1908
mapFunction(): freqterms1: provided
mapFunction(): freqterms1: railway
reduceFunction():returns :  rgo_object(tokensatthislevel=[u'engine', u'draw', u'used', u'trains', u'self-propelled', u'wheeled', u'tracks', u'vehicle', u'railway', u'along', u'consisting', u'pull', u'passengers', u'transportation', u'responsible', u'commercial', u'system', u'operating', u'freight', u'trains', u'organization', u'line'])
mapFunction(): freqterms1: car
reduceFunction():returns :  rgo_object(tokensatthislevel=[u'engine', u'draw', u'used', u'trains', u'self-propelled', u'wheeled', u'tracks', u'vehicle', u'railway', u'along', u'consisting', u'pull', u'passengers', u'transportation', u'responsible', u'commercial', u'system', u'operating', u'freight', u'trains', u'organization', u'line', u'engine', u'combustion', u'propelled', u'four', u'internal', u'motor', u'vehicle', u'usually', u'wheels'])
mapFunction(): freqterms1: drawn
reduceFunction():returns :  rgo_object(tokensatthislevel=[u'engine', u'draw', u'used', u'trains', u'self-propelled', u'wheeled', u'tracks', u'vehicle', u'railway', u'along', u'consisting', u'pull', u'passengers', u'transportation', u'responsible', u'commercial', u'system', u'operating', u'freight', u'trains', u'organization', u'line', u'engine', u'combustion', u'propelled', u'four', u'internal', u'motor', u'vehicle', u'usually', u'wheels', u'make', u'lines', u'surface', u'mark'])
mapFunction(): freqterms1: line
reduceFunction():returns :  rgo_object(tokensatthislevel=[u'engine', u'draw', u'used', u'trains', u'self-propelled', u'wheeled', u'tracks', u'vehicle', u'railway', u'along', u'consisting', u'pull', u'passengers', u'transportation', u'responsible', u'commercial', u'system', u'operating', u'freight', u'trains', u'organization', u'line', u'engine', u'combustion', u'propelled', u'four', u'internal', u'motor', u'vehicle', u'usually', u'wheels', u'make', u'lines', u'surface', u'mark', u'people', u'one', u'beside', u'formation', u'another', u'things'])
mapFunction(): freqterms1: public
reduceFunction():returns :  rgo_object(tokensatthislevel=[u'engine', u'draw', u'used', u'trains', u'self-propelled', u'wheeled', u'tracks', u'vehicle', u'railway', u'along', u'consisting', u'pull', u'passengers', u'transportation', u'responsible', u'commercial', u'system', u'operating', u'freight', u'trains', u'organization', u'line', u'engine', u'combustion', u'propelled', u'four', u'internal', u'motor', u'vehicle', u'usually', u'wheels', u'make', u'lines', u'surface', u'mark', u'people', u'one', u'beside', u'formation', u'another', u'things', u'people', u'considered', u'general', u'whole'])
mapFunction(): freqterms1: transport
reduceFunction():returns :  rgo_object(tokensatthislevel=[u'engine', u'draw', u'used', u'trains', u'self-propelled', u'wheeled', u'tracks', u'vehicle', u'railway', u'along', u'consisting', u'pull', u'passengers', u'transportation', u'responsible', u'commercial', u'system', u'operating', u'freight', u'trains', u'organization', u'line', u'engine', u'combustion', u'propelled', u'four', u'internal', u'motor', u'vehicle', u'usually', u'wheels', u'make', u'lines', u'surface', u'mark', u'people', u'one', u'beside', u'formation', u'another', u'things', u'people', u'considered', u'general', u'whole', u'transportation', u'means', u'serves', u'something'])
15/12/29 16:49:07 INFO PythonRunner: Times: total = 40934, boot = 888, init = 31492, finish = 8554
15/12/29 16:49:07 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
15/12/29 16:49:07 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 41026 ms on localhost (1/2)
mapFunction(): freqterms1: powered
reduceFunction():returns :  rgo_object(tokensatthislevel=[u'necessary', u'give', u'something', u'useful', u'force', u'power', u'supply', u'functioning'])
mapFunction(): freqterms1: electricity
reduceFunction():returns :  rgo_object(tokensatthislevel=[u'necessary', u'give', u'something', u'useful', u'force', u'power', u'supply', u'functioning', u'associated', u'phenomenon', u'stationary', u'protons', u'moving', u'electrons', u'physical'])
mapFunction(): freqterms1: cars
reduceFunction():returns :  rgo_object(tokensatthislevel=[u'necessary', u'give', u'something', u'useful', u'force', u'power', u'supply', u'functioning', u'associated', u'phenomenon', u'stationary', u'protons', u'moving', u'electrons', u'physical', u'engine', u'combustion', u'propelled', u'four', u'internal', u'motor', u'vehicle', u'usually', u'wheels'])
mapFunction(): freqterms1: coupled
reduceFunction():returns :  rgo_object(tokensatthislevel=[u'necessary', u'give', u'something', u'useful', u'force', u'power', u'supply', u'functioning', u'associated', u'phenomenon', u'stationary', u'protons', u'moving', u'electrons', u'physical', u'engine', u'combustion', u'propelled', u'four', u'internal', u'motor', u'vehicle', u'usually', u'wheels', u'people', u'ideas', u'together', u'two', u'bring', u'objects'])
mapFunction(): freqterms1: together
reduceFunction():returns :  rgo_object(tokensatthislevel=[u'necessary', u'give', u'something', u'useful', u'force', u'power', u'supply', u'functioning', u'associated', u'phenomenon', u'stationary', u'protons', u'moving', u'electrons', u'physical', u'engine', u'combustion', u'propelled', u'four', u'internal', u'motor', u'vehicle', u'usually', u'wheels', u'people', u'ideas', u'together', u'two', u'bring', u'objects', u'emotionally', u'mentally', u'stable'])
15/12/29 16:49:08 INFO PythonRunner: Times: total = 41494, boot = 892, init = 32345, finish = 8257
15/12/29 16:49:08 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
15/12/29 16:49:08 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 41562 ms on localhost (2/2)
15/12/29 16:49:08 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:132) finished in 41.566 s
15/12/29 16:49:08 INFO DAGScheduler: looking for newly runnable stages
15/12/29 16:49:08 INFO DAGScheduler: running: Set()
15/12/29 16:49:08 INFO DAGScheduler: waiting: Set(ResultStage 1)
15/12/29 16:49:08 INFO DAGScheduler: failed: Set()
15/12/29 16:49:08 INFO DAGScheduler: Missing parents for ResultStage 1: List()
15/12/29 16:49:08 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:140), which is now runnable
15/12/29 16:49:08 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
15/12/29 16:49:08 INFO MemoryStore: ensureFreeSpace(4976) called with curMem=10691, maxMem=560002498
15/12/29 16:49:08 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 534.0 MB)
15/12/29 16:49:08 INFO MemoryStore: ensureFreeSpace(3046) called with curMem=15667, maxMem=560002498
15/12/29 16:49:08 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 534.0 MB)
15/12/29 16:49:08 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:36530 (size: 3.0 KB, free: 534.1 MB)
15/12/29 16:49:08 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
15/12/29 16:49:08 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:140)
15/12/29 16:49:08 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
15/12/29 16:49:08 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
15/12/29 16:49:08 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
15/12/29 16:49:08 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
15/12/29 16:49:08 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
15/12/29 16:49:08 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/12/29 16:49:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
15/12/29 16:49:08 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/12/29 16:49:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
reduceFunction():returns :  rgo_object(tokensatthislevel=[u'necessary', u'give', u'something', u'useful', u'force', u'power', u'supply', u'functioning', u'associated', u'phenomenon', u'stationary', u'protons', u'moving', u'electrons', u'physical', u'engine', u'combustion', u'propelled', u'four', u'internal', u'motor', u'vehicle', u'usually', u'wheels', u'people', u'ideas', u'together', u'two', u'bring', u'objects', u'emotionally', u'mentally', u'stable', u'engine', u'draw', u'used', u'trains', u'self-propelled', u'wheeled', u'tracks', u'vehicle', u'railway', u'along', u'consisting', u'pull', u'passengers', u'transportation', u'responsible', u'commercial', u'system', u'operating', u'freight', u'trains', u'organization', u'line', u'engine', u'combustion', u'propelled', u'four', u'internal', u'motor', u'vehicle', u'usually', u'wheels', u'make', u'lines', u'surface', u'mark', u'people', u'one', u'beside', u'formation', u'another', u'things', u'people', u'considered', u'general', u'whole', u'transportation', u'means', u'serves', u'something'])
15/12/29 16:49:08 INFO PythonRunner: Times: total = 35, boot = -336, init = 369, finish = 2
15/12/29 16:49:08 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 2494 bytes result sent to driver
15/12/29 16:49:08 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 77 ms on localhost (1/2)
15/12/29 16:49:08 INFO PythonRunner: Times: total = 427, boot = 426, init = 1, finish = 0
15/12/29 16:49:08 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
15/12/29 16:49:08 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 458 ms on localhost (2/2)
15/12/29 16:49:08 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
15/12/29 16:49:08 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:140) finished in 0.437 s
15/12/29 16:49:08 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:140, took 42.051440 s
15/12/29 16:49:08 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:143
15/12/29 16:49:08 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:143) with 2 output partitions
15/12/29 16:49:08 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:143)
15/12/29 16:49:08 INFO DAGScheduler: Parents of final stage: List()
15/12/29 16:49:08 INFO DAGScheduler: Missing parents: List()
15/12/29 16:49:08 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:143), which has no missing parents
15/12/29 16:49:08 INFO MemoryStore: ensureFreeSpace(5872) called with curMem=18713, maxMem=560002498
15/12/29 16:49:08 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 534.0 MB)
15/12/29 16:49:08 INFO MemoryStore: ensureFreeSpace(3417) called with curMem=24585, maxMem=560002498
15/12/29 16:49:08 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 534.0 MB)
15/12/29 16:49:08 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:36530 (size: 3.3 KB, free: 534.0 MB)
15/12/29 16:49:08 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
15/12/29 16:49:08 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:143)
15/12/29 16:49:08 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
15/12/29 16:49:08 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
15/12/29 16:49:08 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 3495 bytes)
15/12/29 16:49:08 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
15/12/29 16:49:08 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
15/12/29 16:49:08 INFO PythonRunner: Times: total = 49, boot = -240, init = 289, finish = 0
15/12/29 16:49:08 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
15/12/29 16:49:08 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 60 ms on localhost (1/2)
15/12/29 16:49:08 INFO PythonRunner: Times: total = 141, boot = 141, init = 0, finish = 0
15/12/29 16:49:08 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 2796 bytes result sent to driver
15/12/29 16:49:08 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 154 ms on localhost (2/2)
15/12/29 16:49:08 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
15/12/29 16:49:08 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:143) finished in 0.150 s
15/12/29 16:49:08 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:143, took 0.189305 s
Spark_MapReduce() - SparkSQL DataFrame query results:
Row(tokensatthislevel=[u'necessary', u'give', u'something', u'useful', u'force', u'power', u'supply', u'functioning', u'associated', u'phenomenon', u'stationary', u'protons', u'moving', u'electrons', u'physical', u'engine', u'combustion', u'propelled', u'four', u'internal', u'motor', u'vehicle', u'usually', u'wheels', u'people', u'ideas', u'together', u'two', u'bring', u'objects', u'emotionally', u'mentally', u'stable', u'engine', u'draw', u'used', u'trains', u'self-propelled', u'wheeled', u'tracks', u'vehicle', u'railway', u'along', u'consisting', u'pull', u'passengers', u'transportation', u'responsible', u'commercial', u'system', u'operating', u'freight', u'trains', u'organization', u'line', u'engine', u'combustion', u'propelled', u'four', u'internal', u'motor', u'vehicle', u'usually', u'wheels', u'make', u'lines', u'surface', u'mark', u'people', u'one', u'beside', u'formation', u'another', u'things', u'people', u'considered', u'general', u'whole', u'transportation', u'means', u'serves', u'something'])
15/12/29 16:49:09 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
15/12/29 16:49:09 INFO DAGScheduler: Stopping DAGScheduler
15/12/29 16:49:09 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
15/12/29 16:49:09 INFO MemoryStore: MemoryStore cleared
15/12/29 16:49:09 INFO BlockManager: BlockManager stopped
15/12/29 16:49:09 INFO BlockManagerMaster: BlockManagerMaster stopped
15/12/29 16:49:09 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
15/12/29 16:49:09 INFO SparkContext: Successfully stopped SparkContext
15/12/29 16:49:09 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
15/12/29 16:49:09 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
15/12/29 16:49:09 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:tokensofthislevel: [u'necessary', u'give', u'something', u'useful', u'force', u'power', u'supply', u'functioning', u'associated', u'phenomenon', u'stationary', u'protons', u'moving', u'electrons', u'physical', u'engine', u'combustion', u'propelled', u'four', u'internal', u'motor', u'vehicle', u'usually', u'wheels', u'people', u'ideas', u'together', u'two', u'bring', u'objects', u'emotionally', u'mentally', u'stable', u'engine', u'draw', u'used', u'trains', u'self-propelled', u'wheeled', u'tracks', u'vehicle', u'railway', u'along', u'consisting', u'pull', u'passengers', u'transportation', u'responsible', u'commercial', u'system', u'operating', u'freight', u'trains', u'organization', u'line', u'engine', u'combustion', u'propelled', u'four', u'internal', u'motor', u'vehicle', u'usually', u'wheels', u'make', u'lines', u'surface', u'mark', u'people', u'one', u'beside', u'formation', u'another', u'things', u'people', u'considered', u'general', u'whole', u'transportation', u'means', u'serves', u'something']
prevlevelsynsets: [Synset('locomotive.n.01'), Synset('railway.n.01'), Synset('car.n.01'), Synset('trace.n.01'), Synset('line.n.01'), Synset('populace.n.01'), Synset('conveyance.n.01'), Synset('supply.n.01'), Synset('power.n.01'), Synset('electricity.n.01'), Synset('car.n.01'), Synset('match.n.01'), Synset('together.s.01')]
defaultdict(<type 'list'>, {u'provided': [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport'], u'coupled': [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport'], u'electricity': [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport'], u'cars': [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport'], u'powered': [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport'], u'line': [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport'], u'together': [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport'], u'public': [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport'], u'car': [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport'], u'drawn': [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport'], u'railway': [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport'], u'locomotive': [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport'], u'transport': [u'coupled', u'cars', u'coupled', u'locomotive', u'car', u'railway', u'line', u'transport']})
ksynset= Synset('supply.v.01')
lsynset= Synset('match.v.03')
ksynset= Synset('supply.v.01')
lsynset= Synset('car.n.01')
ksynset= Synset('supply.v.01')
lsynset= Synset('match.v.03')
ksynset= Synset('supply.v.01')
lsynset= Synset('locomotive.n.01')
ksynset= Synset('supply.v.01')
lsynset= Synset('car.n.01')
ksynset= Synset('supply.v.01')
lsynset= Synset('railway.n.01')
ksynset= Synset('supply.v.01')
lsynset= Synset('line.n.01')
ksynset= Synset('supply.v.01')
lsynset= Synset('conveyance.n.03')
ksynset= Synset('match.v.03')
lsynset= Synset('match.v.03')
ksynset= Synset('match.v.03')
lsynset= Synset('car.n.01')
ksynset= Synset('match.v.03')
lsynset= Synset('match.v.03')
ksynset= Synset('match.v.03')
lsynset= Synset('locomotive.n.01')
ksynset= Synset('match.v.03')
lsynset= Synset('car.n.01')
ksynset= Synset('match.v.03')
lsynset= Synset('railway.n.01')
ksynset= Synset('match.v.03')
lsynset= Synset('line.n.01')
ksynset= Synset('match.v.03')
lsynset= Synset('conveyance.n.03')
ksynset= Synset('electricity.n.01')
lsynset= Synset('match.v.03')
ksynset= Synset('electricity.n.01')
lsynset= Synset('car.n.01')
ksynset= Synset('electricity.n.01')
lsynset= Synset('match.v.03')
ksynset= Synset('electricity.n.01')
lsynset= Synset('locomotive.n.01')
ksynset= Synset('electricity.n.01')
lsynset= Synset('car.n.01')
ksynset= Synset('electricity.n.01')
lsynset= Synset('railway.n.01')
ksynset= Synset('electricity.n.01')
lsynset= Synset('line.n.01')
ksynset= Synset('electricity.n.01')
lsynset= Synset('conveyance.n.03')
ksynset= Synset('car.n.01')
lsynset= Synset('match.v.03')
ksynset= Synset('car.n.01')
lsynset= Synset('car.n.01')
ksynset= Synset('car.n.01')
lsynset= Synset('match.v.03')
ksynset= Synset('car.n.01')
lsynset= Synset('locomotive.n.01')
ksynset= Synset('car.n.01')
lsynset= Synset('car.n.01')
ksynset= Synset('car.n.01')
lsynset= Synset('railway.n.01')
ksynset= Synset('car.n.01')
lsynset= Synset('line.n.01')
ksynset= Synset('car.n.01')
lsynset= Synset('conveyance.n.03')
ksynset= Synset('power.v.01')
lsynset= Synset('match.v.03')
ksynset= Synset('power.v.01')
lsynset= Synset('car.n.01')
ksynset= Synset('power.v.01')
lsynset= Synset('match.v.03')
ksynset= Synset('power.v.01')
lsynset= Synset('locomotive.n.01')
ksynset= Synset('power.v.01')
lsynset= Synset('car.n.01')
ksynset= Synset('power.v.01')
lsynset= Synset('railway.n.01')
ksynset= Synset('power.v.01')
lsynset= Synset('line.n.01')
ksynset= Synset('power.v.01')
lsynset= Synset('conveyance.n.03')
ksynset= Synset('line.n.01')
lsynset= Synset('match.v.03')
ksynset= Synset('line.n.01')
lsynset= Synset('car.n.01')
ksynset= Synset('line.n.01')
lsynset= Synset('match.v.03')
ksynset= Synset('line.n.01')
lsynset= Synset('locomotive.n.01')
ksynset= Synset('line.n.01')
lsynset= Synset('car.n.01')
ksynset= Synset('line.n.01')
lsynset= Synset('railway.n.01')
ksynset= Synset('line.n.01')
lsynset= Synset('line.n.01')
ksynset= Synset('line.n.01')
lsynset= Synset('conveyance.n.03')
ksynset= Synset('together.s.01')
lsynset= Synset('match.v.03')
ksynset= Synset('together.s.01')
lsynset= Synset('car.n.01')
ksynset= Synset('together.s.01')
lsynset= Synset('match.v.03')
ksynset= Synset('together.s.01')
lsynset= Synset('locomotive.n.01')
ksynset= Synset('together.s.01')
lsynset= Synset('car.n.01')
ksynset= Synset('together.s.01')
lsynset= Synset('railway.n.01')
ksynset= Synset('together.s.01')
lsynset= Synset('line.n.01')
ksynset= Synset('together.s.01')
lsynset= Synset('conveyance.n.03')
ksynset= Synset('populace.n.01')
lsynset= Synset('match.v.03')
ksynset= Synset('populace.n.01')
lsynset= Synset('car.n.01')
ksynset= Synset('populace.n.01')
lsynset= Synset('match.v.03')
ksynset= Synset('populace.n.01')
lsynset= Synset('locomotive.n.01')
ksynset= Synset('populace.n.01')
lsynset= Synset('car.n.01')
ksynset= Synset('populace.n.01')
lsynset= Synset('railway.n.01')
ksynset= Synset('populace.n.01')
lsynset= Synset('line.n.01')
ksynset= Synset('populace.n.01')
lsynset= Synset('conveyance.n.03')
ksynset= Synset('car.n.01')
lsynset= Synset('match.v.03')
ksynset= Synset('car.n.01')
lsynset= Synset('car.n.01')
ksynset= Synset('car.n.01')
lsynset= Synset('match.v.03')
ksynset= Synset('car.n.01')
lsynset= Synset('locomotive.n.01')
ksynset= Synset('car.n.01')
lsynset= Synset('car.n.01')
ksynset= Synset('car.n.01')
lsynset= Synset('railway.n.01')
ksynset= Synset('car.n.01')
lsynset= Synset('line.n.01')
ksynset= Synset('car.n.01')
lsynset= Synset('conveyance.n.03')
ksynset= Synset('pull.v.01')
lsynset= Synset('match.v.03')
ksynset= Synset('pull.v.01')
lsynset= Synset('car.n.01')
ksynset= Synset('pull.v.01')
lsynset= Synset('match.v.03')
ksynset= Synset('pull.v.01')
lsynset= Synset('locomotive.n.01')
ksynset= Synset('pull.v.01')
lsynset= Synset('car.n.01')
ksynset= Synset('pull.v.01')
lsynset= Synset('railway.n.01')
ksynset= Synset('pull.v.01')
lsynset= Synset('line.n.01')
ksynset= Synset('pull.v.01')
lsynset= Synset('conveyance.n.03')
ksynset= Synset('railway.n.01')
lsynset= Synset('match.v.03')
ksynset= Synset('railway.n.01')
lsynset= Synset('car.n.01')
ksynset= Synset('railway.n.01')
lsynset= Synset('match.v.03')
ksynset= Synset('railway.n.01')
lsynset= Synset('locomotive.n.01')
ksynset= Synset('railway.n.01')
lsynset= Synset('car.n.01')
ksynset= Synset('railway.n.01')
lsynset= Synset('railway.n.01')
ksynset= Synset('railway.n.01')
lsynset= Synset('line.n.01')
ksynset= Synset('railway.n.01')
lsynset= Synset('conveyance.n.03')
ksynset= Synset('locomotive.n.01')
lsynset= Synset('match.v.03')
ksynset= Synset('locomotive.n.01')
lsynset= Synset('car.n.01')
ksynset= Synset('locomotive.n.01')
lsynset= Synset('match.v.03')
ksynset= Synset('locomotive.n.01')
lsynset= Synset('locomotive.n.01')
ksynset= Synset('locomotive.n.01')
lsynset= Synset('car.n.01')
ksynset= Synset('locomotive.n.01')
lsynset= Synset('railway.n.01')
ksynset= Synset('locomotive.n.01')
lsynset= Synset('line.n.01')
ksynset= Synset('locomotive.n.01')
lsynset= Synset('conveyance.n.03')
ksynset= Synset('conveyance.n.03')
lsynset= Synset('match.v.03')
ksynset= Synset('conveyance.n.03')
lsynset= Synset('car.n.01')
ksynset= Synset('conveyance.n.03')
lsynset= Synset('match.v.03')
ksynset= Synset('conveyance.n.03')
lsynset= Synset('locomotive.n.01')
ksynset= Synset('conveyance.n.03')
lsynset= Synset('car.n.01')
ksynset= Synset('conveyance.n.03')
lsynset= Synset('railway.n.01')
ksynset= Synset('conveyance.n.03')
lsynset= Synset('line.n.01')
ksynset= Synset('conveyance.n.03')
lsynset= Synset('conveyance.n.03')
Core number (sorted) : [(u'cars', 18), (u'coupled', 18), (u'locomotive', 18), (u'railway', 18), (u'car', 18), (u'line', 18), (u'transport', 18), (u'provided', 14), (u'powered', 14), (u'electricity', 14), (u'together', 14), (u'drawn', 14), (u'public', 14)]
=============================================================================================================
Unsupervised Classification based on top percentile Core numbers of the definition graph(subgraph of WordNet)
=============================================================================================================
This document belongs to class: cars ,core number= 18
This document belongs to class: coupled ,core number= 18
This document belongs to class: locomotive ,core number= 18
max_core_number 18
===================================================================
Page Rank of the vertices of RGO Definition Graph
===================================================================
[(u'cars', 0.0933104404304159), (u'coupled', 0.0933104404304159), (u'locomotive', 0.0933104404304159), (u'railway', 0.0933104404304159), (u'car', 0.0933104404304159), (u'line', 0.0933104404304159), (u'transport', 0.0933104404304159), (u'provided', 0.05780448616451471), (u'powered', 0.05780448616451471), (u'electricity', 0.05780448616451471), (u'together', 0.05780448616451471), (u'drawn', 0.05780448616451471), (u'public', 0.05780448616451471)]
==========================================================================================================
Alternative Quantitative Intrinsic Merit  - connectivity of RGO Definition Graph - Mengers Theorem
==========================================================================================================
7
==========================================================================================================
Alternative Quantitative Intrinsic Merit  - Maxflow-Mincut of RGO Definition Graph - Minimum Edge Cut
==========================================================================================================
set([(u'transport', u'provided'), (u'car', u'provided'), (u'line', u'provided'), (u'coupled', u'provided'), (u'locomotive', u'provided'), (u'railway', u'provided'), (u'cars', u'provided')])
==========================================================================================================
Alternative Quantitative Intrinsic Merit  - Maxflow-Mincut of RGO Definition Graph - Stoer-Wagner
==========================================================================================================
15/12/29 16:50:41 INFO ShutdownHookManager: Shutdown hook called
15/12/29 16:50:41 INFO ShutdownHookManager: Deleting directory /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/pyspark-6f9534da-949a-425f-b084-e92a266106bd
15/12/29 16:50:41 INFO ShutdownHookManager: Deleting directory /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/pyspark-98e42a8e-c89c-469a-885b-f030225ca27f
15/12/29 16:50:41 INFO ShutdownHookManager: Deleting directory /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/pyspark-4aedfb61-cc6f-4388-b662-9146242d17e8
15/12/29 16:50:41 INFO ShutdownHookManager: Deleting directory /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/pyspark-dac9a9ed-488d-410f-9a11-8b5f5bdb327c
15/12/29 16:50:41 INFO ShutdownHookManager: Deleting directory /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/pyspark-e1b6d1ae-8ce2-42e3-a566-1a29a6c4d578
15/12/29 16:50:41 INFO ShutdownHookManager: Deleting directory /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/pyspark-18266ef3-02d2-4a90-a646-a2b49b1756fc
15/12/29 16:50:41 INFO ShutdownHookManager: Deleting directory /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/pyspark-1e2fee4a-6407-4ae8-b944-a5e273a1ec41
15/12/29 16:50:41 INFO ShutdownHookManager: Deleting directory /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/pyspark-944986a2-22e6-4f9c-b6a7-cb14dd93d797
15/12/29 16:50:41 INFO ShutdownHookManager: Deleting directory /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/pyspark-b9cbd33f-43ea-4f91-bdfd-8e132a6710f1
15/12/29 16:50:41 INFO ShutdownHookManager: Deleting directory /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/pyspark-d4f77a57-ee50-49d7-8b99-316a996ab961
15/12/29 16:50:41 INFO ShutdownHookManager: Deleting directory /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/pyspark-1fccab45-021c-4153-b0cb-7f129f412c57
15/12/29 16:50:41 INFO ShutdownHookManager: Deleting directory /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/pyspark-b463d253-805e-4018-8507-96053e278f7b
15/12/29 16:50:41 INFO ShutdownHookManager: Deleting directory /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/pyspark-f7c19bd5-7694-469a-8842-ae1da1649110
15/12/29 16:50:41 INFO ShutdownHookManager: Deleting directory /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/pyspark-5b160c87-86fd-4458-9c7a-f7df3faeb95f
15/12/29 16:50:41 INFO ShutdownHookManager: Deleting directory /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/pyspark-a7e58bb6-2dc1-4c51-9638-677a02e682b1
15/12/29 16:50:41 INFO ShutdownHookManager: Deleting directory /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/pyspark-aa04b627-e8c6-4c4c-b019-08b971f258c5
15/12/29 16:50:41 INFO ShutdownHookManager: Deleting directory /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/pyspark-9ab4de24-46c3-4624-a219-f824474d5f8d
15/12/29 16:50:41 INFO ShutdownHookManager: Deleting directory /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/pyspark-c43cc29a-bcc7-4f09-a080-e8c01df5d415
15/12/29 16:50:41 INFO ShutdownHookManager: Deleting directory /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/pyspark-80cd23a9-3a58-441f-bc3d-66832dbc839e
15/12/29 16:50:41 INFO ShutdownHookManager: Deleting directory /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/pyspark-abdf5862-a020-4600-be9a-a0fe4f58ad41
15/12/29 16:50:41 INFO ShutdownHookManager: Deleting directory /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/pyspark-e7dab515-7e37-4668-8f8f-5d17de35eea8
15/12/29 16:50:41 INFO ShutdownHookManager: Deleting directory /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/pyspark-09736129-574f-43e8-9f18-a49feb6d98a4
15/12/29 16:50:41 INFO ShutdownHookManager: Deleting directory /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/pyspark-d7c78daa-312b-491d-974f-8cd84f036de6
15/12/29 16:50:41 INFO ShutdownHookManager: Deleting directory /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8/pyspark-15b05423-c7d0-42fb-ba90-bb82abd9990b
15/12/29 16:50:41 INFO ShutdownHookManager: Deleting directory /tmp/spark-33ac0783-860a-4126-aaa3-93efaeecfbc8
