asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: town
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'urban', u'smaller', u'area', u'is', u'that', u'an', u'city', u'boundary', u'fixed', u'with', u'than'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): curve
mapFunction_Parents(): keyword: curve ; prevleveltokens: state
mapFunction_Parents(): keyword= curve ; syndef_tokens= set([u'a', u'nation', u'of', u'one', u'districts', u'constituent', u'the', u'territory', u'occupied', u'by', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/02/05 17:04:07 INFO PythonRunner: Times: total = 13153, boot = 494, init = 560, finish = 12099
16/02/05 17:04:07 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/02/05 17:04:07 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 13265 ms on localhost (2/2)
16/02/05 17:04:07 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/02/05 17:04:07 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219) finished in 13.283 s
16/02/05 17:04:07 INFO DAGScheduler: looking for newly runnable stages
16/02/05 17:04:07 INFO DAGScheduler: running: Set()
16/02/05 17:04:07 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/02/05 17:04:07 INFO DAGScheduler: failed: Set()
16/02/05 17:04:07 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/02/05 17:04:07 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221), which is now runnable
16/02/05 17:04:07 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10716, maxMem=549244108
16/02/05 17:04:07 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 523.8 MB)
16/02/05 17:04:07 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15700, maxMem=549244108
16/02/05 17:04:07 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 523.8 MB)
16/02/05 17:04:07 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:34568 (size: 3.0 KB, free: 523.8 MB)
16/02/05 17:04:07 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/02/05 17:04:07 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221)
16/02/05 17:04:07 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/02/05 17:04:07 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/02/05 17:04:07 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/02/05 17:04:07 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/02/05 17:04:07 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/02/05 17:04:07 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/02/05 17:04:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/02/05 17:04:07 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/02/05 17:04:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/02/05 17:04:08 INFO PythonRunner: Times: total = 194, boot = 193, init = 1, finish = 0
reduceFunction_Parents(): returns= ['None', u'bend', 'None']
16/02/05 17:04:08 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1280 bytes result sent to driver
16/02/05 17:04:08 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 225 ms on localhost (1/2)
16/02/05 17:04:08 INFO PythonRunner: Times: total = 282, boot = 281, init = 1, finish = 0
16/02/05 17:04:08 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/02/05 17:04:08 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 302 ms on localhost (2/2)
16/02/05 17:04:08 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/02/05 17:04:08 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221) finished in 0.303 s
16/02/05 17:04:08 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221, took 13.938870 s
16/02/05 17:04:08 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224
16/02/05 17:04:08 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224) with 2 output partitions
16/02/05 17:04:08 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224)
16/02/05 17:04:08 INFO DAGScheduler: Parents of final stage: List()
16/02/05 17:04:08 INFO DAGScheduler: Missing parents: List()
16/02/05 17:04:08 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224), which has no missing parents
16/02/05 17:04:08 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18756, maxMem=549244108
16/02/05 17:04:08 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 523.8 MB)
16/02/05 17:04:08 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24572, maxMem=549244108
16/02/05 17:04:08 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 523.8 MB)
16/02/05 17:04:08 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:34568 (size: 3.3 KB, free: 523.8 MB)
16/02/05 17:04:08 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/02/05 17:04:08 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224)
16/02/05 17:04:08 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/02/05 17:04:08 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/02/05 17:04:08 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2361 bytes)
16/02/05 17:04:08 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/02/05 17:04:08 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/02/05 17:04:08 INFO PythonRunner: Times: total = 82, boot = 82, init = 0, finish = 0
16/02/05 17:04:08 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1348 bytes result sent to driver
16/02/05 17:04:08 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 95 ms on localhost (1/2)
16/02/05 17:04:08 INFO PythonRunner: Times: total = 318, boot = 317, init = 1, finish = 0
16/02/05 17:04:08 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/02/05 17:04:08 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 324 ms on localhost (2/2)
16/02/05 17:04:08 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/02/05 17:04:08 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224) finished in 0.304 s
16/02/05 17:04:08 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224, took 0.343502 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/02/05 17:04:08 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/02/05 17:04:08 INFO DAGScheduler: Stopping DAGScheduler
16/02/05 17:04:08 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/02/05 17:04:08 INFO MemoryStore: MemoryStore cleared
16/02/05 17:04:08 INFO BlockManager: BlockManager stopped
16/02/05 17:04:08 INFO BlockManagerMaster: BlockManagerMaster stopped
16/02/05 17:04:08 INFO SparkContext: Successfully stopped SparkContext
16/02/05 17:04:08 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/02/05 17:04:08 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/02/05 17:04:08 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/02/05 17:04:08 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'bend', u'None']
16/02/05 17:04:09 INFO SparkContext: Running Spark version 1.5.2
16/02/05 17:04:09 INFO SecurityManager: Changing view acls to: root
16/02/05 17:04:09 INFO SecurityManager: Changing modify acls to: root
16/02/05 17:04:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/02/05 17:04:09 INFO Slf4jLogger: Slf4jLogger started
16/02/05 17:04:09 INFO Remoting: Starting remoting
16/02/05 17:04:09 INFO Utils: Successfully started service 'sparkDriver' on port 53198.
16/02/05 17:04:09 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:53198]
16/02/05 17:04:09 INFO SparkEnv: Registering MapOutputTracker
16/02/05 17:04:09 INFO SparkEnv: Registering BlockManagerMaster
16/02/05 17:04:09 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-f26ab448-5cec-46f4-a797-f5198bee8e8c
16/02/05 17:04:09 INFO MemoryStore: MemoryStore started with capacity 523.4 MB
16/02/05 17:04:09 INFO HttpFileServer: HTTP File server directory is /tmp/spark-dadd0e29-0794-4c88-9906-5a3b1e594e2c/httpd-0c439722-05e7-46a6-9f8f-93d110b58029
16/02/05 17:04:09 INFO HttpServer: Starting HTTP Server
16/02/05 17:04:09 INFO Utils: Successfully started service 'HTTP file server' on port 47354.
16/02/05 17:04:09 INFO SparkEnv: Registering OutputCommitCoordinator
16/02/05 17:04:10 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/02/05 17:04:10 INFO SparkUI: Started SparkUI at http://localhost:4040
16/02/05 17:04:10 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-dadd0e29-0794-4c88-9906-5a3b1e594e2c/userFiles-ce55197a-0779-458d-8c3d-dc6a45b13fb7/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/02/05 17:04:10 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1454672050057
16/02/05 17:04:10 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/02/05 17:04:10 INFO Executor: Starting executor ID driver on host localhost
16/02/05 17:04:10 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36276.
16/02/05 17:04:10 INFO NettyBlockTransferService: Server created on 36276
16/02/05 17:04:10 INFO BlockManagerMaster: Trying to register BlockManager
16/02/05 17:04:10 INFO BlockManagerMasterEndpoint: Registering block manager localhost:36276 with 523.4 MB RAM, BlockManagerId(driver, localhost, 36276)
16/02/05 17:04:10 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): together
16/02/05 17:04:10 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221
16/02/05 17:04:10 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219)
16/02/05 17:04:10 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221) with 2 output partitions
16/02/05 17:04:10 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221)
16/02/05 17:04:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/02/05 17:04:10 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/02/05 17:04:10 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219), which has no missing parents
16/02/05 17:04:10 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=548819435
16/02/05 17:04:10 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 523.4 MB)
16/02/05 17:04:10 INFO MemoryStore: ensureFreeSpace(4148) called with curMem=6568, maxMem=548819435
16/02/05 17:04:10 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 523.4 MB)
16/02/05 17:04:10 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:36276 (size: 4.1 KB, free: 523.4 MB)
16/02/05 17:04:10 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/02/05 17:04:10 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219)
16/02/05 17:04:10 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/02/05 17:04:10 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2408 bytes)
16/02/05 17:04:10 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2430 bytes)
16/02/05 17:04:10 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/02/05 17:04:10 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1454672050057
16/02/05 17:04:10 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-dadd0e29-0794-4c88-9906-5a3b1e594e2c/userFiles-ce55197a-0779-458d-8c3d-dc6a45b13fb7/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/02/05 17:04:10 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: kilometer
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: area
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: elaborate
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'and', u'idea', u'an', u'as', u'in', u'discourse', u'writing', u'to', u'add', u'details', u'way', u'learned', u',', u'clarify', u'meaning', u';', u'a', u'account', u'of', u'usually', u'the', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: exist
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'be', u',', u'an', u'have', u'existence', u'extant'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: commissariat
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'supply', u'of', u'foods', u'or', u'stock'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: town
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'urban', u'smaller', u'area', u'is', u'that', u'an', u'city', u'boundary', u'fixed', u'with', u'than'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: state
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'nation', u'of', u'one', u'districts', u'constituent', u'the', u'territory', u'occupied', u'by', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/02/05 17:04:22 INFO PythonRunner: Times: total = 12273, boot = 587, init = 785, finish = 10901
16/02/05 17:04:22 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/02/05 17:04:22 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 12397 ms on localhost (1/2)
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: set
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): adding to parents: syn =  Synset('set.n.01') ; keyword:  together  in syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= [u'set']
reduceFunction_Parents(): returns= ['None', u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: bend
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: giant
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: astatine
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: present
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'set']
asfer_pickle_string_load(): picklef.readlines(): together
mapFunction_Parents(): keyword: together ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= together ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'set']
16/02/05 17:04:22 INFO PythonRunner: Times: total = 12534, boot = 576, init = 558, finish = 11400
16/02/05 17:04:22 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/02/05 17:04:22 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219) finished in 12.645 s
16/02/05 17:04:22 INFO DAGScheduler: looking for newly runnable stages
16/02/05 17:04:22 INFO DAGScheduler: running: Set()
16/02/05 17:04:22 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/02/05 17:04:22 INFO DAGScheduler: failed: Set()
16/02/05 17:04:22 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/02/05 17:04:22 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221), which is now runnable
16/02/05 17:04:22 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10716, maxMem=548819435
16/02/05 17:04:22 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 523.4 MB)
16/02/05 17:04:22 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15700, maxMem=548819435
16/02/05 17:04:22 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 523.4 MB)
16/02/05 17:04:22 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:36276 (size: 3.0 KB, free: 523.4 MB)
16/02/05 17:04:22 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/02/05 17:04:22 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221)
16/02/05 17:04:22 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/02/05 17:04:22 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 12637 ms on localhost (2/2)
16/02/05 17:04:22 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/02/05 17:04:22 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/02/05 17:04:22 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/02/05 17:04:22 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/02/05 17:04:22 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/02/05 17:04:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/02/05 17:04:22 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/02/05 17:04:22 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/02/05 17:04:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/02/05 17:04:23 INFO PythonRunner: Times: total = 210, boot = 209, init = 0, finish = 1
16/02/05 17:04:23 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/02/05 17:04:23 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 230 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'set', 'None']
16/02/05 17:04:23 INFO PythonRunner: Times: total = 383, boot = 382, init = 0, finish = 1
16/02/05 17:04:23 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1279 bytes result sent to driver
16/02/05 17:04:23 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 438 ms on localhost (2/2)
16/02/05 17:04:23 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221) finished in 0.412 s
16/02/05 17:04:23 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/02/05 17:04:23 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221, took 13.124302 s
16/02/05 17:04:23 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224
16/02/05 17:04:23 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224) with 2 output partitions
16/02/05 17:04:23 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224)
16/02/05 17:04:23 INFO DAGScheduler: Parents of final stage: List()
16/02/05 17:04:23 INFO DAGScheduler: Missing parents: List()
16/02/05 17:04:23 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224), which has no missing parents
16/02/05 17:04:23 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18756, maxMem=548819435
16/02/05 17:04:23 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 523.4 MB)
16/02/05 17:04:23 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24572, maxMem=548819435
16/02/05 17:04:23 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 523.4 MB)
16/02/05 17:04:23 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:36276 (size: 3.3 KB, free: 523.4 MB)
16/02/05 17:04:23 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/02/05 17:04:23 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224)
16/02/05 17:04:23 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/02/05 17:04:23 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/02/05 17:04:23 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2360 bytes)
16/02/05 17:04:23 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/02/05 17:04:23 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/02/05 17:04:23 INFO PythonRunner: Times: total = 62, boot = -29, init = 91, finish = 0
16/02/05 17:04:23 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/02/05 17:04:23 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 155 ms on localhost (1/2)
16/02/05 17:04:23 INFO PythonRunner: Times: total = 308, boot = 308, init = 0, finish = 0
16/02/05 17:04:23 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1347 bytes result sent to driver
16/02/05 17:04:23 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 327 ms on localhost (2/2)
16/02/05 17:04:23 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/02/05 17:04:23 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224) finished in 0.309 s
16/02/05 17:04:23 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224, took 0.348948 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/02/05 17:04:24 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/02/05 17:04:24 INFO DAGScheduler: Stopping DAGScheduler
16/02/05 17:04:24 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/02/05 17:04:24 INFO MemoryStore: MemoryStore cleared
16/02/05 17:04:24 INFO BlockManager: BlockManager stopped
16/02/05 17:04:24 INFO BlockManagerMaster: BlockManagerMaster stopped
16/02/05 17:04:24 INFO SparkContext: Successfully stopped SparkContext
16/02/05 17:04:24 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/02/05 17:04:24 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/02/05 17:04:24 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/02/05 17:04:24 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'set', u'None']
16/02/05 17:04:24 INFO SparkContext: Running Spark version 1.5.2
16/02/05 17:04:24 INFO SecurityManager: Changing view acls to: root
16/02/05 17:04:24 INFO SecurityManager: Changing modify acls to: root
16/02/05 17:04:24 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/02/05 17:04:24 INFO Slf4jLogger: Slf4jLogger started
16/02/05 17:04:24 INFO Remoting: Starting remoting
16/02/05 17:04:25 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:53710]
16/02/05 17:04:25 INFO Utils: Successfully started service 'sparkDriver' on port 53710.
16/02/05 17:04:25 INFO SparkEnv: Registering MapOutputTracker
16/02/05 17:04:25 INFO SparkEnv: Registering BlockManagerMaster
16/02/05 17:04:25 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-f70b3d5a-781f-4478-848b-a2e520cc1341
16/02/05 17:04:25 INFO MemoryStore: MemoryStore started with capacity 523.4 MB
16/02/05 17:04:25 INFO HttpFileServer: HTTP File server directory is /tmp/spark-dadd0e29-0794-4c88-9906-5a3b1e594e2c/httpd-ee970683-5cf5-41ca-b7cc-cb396f68752f
16/02/05 17:04:25 INFO HttpServer: Starting HTTP Server
16/02/05 17:04:25 INFO Utils: Successfully started service 'HTTP file server' on port 42504.
16/02/05 17:04:25 INFO SparkEnv: Registering OutputCommitCoordinator
16/02/05 17:04:25 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/02/05 17:04:25 INFO SparkUI: Started SparkUI at http://localhost:4040
16/02/05 17:04:25 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-dadd0e29-0794-4c88-9906-5a3b1e594e2c/userFiles-646fe9d6-2934-42e6-a1e3-1bc5633e7d54/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/02/05 17:04:25 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1454672065340
16/02/05 17:04:25 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/02/05 17:04:25 INFO Executor: Starting executor ID driver on host localhost
16/02/05 17:04:25 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53739.
16/02/05 17:04:25 INFO NettyBlockTransferService: Server created on 53739
16/02/05 17:04:25 INFO BlockManagerMaster: Trying to register BlockManager
16/02/05 17:04:25 INFO BlockManagerMasterEndpoint: Registering block manager localhost:53739 with 523.4 MB RAM, BlockManagerId(driver, localhost, 53739)
16/02/05 17:04:25 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): element
16/02/05 17:04:25 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221
16/02/05 17:04:25 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219)
16/02/05 17:04:25 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221) with 2 output partitions
16/02/05 17:04:25 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221)
16/02/05 17:04:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/02/05 17:04:25 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/02/05 17:04:25 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219), which has no missing parents
16/02/05 17:04:25 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=548819435
16/02/05 17:04:25 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 523.4 MB)
16/02/05 17:04:25 INFO MemoryStore: ensureFreeSpace(4146) called with curMem=6568, maxMem=548819435
16/02/05 17:04:25 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 523.4 MB)
16/02/05 17:04:25 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:53739 (size: 4.0 KB, free: 523.4 MB)
16/02/05 17:04:25 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/02/05 17:04:25 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219)
16/02/05 17:04:25 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/02/05 17:04:25 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2408 bytes)
16/02/05 17:04:25 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2430 bytes)
16/02/05 17:04:25 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/02/05 17:04:25 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1454672065340
16/02/05 17:04:25 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/02/05 17:04:25 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-dadd0e29-0794-4c88-9906-5a3b1e594e2c/userFiles-646fe9d6-2934-42e6-a1e3-1bc5633e7d54/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: metropolitan
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: kilometer

mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: area
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: elaborate
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'and', u'idea', u'an', u'as', u'in', u'discourse', u'writing', u'to', u'add', u'details', u'way', u'learned', u',', u'clarify', u'meaning', u';', u'a', u'account', u'of', u'usually', u'the', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: exist
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'be', u',', u'an', u'have', u'existence', u'extant'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: commissariat
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'supply', u'of', u'foods', u'or', u'stock'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: town
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'urban', u'smaller', u'area', u'is', u'that', u'an', u'city', u'boundary', u'fixed', u'with', u'than'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: state
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'nation', u'of', u'one', u'districts', u'constituent', u'the', u'territory', u'occupied', u'by', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/02/05 17:04:37 INFO PythonRunner: Times: total = 12193, boot = 631, init = 409, finish = 11153
16/02/05 17:04:37 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/02/05 17:04:37 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 12336 ms on localhost (1/2)
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: set
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: bend
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: giant
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: astatine
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('astatine.n.01') ; keyword:  element  in syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= [u'astatine']
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: present
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
asfer_pickle_string_load(): picklef.readlines(): element
mapFunction_Parents(): keyword: element ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= element ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'astatine']
16/02/05 17:04:39 INFO PythonRunner: Times: total = 13228, boot = 615, init = 742, finish = 11871
16/02/05 17:04:39 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/02/05 17:04:39 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 13374 ms on localhost (2/2)
16/02/05 17:04:39 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/02/05 17:04:39 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219) finished in 13.382 s
16/02/05 17:04:39 INFO DAGScheduler: looking for newly runnable stages
16/02/05 17:04:39 INFO DAGScheduler: running: Set()
16/02/05 17:04:39 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/02/05 17:04:39 INFO DAGScheduler: failed: Set()
16/02/05 17:04:39 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/02/05 17:04:39 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221), which is now runnable
16/02/05 17:04:39 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10714, maxMem=548819435
16/02/05 17:04:39 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 523.4 MB)
16/02/05 17:04:39 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15698, maxMem=548819435
16/02/05 17:04:39 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 523.4 MB)
16/02/05 17:04:39 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:53739 (size: 3.0 KB, free: 523.4 MB)
16/02/05 17:04:39 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/02/05 17:04:39 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221)
16/02/05 17:04:39 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/02/05 17:04:39 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/02/05 17:04:39 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/02/05 17:04:39 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/02/05 17:04:39 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/02/05 17:04:39 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/02/05 17:04:39 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/02/05 17:04:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/02/05 17:04:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
reduceFunction_Parents(): returns= ['None', u'astatine', 'None']
16/02/05 17:04:39 INFO PythonRunner: Times: total = 50, boot = -692, init = 741, finish = 1
16/02/05 17:04:39 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1284 bytes result sent to driver
16/02/05 17:04:39 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 72 ms on localhost (1/2)
16/02/05 17:04:39 INFO PythonRunner: Times: total = 359, boot = 359, init = 0, finish = 0
16/02/05 17:04:39 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/02/05 17:04:39 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 382 ms on localhost (2/2)
16/02/05 17:04:39 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221) finished in 0.362 s
16/02/05 17:04:39 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221, took 13.793351 s
16/02/05 17:04:39 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/02/05 17:04:39 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224
16/02/05 17:04:39 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224) with 2 output partitions
16/02/05 17:04:39 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224)
16/02/05 17:04:39 INFO DAGScheduler: Parents of final stage: List()
16/02/05 17:04:39 INFO DAGScheduler: Missing parents: List()
16/02/05 17:04:39 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224), which has no missing parents
16/02/05 17:04:39 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18754, maxMem=548819435
16/02/05 17:04:39 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 523.4 MB)
16/02/05 17:04:39 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24570, maxMem=548819435
16/02/05 17:04:39 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 523.4 MB)
16/02/05 17:04:39 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:53739 (size: 3.3 KB, free: 523.4 MB)
16/02/05 17:04:39 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/02/05 17:04:39 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224)
16/02/05 17:04:39 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/02/05 17:04:39 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/02/05 17:04:39 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2365 bytes)
16/02/05 17:04:39 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/02/05 17:04:39 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/02/05 17:04:39 INFO PythonRunner: Times: total = 54, boot = -227, init = 281, finish = 0
16/02/05 17:04:39 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/02/05 17:04:39 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 67 ms on localhost (1/2)
16/02/05 17:04:39 INFO PythonRunner: Times: total = 156, boot = 155, init = 0, finish = 1
16/02/05 17:04:39 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1352 bytes result sent to driver
16/02/05 17:04:39 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 166 ms on localhost (2/2)
16/02/05 17:04:39 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224) finished in 0.168 s
16/02/05 17:04:39 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/02/05 17:04:39 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224, took 0.181419 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/02/05 17:04:39 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/02/05 17:04:39 INFO DAGScheduler: Stopping DAGScheduler
16/02/05 17:04:39 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/02/05 17:04:39 INFO MemoryStore: MemoryStore cleared
16/02/05 17:04:39 INFO BlockManager: BlockManager stopped
16/02/05 17:04:39 INFO BlockManagerMaster: BlockManagerMaster stopped
16/02/05 17:04:39 INFO SparkContext: Successfully stopped SparkContext
16/02/05 17:04:39 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/02/05 17:04:39 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/02/05 17:04:39 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/02/05 17:04:39 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'astatine', u'None']
16/02/05 17:04:40 INFO SparkContext: Running Spark version 1.5.2
16/02/05 17:04:40 INFO SecurityManager: Changing view acls to: root
16/02/05 17:04:40 INFO SecurityManager: Changing modify acls to: root
16/02/05 17:04:40 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/02/05 17:04:41 INFO Slf4jLogger: Slf4jLogger started
16/02/05 17:04:41 INFO Remoting: Starting remoting
16/02/05 17:04:41 INFO Utils: Successfully started service 'sparkDriver' on port 44093.
16/02/05 17:04:41 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:44093]
16/02/05 17:04:41 INFO SparkEnv: Registering MapOutputTracker
16/02/05 17:04:41 INFO SparkEnv: Registering BlockManagerMaster
16/02/05 17:04:41 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-4be52d5a-0f80-463f-8b3d-b53dcf5e3502
16/02/05 17:04:41 INFO MemoryStore: MemoryStore started with capacity 525.4 MB
16/02/05 17:04:41 INFO HttpFileServer: HTTP File server directory is /tmp/spark-dadd0e29-0794-4c88-9906-5a3b1e594e2c/httpd-b278f51b-d579-4cc8-a0b5-a50458cb02f1
16/02/05 17:04:41 INFO HttpServer: Starting HTTP Server
16/02/05 17:04:41 INFO Utils: Successfully started service 'HTTP file server' on port 45320.
16/02/05 17:04:41 INFO SparkEnv: Registering OutputCommitCoordinator
16/02/05 17:04:41 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/02/05 17:04:41 INFO SparkUI: Started SparkUI at http://localhost:4040
16/02/05 17:04:41 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-dadd0e29-0794-4c88-9906-5a3b1e594e2c/userFiles-b7e56a4c-cd45-4def-88ba-9bc80849d36e/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/02/05 17:04:41 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1454672081438
16/02/05 17:04:41 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/02/05 17:04:41 INFO Executor: Starting executor ID driver on host localhost
16/02/05 17:04:41 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 48702.
16/02/05 17:04:41 INFO NettyBlockTransferService: Server created on 48702
16/02/05 17:04:41 INFO BlockManagerMaster: Trying to register BlockManager
16/02/05 17:04:41 INFO BlockManagerMasterEndpoint: Registering block manager localhost:48702 with 525.4 MB RAM, BlockManagerId(driver, localhost, 48702)
16/02/05 17:04:41 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): person
16/02/05 17:04:41 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221
16/02/05 17:04:41 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219)
16/02/05 17:04:41 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221) with 2 output partitions
16/02/05 17:04:41 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221)
16/02/05 17:04:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/02/05 17:04:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/02/05 17:04:41 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219), which has no missing parents
16/02/05 17:04:41 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=550942801
16/02/05 17:04:41 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 525.4 MB)
16/02/05 17:04:41 INFO MemoryStore: ensureFreeSpace(4148) called with curMem=6568, maxMem=550942801
16/02/05 17:04:41 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 525.4 MB)
16/02/05 17:04:41 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:48702 (size: 4.1 KB, free: 525.4 MB)
16/02/05 17:04:41 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/02/05 17:04:41 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219)
16/02/05 17:04:41 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/02/05 17:04:41 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2408 bytes)
16/02/05 17:04:41 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2430 bytes)
16/02/05 17:04:41 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/02/05 17:04:41 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1454672081438
16/02/05 17:04:41 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/02/05 17:04:41 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-dadd0e29-0794-4c88-9906-5a3b1e594e2c/userFiles-b7e56a4c-cd45-4def-88ba-9bc80849d36e/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: kilometer
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: set
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: area
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: elaborate
mapFunction_Parents(): keyword=mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'and', u'idea', u'an', u'as', u'in', u'discourse', u'writing', u'to', u'add', u'details', u'way', u'learned', u',', u'clarify', u'meaning', u';', u'a', u'account', u'of', u'usually', u'the', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person ; syndef_tokens= set([u'a', u'and',  u'kind'person, 
u'used'mapFunction_Parents(): keyword:, u'group', u'that' , personu'of' , ; prevleveltokens:u'belong' , existu'same', 
u'so'mapFunction_Parents(): keyword=, u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: bend
 person ; syndef_tokens= set([u'be', u',', u'an', u'have', u'existence', u'extant'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: commissariat
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'supply', u'of', u'foods', u'or', u'stock'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: town
mapFunction_Parents(): keyword=mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'urban', u'smaller', u'area', u'is', u'that', u'an', u'city', u'boundary', u'fixed', u'with', u'than'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: state
 person ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: giant
mapFunction_Parents(): keyword=mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'nation', u'of', u'one', u'districts', u'constituent', u'the', u'territory', u'occupied', u'by', u'administrative' ])
personmapFunction_Parents(): returns= ; syndef_tokens=  [set([]
u'a'reduceFunction_Parents(): returns=, u'and', u'exceptional',  u'importance'[, 'u'of'N, ou'person'n, e'u'reputation']])

mapFunction_Parents(): adding to parents: syn =  Synset('colossus.n.02') ; keyword:  person  in syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= [u'giant']
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: astatine
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: present
16/02/05 17:04:51 INFO PythonRunner: Times: total = 10201, boot = 523, init = 673, finish = 9005
16/02/05 17:04:51 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/02/05 17:04:51 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 10288 ms on localhost (1/2)
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): person
mapFunction_Parents(): keyword: person ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= person ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
16/02/05 17:04:52 INFO PythonRunner: Times: total = 10305, boot = 514, init = 483, finish = 9308
16/02/05 17:04:52 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/02/05 17:04:52 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219) finished in 10.398 s
16/02/05 17:04:52 INFO DAGScheduler: looking for newly runnable stages
16/02/05 17:04:52 INFO DAGScheduler: running: Set()
16/02/05 17:04:52 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/02/05 17:04:52 INFO DAGScheduler: failed: Set()
16/02/05 17:04:52 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/02/05 17:04:52 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221), which is now runnable
16/02/05 17:04:52 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10716, maxMem=550942801
16/02/05 17:04:52 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 525.4 MB)
16/02/05 17:04:52 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15700, maxMem=550942801
16/02/05 17:04:52 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 525.4 MB)
16/02/05 17:04:52 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:48702 (size: 3.0 KB, free: 525.4 MB)
16/02/05 17:04:52 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/02/05 17:04:52 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221)
16/02/05 17:04:52 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/02/05 17:04:52 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 10398 ms on localhost (2/2)
16/02/05 17:04:52 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/02/05 17:04:52 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/02/05 17:04:52 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/02/05 17:04:52 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/02/05 17:04:52 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/02/05 17:04:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/02/05 17:04:52 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/02/05 17:04:52 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/02/05 17:04:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/02/05 17:04:52 INFO PythonRunner: Times: total = 182, boot = 182, init = 0, finish = 0
16/02/05 17:04:52 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/02/05 17:04:52 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 202 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'giant', 'None']
16/02/05 17:04:52 INFO PythonRunner: Times: total = 272, boot = 271, init = 0, finish = 1
16/02/05 17:04:52 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1281 bytes result sent to driver
16/02/05 17:04:52 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221) finished in 0.282 s
16/02/05 17:04:52 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221, took 10.743689 s
16/02/05 17:04:52 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 296 ms on localhost (2/2)
16/02/05 17:04:52 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/02/05 17:04:52 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224
16/02/05 17:04:52 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224) with 2 output partitions
16/02/05 17:04:52 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224)
16/02/05 17:04:52 INFO DAGScheduler: Parents of final stage: List()
16/02/05 17:04:52 INFO DAGScheduler: Missing parents: List()
16/02/05 17:04:52 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224), which has no missing parents
16/02/05 17:04:52 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18756, maxMem=550942801
16/02/05 17:04:52 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 525.4 MB)
16/02/05 17:04:52 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24572, maxMem=550942801
16/02/05 17:04:52 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 525.4 MB)
16/02/05 17:04:52 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:48702 (size: 3.3 KB, free: 525.4 MB)
16/02/05 17:04:52 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/02/05 17:04:52 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224)
16/02/05 17:04:52 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/02/05 17:04:52 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/02/05 17:04:52 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2362 bytes)
16/02/05 17:04:52 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/02/05 17:04:52 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/02/05 17:04:52 INFO PythonRunner: Times: total = 65, boot = 65, init = 0, finish = 0
16/02/05 17:04:52 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1349 bytes result sent to driver
16/02/05 17:04:52 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 79 ms on localhost (1/2)
16/02/05 17:04:52 INFO PythonRunner: Times: total = 110, boot = 110, init = 0, finish = 0
16/02/05 17:04:52 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/02/05 17:04:52 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 122 ms on localhost (2/2)
16/02/05 17:04:52 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/02/05 17:04:52 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224) finished in 0.119 s
16/02/05 17:04:52 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224, took 0.135756 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/02/05 17:04:52 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/02/05 17:04:52 INFO DAGScheduler: Stopping DAGScheduler
16/02/05 17:04:52 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/02/05 17:04:52 INFO MemoryStore: MemoryStore cleared
16/02/05 17:04:52 INFO BlockManager: BlockManager stopped
16/02/05 17:04:52 INFO BlockManagerMaster: BlockManagerMaster stopped
16/02/05 17:04:52 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/02/05 17:04:52 INFO SparkContext: Successfully stopped SparkContext
16/02/05 17:04:52 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'giant', u'None']
16/02/05 17:04:53 INFO SparkContext: Running Spark version 1.5.2
16/02/05 17:04:53 INFO SecurityManager: Changing view acls to: root
16/02/05 17:04:53 INFO SecurityManager: Changing modify acls to: root
16/02/05 17:04:53 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/02/05 17:04:53 INFO Slf4jLogger: Slf4jLogger started
16/02/05 17:04:53 INFO Remoting: Starting remoting
16/02/05 17:04:53 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:43324]
16/02/05 17:04:53 INFO Utils: Successfully started service 'sparkDriver' on port 43324.
16/02/05 17:04:53 INFO SparkEnv: Registering MapOutputTracker
16/02/05 17:04:53 INFO SparkEnv: Registering BlockManagerMaster
16/02/05 17:04:53 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-fc6d74e3-fd5f-4664-89f7-759c9ff05e6d
16/02/05 17:04:53 INFO MemoryStore: MemoryStore started with capacity 525.4 MB
16/02/05 17:04:53 INFO HttpFileServer: HTTP File server directory is /tmp/spark-dadd0e29-0794-4c88-9906-5a3b1e594e2c/httpd-ef82c7bb-3d5b-4b24-b0eb-37d5bfcf7d0c
16/02/05 17:04:53 INFO HttpServer: Starting HTTP Server
16/02/05 17:04:53 INFO Utils: Successfully started service 'HTTP file server' on port 45059.
16/02/05 17:04:53 INFO SparkEnv: Registering OutputCommitCoordinator
16/02/05 17:04:53 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/02/05 17:04:53 INFO SparkUI: Started SparkUI at http://localhost:4040
16/02/05 17:04:53 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-dadd0e29-0794-4c88-9906-5a3b1e594e2c/userFiles-9f1a0af7-6227-49cb-9fab-7122e7d7480e/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/02/05 17:04:53 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1454672093956
16/02/05 17:04:54 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/02/05 17:04:54 INFO Executor: Starting executor ID driver on host localhost
16/02/05 17:04:54 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58187.
16/02/05 17:04:54 INFO NettyBlockTransferService: Server created on 58187
16/02/05 17:04:54 INFO BlockManagerMaster: Trying to register BlockManager
16/02/05 17:04:54 INFO BlockManagerMasterEndpoint: Registering block manager localhost:58187 with 525.4 MB RAM, BlockManagerId(driver, localhost, 58187)
16/02/05 17:04:54 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): reputation
16/02/05 17:04:54 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221
16/02/05 17:04:54 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219)
16/02/05 17:04:54 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221) with 2 output partitions
16/02/05 17:04:54 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221)
16/02/05 17:04:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/02/05 17:04:54 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/02/05 17:04:54 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219), which has no missing parents
16/02/05 17:04:54 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=550942801
16/02/05 17:04:54 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 525.4 MB)
16/02/05 17:04:54 INFO MemoryStore: ensureFreeSpace(4148) called with curMem=6568, maxMem=550942801
16/02/05 17:04:54 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 525.4 MB)
16/02/05 17:04:54 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:58187 (size: 4.1 KB, free: 525.4 MB)
16/02/05 17:04:54 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/02/05 17:04:54 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219)
16/02/05 17:04:54 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/02/05 17:04:54 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2408 bytes)
16/02/05 17:04:54 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2430 bytes)
16/02/05 17:04:54 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/02/05 17:04:54 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1454672093956
16/02/05 17:04:54 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/02/05 17:04:54 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-dadd0e29-0794-4c88-9906-5a3b1e594e2c/userFiles-9f1a0af7-6227-49cb-9fab-7122e7d7480e/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: kilometer
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: area
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: elaborate
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'and', u'idea', u'an', u'as', u'in', u'discourse', u'writing', u'to', u'add', u'details', u'way', u'learned', u',', u'clarify', u'meaning', u';', u'a', u'account', u'of', u'usually', u'the', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: exist
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'be', u',', u'an', u'have', u'existence', u'extant'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: commissariat
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'supply', u'of', u'foods', u'or', u'stock'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: town
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'urban', u'smaller', u'area', u'is', u'that', u'an', u'city', u'boundary', u'fixed', u'with', u'than'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: state
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: set
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'nation', u'of', u'one', u'districts', u'constituent', u'the', u'territory', u'occupied', u'by', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/02/05 17:05:02 INFO PythonRunner: Times: total = 8091, boot = 468, init = 428, finish = 7195
16/02/05 17:05:02 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/02/05 17:05:02 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8170 ms on localhost (1/2)
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: bend
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: giant
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): adding to parents: syn =  Synset('colossus.n.02') ; keyword:  reputation  in syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= [u'giant']
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: astatine
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: present
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
asfer_pickle_string_load(): picklef.readlines(): reputation
mapFunction_Parents(): keyword: reputation ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= reputation ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'giant']
16/02/05 17:05:02 INFO PythonRunner: Times: total = 8259, boot = 460, init = 382, finish = 7417
16/02/05 17:05:02 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/02/05 17:05:02 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219) finished in 8.338 s
16/02/05 17:05:02 INFO DAGScheduler: looking for newly runnable stages
16/02/05 17:05:02 INFO DAGScheduler: running: Set()
16/02/05 17:05:02 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/02/05 17:05:02 INFO DAGScheduler: failed: Set()
16/02/05 17:05:02 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/02/05 17:05:02 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221), which is now runnable
16/02/05 17:05:02 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10716, maxMem=550942801
16/02/05 17:05:02 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 525.4 MB)
16/02/05 17:05:02 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15700, maxMem=550942801
16/02/05 17:05:02 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 525.4 MB)
16/02/05 17:05:02 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8330 ms on localhost (2/2)
16/02/05 17:05:02 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:58187 (size: 3.0 KB, free: 525.4 MB)
16/02/05 17:05:02 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/02/05 17:05:02 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/02/05 17:05:02 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221)
16/02/05 17:05:02 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/02/05 17:05:02 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/02/05 17:05:02 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/02/05 17:05:02 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/02/05 17:05:02 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/02/05 17:05:02 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/02/05 17:05:02 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/02/05 17:05:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/02/05 17:05:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
reduceFunction_Parents(): returns= ['None', u'giant', 'None']
16/02/05 17:05:02 INFO PythonRunner: Times: total = 76, boot = 73, init = 2, finish = 1
16/02/05 17:05:02 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1281 bytes result sent to driver
16/02/05 17:05:02 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 131 ms on localhost (1/2)
16/02/05 17:05:02 INFO PythonRunner: Times: total = 272, boot = 272, init = 0, finish = 0
16/02/05 17:05:02 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/02/05 17:05:02 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221) finished in 0.284 s
16/02/05 17:05:02 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221, took 8.664763 s
16/02/05 17:05:02 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 301 ms on localhost (2/2)
16/02/05 17:05:02 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/02/05 17:05:02 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224
16/02/05 17:05:02 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224) with 2 output partitions
16/02/05 17:05:02 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224)
16/02/05 17:05:02 INFO DAGScheduler: Parents of final stage: List()
16/02/05 17:05:02 INFO DAGScheduler: Missing parents: List()
16/02/05 17:05:02 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224), which has no missing parents
16/02/05 17:05:02 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18756, maxMem=550942801
16/02/05 17:05:02 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 525.4 MB)
16/02/05 17:05:02 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24572, maxMem=550942801
16/02/05 17:05:02 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 525.4 MB)
16/02/05 17:05:02 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:58187 (size: 3.3 KB, free: 525.4 MB)
16/02/05 17:05:02 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/02/05 17:05:02 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224)
16/02/05 17:05:02 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/02/05 17:05:02 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/02/05 17:05:02 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2362 bytes)
16/02/05 17:05:02 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/02/05 17:05:02 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/02/05 17:05:02 INFO PythonRunner: Times: total = 65, boot = -64, init = 129, finish = 0
16/02/05 17:05:02 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/02/05 17:05:02 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 74 ms on localhost (1/2)
16/02/05 17:05:02 INFO PythonRunner: Times: total = 153, boot = 152, init = 0, finish = 1
16/02/05 17:05:03 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1349 bytes result sent to driver
16/02/05 17:05:03 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 168 ms on localhost (2/2)
16/02/05 17:05:03 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/02/05 17:05:03 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224) finished in 0.153 s
16/02/05 17:05:03 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224, took 0.178686 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/02/05 17:05:03 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/02/05 17:05:03 INFO DAGScheduler: Stopping DAGScheduler
16/02/05 17:05:03 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/02/05 17:05:03 INFO MemoryStore: MemoryStore cleared
16/02/05 17:05:03 INFO BlockManager: BlockManager stopped
16/02/05 17:05:03 INFO BlockManagerMaster: BlockManagerMaster stopped
16/02/05 17:05:03 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/02/05 17:05:03 INFO SparkContext: Successfully stopped SparkContext
16/02/05 17:05:03 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/02/05 17:05:03 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/02/05 17:05:03 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'giant', u'None']
16/02/05 17:05:04 INFO SparkContext: Running Spark version 1.5.2
16/02/05 17:05:04 INFO SecurityManager: Changing view acls to: root
16/02/05 17:05:04 INFO SecurityManager: Changing modify acls to: root
16/02/05 17:05:04 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/02/05 17:05:04 INFO Slf4jLogger: Slf4jLogger started
16/02/05 17:05:04 INFO Remoting: Starting remoting
16/02/05 17:05:04 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:50169]
16/02/05 17:05:04 INFO Utils: Successfully started service 'sparkDriver' on port 50169.
16/02/05 17:05:04 INFO SparkEnv: Registering MapOutputTracker
16/02/05 17:05:04 INFO SparkEnv: Registering BlockManagerMaster
16/02/05 17:05:04 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-ff63b102-629b-4c65-8aca-170d80b2299b
16/02/05 17:05:04 INFO MemoryStore: MemoryStore started with capacity 525.4 MB
16/02/05 17:05:04 INFO HttpFileServer: HTTP File server directory is /tmp/spark-dadd0e29-0794-4c88-9906-5a3b1e594e2c/httpd-d31d82c5-827b-4b60-bb24-beb09b5e44c6
16/02/05 17:05:04 INFO HttpServer: Starting HTTP Server
16/02/05 17:05:04 INFO Utils: Successfully started service 'HTTP file server' on port 45285.
16/02/05 17:05:04 INFO SparkEnv: Registering OutputCommitCoordinator
16/02/05 17:05:04 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/02/05 17:05:04 INFO SparkUI: Started SparkUI at http://localhost:4040
16/02/05 17:05:04 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-dadd0e29-0794-4c88-9906-5a3b1e594e2c/userFiles-ed2f56aa-1778-4dca-95de-b9d825363743/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/02/05 17:05:04 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1454672104345
16/02/05 17:05:04 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/02/05 17:05:04 INFO Executor: Starting executor ID driver on host localhost
16/02/05 17:05:04 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51901.
16/02/05 17:05:04 INFO NettyBlockTransferService: Server created on 51901
16/02/05 17:05:04 INFO BlockManagerMaster: Trying to register BlockManager
16/02/05 17:05:04 INFO BlockManagerMasterEndpoint: Registering block manager localhost:51901 with 525.4 MB RAM, BlockManagerId(driver, localhost, 51901)
16/02/05 17:05:04 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): time
16/02/05 17:05:04 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221
16/02/05 17:05:04 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219)
16/02/05 17:05:04 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221) with 2 output partitions
16/02/05 17:05:04 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221)
16/02/05 17:05:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/02/05 17:05:04 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/02/05 17:05:04 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219), which has no missing parents
16/02/05 17:05:04 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=550942801
16/02/05 17:05:04 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 525.4 MB)
16/02/05 17:05:04 INFO MemoryStore: ensureFreeSpace(4148) called with curMem=6568, maxMem=550942801
16/02/05 17:05:04 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 525.4 MB)
16/02/05 17:05:04 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:51901 (size: 4.1 KB, free: 525.4 MB)
16/02/05 17:05:04 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/02/05 17:05:04 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219)
16/02/05 17:05:04 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/02/05 17:05:04 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2408 bytes)
16/02/05 17:05:04 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2430 bytes)
16/02/05 17:05:04 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/02/05 17:05:04 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1454672104345
16/02/05 17:05:04 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/02/05 17:05:04 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-dadd0e29-0794-4c88-9906-5a3b1e594e2c/userFiles-ed2f56aa-1778-4dca-95de-b9d825363743/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: kilometer
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: set
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: area
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: timemapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: bend
 ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: elaborate
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'and', u'idea', u'an', u'as', u'in', u'discourse', u'writing', u'to', u'add', u'details', u'way', u'learned', u',', u'clarify', u'meaning', u';', u'a', u'account', u'of', u'usually', u'the', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: exist
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'be', u',', u'an', u'have', u'existence', u'extant'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: commissariat
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'supply', u'of', u'foods', u'or', u'stock'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: town
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: giant
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'urban', u'smaller', u'area', u'is', u'that', u'an', u'city', u'boundary', u'fixed', u'with', u'than'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: state
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: astatine
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: present
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'nation', u'of', u'one', u'districts', u'constituent', u'the', u'territory', u'occupied', u'by', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/02/05 17:05:13 INFO PythonRunner: Times: total = 8569, boot = 776, init = 556, finish = 7237
16/02/05 17:05:13 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/02/05 17:05:13 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8655 ms on localhost (1/2)
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): adding to parents: syn =  Synset('present.n.01') ; keyword:  time  in syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= [u'present']
reduceFunction_Parents(): returns= ['None', u'present']
asfer_pickle_string_load(): picklef.readlines(): time
mapFunction_Parents(): keyword: time ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= time ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'present']
16/02/05 17:05:13 INFO PythonRunner: Times: total = 8630, boot = 538, init = 664, finish = 7428
16/02/05 17:05:13 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/02/05 17:05:13 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8720 ms on localhost (2/2)
16/02/05 17:05:13 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/02/05 17:05:13 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219) finished in 8.722 s
16/02/05 17:05:13 INFO DAGScheduler: looking for newly runnable stages
16/02/05 17:05:13 INFO DAGScheduler: running: Set()
16/02/05 17:05:13 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/02/05 17:05:13 INFO DAGScheduler: failed: Set()
16/02/05 17:05:13 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/02/05 17:05:13 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221), which is now runnable
16/02/05 17:05:13 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10716, maxMem=550942801
16/02/05 17:05:13 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 525.4 MB)
16/02/05 17:05:13 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15700, maxMem=550942801
16/02/05 17:05:13 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 525.4 MB)
16/02/05 17:05:13 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:51901 (size: 3.0 KB, free: 525.4 MB)
16/02/05 17:05:13 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/02/05 17:05:13 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221)
16/02/05 17:05:13 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/02/05 17:05:13 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/02/05 17:05:13 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/02/05 17:05:13 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/02/05 17:05:13 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/02/05 17:05:13 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/02/05 17:05:13 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/02/05 17:05:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/02/05 17:05:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
16/02/05 17:05:13 INFO PythonRunner: Times: total = 202, boot = 201, init = 1, finish = 0
16/02/05 17:05:13 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
reduceFunction_Parents(): returns= ['None', u'present', 'None']
16/02/05 17:05:13 INFO PythonRunner: Times: total = 208, boot = 207, init = 0, finish = 1
16/02/05 17:05:13 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1283 bytes result sent to driver
16/02/05 17:05:13 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 236 ms on localhost (1/2)
16/02/05 17:05:13 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221) finished in 0.253 s
16/02/05 17:05:13 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221, took 9.013759 s
16/02/05 17:05:13 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 248 ms on localhost (2/2)
16/02/05 17:05:13 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/02/05 17:05:13 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224
16/02/05 17:05:13 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224) with 2 output partitions
16/02/05 17:05:13 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224)
16/02/05 17:05:13 INFO DAGScheduler: Parents of final stage: List()
16/02/05 17:05:13 INFO DAGScheduler: Missing parents: List()
16/02/05 17:05:13 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224), which has no missing parents
16/02/05 17:05:13 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18756, maxMem=550942801
16/02/05 17:05:13 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 525.4 MB)
16/02/05 17:05:13 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24572, maxMem=550942801
16/02/05 17:05:13 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 525.4 MB)
16/02/05 17:05:13 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:51901 (size: 3.3 KB, free: 525.4 MB)
16/02/05 17:05:13 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/02/05 17:05:13 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224)
16/02/05 17:05:13 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/02/05 17:05:13 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/02/05 17:05:13 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2364 bytes)
16/02/05 17:05:13 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/02/05 17:05:13 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/02/05 17:05:13 INFO PythonRunner: Times: total = 124, boot = 123, init = 1, finish = 0
16/02/05 17:05:13 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1351 bytes result sent to driver
16/02/05 17:05:13 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 144 ms on localhost (1/2)
16/02/05 17:05:13 INFO PythonRunner: Times: total = 207, boot = 207, init = 0, finish = 0
16/02/05 17:05:13 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/02/05 17:05:13 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 224 ms on localhost (2/2)
16/02/05 17:05:13 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/02/05 17:05:13 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224) finished in 0.222 s
16/02/05 17:05:13 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224, took 0.252144 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/02/05 17:05:13 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/02/05 17:05:13 INFO DAGScheduler: Stopping DAGScheduler
16/02/05 17:05:14 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/02/05 17:05:14 INFO MemoryStore: MemoryStore cleared
16/02/05 17:05:14 INFO BlockManager: BlockManager stopped
16/02/05 17:05:14 INFO BlockManagerMaster: BlockManagerMaster stopped
16/02/05 17:05:14 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/02/05 17:05:14 INFO SparkContext: Successfully stopped SparkContext
16/02/05 17:05:14 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/02/05 17:05:14 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/02/05 17:05:14 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'present', u'None']
16/02/05 17:05:14 INFO SparkContext: Running Spark version 1.5.2
16/02/05 17:05:14 INFO SecurityManager: Changing view acls to: root
16/02/05 17:05:14 INFO SecurityManager: Changing modify acls to: root
16/02/05 17:05:14 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/02/05 17:05:14 INFO Slf4jLogger: Slf4jLogger started
16/02/05 17:05:15 INFO Remoting: Starting remoting
16/02/05 17:05:15 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:36849]
16/02/05 17:05:15 INFO Utils: Successfully started service 'sparkDriver' on port 36849.
16/02/05 17:05:15 INFO SparkEnv: Registering MapOutputTracker
16/02/05 17:05:15 INFO SparkEnv: Registering BlockManagerMaster
16/02/05 17:05:15 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-6e2836bd-fb26-46d2-9b89-f95da0b82b42
16/02/05 17:05:15 INFO MemoryStore: MemoryStore started with capacity 524.5 MB
16/02/05 17:05:15 INFO HttpFileServer: HTTP File server directory is /tmp/spark-dadd0e29-0794-4c88-9906-5a3b1e594e2c/httpd-f5bee8ec-089e-4512-a5a0-582bf540cf31
16/02/05 17:05:15 INFO HttpServer: Starting HTTP Server
16/02/05 17:05:15 INFO Utils: Successfully started service 'HTTP file server' on port 51481.
16/02/05 17:05:15 INFO SparkEnv: Registering OutputCommitCoordinator
16/02/05 17:05:15 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/02/05 17:05:15 INFO SparkUI: Started SparkUI at http://localhost:4040
16/02/05 17:05:15 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-dadd0e29-0794-4c88-9906-5a3b1e594e2c/userFiles-8c76f110-c5fc-44cf-abf7-44344c44c0a9/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/02/05 17:05:15 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1454672115197
16/02/05 17:05:15 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/02/05 17:05:15 INFO Executor: Starting executor ID driver on host localhost
16/02/05 17:05:15 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58598.
16/02/05 17:05:15 INFO NettyBlockTransferService: Server created on 58598
16/02/05 17:05:15 INFO BlockManagerMaster: Trying to register BlockManager
16/02/05 17:05:15 INFO BlockManagerMasterEndpoint: Registering block manager localhost:58598 with 524.5 MB RAM, BlockManagerId(driver, localhost, 58598)
16/02/05 17:05:15 INFO BlockManagerMaster: Registered BlockManager
asfer_pickle_string_dump(): picklef.write(): position
16/02/05 17:05:15 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221
16/02/05 17:05:15 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219)
16/02/05 17:05:15 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221) with 2 output partitions
16/02/05 17:05:15 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221)
16/02/05 17:05:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/02/05 17:05:15 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/02/05 17:05:15 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219), which has no missing parents
16/02/05 17:05:15 INFO MemoryStore: ensureFreeSpace(6568) called with curMem=0, maxMem=549951897
16/02/05 17:05:15 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 524.5 MB)
16/02/05 17:05:15 INFO MemoryStore: ensureFreeSpace(4148) called with curMem=6568, maxMem=549951897
16/02/05 17:05:15 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 524.5 MB)
16/02/05 17:05:15 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:58598 (size: 4.1 KB, free: 524.5 MB)
16/02/05 17:05:15 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/02/05 17:05:15 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219)
16/02/05 17:05:15 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/02/05 17:05:15 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2408 bytes)
16/02/05 17:05:15 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2430 bytes)
16/02/05 17:05:15 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/02/05 17:05:15 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1454672115197
16/02/05 17:05:15 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/02/05 17:05:15 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-dadd0e29-0794-4c88-9906-5a3b1e594e2c/userFiles-8c76f110-c5fc-44cf-abf7-44344c44c0a9/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: metropolitan
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): adding to parents: syn =  Synset('metropolitan.n.01') ; keyword:  position  in syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: area
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: kilometer
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: elaborate
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'and', u'idea', u'an', u'as', u'in', u'discourse', u'writing', u'to', u'add', u'details', u'way', u'learned', u',', u'clarify', u'meaning', u';', u'a', u'account', u'of', u'usually', u'the', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: exist
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'be', u',', u'an', u'have', u'existence', u'extant'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: commissariat
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'supply', u'of', u'foods', u'or', u'stock'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: town
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'urban', u'smaller', u'area', u'is', u'that', u'an', u'city', u'boundary', u'fixed', u'with', u'than'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: state
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'nation', u'of', u'one', u'districts', u'constituent', u'the', u'territory', u'occupied', u'by', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
16/02/05 17:05:23 INFO PythonRunner: Times: total = 8015, boot = 458, init = 367, finish = 7190
16/02/05 17:05:23 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/02/05 17:05:23 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8093 ms on localhost (1/2)
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'0.621371', u')', u'of', u'metric', u'equal', u'to', u'length', u'miles', u'meters', u'(', u'or', u'unit', u'1000'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: set
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'kind', u'used', u'group', u'that', u'of', u'belong', u'same', u'so', u'together', u'things', u'the', u'are'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: bend
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'of', u'segment', u'curve', u'circular'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: giant
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'exceptional', u'importance', u'of', u'person', u'reputation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: astatine
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'product', u'radioactive', u'decay', u'series', u'(', u'heaviest', u'uranium', u'thorium', u'element', u')', u'halogen', u'unstable', u'of', u'the', u'highly', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: present
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'happening', u'that', u'stretch', u'of', u'is', u'continuous', u'period', u'any', u'moment', u'including', u'time', u'speech', u'the', u'now', u';'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/02/05 17:05:23 INFO PythonRunner: Times: total = 8409, boot = 461, init = 424, finish = 7524
16/02/05 17:05:23 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/02/05 17:05:23 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:219) finished in 8.496 s
16/02/05 17:05:23 INFO DAGScheduler: looking for newly runnable stages
16/02/05 17:05:23 INFO DAGScheduler: running: Set()
16/02/05 17:05:23 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/02/05 17:05:23 INFO DAGScheduler: failed: Set()
16/02/05 17:05:23 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/02/05 17:05:23 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221), which is now runnable
16/02/05 17:05:23 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8495 ms on localhost (2/2)
16/02/05 17:05:23 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/02/05 17:05:23 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=10716, maxMem=549951897
16/02/05 17:05:23 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 524.5 MB)
16/02/05 17:05:23 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=15700, maxMem=549951897
16/02/05 17:05:23 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 524.5 MB)
16/02/05 17:05:23 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:58598 (size: 3.0 KB, free: 524.5 MB)
16/02/05 17:05:23 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/02/05 17:05:23 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221)
16/02/05 17:05:23 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/02/05 17:05:23 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/02/05 17:05:23 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/02/05 17:05:23 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/02/05 17:05:23 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/02/05 17:05:23 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/02/05 17:05:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
16/02/05 17:05:23 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/02/05 17:05:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
16/02/05 17:05:23 INFO PythonRunner: Times: total = 57, boot = -243, init = 300, finish = 0
reduceFunction_Parents(): returns= ['None', u'metropolitan']
16/02/05 17:05:23 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1280 bytes result sent to driver
16/02/05 17:05:23 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 82 ms on localhost (1/2)
16/02/05 17:05:24 INFO PythonRunner: Times: total = 211, boot = 210, init = 1, finish = 0
16/02/05 17:05:24 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/02/05 17:05:24 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221) finished in 0.203 s
16/02/05 17:05:24 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:221, took 8.754052 s
16/02/05 17:05:24 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 239 ms on localhost (2/2)
16/02/05 17:05:24 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/02/05 17:05:24 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224
16/02/05 17:05:24 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224) with 2 output partitions
16/02/05 17:05:24 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224)
16/02/05 17:05:24 INFO DAGScheduler: Parents of final stage: List()
16/02/05 17:05:24 INFO DAGScheduler: Missing parents: List()
16/02/05 17:05:24 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224), which has no missing parents
16/02/05 17:05:24 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=18756, maxMem=549951897
16/02/05 17:05:24 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 524.5 MB)
16/02/05 17:05:24 INFO MemoryStore: ensureFreeSpace(3378) called with curMem=24572, maxMem=549951897
16/02/05 17:05:24 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 524.4 MB)
16/02/05 17:05:24 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:58598 (size: 3.3 KB, free: 524.5 MB)
16/02/05 17:05:24 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/02/05 17:05:24 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224)
16/02/05 17:05:24 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/02/05 17:05:24 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/02/05 17:05:24 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2361 bytes)
16/02/05 17:05:24 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/02/05 17:05:24 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/02/05 17:05:24 INFO PythonRunner: Times: total = 80, boot = 79, init = 0, finish = 1
16/02/05 17:05:24 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1345 bytes result sent to driver
16/02/05 17:05:24 INFO PythonRunner: Times: total = 82, boot = 34, init = 48, finish = 0
16/02/05 17:05:24 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/02/05 17:05:24 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 93 ms on localhost (1/2)
16/02/05 17:05:24 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 93 ms on localhost (2/2)
16/02/05 17:05:24 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/02/05 17:05:24 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224) finished in 0.072 s
16/02/05 17:05:24 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:224, took 0.120711 s
Spark_MapReduce_Parents() - SparkSQL DataFrame query results:
16/02/05 17:05:24 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/02/05 17:05:24 INFO DAGScheduler: Stopping DAGScheduler
16/02/05 17:05:24 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/02/05 17:05:24 INFO MemoryStore: MemoryStore cleared
16/02/05 17:05:24 INFO BlockManager: BlockManager stopped
16/02/05 17:05:24 INFO BlockManagerMaster: BlockManagerMaster stopped
16/02/05 17:05:24 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/02/05 17:05:24 INFO SparkContext: Successfully stopped SparkContext
16/02/05 17:05:24 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/02/05 17:05:24 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/02/05 17:05:24 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Spark_MapReduce_Parents(): dict_query_results[1]= [u'None', u'metropolitan']
InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:freqterms1= [u'serving', u'Madras', u'Bengal', u'including', u'existence', u'geography', u'group', u'title', u'writing', u'add', u'halogen', u'Tamil', u'exceptional', u'kind', u'Bay', u'learned', u'meaning', u'miles', u'unstable', u'circular', u'smaller', u'people', u'series', u'idea', u'Christianity', u'culture', u'meters', u'special', u'0.621371', u'Orthodox', u'boundary', u'body', u'importance', u'equivalent', u'thorium', u'clarify', u'fixed', u'region', u'decay', u'equal', u'length', u'usually', u'1000', u'formerly', u'supply', u'period', u'highly', u'indefinite', u'unit', u'city', u'given', u'area', u'stretch', u'archbishop', u'way', u'urban', u'government', u'continuous', u'western', u'particular', u'extant', u'account', u'patriarch', u'Eastern', u'Church', u'politically', u'distinguished', u'metric', u'heaviest', u'organized', u'foods', u'bishop', u'things', u'belong', u'uranium', u'discourse', u'speech', u'details', u'geographical', u'Nadu', u'stock', u'product', u'used', u'moment', u'purpose', u'segment', u'single', u'radioactive', u'happening', u'curve', u'together', u'element', u'person', u'reputation', u'time', u'position']
16/02/05 17:05:25 INFO SparkContext: Running Spark version 1.5.2
16/02/05 17:05:25 INFO SecurityManager: Changing view acls to: root
16/02/05 17:05:25 INFO SecurityManager: Changing modify acls to: root
16/02/05 17:05:25 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/02/05 17:05:25 INFO Slf4jLogger: Slf4jLogger started
16/02/05 17:05:25 INFO Remoting: Starting remoting
16/02/05 17:05:25 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:55186]
16/02/05 17:05:25 INFO Utils: Successfully started service 'sparkDriver' on port 55186.
16/02/05 17:05:25 INFO SparkEnv: Registering MapOutputTracker
16/02/05 17:05:25 INFO SparkEnv: Registering BlockManagerMaster
16/02/05 17:05:25 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-8a90d458-018a-4223-8c1a-3d65614ff022
16/02/05 17:05:25 INFO MemoryStore: MemoryStore started with capacity 524.5 MB
16/02/05 17:05:25 INFO HttpFileServer: HTTP File server directory is /tmp/spark-dadd0e29-0794-4c88-9906-5a3b1e594e2c/httpd-4d457fde-d480-4385-8fcc-aa9cb93f2d9e
16/02/05 17:05:25 INFO HttpServer: Starting HTTP Server
16/02/05 17:05:25 INFO Utils: Successfully started service 'HTTP file server' on port 44800.
16/02/05 17:05:25 INFO SparkEnv: Registering OutputCommitCoordinator
16/02/05 17:05:25 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/02/05 17:05:25 INFO SparkUI: Started SparkUI at http://localhost:4040
16/02/05 17:05:25 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-dadd0e29-0794-4c88-9906-5a3b1e594e2c/userFiles-46fafb9e-8ae0-4b64-a6ad-01303ca76dea/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/02/05 17:05:25 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1454672125620
16/02/05 17:05:25 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/02/05 17:05:25 INFO Executor: Starting executor ID driver on host localhost
16/02/05 17:05:25 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33814.
16/02/05 17:05:25 INFO NettyBlockTransferService: Server created on 33814
16/02/05 17:05:25 INFO BlockManagerMaster: Trying to register BlockManager
16/02/05 17:05:25 INFO BlockManagerMasterEndpoint: Registering block manager localhost:33814 with 524.5 MB RAM, BlockManagerId(driver, localhost, 33814)
16/02/05 17:05:25 INFO BlockManagerMaster: Registered BlockManager
Spark_MapReduce(): wordsatthislevel: [u'serving', u'Madras', u'Bengal', u'including', u'existence', u'geography', u'group', u'title', u'writing', u'add', u'halogen', u'Tamil', u'exceptional', u'kind', u'Bay', u'learned', u'meaning', u'miles', u'unstable', u'circular', u'smaller', u'people', u'series', u'idea', u'Christianity', u'culture', u'meters', u'special', u'0.621371', u'Orthodox', u'boundary', u'body', u'importance', u'equivalent', u'thorium', u'clarify', u'fixed', u'region', u'decay', u'equal', u'length', u'usually', u'1000', u'formerly', u'supply', u'period', u'highly', u'indefinite', u'unit', u'city', u'given', u'area', u'stretch', u'archbishop', u'way', u'urban', u'government', u'continuous', u'western', u'particular', u'extant', u'account', u'patriarch', u'Eastern', u'Church', u'politically', u'distinguished', u'metric', u'heaviest', u'organized', u'foods', u'bishop', u'things', u'belong', u'uranium', u'discourse', u'speech', u'details', u'geographical', u'Nadu', u'stock', u'product', u'used', u'moment', u'purpose', u'segment', u'single', u'radioactive', u'happening', u'curve', u'together', u'element', u'person', u'reputation', u'time', u'position']
16/02/05 17:05:25 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:161
16/02/05 17:05:25 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:153)
16/02/05 17:05:25 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:161) with 2 output partitions
16/02/05 17:05:25 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:161)
16/02/05 17:05:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/02/05 17:05:25 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/02/05 17:05:25 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:153), which has no missing parents
16/02/05 17:05:25 INFO MemoryStore: ensureFreeSpace(6552) called with curMem=0, maxMem=549951897
16/02/05 17:05:25 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 524.5 MB)
16/02/05 17:05:25 INFO MemoryStore: ensureFreeSpace(4139) called with curMem=6552, maxMem=549951897
16/02/05 17:05:25 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 524.5 MB)
16/02/05 17:05:25 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:33814 (size: 4.0 KB, free: 524.5 MB)
16/02/05 17:05:25 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/02/05 17:05:25 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:153)
16/02/05 17:05:25 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/02/05 17:05:25 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2972 bytes)
16/02/05 17:05:25 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2989 bytes)
16/02/05 17:05:25 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/02/05 17:05:25 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1454672125620
16/02/05 17:05:25 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/02/05 17:05:25 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-dadd0e29-0794-4c88-9906-5a3b1e594e2c/userFiles-46fafb9e-8ae0-4b64-a6ad-01303ca76dea/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
mapFunction(): freqterms1:mapFunction(): freqterms1: unit
 serving
mapFunction(): freqterms1: city
mapFunction(): freqterms1: given
mapFunction(): freqterms1: area
mapFunction(): freqterms1: stretch
mapFunction(): freqterms1: archbishop
mapFunction(): freqterms1: way
mapFunction(): freqterms1: urban
mapFunction(): freqterms1: government
mapFunction(): freqterms1: continuous
mapFunction(): freqterms1: western
mapFunction(): freqterms1: particular
mapFunction(): freqterms1: extant
mapFunction(): freqterms1: account
mapFunction(): freqterms1: patriarch
mapFunction(): freqterms1: Eastern
mapFunction(): freqterms1: Church
mapFunction(): freqterms1: politically
mapFunction(): freqterms1: distinguished
mapFunction(): freqterms1: Madras
mapFunction(): freqterms1: metric
mapFunction(): freqterms1: Bengal
mapFunction(): freqterms1: including
mapFunction(): freqterms1: heaviest
mapFunction(): freqterms1: existence
mapFunction(): freqterms1: geography
mapFunction(): freqterms1: group
mapFunction(): freqterms1: organized
mapFunction(): freqterms1: foods
mapFunction(): freqterms1: title
mapFunction(): freqterms1: bishop
mapFunction(): freqterms1: writing
mapFunction(): freqterms1: things
mapFunction(): freqterms1: add
mapFunction(): freqterms1: belong
mapFunction(): freqterms1: halogen
mapFunction(): freqterms1: uranium
mapFunction(): freqterms1: Tamil
mapFunction(): freqterms1: discourse
mapFunction(): freqterms1: speech
mapFunction(): freqterms1: exceptional
mapFunction(): freqterms1: details
mapFunction(): freqterms1: kind
mapFunction(): freqterms1: geographical
mapFunction(): freqterms1: Nadu
mapFunction(): freqterms1: stock
mapFunction(): freqterms1: Bay
mapFunction(): freqterms1: learned
mapFunction(): freqterms1: product
mapFunction(): freqterms1: meaning
mapFunction(): freqterms1: used
mapFunction(): freqterms1: moment
mapFunction(): freqterms1: purpose
mapFunction(): freqterms1: miles
mapFunction(): freqterms1: segment
mapFunction(): freqterms1: single
mapFunction(): freqterms1: unstable
mapFunction(): freqterms1: circular
mapFunction(): freqterms1: radioactive
mapFunction(): freqterms1: happening
mapFunction(): freqterms1: smaller
mapFunction(): freqterms1: curve
mapFunction(): freqterms1: together
mapFunction(): freqterms1: people
mapFunction(): freqterms1: element
mapFunction(): freqterms1: series
mapFunction(): freqterms1: idea
mapFunction(): freqterms1: person
mapFunction(): freqterms1: reputation
mapFunction(): freqterms1: time
mapFunction(): freqterms1: Christianity
mapFunction(): freqterms1: culture
mapFunction(): freqterms1: meters
mapFunction(): freqterms1: special
mapFunction(): freqterms1: 0.621371
mapFunction(): freqterms1: Orthodox
mapFunction(): freqterms1: boundary
mapFunction(): freqterms1: position
mapFunction(): freqterms1: body
16/02/05 17:05:35 INFO PythonRunner: Times: total = 10040, boot = 452, init = 386, finish = 9202
16/02/05 17:05:35 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
16/02/05 17:05:35 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 10101 ms on localhost (1/2)
mapFunction(): freqterms1: importance
mapFunction(): freqterms1: equivalent
mapFunction(): freqterms1: thorium
mapFunction(): freqterms1: clarify
mapFunction(): freqterms1: fixed
mapFunction(): freqterms1: region
mapFunction(): freqterms1: decay
mapFunction(): freqterms1: equal
mapFunction(): freqterms1: length
mapFunction(): freqterms1: usually
mapFunction(): freqterms1: 1000
mapFunction(): freqterms1: formerly
mapFunction(): freqterms1: supply
mapFunction(): freqterms1: period
mapFunction(): freqterms1: highly
mapFunction(): freqterms1: indefinite
16/02/05 17:05:36 INFO PythonRunner: Times: total = 10400, boot = 465, init = 372, finish = 9563
16/02/05 17:05:36 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
16/02/05 17:05:36 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 10482 ms on localhost (2/2)
16/02/05 17:05:36 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/02/05 17:05:36 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:153) finished in 10.474 s
16/02/05 17:05:36 INFO DAGScheduler: looking for newly runnable stages
16/02/05 17:05:36 INFO DAGScheduler: running: Set()
16/02/05 17:05:36 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/02/05 17:05:36 INFO DAGScheduler: failed: Set()
16/02/05 17:05:36 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/02/05 17:05:36 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:161), which is now runnable
16/02/05 17:05:36 INFO MemoryStore: ensureFreeSpace(4976) called with curMem=10691, maxMem=549951897
16/02/05 17:05:36 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 524.5 MB)
16/02/05 17:05:36 INFO MemoryStore: ensureFreeSpace(3048) called with curMem=15667, maxMem=549951897
16/02/05 17:05:36 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 524.5 MB)
16/02/05 17:05:36 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:33814 (size: 3.0 KB, free: 524.5 MB)
16/02/05 17:05:36 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/02/05 17:05:36 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:161)
16/02/05 17:05:36 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/02/05 17:05:36 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/02/05 17:05:36 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/02/05 17:05:36 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/02/05 17:05:36 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/02/05 17:05:36 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/02/05 17:05:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
16/02/05 17:05:36 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/02/05 17:05:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/02/05 17:05:36 INFO PythonRunner: Times: total = 65, boot = -200, init = 264, finish = 1
16/02/05 17:05:36 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/02/05 17:05:36 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 89 ms on localhost (1/2)
16/02/05 17:05:36 INFO PythonRunner: Times: total = 308, boot = 304, init = 0, finish = 4
16/02/05 17:05:36 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 10233 bytes result sent to driver
16/02/05 17:05:36 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:161) finished in 0.340 s
16/02/05 17:05:36 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:161, took 10.853897 s
16/02/05 17:05:36 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 335 ms on localhost (2/2)
16/02/05 17:05:36 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/02/05 17:05:36 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:164
16/02/05 17:05:36 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:164) with 2 output partitions
16/02/05 17:05:36 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:164)
16/02/05 17:05:36 INFO DAGScheduler: Parents of final stage: List()
16/02/05 17:05:36 INFO DAGScheduler: Missing parents: List()
16/02/05 17:05:36 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:164), which has no missing parents
16/02/05 17:05:36 INFO MemoryStore: ensureFreeSpace(5872) called with curMem=18715, maxMem=549951897
16/02/05 17:05:36 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 524.5 MB)
16/02/05 17:05:36 INFO MemoryStore: ensureFreeSpace(3419) called with curMem=24587, maxMem=549951897
16/02/05 17:05:36 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 524.4 MB)
16/02/05 17:05:36 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:33814 (size: 3.3 KB, free: 524.5 MB)
16/02/05 17:05:36 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/02/05 17:05:36 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:164)
16/02/05 17:05:36 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/02/05 17:05:36 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/02/05 17:05:36 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 11187 bytes)
16/02/05 17:05:36 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/02/05 17:05:36 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/02/05 17:05:36 INFO PythonRunner: Times: total = 75, boot = -121, init = 195, finish = 1
16/02/05 17:05:36 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 10543 bytes result sent to driver
16/02/05 17:05:36 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 101 ms on localhost (1/2)
16/02/05 17:05:36 INFO PythonRunner: Times: total = 163, boot = 163, init = 0, finish = 0
16/02/05 17:05:36 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/02/05 17:05:36 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 170 ms on localhost (2/2)
16/02/05 17:05:36 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/02/05 17:05:36 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:164) finished in 0.170 s
16/02/05 17:05:36 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_SparkMapReducer.py:164, took 0.191836 s
Spark_MapReduce() - SparkSQL DataFrame query results:
Row(tokensatthislevel=[u'individual', u'quantity', u'food', u'drink', u'taken', u'part', u'meal', u'state', u'southeastern', u'India', u'Bay', u'Bengal', u'south', u'Andhra', u'Pradesh', u'formerly', u'Madras', u'region', u'whose', u'eastern', u'part', u'Bangladesh', u'whose', u'western', u'part', u'included', u'India', u'part', u'made', u'state', u'fact', u'existing', u'study', u'earth', u'surface', u'includes', u'people', u'responses', u'topography', u'climate', u'soil', u'vegetation', u'number', u'entities', u'members', u'considered', u'unit', u'heading', u'names', u'statute', u'legislative', u'bill', u'give', u'brief', u'summary', u'matters', u'deals', u'act', u'creating', u'written', u'works', u'condition', u'mostly', u'boys', u'characterized', u'behavioral', u'learning', u'disorders', u'five', u'related', u'nonmetallic', u'elements', u'fluorine', u'chlorine', u'bromine', u'iodine', u'astatine', u'monovalent', u'readily', u'form', u'negative', u'ions', u'member', u'mixed', u'Dravidian', u'Caucasian', u'people', u'southern', u'India', u'Sri', u'Lanka', u'deviating', u'widely', u'norm', u'physical', u'mental', u'ability', u'used', u'especially', u'children', u'normal', u'intelligence', u'category', u'things', u'distinguished', u'common', u'characteristic', u'quality', u'indentation', u'shoreline', u'larger', u'cove', u'smaller', u'gulf', u'student', u'certain', u'subject', u'logical', u'consequence', u'unit', u'length', u'equal', u'1,760', u'yards', u'5,280', u'feet', u'exactly', u'1609.344', u'meters', u'lacking', u'stability', u'fixity', u'firmness', u'advertisement', u'usually', u'printed', u'page', u'leaflet', u'intended', u'wide', u'distribution', u'voice', u'faint', u'plural', u'group', u'human', u'beings', u'men', u'women', u'children', u'collectively', u'similar', u'things', u'placed', u'order', u'happening', u'one', u'another', u'personal', u'view', u'monotheistic', u'system', u'beliefs', u'practices', u'based', u'Old', u'Testament', u'teachings', u'Jesus', u'embodied', u'New', u'Testament', u'emphasizing', u'role', u'Jesus', u'savior', u'particular', u'society', u'particular', u'time', u'place', u'basic', u'unit', u'length', u'adopted', u'Systeme', u'International', u"d'Unites", u'approximately', u'1.094', u'yards', u'special', u'offering', u'usually', u'temporary', u'reduced', u'price', u'featured', u'advertising', u'pertaining', u'characteristic', u'Judaism', u'line', u'determining', u'limits', u'area', u'entire', u'structure', u'organism', u'animal', u'plant', u'human', u'prominent', u'status', u'person', u'thing', u'equal', u'another', u'value', u'measure', u'force', u'effect', u'significance', u'etc', u'soft', u'silvery-white', u'tetravalent', u'radioactive', u'metallic', u'element', u'isotope', u'232', u'used', u'power', u'source', u'nuclear', u'reactors', u'occurs', u'thorite', u'monazite', u'sands', u'make', u'clear', u'comprehensible', u'restore', u'replacing', u'part', u'putting', u'together', u'torn', u'broken', u'extended', u'spatial', u'location', u'something', u'gradual', u'decrease', u'stored', u'charge', u'current', u'person', u'equal', u'standing', u'another', u'group', u'linear', u'extent', u'space', u'one', u'end', u'longest', u'dimension', u'something', u'fixed', u'place', u'normal', u'conditions', u'cardinal', u'number', u'product', u'10', u'100', u'previous', u'time', u'amount', u'something', u'available', u'use', u'amount', u'time', u'high', u'degree', u'extent', u'favorably', u'much', u'respect', u'vague', u'clearly', u'defined', u'stated', u'division', u'quantity', u'accepted', u'standard', u'measurement', u'exchange', u'large', u'densely', u'populated', u'urban', u'area', u'include', u'several', u'independent', u'administrative', u'districts', u'assumption', u'taken', u'granted', u'particular', u'geographical', u'region', u'indefinite', u'boundary', u'usually', u'serving', u'special', u'purpose', u'distinguished', u'people', u'culture', u'geography', u'large', u'unbroken', u'expanse', u'distance', u'bishop', u'highest', u'rank', u'result', u'obtained', u'end', u'achieved', u'relating', u'concerned', u'city', u'densely', u'populated', u'area', u'organization', u'governing', u'authority', u'political', u'unit', u'continuing', u'time', u'space', u'without', u'interruption', u'film', u'life', u'western', u'United', u'States', u'period', u'exploration', u'development', u'fact', u'part', u'opposed', u'general', u'still', u'existence', u'extinct', u'destroyed', u'lost', u'record', u'narrative', u'description', u'past', u'events', u'man', u'older', u'higher', u'rank', u'lying', u'toward', u'situated', u'east', u'one', u'groups', u'Christians', u'beliefs', u'forms', u'worship', u'regard', u'social', u'relationships', u'involving', u'authority', u'mark', u'different', u'function', u'topological', u'space', u'gives', u'two', u'points', u'space', u'value', u'equal', u'distance', u'usually', u'describes', u'large', u'person', u'fat', u'large', u'frame', u'carry', u'plan', u'direct', u'complex', u'undertaking', u'substance', u'metabolized', u'animal', u'give', u'energy', u'build', u'tissue', u'senior', u'member', u'Christian', u'clergy', u'spiritual', u'administrative', u'authority', u'appointed', u'Christian', u'churches', u'oversee', u'priests', u'ministers', u'considered', u'churches', u'successors', u'twelve', u'Apostles', u'Christ', u'movable', u'possession', u'especially', u'articles', u'clothing', u'owned', u'possession', u'heavy', u'toxic', u'silvery-white', u'radioactive', u'metallic', u'element', u'occurs', u'many', u'isotopes', u'used', u'nuclear', u'fuels', u'nuclear', u'weapons', u'extended', u'verbal', u'expression', u'speech', u'writing', u'act', u'delivering', u'formal', u'spoken', u'communication', u'audience', u'small', u'part', u'considered', u'separately', u'whole', u'relating', u'science', u'geography', u'capital', u'raised', u'corporation', u'issue', u'shares', u'entitling', u'holders', u'ownership', u'interest', u'equity', u'commodities', u'offered', u'sale', u'put', u'service', u'make', u'work', u'employ', u'particular', u'purpose', u'inherent', u'natural', u'purpose', u'particular', u'point', u'time', u'anticipated', u'outcome', u'intended', u'guides', u'planned', u'actions', u'one', u'several', u'parts', u'pieces', u'fit', u'others', u'constitute', u'whole', u'object', u'base', u'hit', u'batter', u'stops', u'safely', u'first', u'base', u'exhibiting', u'caused', u'radioactivity', u'event', u'happens', u'trace', u'point', u'whose', u'direction', u'motion', u'changes', u'mentally', u'emotionally', u'stable', u'abstract', u'part', u'something', u'human', u'general', u'estimation', u'public', u'person', u'instance', u'single', u'occasion', u'event', u'particular', u'portion', u'space', u'occupied', u'something'])
16/02/05 17:05:37 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/02/05 17:05:37 INFO DAGScheduler: Stopping DAGScheduler
16/02/05 17:05:37 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/02/05 17:05:37 INFO MemoryStore: MemoryStore cleared
16/02/05 17:05:37 INFO BlockManager: BlockManager stopped
16/02/05 17:05:37 INFO BlockManagerMaster: BlockManagerMaster stopped
16/02/05 17:05:37 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/02/05 17:05:37 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/02/05 17:05:37 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/02/05 17:05:37 INFO SparkContext: Successfully stopped SparkContext
16/02/05 17:05:37 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:tokensofthislevel: [u'individual', u'quantity', u'food', u'drink', u'taken', u'part', u'meal', u'state', u'southeastern', u'India', u'Bay', u'Bengal', u'south', u'Andhra', u'Pradesh', u'formerly', u'Madras', u'region', u'whose', u'eastern', u'part', u'Bangladesh', u'whose', u'western', u'part', u'included', u'India', u'part', u'made', u'state', u'fact', u'existing', u'study', u'earth', u'surface', u'includes', u'people', u'responses', u'topography', u'climate', u'soil', u'vegetation', u'number', u'entities', u'members', u'considered', u'unit', u'heading', u'names', u'statute', u'legislative', u'bill', u'give', u'brief', u'summary', u'matters', u'deals', u'act', u'creating', u'written', u'works', u'condition', u'mostly', u'boys', u'characterized', u'behavioral', u'learning', u'disorders', u'five', u'related', u'nonmetallic', u'elements', u'fluorine', u'chlorine', u'bromine', u'iodine', u'astatine', u'monovalent', u'readily', u'form', u'negative', u'ions', u'member', u'mixed', u'Dravidian', u'Caucasian', u'people', u'southern', u'India', u'Sri', u'Lanka', u'deviating', u'widely', u'norm', u'physical', u'mental', u'ability', u'used', u'especially', u'children', u'normal', u'intelligence', u'category', u'things', u'distinguished', u'common', u'characteristic', u'quality', u'indentation', u'shoreline', u'larger', u'cove', u'smaller', u'gulf', u'student', u'certain', u'subject', u'logical', u'consequence', u'unit', u'length', u'equal', u'1,760', u'yards', u'5,280', u'feet', u'exactly', u'1609.344', u'meters', u'lacking', u'stability', u'fixity', u'firmness', u'advertisement', u'usually', u'printed', u'page', u'leaflet', u'intended', u'wide', u'distribution', u'voice', u'faint', u'plural', u'group', u'human', u'beings', u'men', u'women', u'children', u'collectively', u'similar', u'things', u'placed', u'order', u'happening', u'one', u'another', u'personal', u'view', u'monotheistic', u'system', u'beliefs', u'practices', u'based', u'Old', u'Testament', u'teachings', u'Jesus', u'embodied', u'New', u'Testament', u'emphasizing', u'role', u'Jesus', u'savior', u'particular', u'society', u'particular', u'time', u'place', u'basic', u'unit', u'length', u'adopted', u'Systeme', u'International', u"d'Unites", u'approximately', u'1.094', u'yards', u'special', u'offering', u'usually', u'temporary', u'reduced', u'price', u'featured', u'advertising', u'pertaining', u'characteristic', u'Judaism', u'line', u'determining', u'limits', u'area', u'entire', u'structure', u'organism', u'animal', u'plant', u'human', u'prominent', u'status', u'person', u'thing', u'equal', u'another', u'value', u'measure', u'force', u'effect', u'significance', u'etc', u'soft', u'silvery-white', u'tetravalent', u'radioactive', u'metallic', u'element', u'isotope', u'232', u'used', u'power', u'source', u'nuclear', u'reactors', u'occurs', u'thorite', u'monazite', u'sands', u'make', u'clear', u'comprehensible', u'restore', u'replacing', u'part', u'putting', u'together', u'torn', u'broken', u'extended', u'spatial', u'location', u'something', u'gradual', u'decrease', u'stored', u'charge', u'current', u'person', u'equal', u'standing', u'another', u'group', u'linear', u'extent', u'space', u'one', u'end', u'longest', u'dimension', u'something', u'fixed', u'place', u'normal', u'conditions', u'cardinal', u'number', u'product', u'10', u'100', u'previous', u'time', u'amount', u'something', u'available', u'use', u'amount', u'time', u'high', u'degree', u'extent', u'favorably', u'much', u'respect', u'vague', u'clearly', u'defined', u'stated', u'division', u'quantity', u'accepted', u'standard', u'measurement', u'exchange', u'large', u'densely', u'populated', u'urban', u'area', u'include', u'several', u'independent', u'administrative', u'districts', u'assumption', u'taken', u'granted', u'particular', u'geographical', u'region', u'indefinite', u'boundary', u'usually', u'serving', u'special', u'purpose', u'distinguished', u'people', u'culture', u'geography', u'large', u'unbroken', u'expanse', u'distance', u'bishop', u'highest', u'rank', u'result', u'obtained', u'end', u'achieved', u'relating', u'concerned', u'city', u'densely', u'populated', u'area', u'organization', u'governing', u'authority', u'political', u'unit', u'continuing', u'time', u'space', u'without', u'interruption', u'film', u'life', u'western', u'United', u'States', u'period', u'exploration', u'development', u'fact', u'part', u'opposed', u'general', u'still', u'existence', u'extinct', u'destroyed', u'lost', u'record', u'narrative', u'description', u'past', u'events', u'man', u'older', u'higher', u'rank', u'lying', u'toward', u'situated', u'east', u'one', u'groups', u'Christians', u'beliefs', u'forms', u'worship', u'regard', u'social', u'relationships', u'involving', u'authority', u'mark', u'different', u'function', u'topological', u'space', u'gives', u'two', u'points', u'space', u'value', u'equal', u'distance', u'usually', u'describes', u'large', u'person', u'fat', u'large', u'frame', u'carry', u'plan', u'direct', u'complex', u'undertaking', u'substance', u'metabolized', u'animal', u'give', u'energy', u'build', u'tissue', u'senior', u'member', u'Christian', u'clergy', u'spiritual', u'administrative', u'authority', u'appointed', u'Christian', u'churches', u'oversee', u'priests', u'ministers', u'considered', u'churches', u'successors', u'twelve', u'Apostles', u'Christ', u'movable', u'possession', u'especially', u'articles', u'clothing', u'owned', u'possession', u'heavy', u'toxic', u'silvery-white', u'radioactive', u'metallic', u'element', u'occurs', u'many', u'isotopes', u'used', u'nuclear', u'fuels', u'nuclear', u'weapons', u'extended', u'verbal', u'expression', u'speech', u'writing', u'act', u'delivering', u'formal', u'spoken', u'communication', u'audience', u'small', u'part', u'considered', u'separately', u'whole', u'relating', u'science', u'geography', u'capital', u'raised', u'corporation', u'issue', u'shares', u'entitling', u'holders', u'ownership', u'interest', u'equity', u'commodities', u'offered', u'sale', u'put', u'service', u'make', u'work', u'employ', u'particular', u'purpose', u'inherent', u'natural', u'purpose', u'particular', u'point', u'time', u'anticipated', u'outcome', u'intended', u'guides', u'planned', u'actions', u'one', u'several', u'parts', u'pieces', u'fit', u'others', u'constitute', u'whole', u'object', u'base', u'hit', u'batter', u'stops', u'safely', u'first', u'base', u'exhibiting', u'caused', u'radioactivity', u'event', u'happens', u'trace', u'point', u'whose', u'direction', u'motion', u'changes', u'mentally', u'emotionally', u'stable', u'abstract', u'part', u'something', u'human', u'general', u'estimation', u'public', u'person', u'instance', u'single', u'occasion', u'event', u'particular', u'portion', u'space', u'occupied', u'something']
prevlevelsynsets: [Synset('unit_of_measurement.n.01'), Synset('city.n.01'), Synset('given.n.01'), Synset('area.n.01'), Synset('stretch.n.01'), Synset('archbishop.n.01'), Synset('means.n.01'), Synset('urban.a.01'), Synset('government.n.01'), Synset('continuous.a.01'), Synset('western.n.01'), Synset('particular.n.01'), Synset('extant.a.01'), Synset('history.n.01'), Synset('patriarch.n.01'), Synset('eastern.s.01'), Synset('church.n.01'), Synset('politically.r.01'), Synset('helping.n.01'), Synset('distinguish.v.01'), Synset('tamil_nadu.n.01'), Synset('bengal.n.01'), Synset('metric_function.n.01'), Synset('include.v.01'), Synset('being.n.01'), Synset('geography.n.01'), Synset('fleshy.s.01'), Synset('originator.n.01'), Synset('group.n.01'), Synset('food.n.01'), Synset('title.n.01'), Synset('bishop.n.01'), Synset('writing.n.01'), Synset('things.n.01'), Synset('attention_deficit_disorder.n.01'), Synset('belong.v.01'), Synset('halogen.n.01'), Synset('uranium.n.01'), Synset('discourse.n.01'), Synset('tamil.n.01'), Synset('address.n.01'), Synset('exceeding.s.01'), Synset('detail.n.01'), Synset('geographic.a.01'), Synset('kind.n.01'), Synset('bay.n.01'), Synset('stock.n.01'), Synset('learn.v.01'), Synset('merchandise.n.01'), Synset('use.n.01'), Synset('moment.n.01'), Synset('entail.n.01'), Synset('purpose.n.01'), Synset('section.n.01'), Synset('mile.n.01'), Synset('unstable.a.01'), Synset('single.n.01'), Synset('radioactive.a.01'), Synset('circular.n.01'), Synset('happening.n.01'), Synset('curve.n.01'), Synset('little.n.01'), Synset('together.s.01'), Synset('people.n.01'), Synset('series.n.01'), Synset('component.n.01'), Synset('person.n.01'), Synset('repute.n.01'), Synset('idea.n.01'), Synset('christianity.n.01'), Synset('culture.n.01'), Synset('meter.n.01'), Synset('special.n.01'), Synset('orthodox.a.01'), Synset('time.n.01'), Synset('boundary.n.01'), Synset('position.n.01'), Synset('body.n.01'), Synset('importance.n.01'), Synset('equivalent.n.01'), Synset('thorium.n.01'), Synset('clarify.v.01'), Synset('repair.n.01'), Synset('region.n.01'), Synset('decay.n.01'), Synset('peer.n.01'), Synset('length.n.01'), Synset('normally.r.01'), Synset('thousand.n.01'), Synset('once.r.01'), Synset('supply.n.01'), Synset('time_period.n.01'), Synset('highly.r.01'), Synset('indefinite.a.01')]
defaultdict(<type 'list'>, {u'serving': [u'None', u'area'], u'Madras': [u'Chennai', u'Chennai', u'None'], u'Bengal': [u'Chennai', u'Chennai', u'None'], u'including': [u'None', u'present', u'None'], u'existence': [u'None', u'None', u'exist'], u'geography': [u'None', u'area'], u'group': [u'None', u'set', u'None'], u'title': [u'None', u'metropolitan'], u'writing': [u'None', u'None', u'elaborate'], u'add': [u'None', u'None', u'elaborate'], u'halogen': [u'None', u'astatine', u'None'], u'Tamil': [u'Chennai', u'Chennai', u'None'], u'exceptional': [u'None', u'giant', u'None'], u'kind': [u'None', u'set', u'None'], u'Bay': [u'Chennai', u'Chennai', u'None'], u'boundary': [u'None', u'area', u'town'], u'miles': [u'kilometer', u'None', u'kilometer'], u'unstable': [u'None', u'astatine', u'None'], u'circular': [u'None', u'bend', u'None'], u'smaller': [u'None', u'None', u'town'], u'people': [u'None', u'area'], u'series': [u'None', u'astatine', u'None'], u'idea': [u'None', u'None', u'elaborate'], u'Christianity': [u'None', u'metropolitan'], u'culture': [u'None', u'area'], u'meters': [u'kilometer', u'None', u'kilometer'], u'special': [u'None', u'area'], u'0.621371': [u'kilometer', u'None', u'kilometer'], u'Orthodox': [u'None', u'metropolitan'], u'learned': [u'None', u'None', u'elaborate'], u'body': [u'None', u'None'], u'importance': [u'None', u'giant', u'None'], u'equivalent': [u'None', u'metropolitan'], u'thorium': [u'None', u'astatine', u'None'], u'clarify': [u'None', u'None', u'elaborate'], u'fixed': [u'None', u'None', u'town'], u'region': [u'None', u'area'], u'decay': [u'None', u'astatine', u'None'], u'meaning': [u'None', u'None', u'elaborate'], u'length': [u'kilometer', u'None', u'kilometer'], u'usually': [u'None', u'area', u'elaborate'], u'1000': [u'kilometer', u'None', u'kilometer'], u'formerly': [u'Chennai', u'Chennai', u'None'], u'supply': [u'None', u'None', u'commissariat'], u'period': [u'None', u'present', u'None'], u'highly': [u'None', u'astatine', u'None'], u'indefinite': [u'None', u'area'], u'unit': [u'kilometer', u'None', u'kilometer'], u'city': [u'Chennai', u'Chennai', u'None', u'town'], u'given': [u'None', u'metropolitan'], u'area': [u'None', u'None', u'town'], u'stretch': [u'None', u'present', u'None'], u'archbishop': [u'None', u'metropolitan'], u'way': [u'None', u'None', u'elaborate'], u'urban': [u'None', u'None', u'town'], u'government': [u'None', u'None'], u'continuous': [u'None', u'present', u'None'], u'western': [u'None', u'metropolitan'], u'particular': [u'None', u'area'], u'extant': [u'None', u'None', u'exist'], u'account': [u'None', u'None', u'elaborate'], u'patriarch': [u'None', u'metropolitan'], u'Eastern': [u'None', u'metropolitan'], u'Church': [u'None', u'metropolitan'], u'politically': [u'None', u'None'], u'distinguished': [u'None', u'area'], u'metric': [u'kilometer', u'None', u'kilometer'], u'heaviest': [u'None', u'astatine', u'None'], u'organized': [u'None', u'None'], u'equal': [u'kilometer', u'None', u'kilometer'], u'foods': [u'None', u'None', u'commissariat'], u'bishop': [u'None', u'metropolitan'], u'things': [u'None', u'set', u'None'], u'belong': [u'None', u'set', u'None'], u'uranium': [u'None', u'astatine', u'None'], u'discourse': [u'None', u'None', u'elaborate'], u'speech': [u'None', u'present', u'None'], u'details': [u'None', u'None', u'elaborate'], u'geographical': [u'None', u'area'], u'Nadu': [u'Chennai', u'Chennai', u'None'], u'stock': [u'None', u'None', u'commissariat'], u'product': [u'None', u'astatine', u'None'], u'used': [u'None', u'set', u'None'], u'moment': [u'None', u'present', u'None'], u'purpose': [u'None', u'area'], u'segment': [u'None', u'bend', u'None'], u'single': [u'None', u'None'], u'radioactive': [u'None', u'astatine', u'None'], u'happening': [u'None', u'present', u'None'], u'curve': [u'None', u'bend', u'None'], u'together': [u'None', u'set', u'None'], u'element': [u'None', u'astatine', u'None'], u'person': [u'None', u'giant', u'None'], u'reputation': [u'None', u'giant', u'None'], u'time': [u'None', u'present', u'None'], u'position': [u'None', u'metropolitan']})
ksynset= Synset('helping.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('helping.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('tamil_nadu.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('tamil_nadu.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('tamil_nadu.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('bengal.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('bengal.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('bengal.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('include.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('include.v.01')
lsynset= Synset('present.n.01')
ksynset= Synset('include.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('being.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('being.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('being.n.01')
lsynset= Synset('exist.v.01')
ksynset= Synset('geography.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('geography.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('group.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('group.n.01')
lsynset= Synset('set.n.01')
ksynset= Synset('group.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('title.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('title.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('writing.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('writing.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('writing.n.01')
lsynset= Synset('elaborate.v.01')
ksynset= Synset('attention_deficit_disorder.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('attention_deficit_disorder.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('attention_deficit_disorder.n.01')
lsynset= Synset('elaborate.v.01')
ksynset= Synset('halogen.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('halogen.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('halogen.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('tamil.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('tamil.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('tamil.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('exceeding.s.01')
lsynset= Synset('none.n.01')
ksynset= Synset('exceeding.s.01')
lsynset= Synset('giant.n.01')
ksynset= Synset('exceeding.s.01')
lsynset= Synset('none.n.01')
ksynset= Synset('kind.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('kind.n.01')
lsynset= Synset('set.n.01')
ksynset= Synset('kind.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('bay.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('bay.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('bay.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('boundary.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('boundary.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('boundary.n.01')
lsynset= Synset('town.n.01')
ksynset= Synset('mile.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('mile.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('mile.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('unstable.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('unstable.a.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('unstable.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('circular.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('circular.n.01')
lsynset= Synset('bend.n.01')
ksynset= Synset('circular.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('smaller.s.01')
lsynset= Synset('none.n.01')
ksynset= Synset('smaller.s.01')
lsynset= Synset('none.n.01')
ksynset= Synset('smaller.s.01')
lsynset= Synset('town.n.01')
ksynset= Synset('people.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('people.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('series.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('series.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('series.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('idea.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('idea.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('idea.n.01')
lsynset= Synset('elaborate.v.01')
ksynset= Synset('christianity.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('christianity.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('culture.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('culture.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('meter.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('meter.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('meter.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('special.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('special.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('orthodox.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('orthodox.a.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('learn.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('learn.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('learn.v.01')
lsynset= Synset('elaborate.v.01')
ksynset= Synset('body.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('body.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('importance.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('importance.n.01')
lsynset= Synset('giant.n.01')
ksynset= Synset('importance.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('equivalent.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('equivalent.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('thorium.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('thorium.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('thorium.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('clarify.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('clarify.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('clarify.v.01')
lsynset= Synset('elaborate.v.01')
ksynset= Synset('repair.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('repair.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('repair.v.01')
lsynset= Synset('town.n.01')
ksynset= Synset('region.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('region.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('decay.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('decay.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('decay.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('meaning.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('meaning.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('meaning.n.01')
lsynset= Synset('elaborate.v.01')
ksynset= Synset('length.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('length.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('length.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('normally.r.01')
lsynset= Synset('none.n.01')
ksynset= Synset('normally.r.01')
lsynset= Synset('area.n.01')
ksynset= Synset('normally.r.01')
lsynset= Synset('elaborate.v.01')
ksynset= Synset('thousand.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('thousand.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('thousand.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('once.r.03')
lsynset= Synset('chennai.n.01')
ksynset= Synset('once.r.03')
lsynset= Synset('chennai.n.01')
ksynset= Synset('once.r.03')
lsynset= Synset('none.n.01')
ksynset= Synset('supply.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('supply.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('supply.n.01')
lsynset= Synset('commissariat.n.01')
ksynset= Synset('time_period.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('time_period.n.01')
lsynset= Synset('present.n.01')
ksynset= Synset('time_period.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('highly.r.01')
lsynset= Synset('none.n.01')
ksynset= Synset('highly.r.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('highly.r.01')
lsynset= Synset('none.n.01')
ksynset= Synset('indefinite.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('indefinite.a.01')
lsynset= Synset('area.n.01')
ksynset= Synset('unit_of_measurement.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('unit_of_measurement.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('unit_of_measurement.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('city.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('city.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('city.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('city.n.01')
lsynset= Synset('town.n.01')
ksynset= Synset('given.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('given.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('area.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('area.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('area.n.01')
lsynset= Synset('town.n.01')
ksynset= Synset('stretch.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('stretch.n.01')
lsynset= Synset('present.n.01')
ksynset= Synset('stretch.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('archbishop.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('archbishop.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('manner.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('manner.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('manner.n.01')
lsynset= Synset('elaborate.v.01')
ksynset= Synset('urban.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('urban.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('urban.a.01')
lsynset= Synset('town.n.01')
ksynset= Synset('government.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('government.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('continuous.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('continuous.a.01')
lsynset= Synset('present.n.01')
ksynset= Synset('continuous.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('western.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('western.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('particular.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('particular.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('extant.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('extant.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('extant.a.01')
lsynset= Synset('exist.v.01')
ksynset= Synset('history.n.02')
lsynset= Synset('none.n.01')
ksynset= Synset('history.n.02')
lsynset= Synset('none.n.01')
ksynset= Synset('history.n.02')
lsynset= Synset('elaborate.v.01')
ksynset= Synset('patriarch.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('patriarch.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('eastern.s.01')
lsynset= Synset('none.n.01')
ksynset= Synset('eastern.s.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('church.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('church.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('politically.r.01')
lsynset= Synset('none.n.01')
ksynset= Synset('politically.r.01')
lsynset= Synset('none.n.01')
ksynset= Synset('distinguish.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('distinguish.v.01')
lsynset= Synset('area.n.01')
ksynset= Synset('metric_function.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('metric_function.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('metric_function.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('heavy.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('heavy.a.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('heavy.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('form.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('form.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('peer.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('peer.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('peer.n.01')
lsynset= Synset('kilometer.n.01')
ksynset= Synset('food.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('food.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('food.n.01')
lsynset= Synset('commissariat.n.01')
ksynset= Synset('bishop.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('bishop.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('things.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('things.n.01')
lsynset= Synset('set.n.01')
ksynset= Synset('things.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('belong.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('belong.v.01')
lsynset= Synset('set.n.01')
ksynset= Synset('belong.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('uranium.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('uranium.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('uranium.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('discourse.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('discourse.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('discourse.n.01')
lsynset= Synset('elaborate.v.01')
ksynset= Synset('address.n.03')
lsynset= Synset('none.n.01')
ksynset= Synset('address.n.03')
lsynset= Synset('present.n.01')
ksynset= Synset('address.n.03')
lsynset= Synset('none.n.01')
ksynset= Synset('details.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('details.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('details.n.01')
lsynset= Synset('elaborate.v.01')
ksynset= Synset('geographic.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('geographic.a.01')
lsynset= Synset('area.n.01')
ksynset= Synset('stock.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('stock.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('stock.n.01')
lsynset= Synset('commissariat.n.01')
ksynset= Synset('merchandise.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('merchandise.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('merchandise.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('use.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('use.v.01')
lsynset= Synset('set.n.01')
ksynset= Synset('use.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('moment.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('moment.n.01')
lsynset= Synset('present.n.01')
ksynset= Synset('moment.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('purpose.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('purpose.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('section.n.04')
lsynset= Synset('none.n.01')
ksynset= Synset('section.n.04')
lsynset= Synset('bend.n.01')
ksynset= Synset('section.n.04')
lsynset= Synset('none.n.01')
ksynset= Synset('single.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('single.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('radioactive.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('radioactive.a.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('radioactive.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('happening.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('happening.n.01')
lsynset= Synset('present.n.01')
ksynset= Synset('happening.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('curve.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('curve.n.01')
lsynset= Synset('bend.n.01')
ksynset= Synset('curve.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('together.s.01')
lsynset= Synset('none.n.01')
ksynset= Synset('together.s.01')
lsynset= Synset('set.n.01')
ksynset= Synset('together.s.01')
lsynset= Synset('none.n.01')
ksynset= Synset('component.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('component.n.01')
lsynset= Synset('astatine.n.01')
ksynset= Synset('component.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('person.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('person.n.01')
lsynset= Synset('giant.n.01')
ksynset= Synset('person.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('repute.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('repute.n.01')
lsynset= Synset('giant.n.01')
ksynset= Synset('repute.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('time.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('time.n.01')
lsynset= Synset('present.n.01')
ksynset= Synset('time.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('position.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('position.n.01')
lsynset= Synset('metropolitan.n.01')
Core number (sorted) : [(u'None', 96), (u'area', 16), (u'metropolitan', 12), (u'astatine', 11), (u'elaborate', 11), (u'kilometer', 8), (u'present', 8), (u'Chennai', 7), (u'town', 7), (u'boundary', 6), (u'set', 6), (u'usually', 6), (u'city', 6), (u'serving', 4), (u'Madras', 4), (u'Bengal', 4), (u'including', 4), (u'existence', 4), (u'geography', 4), (u'giant', 4), (u'group', 4), (u'decay', 4), (u'commissariat', 4), (u'writing', 4), (u'add', 4), (u'halogen', 4), (u'circular', 4), (u'Tamil', 4), (u'kind', 4), (u'Bay', 4), (u'meaning', 4), (u'miles', 4), (u'unstable', 4), (u'fixed', 4), (u'people', 4), (u'series', 4), (u'idea', 4), (u'Christianity', 4), (u'culture', 4), (u'meters', 4), (u'special', 4), (u'0.621371', 4), (u'Orthodox', 4), (u'learned', 4), (u'importance', 4), (u'equivalent', 4), (u'thorium', 4), (u'clarify', 4), (u'region', 4), (u'title', 4), (u'equal', 4), (u'length', 4), (u'1000', 4), (u'formerly', 4), (u'supply', 4), (u'period', 4), (u'highly', 4), (u'smaller', 4), (u'indefinite', 4), (u'unit', 4), (u'given', 4), (u'stretch', 4), (u'archbishop', 4), (u'way', 4), (u'urban', 4), (u'continuous', 4), (u'western', 4), (u'particular', 4), (u'extant', 4), (u'account', 4), (u'patriarch', 4), (u'Eastern', 4), (u'Church', 4), (u'distinguished', 4), (u'metric', 4), (u'heaviest', 4), (u'foods', 4), (u'exist', 4), (u'bend', 4), (u'bishop', 4), (u'things', 4), (u'exceptional', 4), (u'uranium', 4), (u'discourse', 4), (u'speech', 4), (u'details', 4), (u'geographical', 4), (u'belong', 4), (u'Nadu', 4), (u'stock', 4), (u'product', 4), (u'used', 4), (u'moment', 4), (u'purpose', 4), (u'segment', 4), (u'radioactive', 4), (u'happening', 4), (u'curve', 4), (u'together', 4), (u'element', 4), (u'person', 4), (u'reputation', 4), (u'time', 4), (u'position', 4), (u'government', 2), (u'body', 2), (u'politically', 2), (u'organized', 2), (u'single', 2)]
=============================================================================================================
Unsupervised Classification based on top percentile Core numbers of the definition graph(subgraph of WordNet)
=============================================================================================================
This document belongs to class: None ,core number= 96
This document belongs to class: area ,core number= 16
This document belongs to class: metropolitan ,core number= 12
This document belongs to class: astatine ,core number= 11
This document belongs to class: elaborate ,core number= 11
This document belongs to class: kilometer ,core number= 8
This document belongs to class: present ,core number= 8
This document belongs to class: Chennai ,core number= 7
This document belongs to class: town ,core number= 7
This document belongs to class: boundary ,core number= 6
This document belongs to class: set ,core number= 6
This document belongs to class: usually ,core number= 6
max_core_number 96
===================================================================
Page Rank of the vertices of RGO Definition Graph
===================================================================
[(u'None', 0.230858133575477), (u'area', 0.03499398637330704), (u'metropolitan', 0.029461772285998233), (u'astatine', 0.027186161032418922), (u'elaborate', 0.026847116384274367), (u'kilometer', 0.020359327271681004), (u'present', 0.020359327271681004), (u'Chennai', 0.01776756083961414), (u'set', 0.01580810476452239), (u'town', 0.014654554961844072), (u'giant', 0.011256882257363779), (u'bend', 0.008981271003784472), (u'commissariat', 0.00898127100378447), (u'city', 0.007654358889837709), (u'boundary', 0.007479767627376233), (u'usually', 0.0074783628613798074), (u'exist', 0.006705659750205164), (u'existence', 0.006270588877431641), (u'extant', 0.006270588877431641), (u'segment', 0.005965376934668208), (u'supply', 0.005965376934668208), (u'stock', 0.005965376934668208), (u'foods', 0.005965376934668208), (u'circular', 0.005965376934668207), (u'curve', 0.005965376934668207), (u'exceptional', 0.005812770963286492), (u'importance', 0.005812770963286492), (u'person', 0.005812770963286492), (u'reputation', 0.005812770963286492), (u'group', 0.005660164991904774), (u'kind', 0.005660164991904774), (u'things', 0.005660164991904774), (u'belong', 0.005660164991904774), (u'used', 0.005660164991904774), (u'together', 0.005660164991904774), (u'including', 0.005583862006213917), (u'miles', 0.005583862006213917), (u'meters', 0.005583862006213917), (u'0.621371', 0.005583862006213917), (u'equal', 0.005583862006213917), (u'length', 0.005583862006213917), (u'1000', 0.005583862006213917), (u'period', 0.005583862006213917), (u'unit', 0.005583862006213917), (u'stretch', 0.005583862006213917), (u'continuous', 0.005583862006213917), (u'moment', 0.005583862006213917), (u'metric', 0.005583862006213917), (u'speech', 0.005583862006213917), (u'happening', 0.005583862006213917), (u'time', 0.005583862006213917), (u'Madras', 0.005578162798434741), (u'Bengal', 0.005578162798434741), (u'Tamil', 0.005578162798434741), (u'Bay', 0.005578162798434741), (u'formerly', 0.005578162798434741), (u'Nadu', 0.005578162798434741), (u'decay', 0.00552143229064867), (u'halogen', 0.00552143229064867), (u'unstable', 0.00552143229064867), (u'series', 0.00552143229064867), (u'thorium', 0.005521432290648669), (u'highly', 0.005521432290648669), (u'heaviest', 0.005521432290648669), (u'uranium', 0.005521432290648669), (u'product', 0.005521432290648669), (u'radioactive', 0.005521432290648669), (u'element', 0.005521432290648669), (u'Christianity', 0.005507559020523059), (u'Orthodox', 0.005507559020523059), (u'equivalent', 0.005507559020523059), (u'title', 0.005507559020523059), (u'given', 0.005507559020523059), (u'archbishop', 0.005507559020523059), (u'western', 0.005507559020523059), (u'patriarch', 0.005507559020523059), (u'Eastern', 0.005507559020523059), (u'Church', 0.005507559020523059), (u'bishop', 0.0055075590205230585), (u'position', 0.0055075590205230585), (u'fixed', 0.0054966320869906955), (u'smaller', 0.0054966320869906955), (u'urban', 0.0054966320869906955), (u'writing', 0.00549522732099427), (u'add', 0.00549522732099427), (u'learned', 0.00549522732099427), (u'idea', 0.00549522732099427), (u'clarify', 0.00549522732099427), (u'way', 0.00549522732099427), (u'account', 0.00549522732099427), (u'discourse', 0.0054952273209942695), (u'details', 0.0054952273209942695), (u'meaning', 0.0054952273209942695), (u'serving', 0.005403571535973265), (u'geography', 0.005403571535973265), (u'people', 0.005403571535973265), (u'culture', 0.005403571535973265), (u'special', 0.005403571535973265), (u'region', 0.005403571535973265), (u'indefinite', 0.005403571535973265), (u'particular', 0.005403571535973265), (u'distinguished', 0.005403571535973265), (u'geographical', 0.005403571535973265), (u'purpose', 0.005403571535973265), (u'body', 0.003420435995587728), (u'politically', 0.003420435995587728), (u'organized', 0.003420435995587728), (u'government', 0.003420435995587728), (u'single', 0.003420435995587728)]
==========================================================================================================
Alternative Quantitative Intrinsic Merit  - connectivity of RGO Definition Graph - Mengers Theorem
==========================================================================================================
1
==========================================================================================================
Alternative Quantitative Intrinsic Merit  - Maxflow-Mincut of RGO Definition Graph - Minimum Edge Cut
==========================================================================================================
set([(u'single', u'None')])
==========================================================================================================
Alternative Quantitative Intrinsic Merit  - Maxflow-Mincut of RGO Definition Graph - Stoer-Wagner
==========================================================================================================
16/02/05 17:11:16 INFO ShutdownHookManager: Shutdown hook called
16/02/05 17:11:16 INFO ShutdownHookManager: Deleting directory /tmp/spark-dadd0e29-0794-4c88-9906-5a3b1e594e2c/pyspark-96a94faa-083d-432c-a26b-8323418b2a68
16/02/05 17:11:16 INFO ShutdownHookManager: Deleting directory /tmp/spark-dadd0e29-0794-4c88-9906-5a3b1e594e2c/pyspark-f8d53121-5d22-4e7a-9dd8-569a51df7383
16/02/05 17:11:16 INFO ShutdownHookManager: Deleting directory /tmp/spark-dadd0e29-0794-4c88-9906-5a3b1e594e2c/pyspark-3979642c-d39a-42e1-ac91-2da80217fcce

