mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'of', u'highest', u'bishop', u'rank'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: sum
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'a', u'of', u'money', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: expressed
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'to', u'expression', u'give'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): geographical
mapFunction_Parents(): keyword: geographical ; prevleveltokens: geographical
mapFunction_Parents(): keyword= geographical ; syndef_tokens= set([u'science', u'or', u'to', u'of', u'relating', u'the', u'geography'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/25 13:52:51 INFO PythonRunner: Times: total = 8816, boot = 502, init = 390, finish = 7924
16/03/25 13:52:51 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/25 13:52:51 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 8.934 s
16/03/25 13:52:51 INFO DAGScheduler: looking for newly runnable stages
16/03/25 13:52:51 INFO DAGScheduler: running: Set()
16/03/25 13:52:51 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/25 13:52:51 INFO DAGScheduler: failed: Set()
16/03/25 13:52:51 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/25 13:52:51 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which is now runnable
16/03/25 13:52:51 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11160, maxMem=555755765
16/03/25 13:52:51 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 530.0 MB)
16/03/25 13:52:51 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16144, maxMem=555755765
16/03/25 13:52:51 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8949 ms on localhost (2/2)
16/03/25 13:52:51 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/25 13:52:51 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 530.0 MB)
16/03/25 13:52:51 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:52110 (size: 3.0 KB, free: 530.0 MB)
16/03/25 13:52:51 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/25 13:52:51 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:52:51 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/25 13:52:51 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:52:51 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:52:51 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/25 13:52:51 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:52:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/25 13:52:51 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/25 13:52:51 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:52:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
reduceFunction_Parents(): returns= ['None', u'area', 'None']
16/03/25 13:52:51 INFO PythonRunner: Times: total = 21, boot = -157, init = 178, finish = 0
16/03/25 13:52:51 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1280 bytes result sent to driver
16/03/25 13:52:51 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 55 ms on localhost (1/2)
16/03/25 13:52:51 INFO PythonRunner: Times: total = 218, boot = 217, init = 1, finish = 0
16/03/25 13:52:51 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/25 13:52:51 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.229 s
16/03/25 13:52:51 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 9.249262 s
16/03/25 13:52:51 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 240 ms on localhost (2/2)
16/03/25 13:52:51 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/25 13:52:51 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:52:51 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:52:51 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:52:51 INFO DAGScheduler: Parents of final stage: List()
16/03/25 13:52:51 INFO DAGScheduler: Missing parents: List()
16/03/25 13:52:51 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:52:52 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19199, maxMem=555755765
16/03/25 13:52:52 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 530.0 MB)
16/03/25 13:52:52 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25015, maxMem=555755765
16/03/25 13:52:52 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 530.0 MB)
16/03/25 13:52:52 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:52110 (size: 3.3 KB, free: 530.0 MB)
16/03/25 13:52:52 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/25 13:52:52 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:52:52 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/25 13:52:52 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/25 13:52:52 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2361 bytes)
16/03/25 13:52:52 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/25 13:52:52 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/25 13:52:52 INFO PythonRunner: Times: total = 51, boot = -72, init = 123, finish = 0
16/03/25 13:52:52 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/25 13:52:52 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 58 ms on localhost (1/2)
16/03/25 13:52:52 INFO PythonRunner: Times: total = 149, boot = 149, init = 0, finish = 0
16/03/25 13:52:52 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1348 bytes result sent to driver
16/03/25 13:52:52 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 161 ms on localhost (2/2)
16/03/25 13:52:52 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/25 13:52:52 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.151 s
16/03/25 13:52:52 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 0.175509 s
16/03/25 13:52:52 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/25 13:52:52 INFO DAGScheduler: Stopping DAGScheduler
16/03/25 13:52:52 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/25 13:52:52 INFO MemoryStore: MemoryStore cleared
16/03/25 13:52:52 INFO BlockManager: BlockManager stopped
16/03/25 13:52:52 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/25 13:52:52 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/25 13:52:52 INFO SparkContext: Successfully stopped SparkContext
16/03/25 13:52:52 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/25 13:52:52 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/25 13:52:52 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
graphcache_mapreduce_parents updated: defaultdict(<cyfunction <lambda> at 0xb1f81e6c>, {'4208c80be8e0c0d285fafd73cd5bd9a6': [u'metropolitan', u'None'], 'ed43ebbafa0c6204a5916ca879d5bd26': [u'None', u'area'], '2c49f1424d675552d9e7323a3eef6206': [u'None', u'expansion', u'None'], '44b9adf04881710b0a7c81b0a22b1209': [u'Chennai', u'None'], '45b800affe042d5d9a4228427680a935': [u'Chennai', u'None'], 'e9301955882d67edfb275156ef73113c': [u'metropolitan', u'None'], '552934a698e1bcf880132a2bd5996d11': [u'None', u'area', u'None'], '063da2002ba149bb4025d1e1fcfb49f5': [u'None', u'area', u'None'], 'b7b50c706678d48359a2ac685d535b33': [u'metropolitan', u'None'], '926a71600b58a41448b179d8665fd5df': [u'None', u'expansion', u'None'], 'a8f48eba5bb66d59263f478b93779a2c': [u'metropolitan', u'None'], 'e6ebeac0f1cb14fbd7b903291fcc6a8f': [u'metropolitan', u'None'], 'a31cc044ea8d13e6b1bf4e98768e44a5': [u'None', u'area', u'None'], '9f1808799460fd7b2da9ab51bd7b6775': [u'None', u'area', u'None'], 'd7b9ba5125de58e77ad31543f2c54034': [u'None', u'area', u'None'], 'b1318a4c6d13196fb45da6102d193223': [u'None', u'area', u'None', u'special'], '40603e72c50afb5b6be8a7ff1684c966': [u'Chennai', u'None', u'Madras']})
asfer_pickle_string_dump(): picklef.write(): boundary
16/03/25 13:52:53 INFO SparkContext: Running Spark version 1.5.2
16/03/25 13:52:53 INFO SecurityManager: Changing view acls to: root
16/03/25 13:52:53 INFO SecurityManager: Changing modify acls to: root
16/03/25 13:52:53 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/25 13:52:53 INFO Slf4jLogger: Slf4jLogger started
16/03/25 13:52:53 INFO Remoting: Starting remoting
16/03/25 13:52:53 INFO Utils: Successfully started service 'sparkDriver' on port 55468.
16/03/25 13:52:53 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:55468]
16/03/25 13:52:53 INFO SparkEnv: Registering MapOutputTracker
16/03/25 13:52:53 INFO SparkEnv: Registering BlockManagerMaster
16/03/25 13:52:53 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-d8bc3144-f54b-4f2a-9a39-c72e68cb3339
16/03/25 13:52:53 INFO MemoryStore: MemoryStore started with capacity 530.0 MB
16/03/25 13:52:53 INFO HttpFileServer: HTTP File server directory is /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/httpd-97117374-34c5-491b-b5c7-39f9dc531140
16/03/25 13:52:53 INFO HttpServer: Starting HTTP Server
16/03/25 13:52:53 INFO Utils: Successfully started service 'HTTP file server' on port 53283.
16/03/25 13:52:53 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/25 13:52:53 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/25 13:52:53 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/25 13:52:53 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/userFiles-bcdbb84e-0558-4df8-aa36-b7b31cd60417/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:52:53 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458894173458
16/03/25 13:52:53 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/25 13:52:53 INFO Executor: Starting executor ID driver on host localhost
16/03/25 13:52:53 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42395.
16/03/25 13:52:53 INFO NettyBlockTransferService: Server created on 42395
16/03/25 13:52:53 INFO BlockManagerMaster: Trying to register BlockManager
16/03/25 13:52:53 INFO BlockManagerMasterEndpoint: Registering block manager localhost:42395 with 530.0 MB RAM, BlockManagerId(driver, localhost, 42395)
16/03/25 13:52:53 INFO BlockManagerMaster: Registered BlockManager
16/03/25 13:52:53 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:52:53 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:52:53 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:52:53 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:52:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/25 13:52:53 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/25 13:52:53 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:52:53 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=555755765
16/03/25 13:52:53 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)
16/03/25 13:52:53 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=555755765
16/03/25 13:52:53 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)
16/03/25 13:52:53 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:42395 (size: 4.1 KB, free: 530.0 MB)
16/03/25 13:52:53 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/25 13:52:53 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:52:53 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/25 13:52:53 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2479 bytes)
16/03/25 13:52:53 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2471 bytes)
16/03/25 13:52:53 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/25 13:52:53 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458894173458
16/03/25 13:52:53 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/25 13:52:53 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/userFiles-bcdbb84e-0558-4df8-aa36-b7b31cd60417/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:52:53 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/25 13:52:53 INFO MemoryStore: ensureFreeSpace(216) called with curMem=10732, maxMem=555755765
16/03/25 13:52:53 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/25 13:52:53 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 216.0 B, free 530.0 MB)
16/03/25 13:52:53 INFO MemoryStore: ensureFreeSpace(218) called with curMem=10948, maxMem=555755765
16/03/25 13:52:53 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:42395 (size: 216.0 B, free: 530.0 MB)
16/03/25 13:52:53 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 218.0 B, free 530.0 MB)
16/03/25 13:52:53 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:42395 (size: 218.0 B, free: 530.0 MB)
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: special
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'a', u'and', u'temporary', u'offering', u'that', u')', u'(', u'price', u'featured', u'at', u'in', u'usually', u'is', u'reduced', u'special', u'advertising'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: geography
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'and', u'climate', u'topography', u"'s", u'responses', u'people', u'of', u'study', u'surface', u'includes', u'to', u'soil', u'earth', u'the', u';', u'vegetation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: city
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'a', u'and', u'districts', u'several', u'urban', u'may', u'populated', u'large', u'area', u'independent', u'densely', u';', u'include', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: given
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'for', u'that', u'is', u'an', u'assumption', u'taken', u'granted'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: Madras
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'a', u'on', u';', u'Madras', u'formerly', u')', u'of', u'India', u'Bay', u'state', u'Andhra', u'(', u'in', u'the', u'Bengal', u'Pradesh', u'southeastern', u'south'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: Eastern
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'east', u'situated', u'in', u'the', u'toward', u'or', u'lying'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: archbishop
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'a', u'of', u'highest', u'bishop', u'rank'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: sum
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'a', u'of', u'money', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: expressed
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'to', u'expression', u'give'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: geographical
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'science', u'or', u'to', u'of', u'relating', u'the', u'geography'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: boundary
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'a', u'limits', u'area', u'determining', u'an', u'of', u'line', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/25 13:53:02 INFO PythonRunner: Times: total = 8707, boot = 511, init = 368, finish = 7828
16/03/25 13:53:02 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/25 13:53:02 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8791 ms on localhost (1/2)
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: area
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  boundary  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: expansion
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'a', u'function', u'product', u'terms', u'of', u'sum', u'expressed', u'as', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: serving
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'a', u'food', u'of', u'drink', u'meal', u'an', u'as', u'individual', u'taken', u'part', u'or', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: formerly
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'a', u';', u'time', u'at', u'previous'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: people
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'group', u')', u'(', u'men', u'children', u'or', u'collectively', u'beings', u'human', u'of', u'plural', u'any', u'women'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: Christianity
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'a', u'and', u'monotheistic', u'based', u'embodied', u'on', u'New', u'of', u'in', u'system', u'Jesus', u'as', u'practices', u'role', u'emphasizing', u'teachings', u'Testament', u'Old', u'the', u'beliefs', u'savior'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: culture
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'a', u'and', u'particular', u'society', u'place', u'at', u'time'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: indefinite
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'or', u'stated', u'defined', u'clearly', u'not', u'vague'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): boundary
mapFunction_Parents(): keyword: boundary ; prevleveltokens: bishop
mapFunction_Parents(): keyword= boundary ; syndef_tokens= set([u'and', u'the', u'spiritual', u'Christ', u'twelve', u'some', u'authority', u'in', u'Christian', u'ministers', u'member', u'to', u'churches', u';', u'administrative', u'be', u'Apostles', u'appointed', u'a', u'oversee', u'of', u'priests', u'or', u'considered', u'clergy', u'senior', u'successors', u'having'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
16/03/25 13:53:02 INFO PythonRunner: Times: total = 8954, boot = 503, init = 449, finish = 8002
16/03/25 13:53:02 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/25 13:53:02 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 9.043 s
16/03/25 13:53:02 INFO DAGScheduler: looking for newly runnable stages
16/03/25 13:53:02 INFO DAGScheduler: running: Set()
16/03/25 13:53:02 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/25 13:53:02 INFO DAGScheduler: failed: Set()
16/03/25 13:53:02 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/25 13:53:02 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which is now runnable
16/03/25 13:53:02 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11166, maxMem=555755765
16/03/25 13:53:02 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 530.0 MB)
16/03/25 13:53:02 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16150, maxMem=555755765
16/03/25 13:53:02 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 530.0 MB)
16/03/25 13:53:02 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9030 ms on localhost (2/2)
16/03/25 13:53:02 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/25 13:53:02 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:42395 (size: 3.0 KB, free: 530.0 MB)
16/03/25 13:53:02 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/25 13:53:02 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:53:02 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/25 13:53:02 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:53:02 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:53:02 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/25 13:53:02 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/25 13:53:02 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:53:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/25 13:53:02 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:53:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
reduceFunction_Parents(): returns= ['None', u'area', 'None']
16/03/25 13:53:02 INFO PythonRunner: Times: total = 22, boot = -49, init = 71, finish = 0
16/03/25 13:53:02 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1280 bytes result sent to driver
16/03/25 13:53:02 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 51 ms on localhost (1/2)
16/03/25 13:53:02 INFO PythonRunner: Times: total = 233, boot = 233, init = 0, finish = 0
16/03/25 13:53:02 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/25 13:53:02 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 255 ms on localhost (2/2)
16/03/25 13:53:02 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.254 s
16/03/25 13:53:02 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 9.359687 s
16/03/25 13:53:02 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/25 13:53:03 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:53:03 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:53:03 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:53:03 INFO DAGScheduler: Parents of final stage: List()
16/03/25 13:53:03 INFO DAGScheduler: Missing parents: List()
16/03/25 13:53:03 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:53:03 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19205, maxMem=555755765
16/03/25 13:53:03 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 530.0 MB)
16/03/25 13:53:03 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25021, maxMem=555755765
16/03/25 13:53:03 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 530.0 MB)
16/03/25 13:53:03 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:42395 (size: 3.3 KB, free: 530.0 MB)
16/03/25 13:53:03 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/25 13:53:03 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:53:03 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/25 13:53:03 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/25 13:53:03 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2361 bytes)
16/03/25 13:53:03 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/25 13:53:03 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/25 13:53:03 INFO PythonRunner: Times: total = 65, boot = 64, init = 0, finish = 1
16/03/25 13:53:03 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/25 13:53:03 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 84 ms on localhost (1/2)
16/03/25 13:53:03 INFO PythonRunner: Times: total = 68, boot = -215, init = 283, finish = 0
16/03/25 13:53:03 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1348 bytes result sent to driver
16/03/25 13:53:03 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 88 ms on localhost (2/2)
16/03/25 13:53:03 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/25 13:53:03 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.091 s
16/03/25 13:53:03 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 0.133880 s
16/03/25 13:53:03 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/25 13:53:03 INFO DAGScheduler: Stopping DAGScheduler
16/03/25 13:53:03 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/25 13:53:03 INFO MemoryStore: MemoryStore cleared
16/03/25 13:53:03 INFO BlockManager: BlockManager stopped
16/03/25 13:53:03 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/25 13:53:03 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/25 13:53:03 INFO SparkContext: Successfully stopped SparkContext
16/03/25 13:53:03 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/25 13:53:03 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/25 13:53:03 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
graphcache_mapreduce_parents updated: defaultdict(<cyfunction <lambda> at 0xb1f81e6c>, {'4208c80be8e0c0d285fafd73cd5bd9a6': [u'metropolitan', u'None'], 'ed43ebbafa0c6204a5916ca879d5bd26': [u'None', u'area'], '2c49f1424d675552d9e7323a3eef6206': [u'None', u'expansion', u'None'], '44b9adf04881710b0a7c81b0a22b1209': [u'Chennai', u'None'], '45b800affe042d5d9a4228427680a935': [u'Chennai', u'None'], 'dd10336563a65a645a42bb416a6ebec6': [u'None', u'area', u'None'], 'e9301955882d67edfb275156ef73113c': [u'metropolitan', u'None'], '552934a698e1bcf880132a2bd5996d11': [u'None', u'area', u'None'], '063da2002ba149bb4025d1e1fcfb49f5': [u'None', u'area', u'None'], 'b7b50c706678d48359a2ac685d535b33': [u'metropolitan', u'None'], '926a71600b58a41448b179d8665fd5df': [u'None', u'expansion', u'None'], 'a8f48eba5bb66d59263f478b93779a2c': [u'metropolitan', u'None'], 'e6ebeac0f1cb14fbd7b903291fcc6a8f': [u'metropolitan', u'None'], 'a31cc044ea8d13e6b1bf4e98768e44a5': [u'None', u'area', u'None'], '9f1808799460fd7b2da9ab51bd7b6775': [u'None', u'area', u'None'], 'd7b9ba5125de58e77ad31543f2c54034': [u'None', u'area', u'None'], 'b1318a4c6d13196fb45da6102d193223': [u'None', u'area', u'None', u'special'], '40603e72c50afb5b6be8a7ff1684c966': [u'Chennai', u'None', u'Madras']})
asfer_pickle_string_dump(): picklef.write(): Tamil
16/03/25 13:53:04 INFO SparkContext: Running Spark version 1.5.2
16/03/25 13:53:04 INFO SecurityManager: Changing view acls to: root
16/03/25 13:53:04 INFO SecurityManager: Changing modify acls to: root
16/03/25 13:53:04 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/25 13:53:04 INFO Slf4jLogger: Slf4jLogger started
16/03/25 13:53:04 INFO Remoting: Starting remoting
16/03/25 13:53:04 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:46138]
16/03/25 13:53:04 INFO Utils: Successfully started service 'sparkDriver' on port 46138.
16/03/25 13:53:04 INFO SparkEnv: Registering MapOutputTracker
16/03/25 13:53:04 INFO SparkEnv: Registering BlockManagerMaster
16/03/25 13:53:04 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-749a1880-09ae-4a6d-aadf-264e00cb115c
16/03/25 13:53:04 INFO MemoryStore: MemoryStore started with capacity 530.0 MB
16/03/25 13:53:04 INFO HttpFileServer: HTTP File server directory is /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/httpd-aa348416-37af-483f-bee8-43d1a327310a
16/03/25 13:53:04 INFO HttpServer: Starting HTTP Server
16/03/25 13:53:04 INFO Utils: Successfully started service 'HTTP file server' on port 45045.
16/03/25 13:53:04 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/25 13:53:04 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/25 13:53:04 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/25 13:53:04 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/userFiles-66330d9b-66cc-4c1c-8ce6-01ac123931c2/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:53:04 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458894184550
16/03/25 13:53:04 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/25 13:53:04 INFO Executor: Starting executor ID driver on host localhost
16/03/25 13:53:04 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42735.
16/03/25 13:53:04 INFO NettyBlockTransferService: Server created on 42735
16/03/25 13:53:04 INFO BlockManagerMaster: Trying to register BlockManager
16/03/25 13:53:04 INFO BlockManagerMasterEndpoint: Registering block manager localhost:42735 with 530.0 MB RAM, BlockManagerId(driver, localhost, 42735)
16/03/25 13:53:04 INFO BlockManagerMaster: Registered BlockManager
16/03/25 13:53:04 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:53:04 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:53:04 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:53:04 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:53:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/25 13:53:04 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/25 13:53:04 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:53:04 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=555755765
16/03/25 13:53:04 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)
16/03/25 13:53:04 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=555755765
16/03/25 13:53:04 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)
16/03/25 13:53:04 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:42735 (size: 4.1 KB, free: 530.0 MB)
16/03/25 13:53:04 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/25 13:53:04 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:53:04 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/25 13:53:04 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2479 bytes)
16/03/25 13:53:04 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2500 bytes)
16/03/25 13:53:04 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/25 13:53:04 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458894184550
16/03/25 13:53:04 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/25 13:53:04 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/userFiles-66330d9b-66cc-4c1c-8ce6-01ac123931c2/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:53:04 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/25 13:53:04 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/25 13:53:04 INFO MemoryStore: ensureFreeSpace(218) called with curMem=10732, maxMem=555755765
16/03/25 13:53:04 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 218.0 B, free 530.0 MB)
16/03/25 13:53:04 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:42735 (size: 218.0 B, free: 530.0 MB)
16/03/25 13:53:04 INFO MemoryStore: ensureFreeSpace(245) called with curMem=10950, maxMem=555755765
16/03/25 13:53:04 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 245.0 B, free 530.0 MB)
16/03/25 13:53:04 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:42735 (size: 245.0 B, free: 530.0 MB)
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: special
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): adding to parents: syn =  Synset('chennai.n.01') ; keyword:  Tamil  in syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: area
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: expansion
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'a', u'function', u'product', u'terms', u'of', u'sum', u'expressed', u'as', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: serving
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'a', u'and', u'temporary', u'offering', u'that', u')', u'(', u'price', u'featured', u'at', u'in', u'usually', u'is', u'reduced', u'special', u'advertising'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: geography
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'and', u'climate', u'topography', u"'s", u'responses', u'people', u'of', u'study', u'surface', u'includes', u'to', u'soil', u'earth', u'the', u';', u'vegetation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: city
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'a', u'and', u'districts', u'several', u'urban', u'may', u'populated', u'large', u'area', u'independent', u'densely', u';', u'include', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: given
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'a', u'food', u'of', u'drink', u'meal', u'an', u'as', u'individual', u'taken', u'part', u'or', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: formerly
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'a', u';', u'time', u'at', u'previous'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: people
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'group', u')', u'(', u'men', u'children', u'or', u'collectively', u'beings', u'human', u'of', u'plural', u'any', u'women'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'for', u'that', u'is', u'an', u'assumption', u'taken', u'granted'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: Madras
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: Christianity
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'a', u'on', u';', u'Madras', u'formerly', u')', u'of', u'India', u'Bay', u'state', u'Andhra', u'(', u'in', u'the', u'Bengal', u'Pradesh', u'southeastern', u'south'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: Eastern
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'east', u'situated', u'in', u'the', u'toward', u'or', u'lying'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: archbishop
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'a', u'of', u'highest', u'bishop', u'rank'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: sum
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'a', u'of', u'money', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: expressed
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'a', u'and', u'monotheistic', u'based', u'embodied', u'on', u'New', u'of', u'in', u'system', u'Jesus', u'as', u'practices', u'role', u'emphasizing', u'teachings', u'Testament', u'Old', u'the', u'beliefs', u'savior'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: culture
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'to', u'expression', u'give'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: geographical
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'science', u'or', u'to', u'of', u'relating', u'the', u'geography'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: boundary
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'a', u'and', u'particular', u'society', u'place', u'at', u'time'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'a', u'limits', u'area', u'determining', u'an', u'of', u'line', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: Tamil
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: indefinite
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'a', u'and', u'people', u'of', u'Sri', u'southern', u'member', u'India', u'mixed', u'Dravidian', u'the', u'Lanka', u'Caucasian'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
mapFunction_Parents(): keyword= Tamil ; syndef_tokens= set([u'or', u'stated', u'defined', u'clearly', u'not', u'vague'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Tamil
mapFunction_Parents(): keyword: Tamil ; prevleveltokens: bishop
16/03/25 13:53:13 INFO PythonRunner: Times: total = 8695, boot = 508, init = 361, finish = 7826
mapFunction_Parents(): keyword=16/03/25 13:53:13 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
 Tamil ; syndef_tokens= set([u'and', u'the', u'spiritual', u'Christ', u'twelve', u'some', u'authority', u'in', u'Christian', u'ministers', u'member', u'to', u'churches', u';', u'administrative', u'be', u'Apostles', u'appointed', u'a', u'oversee', u'of', u'priests', u'or', u'considered', u'clergy', u'senior', u'successors', u'having'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
16/03/25 13:53:13 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8819 ms on localhost (1/2)
16/03/25 13:53:13 INFO PythonRunner: Times: total = 8729, boot = 515, init = 425, finish = 7789
16/03/25 13:53:13 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/25 13:53:13 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 8.871 s
16/03/25 13:53:13 INFO DAGScheduler: looking for newly runnable stages
16/03/25 13:53:13 INFO DAGScheduler: running: Set()
16/03/25 13:53:13 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/25 13:53:13 INFO DAGScheduler: failed: Set()
16/03/25 13:53:13 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/25 13:53:13 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which is now runnable
16/03/25 13:53:13 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11195, maxMem=555755765
16/03/25 13:53:13 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8883 ms on localhost (2/2)
16/03/25 13:53:13 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/25 13:53:13 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 530.0 MB)
16/03/25 13:53:13 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16179, maxMem=555755765
16/03/25 13:53:13 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 530.0 MB)
16/03/25 13:53:13 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:42735 (size: 3.0 KB, free: 530.0 MB)
16/03/25 13:53:13 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/25 13:53:13 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:53:13 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/25 13:53:13 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:53:13 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:53:13 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/25 13:53:13 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:53:13 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/25 13:53:13 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:53:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/25 13:53:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 9 ms
reduceFunction_Parents(): returns= [u'Chennai', 'None']
16/03/25 13:53:13 INFO PythonRunner: Times: total = 136, boot = 135, init = 0, finish = 1
16/03/25 13:53:13 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1275 bytes result sent to driver
16/03/25 13:53:13 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 158 ms on localhost (1/2)
16/03/25 13:53:14 INFO PythonRunner: Times: total = 408, boot = 408, init = 0, finish = 0
16/03/25 13:53:14 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/25 13:53:14 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.454 s
16/03/25 13:53:14 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 9.426990 s
16/03/25 13:53:14 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 453 ms on localhost (2/2)
16/03/25 13:53:14 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/25 13:53:14 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:53:14 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:53:14 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:53:14 INFO DAGScheduler: Parents of final stage: List()
16/03/25 13:53:14 INFO DAGScheduler: Missing parents: List()
16/03/25 13:53:14 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:53:14 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19234, maxMem=555755765
16/03/25 13:53:14 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 530.0 MB)
16/03/25 13:53:14 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25050, maxMem=555755765
16/03/25 13:53:14 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 530.0 MB)
16/03/25 13:53:14 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:42735 (size: 3.3 KB, free: 530.0 MB)
16/03/25 13:53:14 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/25 13:53:14 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:53:14 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/25 13:53:14 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/25 13:53:14 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2356 bytes)
16/03/25 13:53:14 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/25 13:53:14 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/25 13:53:14 INFO PythonRunner: Times: total = 12, boot = -277, init = 289, finish = 0
16/03/25 13:53:14 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1340 bytes result sent to driver
16/03/25 13:53:14 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 50 ms on localhost (1/2)
16/03/25 13:53:14 INFO PythonRunner: Times: total = 76, boot = 76, init = 0, finish = 0
16/03/25 13:53:14 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/25 13:53:14 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 88 ms on localhost (2/2)
16/03/25 13:53:14 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/25 13:53:14 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.080 s
16/03/25 13:53:14 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 0.117166 s
16/03/25 13:53:14 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/25 13:53:14 INFO DAGScheduler: Stopping DAGScheduler
16/03/25 13:53:14 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/25 13:53:14 INFO MemoryStore: MemoryStore cleared
16/03/25 13:53:14 INFO BlockManager: BlockManager stopped
16/03/25 13:53:14 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/25 13:53:14 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/25 13:53:14 INFO SparkContext: Successfully stopped SparkContext
16/03/25 13:53:14 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/25 13:53:14 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/25 13:53:14 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
graphcache_mapreduce_parents updated: defaultdict(<cyfunction <lambda> at 0xb1f81e6c>, {'4208c80be8e0c0d285fafd73cd5bd9a6': [u'metropolitan', u'None'], 'ed43ebbafa0c6204a5916ca879d5bd26': [u'None', u'area'], '2c49f1424d675552d9e7323a3eef6206': [u'None', u'expansion', u'None'], '44b9adf04881710b0a7c81b0a22b1209': [u'Chennai', u'None'], '45b800affe042d5d9a4228427680a935': [u'Chennai', u'None'], 'fdc633a5e1dea73592deb7e3bbbe3aea': [u'Chennai', u'None'], 'dd10336563a65a645a42bb416a6ebec6': [u'None', u'area', u'None'], 'e9301955882d67edfb275156ef73113c': [u'metropolitan', u'None'], '552934a698e1bcf880132a2bd5996d11': [u'None', u'area', u'None'], '063da2002ba149bb4025d1e1fcfb49f5': [u'None', u'area', u'None'], 'b7b50c706678d48359a2ac685d535b33': [u'metropolitan', u'None'], '926a71600b58a41448b179d8665fd5df': [u'None', u'expansion', u'None'], 'a8f48eba5bb66d59263f478b93779a2c': [u'metropolitan', u'None'], 'e6ebeac0f1cb14fbd7b903291fcc6a8f': [u'metropolitan', u'None'], 'a31cc044ea8d13e6b1bf4e98768e44a5': [u'None', u'area', u'None'], '9f1808799460fd7b2da9ab51bd7b6775': [u'None', u'area', u'None'], 'd7b9ba5125de58e77ad31543f2c54034': [u'None', u'area', u'None'], 'b1318a4c6d13196fb45da6102d193223': [u'None', u'area', u'None', u'special'], '40603e72c50afb5b6be8a7ff1684c966': [u'Chennai', u'None', u'Madras']})
asfer_pickle_string_dump(): picklef.write(): Nadu
16/03/25 13:53:15 INFO SparkContext: Running Spark version 1.5.2
16/03/25 13:53:15 INFO SecurityManager: Changing view acls to: root
16/03/25 13:53:15 INFO SecurityManager: Changing modify acls to: root
16/03/25 13:53:15 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/25 13:53:15 INFO Slf4jLogger: Slf4jLogger started
16/03/25 13:53:15 INFO Remoting: Starting remoting
16/03/25 13:53:15 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:59716]
16/03/25 13:53:15 INFO Utils: Successfully started service 'sparkDriver' on port 59716.
16/03/25 13:53:15 INFO SparkEnv: Registering MapOutputTracker
16/03/25 13:53:15 INFO SparkEnv: Registering BlockManagerMaster
16/03/25 13:53:15 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-8464c96a-294c-470a-9287-3344c5f56439
16/03/25 13:53:15 INFO MemoryStore: MemoryStore started with capacity 530.0 MB
16/03/25 13:53:15 INFO HttpFileServer: HTTP File server directory is /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/httpd-e2b3ba5f-5033-49ff-bd7c-396c94e83868
16/03/25 13:53:15 INFO HttpServer: Starting HTTP Server
16/03/25 13:53:15 INFO Utils: Successfully started service 'HTTP file server' on port 34029.
16/03/25 13:53:15 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/25 13:53:15 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/25 13:53:15 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/25 13:53:15 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/userFiles-402308e7-a2ea-4be8-ac59-d4574e557e66/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:53:15 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458894195968
16/03/25 13:53:15 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/25 13:53:15 INFO Executor: Starting executor ID driver on host localhost
16/03/25 13:53:16 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55132.
16/03/25 13:53:16 INFO NettyBlockTransferService: Server created on 55132
16/03/25 13:53:16 INFO BlockManagerMaster: Trying to register BlockManager
16/03/25 13:53:16 INFO BlockManagerMasterEndpoint: Registering block manager localhost:55132 with 530.0 MB RAM, BlockManagerId(driver, localhost, 55132)
16/03/25 13:53:16 INFO BlockManagerMaster: Registered BlockManager
16/03/25 13:53:16 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:53:16 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:53:16 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:53:16 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:53:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/25 13:53:16 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/25 13:53:16 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:53:16 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=555755765
16/03/25 13:53:16 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 530.0 MB)
16/03/25 13:53:16 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=555755765
16/03/25 13:53:16 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 530.0 MB)
16/03/25 13:53:16 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:55132 (size: 4.1 KB, free: 530.0 MB)
16/03/25 13:53:16 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/25 13:53:16 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:53:16 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/25 13:53:16 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2493 bytes)
16/03/25 13:53:16 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2480 bytes)
16/03/25 13:53:16 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/25 13:53:16 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458894195968
16/03/25 13:53:16 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/25 13:53:16 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/userFiles-402308e7-a2ea-4be8-ac59-d4574e557e66/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:53:16 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/25 13:53:16 INFO MemoryStore: ensureFreeSpace(220) called with curMem=10732, maxMem=555755765
16/03/25 13:53:16 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 220.0 B, free 530.0 MB)
16/03/25 13:53:16 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/25 13:53:16 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:55132 (size: 220.0 B, free: 530.0 MB)
16/03/25 13:53:16 INFO MemoryStore: ensureFreeSpace(228) called with curMem=10952, maxMem=555755765
16/03/25 13:53:16 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 228.0 B, free 530.0 MB)
16/03/25 13:53:16 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:55132 (size: 228.0 B, free: 530.0 MB)
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: Chennai
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: geography
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'and', u'climate', u'topography', u"'s", u'responses', u'people', u'of', u'study', u'surface', u'includes', u'to', u'soil', u'earth', u'the', u';', u'vegetation'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: city
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'and', u'districts', u'several', u'urban', u'may', u'populated', u'large', u'area', u'independent', u'densely', u';', u'include', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: given
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'for', u'that', u'is', u'an', u'assumption', u'taken', u'granted'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: Madras
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'on', u';', u'Madras', u'formerly', u')', u'of', u'India', u'Bay', u'state', u'Andhra', u'(', u'in', u'the', u'Bengal', u'Pradesh', u'southeastern', u'south'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: Eastern
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'east', u'situated', u'in', u'the', u'toward', u'or', u'lying'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: archbishop
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'of', u'highest', u'bishop', u'rank'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: sum
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'of', u'money', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: expressed
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'to', u'expression', u'give'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: geographical
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'science', u'or', u'to', u'of', u'relating', u'the', u'geography'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: boundary
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'limits', u'area', u'determining', u'an', u'of', u'line', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: Tamil
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'and', u'people', u'of', u'Sri', u'southern', u'member', u'India', u'mixed', u'Dravidian', u'the', u'Lanka', u'Caucasian'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: Nadu
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/25 13:53:25 INFO PythonRunner: Times: total = 9484, boot = 510, init = 615, finish = 8359
16/03/25 13:53:25 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/25 13:53:25 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 9595 ms on localhost (1/2)
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): adding to parents: syn =  Synset('chennai.n.01') ; keyword:  Nadu  in syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: area
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: expansion
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'function', u'product', u'terms', u'of', u'sum', u'expressed', u'as', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: serving
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'food', u'of', u'drink', u'meal', u'an', u'as', u'individual', u'taken', u'part', u'or', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: formerly
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u';', u'time', u'at', u'previous'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: people
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'group', u')', u'(', u'men', u'children', u'or', u'collectively', u'beings', u'human', u'of', u'plural', u'any', u'women'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: Christianity
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'and', u'monotheistic', u'based', u'embodied', u'on', u'New', u'of', u'in', u'system', u'Jesus', u'as', u'practices', u'role', u'emphasizing', u'teachings', u'Testament', u'Old', u'the', u'beliefs', u'savior'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: culture
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'and', u'particular', u'society', u'place', u'at', u'time'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: indefinite
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'or', u'stated', u'defined', u'clearly', u'not', u'vague'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: bishop
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'and', u'the', u'spiritual', u'Christ', u'twelve', u'some', u'authority', u'in', u'Christian', u'ministers', u'member', u'to', u'churches', u';', u'administrative', u'be', u'Apostles', u'appointed', u'a', u'oversee', u'of', u'priests', u'or', u'considered', u'clergy', u'senior', u'successors', u'having'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Nadu
mapFunction_Parents(): keyword: Nadu ; prevleveltokens: special
mapFunction_Parents(): keyword= Nadu ; syndef_tokens= set([u'a', u'and', u'temporary', u'offering', u'that', u')', u'(', u'price', u'featured', u'at', u'in', u'usually', u'is', u'reduced', u'special', u'advertising'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
16/03/25 13:53:26 INFO PythonRunner: Times: total = 9747, boot = 521, init = 589, finish = 8637
16/03/25 13:53:26 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/25 13:53:26 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 9.865 s
16/03/25 13:53:26 INFO DAGScheduler: looking for newly runnable stages
16/03/25 13:53:26 INFO DAGScheduler: running: Set()
16/03/25 13:53:26 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/25 13:53:26 INFO DAGScheduler: failed: Set()
16/03/25 13:53:26 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/25 13:53:26 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which is now runnable
16/03/25 13:53:26 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11180, maxMem=555755765
16/03/25 13:53:26 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 530.0 MB)
16/03/25 13:53:26 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16164, maxMem=555755765
16/03/25 13:53:26 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 530.0 MB)
16/03/25 13:53:26 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9874 ms on localhost (2/2)
16/03/25 13:53:26 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/25 13:53:26 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:55132 (size: 3.0 KB, free: 530.0 MB)
16/03/25 13:53:26 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/25 13:53:26 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:53:26 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/25 13:53:26 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:53:26 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:53:26 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/25 13:53:26 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:53:26 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/25 13:53:26 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:53:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/25 13:53:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
reduceFunction_Parents(): returns= [u'Chennai', 'None']
16/03/25 13:53:26 INFO PythonRunner: Times: total = 22, boot = -137, init = 159, finish = 0
16/03/25 13:53:26 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1275 bytes result sent to driver
16/03/25 13:53:26 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 83 ms on localhost (1/2)
16/03/25 13:53:26 INFO PythonRunner: Times: total = 276, boot = 275, init = 0, finish = 1
16/03/25 13:53:26 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/25 13:53:26 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.295 s
16/03/25 13:53:26 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 10.269057 s
16/03/25 13:53:26 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 294 ms on localhost (2/2)
16/03/25 13:53:26 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/25 13:53:26 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:53:26 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:53:26 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:53:26 INFO DAGScheduler: Parents of final stage: List()
16/03/25 13:53:26 INFO DAGScheduler: Missing parents: List()
16/03/25 13:53:26 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:53:26 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19219, maxMem=555755765
16/03/25 13:53:26 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 530.0 MB)
16/03/25 13:53:26 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25035, maxMem=555755765
16/03/25 13:53:26 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 530.0 MB)
16/03/25 13:53:26 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:55132 (size: 3.3 KB, free: 530.0 MB)
16/03/25 13:53:26 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/25 13:53:26 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:53:26 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/25 13:53:26 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/25 13:53:26 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2356 bytes)
16/03/25 13:53:26 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/25 13:53:26 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/25 13:53:26 INFO PythonRunner: Times: total = 69, boot = -115, init = 184, finish = 0
16/03/25 13:53:26 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/25 13:53:26 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 90 ms on localhost (1/2)
16/03/25 13:53:26 INFO PythonRunner: Times: total = 86, boot = 86, init = 0, finish = 0
16/03/25 13:53:26 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1340 bytes result sent to driver
16/03/25 13:53:26 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 105 ms on localhost (2/2)
16/03/25 13:53:26 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/25 13:53:26 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.103 s
16/03/25 13:53:26 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 0.128017 s
16/03/25 13:53:26 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/25 13:53:26 INFO DAGScheduler: Stopping DAGScheduler
16/03/25 13:53:26 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/25 13:53:26 INFO MemoryStore: MemoryStore cleared
16/03/25 13:53:26 INFO BlockManager: BlockManager stopped
16/03/25 13:53:26 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/25 13:53:26 INFO SparkContext: Successfully stopped SparkContext
16/03/25 13:53:26 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/25 13:53:26 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/25 13:53:26 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
graphcache_mapreduce_parents updated: defaultdict(<cyfunction <lambda> at 0xb1f81e6c>, {'4208c80be8e0c0d285fafd73cd5bd9a6': [u'metropolitan', u'None'], 'ed43ebbafa0c6204a5916ca879d5bd26': [u'None', u'area'], '2c49f1424d675552d9e7323a3eef6206': [u'None', u'expansion', u'None'], '44b9adf04881710b0a7c81b0a22b1209': [u'Chennai', u'None'], '45b800affe042d5d9a4228427680a935': [u'Chennai', u'None'], 'fdc633a5e1dea73592deb7e3bbbe3aea': [u'Chennai', u'None'], 'dd10336563a65a645a42bb416a6ebec6': [u'None', u'area', u'None'], 'e9301955882d67edfb275156ef73113c': [u'metropolitan', u'None'], '552934a698e1bcf880132a2bd5996d11': [u'None', u'area', u'None'], 'f2e69333b98cfc98f544ee3a5717b7c4': [u'Chennai', u'None'], '063da2002ba149bb4025d1e1fcfb49f5': [u'None', u'area', u'None'], 'b7b50c706678d48359a2ac685d535b33': [u'metropolitan', u'None'], '926a71600b58a41448b179d8665fd5df': [u'None', u'expansion', u'None'], 'a8f48eba5bb66d59263f478b93779a2c': [u'metropolitan', u'None'], 'e6ebeac0f1cb14fbd7b903291fcc6a8f': [u'metropolitan', u'None'], 'a31cc044ea8d13e6b1bf4e98768e44a5': [u'None', u'area', u'None'], '9f1808799460fd7b2da9ab51bd7b6775': [u'None', u'area', u'None'], 'd7b9ba5125de58e77ad31543f2c54034': [u'None', u'area', u'None'], 'b1318a4c6d13196fb45da6102d193223': [u'None', u'area', u'None', u'special'], '40603e72c50afb5b6be8a7ff1684c966': [u'Chennai', u'None', u'Madras']})
asfer_pickle_string_dump(): picklef.write(): function
16/03/25 13:53:27 INFO SparkContext: Running Spark version 1.5.2
16/03/25 13:53:27 INFO SecurityManager: Changing view acls to: root
16/03/25 13:53:27 INFO SecurityManager: Changing modify acls to: root
16/03/25 13:53:27 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/25 13:53:27 INFO Slf4jLogger: Slf4jLogger started
16/03/25 13:53:27 INFO Remoting: Starting remoting
16/03/25 13:53:27 INFO Utils: Successfully started service 'sparkDriver' on port 53214.
16/03/25 13:53:27 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:53214]
16/03/25 13:53:27 INFO SparkEnv: Registering MapOutputTracker
16/03/25 13:53:27 INFO SparkEnv: Registering BlockManagerMaster
16/03/25 13:53:27 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-51e4d494-b250-47a7-978b-e86c6e0a57e1
16/03/25 13:53:27 INFO MemoryStore: MemoryStore started with capacity 540.8 MB
16/03/25 13:53:27 INFO HttpFileServer: HTTP File server directory is /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/httpd-5d4fcc31-d826-4029-bb4c-9a83af535bd1
16/03/25 13:53:27 INFO HttpServer: Starting HTTP Server
16/03/25 13:53:27 INFO Utils: Successfully started service 'HTTP file server' on port 40864.
16/03/25 13:53:27 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/25 13:53:27 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/25 13:53:27 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/25 13:53:27 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/userFiles-1bf31102-ebed-41ef-90a4-ac66cb767eaf/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:53:27 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458894207890
16/03/25 13:53:27 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/25 13:53:27 INFO Executor: Starting executor ID driver on host localhost
16/03/25 13:53:27 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38466.
16/03/25 13:53:27 INFO NettyBlockTransferService: Server created on 38466
16/03/25 13:53:27 INFO BlockManagerMaster: Trying to register BlockManager
16/03/25 13:53:27 INFO BlockManagerMasterEndpoint: Registering block manager localhost:38466 with 540.8 MB RAM, BlockManagerId(driver, localhost, 38466)
16/03/25 13:53:27 INFO BlockManagerMaster: Registered BlockManager
16/03/25 13:53:28 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:53:28 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:53:28 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:53:28 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:53:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/25 13:53:28 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/25 13:53:28 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:53:28 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=567080386
16/03/25 13:53:28 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 540.8 MB)
16/03/25 13:53:28 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=567080386
16/03/25 13:53:28 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 540.8 MB)
16/03/25 13:53:28 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:38466 (size: 4.1 KB, free: 540.8 MB)
16/03/25 13:53:28 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/25 13:53:28 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:53:28 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/25 13:53:28 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2493 bytes)
16/03/25 13:53:28 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2512 bytes)
16/03/25 13:53:28 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/25 13:53:28 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458894207890
16/03/25 13:53:28 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/25 13:53:28 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/userFiles-1bf31102-ebed-41ef-90a4-ac66cb767eaf/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:53:28 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/25 13:53:28 INFO MemoryStore: ensureFreeSpace(228) called with curMem=10732, maxMem=567080386
16/03/25 13:53:28 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 228.0 B, free 540.8 MB)
16/03/25 13:53:28 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:38466 (size: 228.0 B, free: 540.8 MB)
16/03/25 13:53:28 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/25 13:53:28 INFO MemoryStore: ensureFreeSpace(246) called with curMem=10960, maxMem=567080386
16/03/25 13:53:28 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 246.0 B, free 540.8 MB)
16/03/25 13:53:28 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:38466 (size: 246.0 B, free: 540.8 MB)
asfer_pickle_string_load(): picklef.readlines(): function
mapFunction_Parents(): keyword: function ; prevleveltokens: geography
asfer_pickle_string_load(): picklef.readlines(): function
mapFunction_Parents(): keyword: function ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= function ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): function
mapFunction_Parents(): keyword: function ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= function ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): function
mapFunction_Parents(): keyword: function ; prevleveltokens: area
mapFunction_Parents(): keyword= function ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): function
mapFunction_Parents(): keyword: function ; prevleveltokens: expansion
mapFunction_Parents(): keyword= function ; syndef_tokens= set([u'a', u'function', u'product', u'terms', u'of', u'sum', u'expressed', u'as', u'or'])
mapFunction_Parents(): adding to parents: syn =  Synset('expansion.n.02') ; keyword:  function  in syndef_tokens= set([u'a', u'function', u'product', u'terms', u'of', u'sum', u'expressed', u'as', u'or'])
mapFunction_Parents(): returns= [u'expansion']
reduceFunction_Parents(): returns= ['None', u'expansion']
asfer_pickle_string_load(): picklef.readlines(): function
mapFunction_Parents(): keyword: function ; prevleveltokens: serving
mapFunction_Parents(): keyword= function ; syndef_tokens= set([u'a', u'food', u'of', u'drink', u'meal', u'an', u'as', u'individual', u'taken', u'part', u'or', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'expansion']
asfer_pickle_string_load(): picklef.readlines(): function
mapFunction_Parents(): keyword: function ; prevleveltokens: formerly
mapFunction_Parents(): keyword= function ; syndef_tokens= set([u'a', u';', u'time', u'at', u'previous'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'expansion']
asfer_pickle_string_load(): picklef.readlines(): function
mapFunction_Parents(): keyword: function ; prevleveltokens: people
mapFunction_Parents(): keyword= function ; syndef_tokens= set([u'group', u')', u'(', u'men', u'children', u'or', u'collectively', u'beings', u'human', u'of', u'plural', u'any', u'women'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'expansion']
asfer_pickle_string_load(): picklef.readlines(): function
mapFunction_Parents(): keyword: function ; prevleveltokens: Christianity
mapFunction_Parents(): keyword= function ; syndef_tokens= set([u'a', u'and', u'monotheistic', u'based', u'embodied', u'on', u'New', u'of', u'in', u'system', u'Jesus', u'as', u'practices', u'role', u'emphasizing', u'teachings', u'Testament', u'Old', u'the', u'beliefs', u'savior'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'expansion']
asfer_pickle_string_load(): picklef.readlines(): function
mapFunction_Parents(): keyword: function ; prevleveltokens: culture
mapFunction_Parents(): keyword= function ; syndef_tokens= set([u'a', u'and', u'particular', u'society', u'place', u'at', u'time'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'expansion']
asfer_pickle_string_load(): picklef.readlines(): function
mapFunction_Parents(): keyword: function ; prevleveltokens: indefinite
mapFunction_Parents(): keyword= function ; syndef_tokens= set([u'or', u'stated', u'defined', u'clearly', u'not', u'vague'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'expansion']
asfer_pickle_string_load(): picklef.readlines(): function
mapFunction_Parents(): keyword: function ; prevleveltokens: bishop
mapFunction_Parents(): keyword= function ; syndef_tokens= set([u'and', u'the', u'spiritual', u'Christ', u'twelve', u'some', u'authority', u'in', u'Christian', u'ministers', u'member', u'to', u'churches', u';', u'administrative', u'be', u'Apostles', u'appointed', u'a', u'oversee', u'of', u'priests', u'or', u'considered', u'clergy', u'senior', u'successors', u'having'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'expansion']
asfer_pickle_string_load(): picklef.readlines(): function
mapFunction_Parents(): keyword: function ; prevleveltokens: special
mapFunction_Parents(): keyword= function ; syndef_tokens= set([u'a', u'and', u'temporary', u'offering', u'that', u')', u'(', u'price', u'featured', u'at', u'in', u'usually', u'is', u'reduced', u'special', u'advertising'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'expansion']
16/03/25 13:53:37 INFO PythonRunner: Times: total = 8965, boot = 500, init = 393, finish = 8072
16/03/25 13:53:37 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/25 13:53:37 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9095 ms on localhost (1/2)
mapFunction_Parents(): keyword= function ; syndef_tokens= set([u'and', u'climate', u'topography', u"'s", u'responses', u'people', u'of', u'study', u'surface', u'includes', u'to', u'soil', u'earth', u'the', u';', u'vegetation'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): function
mapFunction_Parents(): keyword: function ; prevleveltokens: city
mapFunction_Parents(): keyword= function ; syndef_tokens= set([u'a', u'and', u'districts', u'several', u'urban', u'may', u'populated', u'large', u'area', u'independent', u'densely', u';', u'include', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): function
mapFunction_Parents(): keyword: function ; prevleveltokens: given
mapFunction_Parents(): keyword= function ; syndef_tokens= set([u'for', u'that', u'is', u'an', u'assumption', u'taken', u'granted'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): function
mapFunction_Parents(): keyword: function ; prevleveltokens: Madras
mapFunction_Parents(): keyword= function ; syndef_tokens= set([u'a', u'on', u';', u'Madras', u'formerly', u')', u'of', u'India', u'Bay', u'state', u'Andhra', u'(', u'in', u'the', u'Bengal', u'Pradesh', u'southeastern', u'south'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): function
mapFunction_Parents(): keyword: function ; prevleveltokens: Eastern
mapFunction_Parents(): keyword= function ; syndef_tokens= set([u'east', u'situated', u'in', u'the', u'toward', u'or', u'lying'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): function
mapFunction_Parents(): keyword: function ; prevleveltokens: archbishop
mapFunction_Parents(): keyword= function ; syndef_tokens= set([u'a', u'of', u'highest', u'bishop', u'rank'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): function
mapFunction_Parents(): keyword: function ; prevleveltokens: sum
mapFunction_Parents(): keyword= function ; syndef_tokens= set([u'a', u'of', u'money', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): function
mapFunction_Parents(): keyword: function ; prevleveltokens: expressed
mapFunction_Parents(): keyword= function ; syndef_tokens= set([u'to', u'expression', u'give'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): function
mapFunction_Parents(): keyword: function ; prevleveltokens: geographical
mapFunction_Parents(): keyword= function ; syndef_tokens= set([u'science', u'or', u'to', u'of', u'relating', u'the', u'geography'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): function
mapFunction_Parents(): keyword: function ; prevleveltokens: boundary
mapFunction_Parents(): keyword= function ; syndef_tokens= set([u'a', u'limits', u'area', u'determining', u'an', u'of', u'line', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): function
mapFunction_Parents(): keyword: function ; prevleveltokens: Tamil
mapFunction_Parents(): keyword= function ; syndef_tokens= set([u'a', u'and', u'people', u'of', u'Sri', u'southern', u'member', u'India', u'mixed', u'Dravidian', u'the', u'Lanka', u'Caucasian'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): function
mapFunction_Parents(): keyword: function ; prevleveltokens: Nadu
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): function
mapFunction_Parents(): keyword: function ; prevleveltokens: function
mapFunction_Parents(): keyword= function ; syndef_tokens= set([u'mathematical', u'domain', u'set', u'associated', u'is', u'an', u'relation', u'another', u'given', u')', u'(', u'mathematics', u'function', u'that', u'such', u'with', u'a', u'of', u'element', u'range', u'each', u'the'])
mapFunction_Parents(): adding to parents: syn =  Synset('function.n.01') ; keyword:  function  in syndef_tokens= set([u'mathematical', u'domain', u'set', u'associated', u'is', u'an', u'relation', u'another', u'given', u')', u'(', u'mathematics', u'function', u'that', u'such', u'with', u'a', u'of', u'element', u'range', u'each', u'the'])
mapFunction_Parents(): returns= [u'function']
reduceFunction_Parents(): returns= ['None', u'function']
16/03/25 13:53:37 INFO PythonRunner: Times: total = 9364, boot = 498, init = 390, finish = 8476
16/03/25 13:53:37 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/25 13:53:37 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 9461 ms on localhost (2/2)
16/03/25 13:53:37 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/25 13:53:37 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 9.465 s
16/03/25 13:53:37 INFO DAGScheduler: looking for newly runnable stages
16/03/25 13:53:37 INFO DAGScheduler: running: Set()
16/03/25 13:53:37 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/25 13:53:37 INFO DAGScheduler: failed: Set()
16/03/25 13:53:37 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/25 13:53:37 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which is now runnable
16/03/25 13:53:37 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11206, maxMem=567080386
16/03/25 13:53:37 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 540.8 MB)
16/03/25 13:53:37 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16190, maxMem=567080386
16/03/25 13:53:37 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 540.8 MB)
16/03/25 13:53:37 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:38466 (size: 3.0 KB, free: 540.8 MB)
16/03/25 13:53:37 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/25 13:53:37 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:53:37 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/25 13:53:37 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:53:37 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:53:37 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/25 13:53:37 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/25 13:53:37 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:53:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/25 13:53:37 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:53:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/25 13:53:37 INFO PythonRunner: Times: total = 14, boot = -165, init = 179, finish = 0
16/03/25 13:53:37 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/25 13:53:37 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 61 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'expansion', 'None', u'function']
16/03/25 13:53:37 INFO PythonRunner: Times: total = 219, boot = 218, init = 1, finish = 0
16/03/25 13:53:37 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1300 bytes result sent to driver
16/03/25 13:53:37 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.231 s
16/03/25 13:53:37 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 9.728358 s
16/03/25 13:53:37 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 230 ms on localhost (2/2)
16/03/25 13:53:37 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/25 13:53:37 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:53:37 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:53:37 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:53:37 INFO DAGScheduler: Parents of final stage: List()
16/03/25 13:53:37 INFO DAGScheduler: Missing parents: List()
16/03/25 13:53:37 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:53:37 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19245, maxMem=567080386
16/03/25 13:53:37 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 540.8 MB)
16/03/25 13:53:37 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25061, maxMem=567080386
16/03/25 13:53:37 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 540.8 MB)
16/03/25 13:53:37 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:38466 (size: 3.3 KB, free: 540.8 MB)
16/03/25 13:53:37 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/25 13:53:37 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:53:37 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/25 13:53:37 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/25 13:53:37 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2381 bytes)
16/03/25 13:53:37 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/25 13:53:37 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/25 13:53:38 INFO PythonRunner: Times: total = 139, boot = 139, init = 0, finish = 0
16/03/25 13:53:38 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/25 13:53:38 INFO PythonRunner: Times: total = 139, boot = 138, init = 1, finish = 0
16/03/25 13:53:38 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 151 ms on localhost (1/2)
16/03/25 13:53:38 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1368 bytes result sent to driver
16/03/25 13:53:38 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 154 ms on localhost (2/2)
16/03/25 13:53:38 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/25 13:53:38 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.146 s
16/03/25 13:53:38 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 0.172791 s
16/03/25 13:53:38 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/25 13:53:38 INFO DAGScheduler: Stopping DAGScheduler
16/03/25 13:53:38 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/25 13:53:38 INFO MemoryStore: MemoryStore cleared
16/03/25 13:53:38 INFO BlockManager: BlockManager stopped
16/03/25 13:53:38 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/25 13:53:38 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/25 13:53:38 INFO SparkContext: Successfully stopped SparkContext
16/03/25 13:53:38 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/25 13:53:38 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/25 13:53:38 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
graphcache_mapreduce_parents updated: defaultdict(<cyfunction <lambda> at 0xb1f81e6c>, {'4208c80be8e0c0d285fafd73cd5bd9a6': [u'metropolitan', u'None'], 'ed43ebbafa0c6204a5916ca879d5bd26': [u'None', u'area'], '2c49f1424d675552d9e7323a3eef6206': [u'None', u'expansion', u'None'], '44b9adf04881710b0a7c81b0a22b1209': [u'Chennai', u'None'], '45b800affe042d5d9a4228427680a935': [u'Chennai', u'None'], 'fdc633a5e1dea73592deb7e3bbbe3aea': [u'Chennai', u'None'], 'dd10336563a65a645a42bb416a6ebec6': [u'None', u'area', u'None'], 'e9301955882d67edfb275156ef73113c': [u'metropolitan', u'None'], '552934a698e1bcf880132a2bd5996d11': [u'None', u'area', u'None'], 'f2e69333b98cfc98f544ee3a5717b7c4': [u'Chennai', u'None'], '063da2002ba149bb4025d1e1fcfb49f5': [u'None', u'area', u'None'], 'b7b50c706678d48359a2ac685d535b33': [u'metropolitan', u'None'], '926a71600b58a41448b179d8665fd5df': [u'None', u'expansion', u'None'], 'a8f48eba5bb66d59263f478b93779a2c': [u'metropolitan', u'None'], 'e6ebeac0f1cb14fbd7b903291fcc6a8f': [u'metropolitan', u'None'], 'a31cc044ea8d13e6b1bf4e98768e44a5': [u'None', u'area', u'None'], 'c65d3beca4dc2d6f37377a842accc0cd': [u'None', u'expansion', u'None', u'function'], '9f1808799460fd7b2da9ab51bd7b6775': [u'None', u'area', u'None'], 'd7b9ba5125de58e77ad31543f2c54034': [u'None', u'area', u'None'], 'b1318a4c6d13196fb45da6102d193223': [u'None', u'area', u'None', u'special'], '40603e72c50afb5b6be8a7ff1684c966': [u'Chennai', u'None', u'Madras']})
asfer_pickle_string_dump(): picklef.write(): product
16/03/25 13:53:39 INFO SparkContext: Running Spark version 1.5.2
16/03/25 13:53:39 INFO SecurityManager: Changing view acls to: root
16/03/25 13:53:39 INFO SecurityManager: Changing modify acls to: root
16/03/25 13:53:39 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/25 13:53:39 INFO Slf4jLogger: Slf4jLogger started
16/03/25 13:53:39 INFO Remoting: Starting remoting
16/03/25 13:53:39 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:46800]
16/03/25 13:53:39 INFO Utils: Successfully started service 'sparkDriver' on port 46800.
16/03/25 13:53:39 INFO SparkEnv: Registering MapOutputTracker
16/03/25 13:53:39 INFO SparkEnv: Registering BlockManagerMaster
16/03/25 13:53:39 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-b021b7f4-eef9-4a1b-9691-a08ef1da5458
16/03/25 13:53:39 INFO MemoryStore: MemoryStore started with capacity 540.8 MB
16/03/25 13:53:39 INFO HttpFileServer: HTTP File server directory is /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/httpd-21494b9d-b552-49bd-a346-f11e69eab1fa
16/03/25 13:53:39 INFO HttpServer: Starting HTTP Server
16/03/25 13:53:39 INFO Utils: Successfully started service 'HTTP file server' on port 36051.
16/03/25 13:53:39 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/25 13:53:39 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/25 13:53:39 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/25 13:53:39 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/userFiles-a65f6534-5b2e-4d90-95b9-7813bf8791a3/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:53:39 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458894219301
16/03/25 13:53:39 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/25 13:53:39 INFO Executor: Starting executor ID driver on host localhost
16/03/25 13:53:39 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34074.
16/03/25 13:53:39 INFO NettyBlockTransferService: Server created on 34074
16/03/25 13:53:39 INFO BlockManagerMaster: Trying to register BlockManager
16/03/25 13:53:39 INFO BlockManagerMasterEndpoint: Registering block manager localhost:34074 with 540.8 MB RAM, BlockManagerId(driver, localhost, 34074)
16/03/25 13:53:39 INFO BlockManagerMaster: Registered BlockManager
16/03/25 13:53:39 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:53:39 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:53:39 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:53:39 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:53:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/25 13:53:39 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/25 13:53:39 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:53:39 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=567080386
16/03/25 13:53:39 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 540.8 MB)
16/03/25 13:53:39 INFO MemoryStore: ensureFreeSpace(4151) called with curMem=6576, maxMem=567080386
16/03/25 13:53:39 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 540.8 MB)
16/03/25 13:53:39 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:34074 (size: 4.1 KB, free: 540.8 MB)
16/03/25 13:53:39 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/25 13:53:39 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:53:39 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/25 13:53:39 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2509 bytes)
16/03/25 13:53:39 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2493 bytes)
16/03/25 13:53:39 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/25 13:53:39 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458894219301
16/03/25 13:53:39 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/25 13:53:39 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/userFiles-a65f6534-5b2e-4d90-95b9-7813bf8791a3/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:53:39 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/25 13:53:39 INFO MemoryStore: ensureFreeSpace(232) called with curMem=10727, maxMem=567080386
16/03/25 13:53:39 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 232.0 B, free 540.8 MB)
16/03/25 13:53:39 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:34074 (size: 232.0 B, free: 540.8 MB)
16/03/25 13:53:39 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/25 13:53:39 INFO MemoryStore: ensureFreeSpace(244) called with curMem=10959, maxMem=567080386
16/03/25 13:53:39 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 244.0 B, free 540.8 MB)
16/03/25 13:53:39 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:34074 (size: 244.0 B, free: 540.8 MB)
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: Chennai
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: city
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'and', u'districts', u'several', u'urban', u'may', u'populated', u'large', u'area', u'independent', u'densely', u';', u'include', u'administrative'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: given
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'for', u'that', u'is', u'an', u'assumption', u'taken', u'granted'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: Madras
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'on', u';', u'Madras', u'formerly', u')', u'of', u'India', u'Bay', u'state', u'Andhra', u'(', u'in', u'the', u'Bengal', u'Pradesh', u'southeastern', u'south'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: Eastern
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'east', u'situated', u'in', u'the', u'toward', u'or', u'lying'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: archbishop
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'of', u'highest', u'bishop', u'rank'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: sum
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'of', u'money', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: expressed
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'to', u'expression', u'give'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: geographical
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'science', u'or', u'to', u'of', u'relating', u'the', u'geography'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: boundary
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'limits', u'area', u'determining', u'an', u'of', u'line', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: Tamil
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'and', u'people', u'of', u'Sri', u'southern', u'member', u'India', u'mixed', u'Dravidian', u'the', u'Lanka', u'Caucasian'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: Nadu
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: function
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'mathematical', u'domain', u'set', u'associated', u'is', u'an', u'relation', u'another', u'given', u')', u'(', u'mathematics', u'function', u'that', u'such', u'with', u'a', u'of', u'element', u'range', u'each', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: product
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'commodities', u'offered', u'sale', u'for'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/25 13:53:49 INFO PythonRunner: Times: total = 9831, boot = 506, init = 742, finish = 8583
16/03/25 13:53:49 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/25 13:53:49 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 9895 ms on localhost (1/2)
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: area
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: expansion
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'function', u'product', u'terms', u'of', u'sum', u'expressed', u'as', u'or'])
mapFunction_Parents(): adding to parents: syn =  Synset('expansion.n.02') ; keyword:  product  in syndef_tokens= set([u'a', u'function', u'product', u'terms', u'of', u'sum', u'expressed', u'as', u'or'])
mapFunction_Parents(): returns= [u'expansion']
reduceFunction_Parents(): returns= ['None', u'expansion']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: serving
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'food', u'of', u'drink', u'meal', u'an', u'as', u'individual', u'taken', u'part', u'or', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'expansion']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: formerly
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u';', u'time', u'at', u'previous'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'expansion']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: people
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'group', u')', u'(', u'men', u'children', u'or', u'collectively', u'beings', u'human', u'of', u'plural', u'any', u'women'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'expansion']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: Christianity
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'and', u'monotheistic', u'based', u'embodied', u'on', u'New', u'of', u'in', u'system', u'Jesus', u'as', u'practices', u'role', u'emphasizing', u'teachings', u'Testament', u'Old', u'the', u'beliefs', u'savior'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'expansion']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: culture
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'and', u'particular', u'society', u'place', u'at', u'time'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'expansion']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: indefinite
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'or', u'stated', u'defined', u'clearly', u'not', u'vague'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'expansion']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: bishop
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'and', u'the', u'spiritual', u'Christ', u'twelve', u'some', u'authority', u'in', u'Christian', u'ministers', u'member', u'to', u'churches', u';', u'administrative', u'be', u'Apostles', u'appointed', u'a', u'oversee', u'of', u'priests', u'or', u'considered', u'clergy', u'senior', u'successors', u'having'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'expansion']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: special
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'a', u'and', u'temporary', u'offering', u'that', u')', u'(', u'price', u'featured', u'at', u'in', u'usually', u'is', u'reduced', u'special', u'advertising'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'expansion']
asfer_pickle_string_load(): picklef.readlines(): product
mapFunction_Parents(): keyword: product ; prevleveltokens: geography
mapFunction_Parents(): keyword= product ; syndef_tokens= set([u'and', u'climate', u'topography', u"'s", u'responses', u'people', u'of', u'study', u'surface', u'includes', u'to', u'soil', u'earth', u'the', u';', u'vegetation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'expansion']
16/03/25 13:53:49 INFO PythonRunner: Times: total = 10097, boot = 519, init = 587, finish = 8991
16/03/25 13:53:49 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/25 13:53:49 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 10.166 s
16/03/25 13:53:49 INFO DAGScheduler: looking for newly runnable stages
16/03/25 13:53:49 INFO DAGScheduler: running: Set()
16/03/25 13:53:49 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/25 13:53:49 INFO DAGScheduler: failed: Set()
16/03/25 13:53:49 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/25 13:53:49 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which is now runnable
16/03/25 13:53:49 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11203, maxMem=567080386
16/03/25 13:53:49 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 540.8 MB)
16/03/25 13:53:49 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 10167 ms on localhost (2/2)
16/03/25 13:53:49 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/25 13:53:49 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16187, maxMem=567080386
16/03/25 13:53:49 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 540.8 MB)
16/03/25 13:53:49 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:34074 (size: 3.0 KB, free: 540.8 MB)
16/03/25 13:53:49 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/25 13:53:49 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:53:49 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/25 13:53:49 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:53:49 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:53:49 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/25 13:53:49 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:53:49 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/25 13:53:49 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:53:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
16/03/25 13:53:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 15 ms
reduceFunction_Parents(): returns= ['None', u'expansion', 'None']
16/03/25 13:53:49 INFO PythonRunner: Times: total = 19, boot = -104, init = 122, finish = 1
16/03/25 13:53:49 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1285 bytes result sent to driver
16/03/25 13:53:49 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 58 ms on localhost (1/2)
16/03/25 13:53:49 INFO PythonRunner: Times: total = 221, boot = 220, init = 0, finish = 1
16/03/25 13:53:49 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/25 13:53:49 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 257 ms on localhost (2/2)
16/03/25 13:53:49 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.240 s
16/03/25 13:53:49 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 10.472861 s
16/03/25 13:53:49 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/25 13:53:50 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:53:50 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:53:50 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:53:50 INFO DAGScheduler: Parents of final stage: List()
16/03/25 13:53:50 INFO DAGScheduler: Missing parents: List()
16/03/25 13:53:50 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:53:50 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19242, maxMem=567080386
16/03/25 13:53:50 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 540.8 MB)
16/03/25 13:53:50 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25058, maxMem=567080386
16/03/25 13:53:50 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 540.8 MB)
16/03/25 13:53:50 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:34074 (size: 3.3 KB, free: 540.8 MB)
16/03/25 13:53:50 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/25 13:53:50 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:53:50 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/25 13:53:50 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/25 13:53:50 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2366 bytes)
16/03/25 13:53:50 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/25 13:53:50 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/25 13:53:50 INFO PythonRunner: Times: total = 42, boot = 42, init = 0, finish = 0
16/03/25 13:53:50 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1353 bytes result sent to driver
16/03/25 13:53:50 INFO PythonRunner: Times: total = 73, boot = -222, init = 295, finish = 0
16/03/25 13:53:50 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/25 13:53:50 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 84 ms on localhost (1/2)
16/03/25 13:53:50 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 86 ms on localhost (2/2)
16/03/25 13:53:50 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/25 13:53:50 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.085 s
16/03/25 13:53:50 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 0.120669 s
16/03/25 13:53:50 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/25 13:53:50 INFO DAGScheduler: Stopping DAGScheduler
16/03/25 13:53:50 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/25 13:53:50 INFO MemoryStore: MemoryStore cleared
16/03/25 13:53:50 INFO BlockManager: BlockManager stopped
16/03/25 13:53:50 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/25 13:53:50 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/25 13:53:50 INFO SparkContext: Successfully stopped SparkContext
16/03/25 13:53:50 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/25 13:53:50 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/25 13:53:50 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
graphcache_mapreduce_parents updated: defaultdict(<cyfunction <lambda> at 0xb1f81e6c>, {'2c49f1424d675552d9e7323a3eef6206': [u'None', u'expansion', u'None'], '45b800affe042d5d9a4228427680a935': [u'Chennai', u'None'], 'fdc633a5e1dea73592deb7e3bbbe3aea': [u'Chennai', u'None'], 'dd10336563a65a645a42bb416a6ebec6': [u'None', u'area', u'None'], 'a8f48eba5bb66d59263f478b93779a2c': [u'metropolitan', u'None'], '9f1808799460fd7b2da9ab51bd7b6775': [u'None', u'area', u'None'], '44b9adf04881710b0a7c81b0a22b1209': [u'Chennai', u'None'], 'e9301955882d67edfb275156ef73113c': [u'metropolitan', u'None'], '552934a698e1bcf880132a2bd5996d11': [u'None', u'area', u'None'], '063da2002ba149bb4025d1e1fcfb49f5': [u'None', u'area', u'None'], 'a31cc044ea8d13e6b1bf4e98768e44a5': [u'None', u'area', u'None'], 'b1318a4c6d13196fb45da6102d193223': [u'None', u'area', u'None', u'special'], 'ed43ebbafa0c6204a5916ca879d5bd26': [u'None', u'area'], 'c65d3beca4dc2d6f37377a842accc0cd': [u'None', u'expansion', u'None', u'function'], '40603e72c50afb5b6be8a7ff1684c966': [u'Chennai', u'None', u'Madras'], '4208c80be8e0c0d285fafd73cd5bd9a6': [u'metropolitan', u'None'], 'b7b50c706678d48359a2ac685d535b33': [u'metropolitan', u'None'], 'f2e69333b98cfc98f544ee3a5717b7c4': [u'Chennai', u'None'], '926a71600b58a41448b179d8665fd5df': [u'None', u'expansion', u'None'], 'e6ebeac0f1cb14fbd7b903291fcc6a8f': [u'metropolitan', u'None'], '25439f8325592e4ecd8b06f5f799b57a': [u'None', u'expansion', u'None'], 'd7b9ba5125de58e77ad31543f2c54034': [u'None', u'area', u'None']})
asfer_pickle_string_dump(): picklef.write(): terms
16/03/25 13:53:51 INFO SparkContext: Running Spark version 1.5.2
16/03/25 13:53:51 INFO SecurityManager: Changing view acls to: root
16/03/25 13:53:51 INFO SecurityManager: Changing modify acls to: root
16/03/25 13:53:51 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/25 13:53:51 INFO Slf4jLogger: Slf4jLogger started
16/03/25 13:53:51 INFO Remoting: Starting remoting
16/03/25 13:53:51 INFO Utils: Successfully started service 'sparkDriver' on port 53417.
16/03/25 13:53:51 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:53417]
16/03/25 13:53:51 INFO SparkEnv: Registering MapOutputTracker
16/03/25 13:53:51 INFO SparkEnv: Registering BlockManagerMaster
16/03/25 13:53:51 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-9a1f3074-395a-411a-abf2-73fd52e865d5
16/03/25 13:53:51 INFO MemoryStore: MemoryStore started with capacity 540.8 MB
16/03/25 13:53:51 INFO HttpFileServer: HTTP File server directory is /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/httpd-46fe77aa-2cc7-4072-a137-9286b30dcaa5
16/03/25 13:53:51 INFO HttpServer: Starting HTTP Server
16/03/25 13:53:51 INFO Utils: Successfully started service 'HTTP file server' on port 55516.
16/03/25 13:53:51 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/25 13:53:51 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/25 13:53:51 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/25 13:53:51 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/userFiles-6f692c28-d61a-4bf4-a28a-694987044603/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:53:51 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458894231750
16/03/25 13:53:51 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/25 13:53:51 INFO Executor: Starting executor ID driver on host localhost
16/03/25 13:53:51 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49535.
16/03/25 13:53:51 INFO NettyBlockTransferService: Server created on 49535
16/03/25 13:53:51 INFO BlockManagerMaster: Trying to register BlockManager
16/03/25 13:53:51 INFO BlockManagerMasterEndpoint: Registering block manager localhost:49535 with 540.8 MB RAM, BlockManagerId(driver, localhost, 49535)
16/03/25 13:53:51 INFO BlockManagerMaster: Registered BlockManager
16/03/25 13:53:51 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:53:51 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:53:51 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:53:51 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:53:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/25 13:53:51 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/25 13:53:51 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:53:51 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=567080386
16/03/25 13:53:51 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 540.8 MB)
16/03/25 13:53:51 INFO MemoryStore: ensureFreeSpace(4151) called with curMem=6576, maxMem=567080386
16/03/25 13:53:51 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 540.8 MB)
16/03/25 13:53:51 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:49535 (size: 4.1 KB, free: 540.8 MB)
16/03/25 13:53:51 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/25 13:53:51 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:53:51 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/25 13:53:51 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2509 bytes)
16/03/25 13:53:51 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2522 bytes)
16/03/25 13:53:51 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/25 13:53:51 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458894231750
16/03/25 13:53:51 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/25 13:53:51 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/userFiles-6f692c28-d61a-4bf4-a28a-694987044603/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:53:52 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/25 13:53:52 INFO MemoryStore: ensureFreeSpace(244) called with curMem=10727, maxMem=567080386
16/03/25 13:53:52 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 244.0 B, free 540.8 MB)
16/03/25 13:53:52 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:49535 (size: 244.0 B, free: 540.8 MB)
16/03/25 13:53:52 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/25 13:53:52 INFO MemoryStore: ensureFreeSpace(258) called with curMem=10971, maxMem=567080386
16/03/25 13:53:52 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 258.0 B, free 540.8 MB)
16/03/25 13:53:52 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:49535 (size: 258.0 B, free: 540.8 MB)
asfer_pickle_string_load(): picklef.readlines(): terms
mapFunction_Parents(): keyword: terms ; prevleveltokens: Chennai
asfer_pickle_string_load(): picklef.readlines(): terms
mapFunction_Parents(): keyword: terms ; prevleveltokens: city
mapFunction_Parents(): keyword= terms ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): terms
mapFunction_Parents(): keyword: terms ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= terms ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): terms
mapFunction_Parents(): keyword: terms ; prevleveltokens: area
mapFunction_Parents(): keyword= terms ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): terms
mapFunction_Parents(): keyword: terms ; prevleveltokens: expansion
mapFunction_Parents(): keyword= terms ; syndef_tokens= set([u'a', u'function', u'product', u'terms', u'of', u'sum', u'expressed', u'as', u'or'])
mapFunction_Parents(): adding to parents: syn =  Synset('expansion.n.02') ; keyword:  terms  in syndef_tokens= set([u'a', u'function', u'product', u'terms', u'of', u'sum', u'expressed', u'as', u'or'])
mapFunction_Parents(): returns= [u'expansion']
reduceFunction_Parents(): returns= ['None', u'expansion']
asfer_pickle_string_load(): picklef.readlines(): terms
mapFunction_Parents(): keyword: terms ; prevleveltokens: serving
mapFunction_Parents(): keyword= terms ; syndef_tokens= set([u'a', u'food', u'of', u'drink', u'meal', u'an', u'as', u'individual', u'taken', u'part', u'or', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'expansion']
asfer_pickle_string_load(): picklef.readlines(): terms
mapFunction_Parents(): keyword: terms ; prevleveltokens: formerly
mapFunction_Parents(): keyword= terms ; syndef_tokens= set([u'a', u';', u'time', u'at', u'previous'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'expansion']
asfer_pickle_string_load(): picklef.readlines(): terms
mapFunction_Parents(): keyword: terms ; prevleveltokens: people
mapFunction_Parents(): keyword= terms ; syndef_tokens= set([u'group', u')', u'(', u'men', u'children', u'or', u'collectively', u'beings', u'human', u'of', u'plural', u'any', u'women'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'expansion']
asfer_pickle_string_load(): picklef.readlines(): terms
mapFunction_Parents(): keyword: terms ; prevleveltokens: Christianity
mapFunction_Parents(): keyword= terms ; syndef_tokens= set([u'a', u'and', u'monotheistic', u'based', u'embodied', u'on', u'New', u'of', u'in', u'system', u'Jesus', u'as', u'practices', u'role', u'emphasizing', u'teachings', u'Testament', u'Old', u'the', u'beliefs', u'savior'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'expansion']
asfer_pickle_string_load(): picklef.readlines(): terms
mapFunction_Parents(): keyword: terms ; prevleveltokens: culture
mapFunction_Parents(): keyword= terms ; syndef_tokens= set([u'a', u'and', u'particular', u'society', u'place', u'at', u'time'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'expansion']
asfer_pickle_string_load(): picklef.readlines(): terms
mapFunction_Parents(): keyword: terms ; prevleveltokens: indefinite
mapFunction_Parents(): keyword= terms ; syndef_tokens= set([u'or', u'stated', u'defined', u'clearly', u'not', u'vague'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'expansion']
asfer_pickle_string_load(): picklef.readlines(): terms
mapFunction_Parents(): keyword: terms ; prevleveltokens: bishop
mapFunction_Parents(): keyword= terms ; syndef_tokens= set([u'and', u'the', u'spiritual', u'Christ', u'twelve', u'some', u'authority', u'in', u'Christian', u'ministers', u'member', u'to', u'churches', u';', u'administrative', u'be', u'Apostles', u'appointed', u'a', u'oversee', u'of', u'priests', u'or', u'considered', u'clergy', u'senior', u'successors', u'having'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'expansion']
asfer_pickle_string_load(): picklef.readlines(): terms
mapFunction_Parents(): keyword: terms ; prevleveltokens: special
mapFunction_Parents(): keyword= terms ; syndef_tokens= set([u'a', u'and', u'temporary', u'offering', u'that', u')', u'(', u'price', u'featured', u'at', u'in', u'usually', u'is', u'reduced', u'special', u'advertising'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'expansion']
asfer_pickle_string_load(): picklef.readlines(): terms
mapFunction_Parents(): keyword: terms ; prevleveltokens: geography
mapFunction_Parents(): keyword= terms ; syndef_tokens= set([u'and', u'climate', u'topography', u"'s", u'responses', u'people', u'of', u'study', u'surface', u'includes', u'to', u'soil', u'earth', u'the', u';', u'vegetation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'expansion']
16/03/25 13:54:00 INFO PythonRunner: Times: total = 8593, boot = 483, init = 376, finish = 7734
16/03/25 13:54:00 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/25 13:54:00 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8717 ms on localhost (1/2)
mapFunction_Parents(): keyword= terms ; syndef_tokens= set([u'a', u'and', u'districts', u'several', u'urban', u'may', u'populated', u'large', u'area', u'independent', u'densely', u';', u'include', u'administrative'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): terms
mapFunction_Parents(): keyword: terms ; prevleveltokens: given
mapFunction_Parents(): keyword= terms ; syndef_tokens= set([u'for', u'that', u'is', u'an', u'assumption', u'taken', u'granted'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): terms
mapFunction_Parents(): keyword: terms ; prevleveltokens: Madras
mapFunction_Parents(): keyword= terms ; syndef_tokens= set([u'a', u'on', u';', u'Madras', u'formerly', u')', u'of', u'India', u'Bay', u'state', u'Andhra', u'(', u'in', u'the', u'Bengal', u'Pradesh', u'southeastern', u'south'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): terms
mapFunction_Parents(): keyword: terms ; prevleveltokens: Eastern
mapFunction_Parents(): keyword= terms ; syndef_tokens= set([u'east', u'situated', u'in', u'the', u'toward', u'or', u'lying'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): terms
mapFunction_Parents(): keyword: terms ; prevleveltokens: archbishop
mapFunction_Parents(): keyword= terms ; syndef_tokens= set([u'a', u'of', u'highest', u'bishop', u'rank'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): terms
mapFunction_Parents(): keyword: terms ; prevleveltokens: sum
mapFunction_Parents(): keyword= terms ; syndef_tokens= set([u'a', u'of', u'money', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): terms
mapFunction_Parents(): keyword: terms ; prevleveltokens: expressed
mapFunction_Parents(): keyword= terms ; syndef_tokens= set([u'to', u'expression', u'give'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): terms
mapFunction_Parents(): keyword: terms ; prevleveltokens: geographical
mapFunction_Parents(): keyword= terms ; syndef_tokens= set([u'science', u'or', u'to', u'of', u'relating', u'the', u'geography'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): terms
mapFunction_Parents(): keyword: terms ; prevleveltokens: boundary
mapFunction_Parents(): keyword= terms ; syndef_tokens= set([u'a', u'limits', u'area', u'determining', u'an', u'of', u'line', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): terms
mapFunction_Parents(): keyword: terms ; prevleveltokens: Tamil
mapFunction_Parents(): keyword= terms ; syndef_tokens= set([u'a', u'and', u'people', u'of', u'Sri', u'southern', u'member', u'India', u'mixed', u'Dravidian', u'the', u'Lanka', u'Caucasian'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): terms
mapFunction_Parents(): keyword: terms ; prevleveltokens: Nadu
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): terms
mapFunction_Parents(): keyword: terms ; prevleveltokens: function
mapFunction_Parents(): keyword= terms ; syndef_tokens= set([u'mathematical', u'domain', u'set', u'associated', u'is', u'an', u'relation', u'another', u'given', u')', u'(', u'mathematics', u'function', u'that', u'such', u'with', u'a', u'of', u'element', u'range', u'each', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): terms
mapFunction_Parents(): keyword: terms ; prevleveltokens: product
mapFunction_Parents(): keyword= terms ; syndef_tokens= set([u'commodities', u'offered', u'sale', u'for'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): terms
mapFunction_Parents(): keyword: terms ; prevleveltokens: terms
mapFunction_Parents(): keyword= terms ; syndef_tokens= set([u'status', u'people', u'relations', u'to', u'groups', u'between', u'respect', u'the', u'with', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/25 13:54:00 INFO PythonRunner: Times: total = 8926, boot = 475, init = 429, finish = 8022
16/03/25 13:54:00 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/25 13:54:00 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 9.056 s
16/03/25 13:54:00 INFO DAGScheduler: looking for newly runnable stages
16/03/25 13:54:00 INFO DAGScheduler: running: Set()
16/03/25 13:54:00 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/25 13:54:00 INFO DAGScheduler: failed: Set()
16/03/25 13:54:00 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/25 13:54:00 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which is now runnable
16/03/25 13:54:00 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11229, maxMem=567080386
16/03/25 13:54:00 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 540.8 MB)
16/03/25 13:54:01 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 9052 ms on localhost (2/2)
16/03/25 13:54:01 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/25 13:54:01 INFO MemoryStore: ensureFreeSpace(3056) called with curMem=16213, maxMem=567080386
16/03/25 13:54:01 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 540.8 MB)
16/03/25 13:54:01 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:49535 (size: 3.0 KB, free: 540.8 MB)
16/03/25 13:54:01 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/25 13:54:01 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:54:01 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/25 13:54:01 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:54:01 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:54:01 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/25 13:54:01 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/25 13:54:01 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:54:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
16/03/25 13:54:01 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:54:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
16/03/25 13:54:01 INFO PythonRunner: Times: total = 31, boot = -145, init = 176, finish = 0
16/03/25 13:54:01 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/25 13:54:01 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 63 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'expansion', 'None']
16/03/25 13:54:01 INFO PythonRunner: Times: total = 269, boot = 266, init = 0, finish = 3
16/03/25 13:54:01 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1285 bytes result sent to driver
16/03/25 13:54:01 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.296 s
16/03/25 13:54:01 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 9.395177 s
16/03/25 13:54:01 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 297 ms on localhost (2/2)
16/03/25 13:54:01 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/25 13:54:01 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:54:01 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:54:01 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:54:01 INFO DAGScheduler: Parents of final stage: List()
16/03/25 13:54:01 INFO DAGScheduler: Missing parents: List()
16/03/25 13:54:01 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:54:01 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19269, maxMem=567080386
16/03/25 13:54:01 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 540.8 MB)
16/03/25 13:54:01 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25085, maxMem=567080386
16/03/25 13:54:01 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 540.8 MB)
16/03/25 13:54:01 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:49535 (size: 3.3 KB, free: 540.8 MB)
16/03/25 13:54:01 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/25 13:54:01 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:54:01 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/25 13:54:01 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/25 13:54:01 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2366 bytes)
16/03/25 13:54:01 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/25 13:54:01 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/25 13:54:01 INFO PythonRunner: Times: total = 48, boot = 47, init = 1, finish = 0
16/03/25 13:54:01 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1353 bytes result sent to driver
16/03/25 13:54:01 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 59 ms on localhost (1/2)
16/03/25 13:54:01 INFO PythonRunner: Times: total = 59, boot = -91, init = 150, finish = 0
16/03/25 13:54:01 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/25 13:54:01 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 68 ms on localhost (2/2)
16/03/25 13:54:01 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/25 13:54:01 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.078 s
16/03/25 13:54:01 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 0.107649 s
16/03/25 13:54:01 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/25 13:54:01 INFO DAGScheduler: Stopping DAGScheduler
16/03/25 13:54:01 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/25 13:54:01 INFO MemoryStore: MemoryStore cleared
16/03/25 13:54:01 INFO BlockManager: BlockManager stopped
16/03/25 13:54:01 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/25 13:54:01 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/25 13:54:01 INFO SparkContext: Successfully stopped SparkContext
16/03/25 13:54:01 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
graphcache_mapreduce_parents updated: defaultdict(<cyfunction <lambda> at 0xb1f81e6c>, {'2c49f1424d675552d9e7323a3eef6206': [u'None', u'expansion', u'None'], '45b800affe042d5d9a4228427680a935': [u'Chennai', u'None'], 'fdc633a5e1dea73592deb7e3bbbe3aea': [u'Chennai', u'None'], 'dd10336563a65a645a42bb416a6ebec6': [u'None', u'area', u'None'], 'a8f48eba5bb66d59263f478b93779a2c': [u'metropolitan', u'None'], '9f1808799460fd7b2da9ab51bd7b6775': [u'None', u'area', u'None'], '44b9adf04881710b0a7c81b0a22b1209': [u'Chennai', u'None'], 'e9301955882d67edfb275156ef73113c': [u'metropolitan', u'None'], '552934a698e1bcf880132a2bd5996d11': [u'None', u'area', u'None'], '063da2002ba149bb4025d1e1fcfb49f5': [u'None', u'area', u'None'], 'a31cc044ea8d13e6b1bf4e98768e44a5': [u'None', u'area', u'None'], 'b1318a4c6d13196fb45da6102d193223': [u'None', u'area', u'None', u'special'], 'ed43ebbafa0c6204a5916ca879d5bd26': [u'None', u'area'], 'c65d3beca4dc2d6f37377a842accc0cd': [u'None', u'expansion', u'None', u'function'], '3cd540871242471e0d89bea4eabc06ea': [u'None', u'expansion', u'None'], '40603e72c50afb5b6be8a7ff1684c966': [u'Chennai', u'None', u'Madras'], '4208c80be8e0c0d285fafd73cd5bd9a6': [u'metropolitan', u'None'], 'b7b50c706678d48359a2ac685d535b33': [u'metropolitan', u'None'], 'f2e69333b98cfc98f544ee3a5717b7c4': [u'Chennai', u'None'], '926a71600b58a41448b179d8665fd5df': [u'None', u'expansion', u'None'], 'e6ebeac0f1cb14fbd7b903291fcc6a8f': [u'metropolitan', u'None'], '25439f8325592e4ecd8b06f5f799b57a': [u'None', u'expansion', u'None'], 'd7b9ba5125de58e77ad31543f2c54034': [u'None', u'area', u'None']})
asfer_pickle_string_dump(): picklef.write(): equivalent
16/03/25 13:54:02 INFO SparkContext: Running Spark version 1.5.2
16/03/25 13:54:02 INFO SecurityManager: Changing view acls to: root
16/03/25 13:54:02 INFO SecurityManager: Changing modify acls to: root
16/03/25 13:54:02 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/25 13:54:02 INFO Slf4jLogger: Slf4jLogger started
16/03/25 13:54:02 INFO Remoting: Starting remoting
16/03/25 13:54:02 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:36859]
16/03/25 13:54:02 INFO Utils: Successfully started service 'sparkDriver' on port 36859.
16/03/25 13:54:02 INFO SparkEnv: Registering MapOutputTracker
16/03/25 13:54:02 INFO SparkEnv: Registering BlockManagerMaster
16/03/25 13:54:02 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-f07324ee-57dd-4b8c-a5df-8f8bda773a48
16/03/25 13:54:02 INFO MemoryStore: MemoryStore started with capacity 540.8 MB
16/03/25 13:54:02 INFO HttpFileServer: HTTP File server directory is /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/httpd-848b40a6-9051-4cec-a96e-5a61317a9664
16/03/25 13:54:02 INFO HttpServer: Starting HTTP Server
16/03/25 13:54:02 INFO Utils: Successfully started service 'HTTP file server' on port 50227.
16/03/25 13:54:02 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/25 13:54:02 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/25 13:54:02 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/25 13:54:02 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/userFiles-381c36d3-9fce-481e-a5b1-0aedb173ffd8/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:54:02 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458894242882
16/03/25 13:54:02 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/25 13:54:02 INFO Executor: Starting executor ID driver on host localhost
16/03/25 13:54:02 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44301.
16/03/25 13:54:02 INFO NettyBlockTransferService: Server created on 44301
16/03/25 13:54:02 INFO BlockManagerMaster: Trying to register BlockManager
16/03/25 13:54:02 INFO BlockManagerMasterEndpoint: Registering block manager localhost:44301 with 540.8 MB RAM, BlockManagerId(driver, localhost, 44301)
16/03/25 13:54:02 INFO BlockManagerMaster: Registered BlockManager
16/03/25 13:54:03 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:54:03 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:54:03 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:54:03 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:54:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/25 13:54:03 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/25 13:54:03 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:54:03 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=567080386
16/03/25 13:54:03 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 540.8 MB)
16/03/25 13:54:03 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=567080386
16/03/25 13:54:03 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 540.8 MB)
16/03/25 13:54:03 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:44301 (size: 4.1 KB, free: 540.8 MB)
16/03/25 13:54:03 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/25 13:54:03 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:54:03 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/25 13:54:03 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2520 bytes)
16/03/25 13:54:03 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2511 bytes)
16/03/25 13:54:03 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/25 13:54:03 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458894242882
16/03/25 13:54:03 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/25 13:54:03 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/userFiles-381c36d3-9fce-481e-a5b1-0aedb173ffd8/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:54:03 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/25 13:54:03 INFO MemoryStore: ensureFreeSpace(254) called with curMem=10732, maxMem=567080386
16/03/25 13:54:03 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 254.0 B, free 540.8 MB)
16/03/25 13:54:03 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:44301 (size: 254.0 B, free: 540.8 MB)
16/03/25 13:54:03 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/25 13:54:03 INFO MemoryStore: ensureFreeSpace(255) called with curMem=10986, maxMem=567080386
16/03/25 13:54:03 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 255.0 B, free 540.8 MB)
16/03/25 13:54:03 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:44301 (size: 255.0 B, free: 540.8 MB)
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: Chennai
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: given
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): adding to parents: syn =  Synset('metropolitan.n.01') ; keyword:  equivalent  in syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= [u'metropolitan']
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: area
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: expansion
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'a', u'function', u'product', u'terms', u'of', u'sum', u'expressed', u'as', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: serving
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'a', u'food', u'of', u'drink', u'meal', u'an', u'as', u'individual', u'taken', u'part', u'or', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: formerly
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'a', u';', u'time', u'at', u'previous'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: people
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'group', u')', u'(', u'men', u'children', u'or', u'collectively', u'beings', u'human', u'of', u'plural', u'any', u'women'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: Christianity
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'a', u'and', u'monotheistic', u'based', u'embodied', u'on', u'New', u'of', u'in', u'system', u'Jesus', u'as', u'practices', u'role', u'emphasizing', u'teachings', u'Testament', u'Old', u'the', u'beliefs', u'savior'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: culture
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'a', u'and', u'particular', u'society', u'place', u'at', u'time'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: indefinite
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'or', u'stated', u'defined', u'clearly', u'not', u'vague'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: bishop
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'and', u'the', u'spiritual', u'Christ', u'twelve', u'some', u'authority', u'in', u'Christian', u'ministers', u'member', u'to', u'churches', u';', u'administrative', u'be', u'Apostles', u'appointed', u'a', u'oversee', u'of', u'priests', u'or', u'considered', u'clergy', u'senior', u'successors', u'having'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: special
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'a', u'and', u'temporary', u'offering', u'that', u')', u'(', u'price', u'featured', u'at', u'in', u'usually', u'is', u'reduced', u'special', u'advertising'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: geography
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'and', u'climate', u'topography', u"'s", u'responses', u'people', u'of', u'study', u'surface', u'includes', u'to', u'soil', u'earth', u'the', u';', u'vegetation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: city
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'a', u'and', u'districts', u'several', u'urban', u'may', u'populated', u'large', u'area', u'independent', u'densely', u';', u'include', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
16/03/25 13:54:11 INFO PythonRunner: Times: total = 8634, boot = 536, init = 418, finish = 7680
16/03/25 13:54:11 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/25 13:54:11 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8780 ms on localhost (1/2)
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'for', u'that', u'is', u'an', u'assumption', u'taken', u'granted'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: Madras
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'a', u'on', u';', u'Madras', u'formerly', u')', u'of', u'India', u'Bay', u'state', u'Andhra', u'(', u'in', u'the', u'Bengal', u'Pradesh', u'southeastern', u'south'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: Eastern
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'east', u'situated', u'in', u'the', u'toward', u'or', u'lying'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: archbishop
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'a', u'of', u'highest', u'bishop', u'rank'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: sum
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'a', u'of', u'money', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: expressed
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'to', u'expression', u'give'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: geographical
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'science', u'or', u'to', u'of', u'relating', u'the', u'geography'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: boundary
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'a', u'limits', u'area', u'determining', u'an', u'of', u'line', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: Tamil
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'a', u'and', u'people', u'of', u'Sri', u'southern', u'member', u'India', u'mixed', u'Dravidian', u'the', u'Lanka', u'Caucasian'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: Nadu
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: function
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'mathematical', u'domain', u'set', u'associated', u'is', u'an', u'relation', u'another', u'given', u')', u'(', u'mathematics', u'function', u'that', u'such', u'with', u'a', u'of', u'element', u'range', u'each', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: product
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'commodities', u'offered', u'sale', u'for'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: terms
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'status', u'people', u'relations', u'to', u'groups', u'between', u'respect', u'the', u'with', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): equivalent
mapFunction_Parents(): keyword: equivalent ; prevleveltokens: equivalent
mapFunction_Parents(): keyword= equivalent ; syndef_tokens= set([u'a', u'force', u'significance', u'to', u'measure', u'equal', u'value', u'effect', u'person', u'another', u'in', u'thing', u'or', u'etc'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/25 13:54:12 INFO PythonRunner: Times: total = 9174, boot = 524, init = 578, finish = 8072
16/03/25 13:54:12 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/25 13:54:12 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 9.322 s
16/03/25 13:54:12 INFO DAGScheduler: looking for newly runnable stages
16/03/25 13:54:12 INFO DAGScheduler: running: Set()
16/03/25 13:54:12 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/25 13:54:12 INFO DAGScheduler: failed: Set()
16/03/25 13:54:12 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/25 13:54:12 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which is now runnable
16/03/25 13:54:12 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11241, maxMem=567080386
16/03/25 13:54:12 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 540.8 MB)
16/03/25 13:54:12 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16225, maxMem=567080386
16/03/25 13:54:12 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 540.8 MB)
16/03/25 13:54:12 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 9320 ms on localhost (2/2)
16/03/25 13:54:12 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/25 13:54:12 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:44301 (size: 3.0 KB, free: 540.8 MB)
16/03/25 13:54:12 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/25 13:54:12 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:54:12 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/25 13:54:12 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:54:12 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:54:12 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/25 13:54:12 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:54:12 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/25 13:54:12 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:54:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/25 13:54:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
reduceFunction_Parents(): returns= [u'metropolitan', 'None']
16/03/25 13:54:12 INFO PythonRunner: Times: total = 18, boot = -383, init = 401, finish = 0
16/03/25 13:54:12 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1280 bytes result sent to driver
16/03/25 13:54:12 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 55 ms on localhost (1/2)
16/03/25 13:54:12 INFO PythonRunner: Times: total = 233, boot = 231, init = 1, finish = 1
16/03/25 13:54:12 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/25 13:54:12 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 248 ms on localhost (2/2)
16/03/25 13:54:12 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.239 s
16/03/25 13:54:12 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/25 13:54:12 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 9.646951 s
16/03/25 13:54:12 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:54:12 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:54:12 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:54:12 INFO DAGScheduler: Parents of final stage: List()
16/03/25 13:54:12 INFO DAGScheduler: Missing parents: List()
16/03/25 13:54:12 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:54:12 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19280, maxMem=567080386
16/03/25 13:54:12 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 540.8 MB)
16/03/25 13:54:12 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25096, maxMem=567080386
16/03/25 13:54:12 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 540.8 MB)
16/03/25 13:54:12 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:44301 (size: 3.3 KB, free: 540.8 MB)
16/03/25 13:54:12 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/25 13:54:12 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:54:12 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/25 13:54:12 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/25 13:54:12 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2361 bytes)
16/03/25 13:54:12 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/25 13:54:12 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/25 13:54:12 INFO PythonRunner: Times: total = 69, boot = 69, init = 0, finish = 0
16/03/25 13:54:12 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/25 13:54:12 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 80 ms on localhost (1/2)
16/03/25 13:54:13 INFO PythonRunner: Times: total = 325, boot = 325, init = 0, finish = 0
16/03/25 13:54:13 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1345 bytes result sent to driver
16/03/25 13:54:13 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 341 ms on localhost (2/2)
16/03/25 13:54:13 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/25 13:54:13 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.334 s
16/03/25 13:54:13 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 0.367357 s
16/03/25 13:54:13 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/25 13:54:13 INFO DAGScheduler: Stopping DAGScheduler
16/03/25 13:54:13 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/25 13:54:13 INFO MemoryStore: MemoryStore cleared
16/03/25 13:54:13 INFO BlockManager: BlockManager stopped
16/03/25 13:54:13 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/25 13:54:13 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/25 13:54:13 INFO SparkContext: Successfully stopped SparkContext
16/03/25 13:54:13 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/25 13:54:13 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/25 13:54:13 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
graphcache_mapreduce_parents updated: defaultdict(<cyfunction <lambda> at 0xb1f81e6c>, {'2c49f1424d675552d9e7323a3eef6206': [u'None', u'expansion', u'None'], '45b800affe042d5d9a4228427680a935': [u'Chennai', u'None'], 'fdc633a5e1dea73592deb7e3bbbe3aea': [u'Chennai', u'None'], 'dd10336563a65a645a42bb416a6ebec6': [u'None', u'area', u'None'], 'a8f48eba5bb66d59263f478b93779a2c': [u'metropolitan', u'None'], '9f1808799460fd7b2da9ab51bd7b6775': [u'None', u'area', u'None'], '44b9adf04881710b0a7c81b0a22b1209': [u'Chennai', u'None'], 'e9301955882d67edfb275156ef73113c': [u'metropolitan', u'None'], '552934a698e1bcf880132a2bd5996d11': [u'None', u'area', u'None'], '063da2002ba149bb4025d1e1fcfb49f5': [u'None', u'area', u'None'], 'a31cc044ea8d13e6b1bf4e98768e44a5': [u'None', u'area', u'None'], 'b1318a4c6d13196fb45da6102d193223': [u'None', u'area', u'None', u'special'], '57466dae2c092869867908c5c54e241c': [u'metropolitan', u'None'], 'ed43ebbafa0c6204a5916ca879d5bd26': [u'None', u'area'], 'c65d3beca4dc2d6f37377a842accc0cd': [u'None', u'expansion', u'None', u'function'], '3cd540871242471e0d89bea4eabc06ea': [u'None', u'expansion', u'None'], '40603e72c50afb5b6be8a7ff1684c966': [u'Chennai', u'None', u'Madras'], '4208c80be8e0c0d285fafd73cd5bd9a6': [u'metropolitan', u'None'], 'b7b50c706678d48359a2ac685d535b33': [u'metropolitan', u'None'], 'f2e69333b98cfc98f544ee3a5717b7c4': [u'Chennai', u'None'], '926a71600b58a41448b179d8665fd5df': [u'None', u'expansion', u'None'], 'e6ebeac0f1cb14fbd7b903291fcc6a8f': [u'metropolitan', u'None'], '25439f8325592e4ecd8b06f5f799b57a': [u'None', u'expansion', u'None'], 'd7b9ba5125de58e77ad31543f2c54034': [u'None', u'area', u'None']})
asfer_pickle_string_dump(): picklef.write(): Bay
16/03/25 13:54:14 INFO SparkContext: Running Spark version 1.5.2
16/03/25 13:54:14 INFO SecurityManager: Changing view acls to: root
16/03/25 13:54:14 INFO SecurityManager: Changing modify acls to: root
16/03/25 13:54:14 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/25 13:54:14 INFO Slf4jLogger: Slf4jLogger started
16/03/25 13:54:14 INFO Remoting: Starting remoting
16/03/25 13:54:14 INFO Utils: Successfully started service 'sparkDriver' on port 58492.
16/03/25 13:54:14 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:58492]
16/03/25 13:54:14 INFO SparkEnv: Registering MapOutputTracker
16/03/25 13:54:14 INFO SparkEnv: Registering BlockManagerMaster
16/03/25 13:54:14 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-f5d2e157-6aee-4f10-af9a-542f6cdd89ac
16/03/25 13:54:14 INFO MemoryStore: MemoryStore started with capacity 540.8 MB
16/03/25 13:54:14 INFO HttpFileServer: HTTP File server directory is /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/httpd-d0c6f842-9d61-4c7c-9740-a6ddd18d57af
16/03/25 13:54:14 INFO HttpServer: Starting HTTP Server
16/03/25 13:54:14 INFO Utils: Successfully started service 'HTTP file server' on port 40233.
16/03/25 13:54:14 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/25 13:54:14 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/25 13:54:14 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/25 13:54:14 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/userFiles-53257c62-3a49-4c17-be0c-16a8a29bf959/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:54:14 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458894254954
16/03/25 13:54:14 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/25 13:54:14 INFO Executor: Starting executor ID driver on host localhost
16/03/25 13:54:15 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45009.
16/03/25 13:54:15 INFO NettyBlockTransferService: Server created on 45009
16/03/25 13:54:15 INFO BlockManagerMaster: Trying to register BlockManager
16/03/25 13:54:15 INFO BlockManagerMasterEndpoint: Registering block manager localhost:45009 with 540.8 MB RAM, BlockManagerId(driver, localhost, 45009)
16/03/25 13:54:15 INFO BlockManagerMaster: Registered BlockManager
16/03/25 13:54:15 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:54:15 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:54:15 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:54:15 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:54:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/25 13:54:15 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/25 13:54:15 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:54:15 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=567080386
16/03/25 13:54:15 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 540.8 MB)
16/03/25 13:54:15 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=567080386
16/03/25 13:54:15 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 540.8 MB)
16/03/25 13:54:15 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:45009 (size: 4.1 KB, free: 540.8 MB)
16/03/25 13:54:15 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/25 13:54:15 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:54:15 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/25 13:54:15 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2520 bytes)
16/03/25 13:54:15 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2538 bytes)
16/03/25 13:54:15 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/25 13:54:15 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/25 13:54:15 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458894254954
16/03/25 13:54:15 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/userFiles-53257c62-3a49-4c17-be0c-16a8a29bf959/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:54:15 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/25 13:54:15 INFO MemoryStore: ensureFreeSpace(255) called with curMem=10732, maxMem=567080386
16/03/25 13:54:15 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 255.0 B, free 540.8 MB)
16/03/25 13:54:15 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:45009 (size: 255.0 B, free: 540.8 MB)
16/03/25 13:54:15 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/25 13:54:15 INFO MemoryStore: ensureFreeSpace(277) called with curMem=10987, maxMem=567080386
16/03/25 13:54:15 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 277.0 B, free 540.8 MB)
16/03/25 13:54:15 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:45009 (size: 277.0 B, free: 540.8 MB)
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: given
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'for', u'that', u'is', u'an', u'assumption', u'taken', u'granted'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: Madras
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'a', u'on', u';', u'Madras', u'formerly', u')', u'of', u'India', u'Bay', u'state', u'Andhra', u'(', u'in', u'the', u'Bengal', u'Pradesh', u'southeastern', u'south'])
mapFunction_Parents(): adding to parents: syn =  Synset('tamil_nadu.n.01') ; keyword:  Bay  in syndef_tokens= set([u'a', u'on', u';', u'Madras', u'formerly', u')', u'of', u'India', u'Bay', u'state', u'Andhra', u'(', u'in', u'the', u'Bengal', u'Pradesh', u'southeastern', u'south'])
mapFunction_Parents(): returns= [u'Madras']
reduceFunction_Parents(): returns= [u'Madras']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: Eastern
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'east', u'situated', u'in', u'the', u'toward', u'or', u'lying'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Madras']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: archbishop
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'a', u'of', u'highest', u'bishop', u'rank'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Madras']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: sum
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'a', u'of', u'money', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Madras']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: expressed
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'to', u'expression', u'give'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Madras']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: geographical
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'science', u'or', u'to', u'of', u'relating', u'the', u'geography'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Madras']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: boundary
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'a', u'limits', u'area', u'determining', u'an', u'of', u'line', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Madras']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: Tamil
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'a', u'and', u'people', u'of', u'Sri', u'southern', u'member', u'India', u'mixed', u'Dravidian', u'the', u'Lanka', u'Caucasian'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Madras']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: Nadu
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Madras']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: function
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'mathematical', u'domain', u'set', u'associated', u'is', u'an', u'relation', u'another', u'given', u')', u'(', u'mathematics', u'function', u'that', u'such', u'with', u'a', u'of', u'element', u'range', u'each', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Madras']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: product
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'commodities', u'offered', u'sale', u'for'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Madras']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: terms
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'status', u'people', u'relations', u'to', u'groups', u'between', u'respect', u'the', u'with', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Madras']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: equivalent
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'a', u'force', u'significance', u'to', u'measure', u'equal', u'value', u'effect', u'person', u'another', u'in', u'thing', u'or', u'etc'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Madras']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: Bay
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'a', u'smaller', u'shoreline', u'gulf', u'of', u'larger', u'cove', u'but', u'an', u'indentation', u'than'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Madras']
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): adding to parents: syn =  Synset('chennai.n.01') ; keyword:  Bay  in syndef_tokens= 16/03/25 13:54:23 INFO PythonRunner: Times: total = 8685, boot = 513, init = 372, finish = 7800
16/03/25 13:54:23 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: area
16/03/25 13:54:23 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8830 ms on localhost (1/2)
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: expansion
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'a', u'function', u'product', u'terms', u'of', u'sum', u'expressed', u'as', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: serving
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'a', u'food', u'of', u'drink', u'meal', u'an', u'as', u'individual', u'taken', u'part', u'or', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: formerly
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'a', u';', u'time', u'at', u'previous'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: people
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'group', u')', u'(', u'men', u'children', u'or', u'collectively', u'beings', u'human', u'of', u'plural', u'any', u'women'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: Christianity
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'a', u'and', u'monotheistic', u'based', u'embodied', u'on', u'New', u'of', u'in', u'system', u'Jesus', u'as', u'practices', u'role', u'emphasizing', u'teachings', u'Testament', u'Old', u'the', u'beliefs', u'savior'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: culture
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'a', u'and', u'particular', u'society', u'place', u'at', u'time'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: indefinite
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'or', u'stated', u'defined', u'clearly', u'not', u'vague'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: bishop
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'and', u'the', u'spiritual', u'Christ', u'twelve', u'some', u'authority', u'in', u'Christian', u'ministers', u'member', u'to', u'churches', u';', u'administrative', u'be', u'Apostles', u'appointed', u'a', u'oversee', u'of', u'priests', u'or', u'considered', u'clergy', u'senior', u'successors', u'having'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: special
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'a', u'and', u'temporary', u'offering', u'that', u')', u'(', u'price', u'featured', u'at', u'in', u'usually', u'is', u'reduced', u'special', u'advertising'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: geography
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'and', u'climate', u'topography', u"'s", u'responses', u'people', u'of', u'study', u'surface', u'includes', u'to', u'soil', u'earth', u'the', u';', u'vegetation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Bay
mapFunction_Parents(): keyword: Bay ; prevleveltokens: city
mapFunction_Parents(): keyword= Bay ; syndef_tokens= set([u'a', u'and', u'districts', u'several', u'urban', u'may', u'populated', u'large', u'area', u'independent', u'densely', u';', u'include', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
16/03/25 13:54:24 INFO PythonRunner: Times: total = 9020, boot = 516, init = 461, finish = 8043
16/03/25 13:54:24 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/25 13:54:24 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9110 ms on localhost (2/2)
16/03/25 13:54:24 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/25 13:54:24 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 9.092 s
16/03/25 13:54:24 INFO DAGScheduler: looking for newly runnable stages
16/03/25 13:54:24 INFO DAGScheduler: running: Set()
16/03/25 13:54:24 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/25 13:54:24 INFO DAGScheduler: failed: Set()
16/03/25 13:54:24 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/25 13:54:24 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which is now runnable
16/03/25 13:54:24 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11264, maxMem=567080386
16/03/25 13:54:24 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 540.8 MB)
16/03/25 13:54:24 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16248, maxMem=567080386
16/03/25 13:54:24 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 540.8 MB)
16/03/25 13:54:24 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:45009 (size: 3.0 KB, free: 540.8 MB)
16/03/25 13:54:24 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/25 13:54:24 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:54:24 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/25 13:54:24 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:54:24 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:54:24 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/25 13:54:24 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/25 13:54:24 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:54:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/25 13:54:24 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:54:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
reduceFunction_Parents(): returns= [u'Chennai', u'Madras']
16/03/25 13:54:24 INFO PythonRunner: Times: total = 35, boot = -90, init = 124, finish = 1
16/03/25 13:54:24 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1280 bytes result sent to driver
16/03/25 13:54:24 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 89 ms on localhost (1/2)
16/03/25 13:54:24 INFO PythonRunner: Times: total = 207, boot = 206, init = 0, finish = 1
16/03/25 13:54:24 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/25 13:54:24 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 230 ms on localhost (2/2)
16/03/25 13:54:24 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/25 13:54:24 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.226 s
16/03/25 13:54:24 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 9.426360 s
16/03/25 13:54:24 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:54:24 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:54:24 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:54:24 INFO DAGScheduler: Parents of final stage: List()
16/03/25 13:54:24 INFO DAGScheduler: Missing parents: List()
16/03/25 13:54:24 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:54:24 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19303, maxMem=567080386
16/03/25 13:54:24 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 540.8 MB)
16/03/25 13:54:24 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25119, maxMem=567080386
16/03/25 13:54:24 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 540.8 MB)
16/03/25 13:54:24 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:45009 (size: 3.3 KB, free: 540.8 MB)
16/03/25 13:54:24 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/25 13:54:24 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:54:24 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/25 13:54:24 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/25 13:54:24 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2361 bytes)
16/03/25 13:54:24 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/25 13:54:24 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/25 13:54:24 INFO PythonRunner: Times: total = 166, boot = -23, init = 189, finish = 0
16/03/25 13:54:24 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1342 bytes result sent to driver
16/03/25 13:54:24 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 198 ms on localhost (1/2)
16/03/25 13:54:24 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:45009 in memory (size: 3.0 KB, free: 540.8 MB)
16/03/25 13:54:25 INFO PythonRunner: Times: total = 226, boot = 11, init = 215, finish = 0
16/03/25 13:54:25 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/25 13:54:25 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 237 ms on localhost (2/2)
16/03/25 13:54:25 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/25 13:54:25 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.228 s
16/03/25 13:54:25 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 0.366475 s
16/03/25 13:54:25 INFO ContextCleaner: Cleaned accumulator 103
16/03/25 13:54:25 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:45009 in memory (size: 4.1 KB, free: 540.8 MB)
16/03/25 13:54:25 INFO ContextCleaner: Cleaned accumulator 102
16/03/25 13:54:25 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/25 13:54:25 INFO DAGScheduler: Stopping DAGScheduler
16/03/25 13:54:25 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/25 13:54:25 INFO MemoryStore: MemoryStore cleared
16/03/25 13:54:25 INFO BlockManager: BlockManager stopped
16/03/25 13:54:25 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/25 13:54:25 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/25 13:54:25 INFO SparkContext: Successfully stopped SparkContext
16/03/25 13:54:25 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/25 13:54:25 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/25 13:54:25 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
graphcache_mapreduce_parents updated: defaultdict(<cyfunction <lambda> at 0xb1f81e6c>, {'2c49f1424d675552d9e7323a3eef6206': [u'None', u'expansion', u'None'], '45b800affe042d5d9a4228427680a935': [u'Chennai', u'None'], 'fdc633a5e1dea73592deb7e3bbbe3aea': [u'Chennai', u'None'], 'dd10336563a65a645a42bb416a6ebec6': [u'None', u'area', u'None'], 'a8f48eba5bb66d59263f478b93779a2c': [u'metropolitan', u'None'], '9f1808799460fd7b2da9ab51bd7b6775': [u'None', u'area', u'None'], '4b7e9f2659636820e82592ed034512f9': [u'Chennai', u'Madras'], '44b9adf04881710b0a7c81b0a22b1209': [u'Chennai', u'None'], 'e9301955882d67edfb275156ef73113c': [u'metropolitan', u'None'], '552934a698e1bcf880132a2bd5996d11': [u'None', u'area', u'None'], '063da2002ba149bb4025d1e1fcfb49f5': [u'None', u'area', u'None'], 'a31cc044ea8d13e6b1bf4e98768e44a5': [u'None', u'area', u'None'], 'b1318a4c6d13196fb45da6102d193223': [u'None', u'area', u'None', u'special'], '57466dae2c092869867908c5c54e241c': [u'metropolitan', u'None'], 'ed43ebbafa0c6204a5916ca879d5bd26': [u'None', u'area'], 'c65d3beca4dc2d6f37377a842accc0cd': [u'None', u'expansion', u'None', u'function'], '3cd540871242471e0d89bea4eabc06ea': [u'None', u'expansion', u'None'], '40603e72c50afb5b6be8a7ff1684c966': [u'Chennai', u'None', u'Madras'], '4208c80be8e0c0d285fafd73cd5bd9a6': [u'metropolitan', u'None'], 'b7b50c706678d48359a2ac685d535b33': [u'metropolitan', u'None'], 'f2e69333b98cfc98f544ee3a5717b7c4': [u'Chennai', u'None'], '926a71600b58a41448b179d8665fd5df': [u'None', u'expansion', u'None'], 'e6ebeac0f1cb14fbd7b903291fcc6a8f': [u'metropolitan', u'None'], '25439f8325592e4ecd8b06f5f799b57a': [u'None', u'expansion', u'None'], 'd7b9ba5125de58e77ad31543f2c54034': [u'None', u'area', u'None']})
asfer_pickle_string_dump(): picklef.write(): western
16/03/25 13:54:26 INFO SparkContext: Running Spark version 1.5.2
16/03/25 13:54:26 INFO SecurityManager: Changing view acls to: root
16/03/25 13:54:26 INFO SecurityManager: Changing modify acls to: root
16/03/25 13:54:26 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/25 13:54:26 INFO Slf4jLogger: Slf4jLogger started
16/03/25 13:54:26 INFO Remoting: Starting remoting
16/03/25 13:54:26 INFO Utils: Successfully started service 'sparkDriver' on port 46106.
16/03/25 13:54:26 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:46106]
16/03/25 13:54:26 INFO SparkEnv: Registering MapOutputTracker
16/03/25 13:54:26 INFO SparkEnv: Registering BlockManagerMaster
16/03/25 13:54:26 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-e2460bae-78fc-4f63-a518-9b7778c53b59
16/03/25 13:54:26 INFO MemoryStore: MemoryStore started with capacity 541.3 MB
16/03/25 13:54:26 INFO HttpFileServer: HTTP File server directory is /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/httpd-c4571e04-7cad-4701-91df-dcb90bb52e75
16/03/25 13:54:26 INFO HttpServer: Starting HTTP Server
16/03/25 13:54:26 INFO Utils: Successfully started service 'HTTP file server' on port 33075.
16/03/25 13:54:26 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/25 13:54:26 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/25 13:54:26 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/25 13:54:26 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/userFiles-02296801-719f-42eb-b859-562d9b2bdfe2/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:54:26 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458894266297
16/03/25 13:54:26 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/25 13:54:26 INFO Executor: Starting executor ID driver on host localhost
16/03/25 13:54:26 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45686.
16/03/25 13:54:26 INFO NettyBlockTransferService: Server created on 45686
16/03/25 13:54:26 INFO BlockManagerMaster: Trying to register BlockManager
16/03/25 13:54:26 INFO BlockManagerMasterEndpoint: Registering block manager localhost:45686 with 541.3 MB RAM, BlockManagerId(driver, localhost, 45686)
16/03/25 13:54:26 INFO BlockManagerMaster: Registered BlockManager
16/03/25 13:54:26 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:54:26 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:54:26 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:54:26 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:54:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/25 13:54:26 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/25 13:54:26 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:54:26 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=567646617
16/03/25 13:54:26 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 541.3 MB)
16/03/25 13:54:26 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=567646617
16/03/25 13:54:26 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 541.3 MB)
16/03/25 13:54:26 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:45686 (size: 4.1 KB, free: 541.3 MB)
16/03/25 13:54:26 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/25 13:54:26 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:54:26 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/25 13:54:26 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2532 bytes)
16/03/25 13:54:26 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2523 bytes)
16/03/25 13:54:26 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/25 13:54:26 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458894266297
16/03/25 13:54:26 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/25 13:54:26 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/userFiles-02296801-719f-42eb-b859-562d9b2bdfe2/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:54:26 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/25 13:54:26 INFO MemoryStore: ensureFreeSpace(266) called with curMem=10732, maxMem=567646617
16/03/25 13:54:26 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 266.0 B, free 541.3 MB)
16/03/25 13:54:26 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:45686 (size: 266.0 B, free: 541.3 MB)
16/03/25 13:54:26 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/25 13:54:26 INFO MemoryStore: ensureFreeSpace(268) called with curMem=10998, maxMem=567646617
16/03/25 13:54:26 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 268.0 B, free 541.3 MB)
16/03/25 13:54:26 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:45686 (size: 268.0 B, free: 541.3 MB)
asfer_pickle_string_load(): picklef.readlines():asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: Madras
 western
mapFunction_Parents(): keyword: western ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'a', u'on', u';', u'Madras', u'formerly', u')', u'of', u'India', u'Bay', u'state', u'Andhra', u'(', u'in', u'the', u'Bengal', u'Pradesh', u'southeastern', u'south'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: Eastern
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'east', u'situated', u'in', u'the', u'toward', u'or', u'lying'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: archbishop
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'a', u'of', u'highest', u'bishop', u'rank'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: sum
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'a', u'of', u'money', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: expressed
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'to', u'expression', u'give'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: geographical
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'science', u'or', u'to', u'of', u'relating', u'the', u'geography'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: boundary
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'a', u'limits', u'area', u'determining', u'an', u'of', u'line', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: Tamil
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'a', u'and', u'people', u'of', u'Sri', u'southern', u'member', u'India', u'mixed', u'Dravidian', u'the', u'Lanka', u'Caucasian'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: Nadu
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: function
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'mathematical', u'domain', u'set', u'associated', u'is', u'an', u'relation', u'another', u'given', u')', u'(', u'mathematics', u'function', u'that', u'such', u'with', u'a', u'of', u'element', u'range', u'each', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: product
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'commodities', u'offered', u'sale', u'for'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: terms
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'status', u'people', u'relations', u'to', u'groups', u'between', u'respect', u'the', u'with', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: equivalent
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'a', u'force', u'significance', u'to', u'measure', u'equal', u'value', u'effect', u'person', u'another', u'in', u'thing', u'or', u'etc'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: Bay
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'a', u'smaller', u'shoreline', u'gulf', u'of', u'larger', u'cove', u'but', u'an', u'indentation', u'than'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: western
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'a', u'and', u'about', u'United', u'development', u'of', u'life', u'period', u'States', u'exploration', u'western', u'in', u'during', u'the', u'film'])
mapFunction_Parents(): adding to parents: syn =  Synset('western.n.01') ; keyword:  western  in syndef_tokens= set([u'a', u'and', u'about', u'United', u'development', u'of', u'life', u'period', u'States', u'exploration', u'western', u'in', u'during', u'the', u'film'])
mapFunction_Parents(): returns= [u'western']
reduceFunction_Parents(): returns= ['None', u'western']
16/03/25 13:54:36 INFO PythonRunner: Times: total = 10250, boot = 1558, init = 1083, finish = 7609
16/03/25 13:54:36 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/25 13:54:36 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 10358 ms on localhost (1/2)
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): adding to parents: syn =  Synset('metropolitan.n.01') ; keyword:  western  in syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= [u'metropolitan']
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: area
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: expansion
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'a', u'function', u'product', u'terms', u'of', u'sum', u'expressed', u'as', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: serving
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'a', u'food', u'of', u'drink', u'meal', u'an', u'as', u'individual', u'taken', u'part', u'or', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: formerly
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'a', u';', u'time', u'at', u'previous'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: people
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'group', u')', u'(', u'men', u'children', u'or', u'collectively', u'beings', u'human', u'of', u'plural', u'any', u'women'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: Christianity
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'a', u'and', u'monotheistic', u'based', u'embodied', u'on', u'New', u'of', u'in', u'system', u'Jesus', u'as', u'practices', u'role', u'emphasizing', u'teachings', u'Testament', u'Old', u'the', u'beliefs', u'savior'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: culture
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'a', u'and', u'particular', u'society', u'place', u'at', u'time'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: indefinite
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'or', u'stated', u'defined', u'clearly', u'not', u'vague'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: bishop
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'and', u'the', u'spiritual', u'Christ', u'twelve', u'some', u'authority', u'in', u'Christian', u'ministers', u'member', u'to', u'churches', u';', u'administrative', u'be', u'Apostles', u'appointed', u'a', u'oversee', u'of', u'priests', u'or', u'considered', u'clergy', u'senior', u'successors', u'having'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: special
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'a', u'and', u'temporary', u'offering', u'that', u')', u'(', u'price', u'featured', u'at', u'in', u'usually', u'is', u'reduced', u'special', u'advertising'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: geography
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'and', u'climate', u'topography', u"'s", u'responses', u'people', u'of', u'study', u'surface', u'includes', u'to', u'soil', u'earth', u'the', u';', u'vegetation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: city
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'a', u'and', u'districts', u'several', u'urban', u'may', u'populated', u'large', u'area', u'independent', u'densely', u';', u'include', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): western
mapFunction_Parents(): keyword: western ; prevleveltokens: given
mapFunction_Parents(): keyword= western ; syndef_tokens= set([u'for', u'that', u'is', u'an', u'assumption', u'taken', u'granted'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
16/03/25 13:54:37 INFO PythonRunner: Times: total = 10634, boot = 1553, init = 1106, finish = 7975
16/03/25 13:54:37 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/25 13:54:37 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 10730 ms on localhost (2/2)
16/03/25 13:54:37 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/25 13:54:37 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 10.740 s
16/03/25 13:54:37 INFO DAGScheduler: looking for newly runnable stages
16/03/25 13:54:37 INFO DAGScheduler: running: Set()
16/03/25 13:54:37 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/25 13:54:37 INFO DAGScheduler: failed: Set()
16/03/25 13:54:37 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/25 13:54:37 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which is now runnable
16/03/25 13:54:37 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11266, maxMem=567646617
16/03/25 13:54:37 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 541.3 MB)
16/03/25 13:54:37 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16250, maxMem=567646617
16/03/25 13:54:37 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 541.3 MB)
16/03/25 13:54:37 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:45686 (size: 3.0 KB, free: 541.3 MB)
16/03/25 13:54:37 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/25 13:54:37 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:54:37 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/25 13:54:37 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:54:37 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:54:37 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/25 13:54:37 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/25 13:54:37 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:54:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
16/03/25 13:54:37 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:54:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
16/03/25 13:54:37 INFO PythonRunner: Times: total = 27, boot = -238, init = 265, finish = 0
16/03/25 13:54:37 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/25 13:54:37 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 74 ms on localhost (1/2)
reduceFunction_Parents(): returns= [u'metropolitan', 'None', u'western']
16/03/25 13:54:37 INFO PythonRunner: Times: total = 270, boot = 269, init = 1, finish = 0
16/03/25 13:54:37 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1294 bytes result sent to driver
16/03/25 13:54:37 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.276 s
16/03/25 13:54:37 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 11.089373 s
16/03/25 13:54:37 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 284 ms on localhost (2/2)
16/03/25 13:54:37 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/25 13:54:37 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:54:37 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:54:37 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:54:37 INFO DAGScheduler: Parents of final stage: List()
16/03/25 13:54:37 INFO DAGScheduler: Missing parents: List()
16/03/25 13:54:37 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:54:37 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19305, maxMem=567646617
16/03/25 13:54:37 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 541.3 MB)
16/03/25 13:54:37 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25121, maxMem=567646617
16/03/25 13:54:37 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 541.3 MB)
16/03/25 13:54:37 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:45686 (size: 3.3 KB, free: 541.3 MB)
16/03/25 13:54:37 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/25 13:54:37 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:54:37 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/25 13:54:37 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/25 13:54:37 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2375 bytes)
16/03/25 13:54:37 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/25 13:54:37 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/25 13:54:37 INFO PythonRunner: Times: total = 76, boot = -73, init = 149, finish = 0
16/03/25 13:54:37 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/25 13:54:37 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 96 ms on localhost (1/2)
16/03/25 13:54:37 INFO PythonRunner: Times: total = 92, boot = 91, init = 1, finish = 0
16/03/25 13:54:37 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1359 bytes result sent to driver
16/03/25 13:54:37 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 111 ms on localhost (2/2)
16/03/25 13:54:37 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/25 13:54:37 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.113 s
16/03/25 13:54:37 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 0.144395 s
16/03/25 13:54:37 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/25 13:54:37 INFO DAGScheduler: Stopping DAGScheduler
16/03/25 13:54:38 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/25 13:54:38 INFO MemoryStore: MemoryStore cleared
16/03/25 13:54:38 INFO BlockManager: BlockManager stopped
16/03/25 13:54:38 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/25 13:54:38 INFO SparkContext: Successfully stopped SparkContext
16/03/25 13:54:38 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/25 13:54:38 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/25 13:54:38 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
graphcache_mapreduce_parents updated: defaultdict(<cyfunction <lambda> at 0xb1f81e6c>, {'2c49f1424d675552d9e7323a3eef6206': [u'None', u'expansion', u'None'], '45b800affe042d5d9a4228427680a935': [u'Chennai', u'None'], 'fdc633a5e1dea73592deb7e3bbbe3aea': [u'Chennai', u'None'], 'dd10336563a65a645a42bb416a6ebec6': [u'None', u'area', u'None'], 'a8f48eba5bb66d59263f478b93779a2c': [u'metropolitan', u'None'], '9f1808799460fd7b2da9ab51bd7b6775': [u'None', u'area', u'None'], '4b7e9f2659636820e82592ed034512f9': [u'Chennai', u'Madras'], '44b9adf04881710b0a7c81b0a22b1209': [u'Chennai', u'None'], 'e9301955882d67edfb275156ef73113c': [u'metropolitan', u'None'], '552934a698e1bcf880132a2bd5996d11': [u'None', u'area', u'None'], '063da2002ba149bb4025d1e1fcfb49f5': [u'None', u'area', u'None'], 'a31cc044ea8d13e6b1bf4e98768e44a5': [u'None', u'area', u'None'], 'b1318a4c6d13196fb45da6102d193223': [u'None', u'area', u'None', u'special'], '57466dae2c092869867908c5c54e241c': [u'metropolitan', u'None'], 'ed43ebbafa0c6204a5916ca879d5bd26': [u'None', u'area'], '3a2fbf91abebcac17538118b2e02315d': [u'metropolitan', u'None', u'western'], 'c65d3beca4dc2d6f37377a842accc0cd': [u'None', u'expansion', u'None', u'function'], '3cd540871242471e0d89bea4eabc06ea': [u'None', u'expansion', u'None'], '40603e72c50afb5b6be8a7ff1684c966': [u'Chennai', u'None', u'Madras'], '4208c80be8e0c0d285fafd73cd5bd9a6': [u'metropolitan', u'None'], 'b7b50c706678d48359a2ac685d535b33': [u'metropolitan', u'None'], 'f2e69333b98cfc98f544ee3a5717b7c4': [u'Chennai', u'None'], '926a71600b58a41448b179d8665fd5df': [u'None', u'expansion', u'None'], 'e6ebeac0f1cb14fbd7b903291fcc6a8f': [u'metropolitan', u'None'], '25439f8325592e4ecd8b06f5f799b57a': [u'None', u'expansion', u'None'], 'd7b9ba5125de58e77ad31543f2c54034': [u'None', u'area', u'None']})
asfer_pickle_string_dump(): picklef.write(): particular
16/03/25 13:54:38 INFO SparkContext: Running Spark version 1.5.2
16/03/25 13:54:38 INFO SecurityManager: Changing view acls to: root
16/03/25 13:54:38 INFO SecurityManager: Changing modify acls to: root
16/03/25 13:54:38 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/25 13:54:38 INFO Slf4jLogger: Slf4jLogger started
16/03/25 13:54:38 INFO Remoting: Starting remoting
16/03/25 13:54:38 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:50493]
16/03/25 13:54:38 INFO Utils: Successfully started service 'sparkDriver' on port 50493.
16/03/25 13:54:39 INFO SparkEnv: Registering MapOutputTracker
16/03/25 13:54:39 INFO SparkEnv: Registering BlockManagerMaster
16/03/25 13:54:39 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-773f3cdd-6732-454e-b4f4-4f5df3bc4494
16/03/25 13:54:39 INFO MemoryStore: MemoryStore started with capacity 541.3 MB
16/03/25 13:54:39 INFO HttpFileServer: HTTP File server directory is /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/httpd-0499814a-8a45-43a1-8b5b-259aa7791d2a
16/03/25 13:54:39 INFO HttpServer: Starting HTTP Server
16/03/25 13:54:39 INFO Utils: Successfully started service 'HTTP file server' on port 38460.
16/03/25 13:54:39 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/25 13:54:39 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/25 13:54:39 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/25 13:54:39 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/userFiles-f03e9cb8-28b9-484b-b0cd-dba2d26aa4bb/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:54:39 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458894279193
16/03/25 13:54:39 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/25 13:54:39 INFO Executor: Starting executor ID driver on host localhost
16/03/25 13:54:39 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33947.
16/03/25 13:54:39 INFO NettyBlockTransferService: Server created on 33947
16/03/25 13:54:39 INFO BlockManagerMaster: Trying to register BlockManager
16/03/25 13:54:39 INFO BlockManagerMasterEndpoint: Registering block manager localhost:33947 with 541.3 MB RAM, BlockManagerId(driver, localhost, 33947)
16/03/25 13:54:39 INFO BlockManagerMaster: Registered BlockManager
16/03/25 13:54:39 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:54:39 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:54:39 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:54:39 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:54:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/25 13:54:39 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/25 13:54:39 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:54:39 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=567646617
16/03/25 13:54:39 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 541.3 MB)
16/03/25 13:54:39 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=567646617
16/03/25 13:54:39 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 541.3 MB)
16/03/25 13:54:39 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:33947 (size: 4.1 KB, free: 541.3 MB)
16/03/25 13:54:39 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/25 13:54:39 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:54:39 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/25 13:54:39 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2532 bytes)
16/03/25 13:54:39 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2557 bytes)
16/03/25 13:54:39 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/25 13:54:39 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458894279193
16/03/25 13:54:39 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/25 13:54:39 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/userFiles-f03e9cb8-28b9-484b-b0cd-dba2d26aa4bb/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:54:39 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/25 13:54:39 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/25 13:54:39 INFO MemoryStore: ensureFreeSpace(292) called with curMem=10732, maxMem=567646617
16/03/25 13:54:39 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 292.0 B, free 541.3 MB)
16/03/25 13:54:39 INFO MemoryStore: ensureFreeSpace(266) called with curMem=11024, maxMem=567646617
16/03/25 13:54:39 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:33947 (size: 292.0 B, free: 541.3 MB)
16/03/25 13:54:39 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 266.0 B, free 541.3 MB)
16/03/25 13:54:39 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:33947 (size: 266.0 B, free: 541.3 MB)
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: Madras
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'a', u'on', u';', u'Madras', u'formerly', u')', u'of', u'India', u'Bay', u'state', u'Andhra', u'(', u'in', u'the', u'Bengal', u'Pradesh', u'southeastern', u'south'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: Eastern
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'east', u'situated', u'in', u'the', u'toward', u'or', u'lying'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: archbishop
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'a', u'of', u'highest', u'bishop', u'rank'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: sum
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'a', u'of', u'money', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: expressed
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'to', u'expression', u'give'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: geographical
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'science', u'or', u'to', u'of', u'relating', u'the', u'geography'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: boundary
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'a', u'limits', u'area', u'determining', u'an', u'of', u'line', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: Tamil
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'a', u'and', u'people', u'of', u'Sri', u'southern', u'member', u'India', u'mixed', u'Dravidian', u'the', u'Lanka', u'Caucasian'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: Nadu
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: function
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'mathematical', u'domain', u'set', u'associated', u'is', u'an', u'relation', u'another', u'given', u')', u'(', u'mathematics', u'function', u'that', u'such', u'with', u'a', u'of', u'element', u'range', u'each', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: product
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'commodities', u'offered', u'sale', u'for'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: terms
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'status', u'people', u'relations', u'to', u'groups', u'between', u'respect', u'the', u'with', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: equivalent
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'a', u'force', u'significance', u'to', u'measure', u'equal', u'value', u'effect', u'person', u'another', u'in', u'thing', u'or', u'etc'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: Bay
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'a', u'smaller', u'shoreline', u'gulf', u'of', u'larger', u'cove', u'but', u'an', u'indentation', u'than'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: western
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'a', u'and', u'about', u'United', u'development', u'of', u'life', u'period', u'States', u'exploration', u'western', u'in', u'during', u'the', u'film'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: particular
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'a', u'about', u')', u'(', u'some', u'general', u'to', u'as', u'part', u'opposed', u'fact'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/25 13:54:47 INFO PythonRunner: Times: total = 8416, boot = 459, init = 400, finish = 7557
16/03/25 13:54:47 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/25 13:54:47 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8528 ms on localhost (1/2)
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: area
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  particular  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: expansion
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'a', u'function', u'product', u'terms', u'of', u'sum', u'expressed', u'as', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: serving
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'a', u'food', u'of', u'drink', u'meal', u'an', u'as', u'individual', u'taken', u'part', u'or', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: formerly
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'a', u';', u'time', u'at', u'previous'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: people
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'group', u')', u'(', u'men', u'children', u'or', u'collectively', u'beings', u'human', u'of', u'plural', u'any', u'women'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: Christianity
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'a', u'and', u'monotheistic', u'based', u'embodied', u'on', u'New', u'of', u'in', u'system', u'Jesus', u'as', u'practices', u'role', u'emphasizing', u'teachings', u'Testament', u'Old', u'the', u'beliefs', u'savior'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: culture
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'a', u'and', u'particular', u'society', u'place', u'at', u'time'])
mapFunction_Parents(): adding to parents: syn =  Synset('culture.n.01') ; keyword:  particular  in syndef_tokens= set([u'a', u'and', u'particular', u'society', u'place', u'at', u'time'])
mapFunction_Parents(): returns= [u'culture']
reduceFunction_Parents(): returns= ['None', u'area', u'culture']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: indefinite
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'or', u'stated', u'defined', u'clearly', u'not', u'vague'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area', u'culture']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: bishop
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'and', u'the', u'spiritual', u'Christ', u'twelve', u'some', u'authority', u'in', u'Christian', u'ministers', u'member', u'to', u'churches', u';', u'administrative', u'be', u'Apostles', u'appointed', u'a', u'oversee', u'of', u'priests', u'or', u'considered', u'clergy', u'senior', u'successors', u'having'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area', u'culture']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: special
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'a', u'and', u'temporary', u'offering', u'that', u')', u'(', u'price', u'featured', u'at', u'in', u'usually', u'is', u'reduced', u'special', u'advertising'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area', u'culture']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: geography
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'and', u'climate', u'topography', u"'s", u'responses', u'people', u'of', u'study', u'surface', u'includes', u'to', u'soil', u'earth', u'the', u';', u'vegetation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area', u'culture']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: city
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'a', u'and', u'districts', u'several', u'urban', u'may', u'populated', u'large', u'area', u'independent', u'densely', u';', u'include', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area', u'culture']
asfer_pickle_string_load(): picklef.readlines(): particular
mapFunction_Parents(): keyword: particular ; prevleveltokens: given
mapFunction_Parents(): keyword= particular ; syndef_tokens= set([u'for', u'that', u'is', u'an', u'assumption', u'taken', u'granted'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area', u'culture']
16/03/25 13:54:48 INFO PythonRunner: Times: total = 8832, boot = 462, init = 501, finish = 7869
16/03/25 13:54:48 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/25 13:54:48 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8926 ms on localhost (2/2)
16/03/25 13:54:48 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/25 13:54:48 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 8.921 s
16/03/25 13:54:48 INFO DAGScheduler: looking for newly runnable stages
16/03/25 13:54:48 INFO DAGScheduler: running: Set()
16/03/25 13:54:48 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/25 13:54:48 INFO DAGScheduler: failed: Set()
16/03/25 13:54:48 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/25 13:54:48 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which is now runnable
16/03/25 13:54:48 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11290, maxMem=567646617
16/03/25 13:54:48 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 541.3 MB)
16/03/25 13:54:48 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16274, maxMem=567646617
16/03/25 13:54:48 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 541.3 MB)
16/03/25 13:54:48 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:33947 (size: 3.0 KB, free: 541.3 MB)
16/03/25 13:54:48 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/25 13:54:48 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:54:48 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/25 13:54:48 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:54:48 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:54:48 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/25 13:54:48 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/25 13:54:48 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:54:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/25 13:54:48 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:54:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/25 13:54:48 INFO PythonRunner: Times: total = 14, boot = -231, init = 244, finish = 1
16/03/25 13:54:48 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/25 13:54:48 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 70 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'area', u'culture', 'None']
16/03/25 13:54:48 INFO PythonRunner: Times: total = 198, boot = 196, init = 1, finish = 1
16/03/25 13:54:48 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1294 bytes result sent to driver
16/03/25 13:54:48 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 223 ms on localhost (2/2)
16/03/25 13:54:48 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/25 13:54:48 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.214 s
16/03/25 13:54:48 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 9.224986 s
16/03/25 13:54:48 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:54:48 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:54:48 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:54:48 INFO DAGScheduler: Parents of final stage: List()
16/03/25 13:54:48 INFO DAGScheduler: Missing parents: List()
16/03/25 13:54:48 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:54:48 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19329, maxMem=567646617
16/03/25 13:54:48 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 541.3 MB)
16/03/25 13:54:48 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25145, maxMem=567646617
16/03/25 13:54:48 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 541.3 MB)
16/03/25 13:54:48 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:33947 (size: 3.3 KB, free: 541.3 MB)
16/03/25 13:54:48 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/25 13:54:48 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:54:48 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/25 13:54:48 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/25 13:54:48 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2375 bytes)
16/03/25 13:54:48 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/25 13:54:48 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/25 13:54:48 INFO PythonRunner: Times: total = 79, boot = -22, init = 101, finish = 0
16/03/25 13:54:48 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/25 13:54:48 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 92 ms on localhost (1/2)
16/03/25 13:54:48 INFO PythonRunner: Times: total = 145, boot = 144, init = 1, finish = 0
16/03/25 13:54:48 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1362 bytes result sent to driver
16/03/25 13:54:48 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 161 ms on localhost (2/2)
16/03/25 13:54:48 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/25 13:54:48 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.163 s
16/03/25 13:54:48 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 0.176476 s
16/03/25 13:54:48 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/25 13:54:48 INFO DAGScheduler: Stopping DAGScheduler
16/03/25 13:54:49 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/25 13:54:49 INFO MemoryStore: MemoryStore cleared
16/03/25 13:54:49 INFO BlockManager: BlockManager stopped
16/03/25 13:54:49 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/25 13:54:49 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/25 13:54:49 INFO SparkContext: Successfully stopped SparkContext
16/03/25 13:54:49 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/25 13:54:49 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/25 13:54:49 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
graphcache_mapreduce_parents updated: defaultdict(<cyfunction <lambda> at 0xb1f81e6c>, {'2c49f1424d675552d9e7323a3eef6206': [u'None', u'expansion', u'None'], '45b800affe042d5d9a4228427680a935': [u'Chennai', u'None'], 'fdc633a5e1dea73592deb7e3bbbe3aea': [u'Chennai', u'None'], 'dd10336563a65a645a42bb416a6ebec6': [u'None', u'area', u'None'], 'a8f48eba5bb66d59263f478b93779a2c': [u'metropolitan', u'None'], '9f1808799460fd7b2da9ab51bd7b6775': [u'None', u'area', u'None'], '4b7e9f2659636820e82592ed034512f9': [u'Chennai', u'Madras'], '44b9adf04881710b0a7c81b0a22b1209': [u'Chennai', u'None'], 'e9301955882d67edfb275156ef73113c': [u'metropolitan', u'None'], '552934a698e1bcf880132a2bd5996d11': [u'None', u'area', u'None'], '063da2002ba149bb4025d1e1fcfb49f5': [u'None', u'area', u'None'], 'a31cc044ea8d13e6b1bf4e98768e44a5': [u'None', u'area', u'None'], 'b1318a4c6d13196fb45da6102d193223': [u'None', u'area', u'None', u'special'], '57466dae2c092869867908c5c54e241c': [u'metropolitan', u'None'], 'ed43ebbafa0c6204a5916ca879d5bd26': [u'None', u'area'], 'e9da57cf07c9f8d232e2c9c1a07d1a0a': [u'None', u'area', u'culture', u'None'], '3a2fbf91abebcac17538118b2e02315d': [u'metropolitan', u'None', u'western'], 'c65d3beca4dc2d6f37377a842accc0cd': [u'None', u'expansion', u'None', u'function'], '3cd540871242471e0d89bea4eabc06ea': [u'None', u'expansion', u'None'], '40603e72c50afb5b6be8a7ff1684c966': [u'Chennai', u'None', u'Madras'], '4208c80be8e0c0d285fafd73cd5bd9a6': [u'metropolitan', u'None'], 'b7b50c706678d48359a2ac685d535b33': [u'metropolitan', u'None'], 'f2e69333b98cfc98f544ee3a5717b7c4': [u'Chennai', u'None'], '926a71600b58a41448b179d8665fd5df': [u'None', u'expansion', u'None'], 'e6ebeac0f1cb14fbd7b903291fcc6a8f': [u'metropolitan', u'None'], '25439f8325592e4ecd8b06f5f799b57a': [u'None', u'expansion', u'None'], 'd7b9ba5125de58e77ad31543f2c54034': [u'None', u'area', u'None']})
asfer_pickle_string_dump(): picklef.write(): Bengal
16/03/25 13:54:49 INFO SparkContext: Running Spark version 1.5.2
16/03/25 13:54:49 INFO SecurityManager: Changing view acls to: root
16/03/25 13:54:49 INFO SecurityManager: Changing modify acls to: root
16/03/25 13:54:49 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/25 13:54:49 INFO Slf4jLogger: Slf4jLogger started
16/03/25 13:54:49 INFO Remoting: Starting remoting
16/03/25 13:54:50 INFO Utils: Successfully started service 'sparkDriver' on port 60245.
16/03/25 13:54:50 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:60245]
16/03/25 13:54:50 INFO SparkEnv: Registering MapOutputTracker
16/03/25 13:54:50 INFO SparkEnv: Registering BlockManagerMaster
16/03/25 13:54:50 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-bf3c6b01-be99-444c-8b1f-a293c9d4a7d6
16/03/25 13:54:50 INFO MemoryStore: MemoryStore started with capacity 541.3 MB
16/03/25 13:54:50 INFO HttpFileServer: HTTP File server directory is /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/httpd-aa4468af-6d52-45f4-9b9a-79022a8ea941
16/03/25 13:54:50 INFO HttpServer: Starting HTTP Server
16/03/25 13:54:50 INFO Utils: Successfully started service 'HTTP file server' on port 48771.
16/03/25 13:54:50 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/25 13:54:50 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/25 13:54:50 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/25 13:54:50 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/userFiles-bc329a36-ea0d-4e6e-a0c1-9712349f4455/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:54:50 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458894290202
16/03/25 13:54:50 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/25 13:54:50 INFO Executor: Starting executor ID driver on host localhost
16/03/25 13:54:50 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40247.
16/03/25 13:54:50 INFO NettyBlockTransferService: Server created on 40247
16/03/25 13:54:50 INFO BlockManagerMaster: Trying to register BlockManager
16/03/25 13:54:50 INFO BlockManagerMasterEndpoint: Registering block manager localhost:40247 with 541.3 MB RAM, BlockManagerId(driver, localhost, 40247)
16/03/25 13:54:50 INFO BlockManagerMaster: Registered BlockManager
16/03/25 13:54:50 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:54:50 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:54:50 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:54:50 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:54:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/25 13:54:50 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/25 13:54:50 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:54:50 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=567646617
16/03/25 13:54:50 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 541.3 MB)
16/03/25 13:54:50 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=567646617
16/03/25 13:54:50 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 541.3 MB)
16/03/25 13:54:50 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:40247 (size: 4.1 KB, free: 541.3 MB)
16/03/25 13:54:50 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/25 13:54:50 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:54:50 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/25 13:54:50 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2545 bytes)
16/03/25 13:54:50 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2540 bytes)
16/03/25 13:54:50 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/25 13:54:50 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458894290202
16/03/25 13:54:50 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/25 13:54:50 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/userFiles-bc329a36-ea0d-4e6e-a0c1-9712349f4455/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:54:50 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/25 13:54:50 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/25 13:54:50 INFO MemoryStore: ensureFreeSpace(276) called with curMem=10732, maxMem=567646617
16/03/25 13:54:50 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 276.0 B, free 541.3 MB)
16/03/25 13:54:50 INFO MemoryStore: ensureFreeSpace(283) called with curMem=11008, maxMem=567646617
16/03/25 13:54:50 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 283.0 B, free 541.3 MB)
16/03/25 13:54:50 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:40247 (size: 276.0 B, free: 541.3 MB)
16/03/25 13:54:50 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:40247 (size: 283.0 B, free: 541.3 MB)
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: Eastern
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): adding to parents: syn =  Synset('chennai.n.01') ; keyword:  Bengal  in syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: area
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'east', u'situated', u'in', u'the', u'toward', u'or', u'lying'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: archbishop
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'a', u'of', u'highest', u'bishop', u'rank'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: sum
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'a', u'of', u'money', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: expressed
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: expansion
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'to', u'expression', u'give'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: geographical
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'science', u'or', u'to', u'of', u'relating', u'the', u'geography'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: boundary
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'a', u'limits', u'area', u'determining', u'an', u'of', u'line', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: Tamil
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'a', u'function', u'product', u'terms', u'of', u'sum', mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'a', u'and', u'people', u'of', u'Sri', u'southern', u'member', u'India', u'mixed', u'Dravidian', u'the', u'Lanka', u'Caucasian'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: Nadu
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: function
u'expressed', u'as', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: serving
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'mathematical', u'domain', u'set', u'associated', u'is', u'an', u'relation', u'another', u'given', u')', u'(', u'mathematics', u'function', u'that', u'such', u'with', u'a', u'of', u'element', u'range', u'each', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: product
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'commodities', u'offered', u'sale', u'for'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: terms
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'status', u'people', u'relations', u'to', u'groups', u'between', u'respect', u'the', u'with', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: equivalent
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'a', u'force', u'significance', u'to', u'measure', u'equal', u'value', u'effect', u'person', u'another', u'in', u'thing', u'or', u'etc'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: Bay
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'a', u'food', u'of'mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'a', u'smaller', u'shoreline', u'gulf', u'of', u'larger', u'cove', u'but', u'an', u'indentation', u'than'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: western
, u'drink', u'meal', u'an', u'as', u'individual', u'taken', u'part', u'or', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: formerly
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'a', u';', u'time', u'at', u'previous'])
mapFunction_Parents(): returns= []
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'a', u'and', u'about', u'United', u'development', u'of', u'life', u'period', u'States', u'exploration', u'western', u'in', u'during', u'the', u'film'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: particular
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: people
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'a', u'about', u')', u'(', u'some', u'general', u'to', u'as', u'part', u'opposed', u'fact'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: Bengal
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'a', u'whose', u'and', u'Bangladesh', u'eastern', u'region', u'India', u'part', u'western', u'in', u'included', u'now', u'is'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/25 13:54:59 INFO PythonRunner: Times: total = 8708, boot = 467, init = 400, finish = 7841
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'group', u')', u'(', u'men', u'children', u'or', u'collectively', u'beings', u'human', u'of', u'plural', u'any', u'women'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: Christianity
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'a', u'and', u'monotheistic', u'based', u'embodied', u'on', u'New', u'of', u'in', u'system', u'Jesus', u'as', u'practices', u'role', u'emphasizing', u'teachings', u'Testament', u'Old', u'the', u'beliefs', u'savior'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: culture
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'a', u'and', u'particular', u'society', u'place', u'at', u'time'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns=16/03/25 13:54:59 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
 [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: indefinite
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'or', u'stated', u'defined', u'clearly', u'not', u'vague'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: bishop
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'and', u'the', u'spiritual', u'Christ', u'twelve', u'some', u'authority', u'in', u'Christian', u'ministers', u'member', u'to', u'churches', u';', u'administrative', u'be', u'Apostles', u'appointed', u'a', u'oversee', 16/03/25 13:54:59 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8807 ms on localhost (1/2)
u'of', u'priests', u'or', u'considered', u'clergy', u'senior', u'successors', u'having'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: special
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'a', u'and', u'temporary', u'offering', u'that', u')', u'(', u'price', u'featured', u'at', u'in', u'usually', u'is', u'reduced', u'special', u'advertising'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: geography
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'and', u'climate', u'topography', u"'s", u'responses', u'people', u'of', u'study', u'surface', u'includes', u'to', u'soil', u'earth', u'the', u';', u'vegetation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: city
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'a', u'and', u'districts', u'several', u'urban', u'may', u'populated', u'large', u'area', u'independent', u'densely', u';', u'include', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: given
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'for', u'that', u'is', u'an', u'assumption', u'taken', u'granted'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'Chennai']
asfer_pickle_string_load(): picklef.readlines(): Bengal
mapFunction_Parents(): keyword: Bengal ; prevleveltokens: Madras
mapFunction_Parents(): keyword= Bengal ; syndef_tokens= set([u'a', u'on', u';', u'Madras', u'formerly', u')', u'of', u'India', u'Bay', u'state', u'Andhra', u'(', u'in', u'the', u'Bengal', u'Pradesh', u'southeastern', u'south'])
mapFunction_Parents(): adding to parents: syn =  Synset('tamil_nadu.n.01') ; keyword:  Bengal  in syndef_tokens= set([u'a', u'on', u';', u'Madras', u'formerly', u')', u'of', u'India', u'Bay', u'state', u'Andhra', u'(', u'in', u'the', u'Bengal', u'Pradesh', u'southeastern', u'south'])
mapFunction_Parents(): returns= [u'Madras']
reduceFunction_Parents(): returns= [u'Chennai', u'Madras']
16/03/25 13:54:59 INFO PythonRunner: Times: total = 8946, boot = 454, init = 419, finish = 8073
16/03/25 13:54:59 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/25 13:54:59 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9020 ms on localhost (2/2)
16/03/25 13:54:59 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/25 13:54:59 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 9.024 s
16/03/25 13:54:59 INFO DAGScheduler: looking for newly runnable stages
16/03/25 13:54:59 INFO DAGScheduler: running: Set()
16/03/25 13:54:59 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/25 13:54:59 INFO DAGScheduler: failed: Set()
16/03/25 13:54:59 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/25 13:54:59 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which is now runnable
16/03/25 13:54:59 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11291, maxMem=567646617
16/03/25 13:54:59 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 541.3 MB)
16/03/25 13:54:59 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16275, maxMem=567646617
16/03/25 13:54:59 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 541.3 MB)
16/03/25 13:54:59 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:40247 (size: 3.0 KB, free: 541.3 MB)
16/03/25 13:54:59 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/25 13:54:59 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:54:59 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/25 13:54:59 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:54:59 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:54:59 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/25 13:54:59 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/25 13:54:59 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:54:59 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:54:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/25 13:54:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
reduceFunction_Parents(): returns= [u'Chennai', u'Madras', 'None']
16/03/25 13:54:59 INFO PythonRunner: Times: total = 29, boot = -8, init = 36, finish = 1
16/03/25 13:54:59 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1288 bytes result sent to driver
16/03/25 13:54:59 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 61 ms on localhost (1/2)
16/03/25 13:54:59 INFO PythonRunner: Times: total = 223, boot = 222, init = 1, finish = 0
16/03/25 13:54:59 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/25 13:54:59 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.238 s
16/03/25 13:54:59 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 237 ms on localhost (2/2)
16/03/25 13:54:59 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/25 13:54:59 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 9.316559 s
16/03/25 13:54:59 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:54:59 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:54:59 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:54:59 INFO DAGScheduler: Parents of final stage: List()
16/03/25 13:54:59 INFO DAGScheduler: Missing parents: List()
16/03/25 13:54:59 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:54:59 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19330, maxMem=567646617
16/03/25 13:54:59 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 541.3 MB)
16/03/25 13:54:59 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25146, maxMem=567646617
16/03/25 13:54:59 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 541.3 MB)
16/03/25 13:54:59 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:40247 (size: 3.3 KB, free: 541.3 MB)
16/03/25 13:54:59 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/25 13:54:59 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:54:59 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/25 13:54:59 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/25 13:54:59 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2369 bytes)
16/03/25 13:54:59 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/25 13:54:59 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/25 13:54:59 INFO PythonRunner: Times: total = 63, boot = -77, init = 140, finish = 0
16/03/25 13:54:59 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/25 13:54:59 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 73 ms on localhost (1/2)
16/03/25 13:54:59 INFO PythonRunner: Times: total = 80, boot = 80, init = 0, finish = 0
16/03/25 13:54:59 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1353 bytes result sent to driver
16/03/25 13:54:59 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 93 ms on localhost (2/2)
16/03/25 13:54:59 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.080 s
16/03/25 13:54:59 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/25 13:54:59 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 0.129366 s
16/03/25 13:54:59 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/25 13:54:59 INFO DAGScheduler: Stopping DAGScheduler
16/03/25 13:55:00 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/25 13:55:00 INFO MemoryStore: MemoryStore cleared
16/03/25 13:55:00 INFO BlockManager: BlockManager stopped
16/03/25 13:55:00 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/25 13:55:00 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/25 13:55:00 INFO SparkContext: Successfully stopped SparkContext
16/03/25 13:55:00 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/25 13:55:00 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/25 13:55:00 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
graphcache_mapreduce_parents updated: defaultdict(<cyfunction <lambda> at 0xb1f81e6c>, {'2c49f1424d675552d9e7323a3eef6206': [u'None', u'expansion', u'None'], '45b800affe042d5d9a4228427680a935': [u'Chennai', u'None'], 'fdc633a5e1dea73592deb7e3bbbe3aea': [u'Chennai', u'None'], 'dd10336563a65a645a42bb416a6ebec6': [u'None', u'area', u'None'], 'a8f48eba5bb66d59263f478b93779a2c': [u'metropolitan', u'None'], '9f1808799460fd7b2da9ab51bd7b6775': [u'None', u'area', u'None'], '4b7e9f2659636820e82592ed034512f9': [u'Chennai', u'Madras'], '44b9adf04881710b0a7c81b0a22b1209': [u'Chennai', u'None'], 'e9301955882d67edfb275156ef73113c': [u'metropolitan', u'None'], '552934a698e1bcf880132a2bd5996d11': [u'None', u'area', u'None'], '063da2002ba149bb4025d1e1fcfb49f5': [u'None', u'area', u'None'], 'a31cc044ea8d13e6b1bf4e98768e44a5': [u'None', u'area', u'None'], 'b1318a4c6d13196fb45da6102d193223': [u'None', u'area', u'None', u'special'], 'ff4fcba188cd7bb550ed88e9ee5dc6f1': [u'Chennai', u'Madras', u'None'], '57466dae2c092869867908c5c54e241c': [u'metropolitan', u'None'], 'ed43ebbafa0c6204a5916ca879d5bd26': [u'None', u'area'], 'e9da57cf07c9f8d232e2c9c1a07d1a0a': [u'None', u'area', u'culture', u'None'], '3a2fbf91abebcac17538118b2e02315d': [u'metropolitan', u'None', u'western'], 'c65d3beca4dc2d6f37377a842accc0cd': [u'None', u'expansion', u'None', u'function'], '3cd540871242471e0d89bea4eabc06ea': [u'None', u'expansion', u'None'], '40603e72c50afb5b6be8a7ff1684c966': [u'Chennai', u'None', u'Madras'], '4208c80be8e0c0d285fafd73cd5bd9a6': [u'metropolitan', u'None'], 'b7b50c706678d48359a2ac685d535b33': [u'metropolitan', u'None'], 'f2e69333b98cfc98f544ee3a5717b7c4': [u'Chennai', u'None'], '926a71600b58a41448b179d8665fd5df': [u'None', u'expansion', u'None'], 'e6ebeac0f1cb14fbd7b903291fcc6a8f': [u'metropolitan', u'None'], '25439f8325592e4ecd8b06f5f799b57a': [u'None', u'expansion', u'None'], 'd7b9ba5125de58e77ad31543f2c54034': [u'None', u'area', u'None']})
asfer_pickle_string_dump(): picklef.write(): Orthodox
16/03/25 13:55:00 INFO SparkContext: Running Spark version 1.5.2
16/03/25 13:55:00 INFO SecurityManager: Changing view acls to: root
16/03/25 13:55:00 INFO SecurityManager: Changing modify acls to: root
16/03/25 13:55:00 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/25 13:55:00 INFO Slf4jLogger: Slf4jLogger started
16/03/25 13:55:00 INFO Remoting: Starting remoting
16/03/25 13:55:01 INFO Utils: Successfully started service 'sparkDriver' on port 59525.
16/03/25 13:55:01 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:59525]
16/03/25 13:55:01 INFO SparkEnv: Registering MapOutputTracker
16/03/25 13:55:01 INFO SparkEnv: Registering BlockManagerMaster
16/03/25 13:55:01 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-c17b89fd-2c65-44f2-91ab-7007d07d6d71
16/03/25 13:55:01 INFO MemoryStore: MemoryStore started with capacity 541.3 MB
16/03/25 13:55:01 INFO HttpFileServer: HTTP File server directory is /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/httpd-bf86133a-4358-43ac-868b-9b97fafcfe2e
16/03/25 13:55:01 INFO HttpServer: Starting HTTP Server
16/03/25 13:55:01 INFO Utils: Successfully started service 'HTTP file server' on port 34772.
16/03/25 13:55:01 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/25 13:55:01 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/25 13:55:01 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/25 13:55:01 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/userFiles-a50e767c-a6d2-4d06-8713-0609a260c188/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:55:01 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458894301175
16/03/25 13:55:01 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/25 13:55:01 INFO Executor: Starting executor ID driver on host localhost
16/03/25 13:55:01 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33398.
16/03/25 13:55:01 INFO NettyBlockTransferService: Server created on 33398
16/03/25 13:55:01 INFO BlockManagerMaster: Trying to register BlockManager
16/03/25 13:55:01 INFO BlockManagerMasterEndpoint: Registering block manager localhost:33398 with 541.3 MB RAM, BlockManagerId(driver, localhost, 33398)
16/03/25 13:55:01 INFO BlockManagerMaster: Registered BlockManager
16/03/25 13:55:01 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:55:01 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:55:01 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:55:01 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:55:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/25 13:55:01 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/25 13:55:01 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:55:01 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=567646617
16/03/25 13:55:01 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 541.3 MB)
16/03/25 13:55:01 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=567646617
16/03/25 13:55:01 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 541.3 MB)
16/03/25 13:55:01 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:33398 (size: 4.1 KB, free: 541.3 MB)
16/03/25 13:55:01 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/25 13:55:01 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:55:01 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/25 13:55:01 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2545 bytes)
16/03/25 13:55:01 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2572 bytes)
16/03/25 13:55:01 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/25 13:55:01 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458894301175
16/03/25 13:55:01 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/25 13:55:01 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/userFiles-a50e767c-a6d2-4d06-8713-0609a260c188/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:55:01 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/25 13:55:01 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/25 13:55:01 INFO MemoryStore: ensureFreeSpace(309) called with curMem=10732, maxMem=567646617
16/03/25 13:55:01 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 309.0 B, free 541.3 MB)
16/03/25 13:55:01 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:33398 (size: 309.0 B, free: 541.3 MB)
16/03/25 13:55:01 INFO MemoryStore: ensureFreeSpace(276) called with curMem=11041, maxMem=567646617
16/03/25 13:55:01 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 276.0 B, free 541.3 MB)
16/03/25 13:55:01 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:33398 (size: 276.0 B, free: 541.3 MB)
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: Chennai
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: Eastern
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): adding to parents: syn =  Synset('metropolitan.n.01') ; keyword:  Orthodox  in syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= [u'metropolitan']
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: area
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: expansion
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'a', u'function', u'product', u'terms', u'of', u'sum', u'expressed', u'as', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: serving
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'a', u'food', u'of', u'drink', u'meal', u'an', u'as', u'individual', u'taken', u'part', u'or', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: formerly
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'a', u';', u'time', u'at', u'previous'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: people
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'group', u')', u'(', u'men', u'children', u'or', u'collectively', u'beings', u'human', u'of', u'plural', u'any', u'women'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: Christianity
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'a', u'and', u'monotheistic', u'based', u'embodied', u'on', mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'east', u'situated', u'in', u'the', u'toward', u'or', u'lying'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: archbishop
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'a', u'of', u'highest', u'bishop', u'rank'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: sum
u'New', u'of', u'in', u'system', u'Jesus', u'as', u'practices', u'role', u'emphasizing', u'teachings', u'Testament', u'Old', u'the', u'beliefs', u'savior'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: culture
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'a', u'of', u'money', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: expressed
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'a', u'and', u'particular', u'society', u'place', mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'to', u'expression', u'give'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: geographical
u'at', u'time'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'science', u'or', u'to', u'of', u'relating', u'the', u'geography'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: boundary
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: indefinite
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'a', u'limits', u'area', u'determining', u'an', u'of', u'line', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: Tamil
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'or', u'stated', u'defined', u'clearly', u'not', u'vague'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns=mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'a', u'and', u'people', u'of', u'Sri', u'southern', u'member', u'India', u'mixed', u'Dravidian', u'the', u'Lanka', u'Caucasian'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: Nadu
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: function
 [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: bishop
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'mathematical', u'domain', u'set', u'associated', u'is', u'an', u'relation', u'another', u'given', u')', u'(', u'mathematics', u'function', u'that', u'such', u'with', u'a', u'of', u'element', u'range', u'each', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: product
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'commodities', u'offered', u'sale', u'for'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: terms
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'and', u'the', u'spiritual', u'Christ', u'twelve', u'some', u'authority', u'in', u'Christian', u'ministers', u'member', u'to', u'churches', u';', u'administrative', u'be', u'Apostles', u'appointed'mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'status', u'people', u'relations', u'to', u'groups', u'between', , u'respect', u'the', u'with', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
u'a'asfer_pickle_string_load(): picklef.readlines():,  Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: equivalent
u'oversee', u'of', u'priests', u'or', u'considered', u'clergy', u'senior', u'successors', u'having'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: special
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'a', u'force', u'significance', u'to', u'measure', u'equal', u'value', u'effect', u'person', u'another', u'in', u'thing', u'or', u'etc'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: Bay
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'a', u'smaller', u'shoreline', u'gulf', u'of', u'larger', u'cove', u'but', u'an', u'indentation', u'than'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: western
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'a'mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'a', u'and', u'about', u'United', u'development', u'of', u'life', u'period', u'States', u'exploration', u'western', u'in', u'during', u'the', u'film'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: particular
, u'and', u'temporary', u'offering', u'that', u')', u'(', u'price', u'featured', u'at', u'in', u'usually', u'is', u'reduced', u'special', u'advertising'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: geography
mapFunction_Parents(): keyword= OrthodoxmapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'a', u'about', u')', u'(', u'some', u'general', u'to', u'as', u'part', u'opposed', u'fact'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: Bengal
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'a', u'whose', u'and', u'Bangladesh', u'eastern', u'region', u'India', u'part', u'western', u'in', u'included', u'now', u'is'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: Orthodox
 ; syndef_tokens= set([u'and', u'climate', u'topography', u"'s", u'responses', u'people', u'of', u'study', u'surface', u'includes', u'to', u'soil', u'earth', u'the', u';', u'vegetation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: city
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'pertaining', u'Judaism', u'characteristic', u'to', u'of', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'a', u'and', u'districts', u'several', u'urban', u'may', u'populated', u'large', u'area', u'independent', u'densely', u';', u'include', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: given
16/03/25 13:55:10 INFO PythonRunner: Times: total = 8999, boot = 561, init = 544, finish = 7894
16/03/25 13:55:10 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/25 13:55:10 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 9105 ms on localhost (1/2)
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'for', u'that', u'is', u'an', u'assumption', u'taken', u'granted'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Orthodox
mapFunction_Parents(): keyword: Orthodox ; prevleveltokens: Madras
mapFunction_Parents(): keyword= Orthodox ; syndef_tokens= set([u'a', u'on', u';', u'Madras', u'formerly', u')', u'of', u'India', u'Bay', u'state', u'Andhra', u'(', u'in', u'the', u'Bengal', u'Pradesh', u'southeastern', u'south'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
16/03/25 13:55:10 INFO PythonRunner: Times: total = 9108, boot = 567, init = 536, finish = 8005
16/03/25 13:55:10 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/25 13:55:10 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 9.222 s
16/03/25 13:55:10 INFO DAGScheduler: looking for newly runnable stages
16/03/25 13:55:10 INFO DAGScheduler: running: Set()
16/03/25 13:55:10 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/25 13:55:10 INFO DAGScheduler: failed: Set()
16/03/25 13:55:10 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/25 13:55:10 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which is now runnable
16/03/25 13:55:10 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11317, maxMem=567646617
16/03/25 13:55:10 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 541.3 MB)
16/03/25 13:55:10 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16301, maxMem=567646617
16/03/25 13:55:10 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 541.3 MB)
16/03/25 13:55:10 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9220 ms on localhost (2/2)
16/03/25 13:55:10 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/25 13:55:10 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:33398 (size: 3.0 KB, free: 541.3 MB)
16/03/25 13:55:10 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/25 13:55:10 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:55:10 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/25 13:55:10 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:55:10 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:55:10 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/25 13:55:10 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:55:10 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/25 13:55:10 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:55:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/25 13:55:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 9 ms
reduceFunction_Parents(): returns= [u'metropolitan', 'None']
16/03/25 13:55:10 INFO PythonRunner: Times: total = 131, boot = 128, init = 1, finish = 2
16/03/25 13:55:10 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1280 bytes result sent to driver
16/03/25 13:55:10 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 161 ms on localhost (1/2)
16/03/25 13:55:10 INFO PythonRunner: Times: total = 219, boot = 218, init = 1, finish = 0
16/03/25 13:55:10 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/25 13:55:10 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.223 s
16/03/25 13:55:10 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 9.520790 s
16/03/25 13:55:10 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 242 ms on localhost (2/2)
16/03/25 13:55:10 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/25 13:55:11 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:55:11 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:55:11 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:55:11 INFO DAGScheduler: Parents of final stage: List()
16/03/25 13:55:11 INFO DAGScheduler: Missing parents: List()
16/03/25 13:55:11 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:55:11 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19356, maxMem=567646617
16/03/25 13:55:11 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 541.3 MB)
16/03/25 13:55:11 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25172, maxMem=567646617
16/03/25 13:55:11 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 541.3 MB)
16/03/25 13:55:11 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:33398 (size: 3.3 KB, free: 541.3 MB)
16/03/25 13:55:11 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/25 13:55:11 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:55:11 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/25 13:55:11 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/25 13:55:11 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2361 bytes)
16/03/25 13:55:11 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/25 13:55:11 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/25 13:55:11 INFO PythonRunner: Times: total = 9, boot = -45, init = 54, finish = 0
16/03/25 13:55:11 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/25 13:55:11 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 53 ms on localhost (1/2)
16/03/25 13:55:11 INFO PythonRunner: Times: total = 233, boot = 232, init = 1, finish = 0
16/03/25 13:55:11 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1345 bytes result sent to driver
16/03/25 13:55:11 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 246 ms on localhost (2/2)
16/03/25 13:55:11 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/25 13:55:11 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.236 s
16/03/25 13:55:11 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 0.282789 s
16/03/25 13:55:11 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/25 13:55:11 INFO DAGScheduler: Stopping DAGScheduler
16/03/25 13:55:11 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/25 13:55:11 INFO MemoryStore: MemoryStore cleared
16/03/25 13:55:11 INFO BlockManager: BlockManager stopped
16/03/25 13:55:11 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/25 13:55:11 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/25 13:55:11 INFO SparkContext: Successfully stopped SparkContext
16/03/25 13:55:11 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
graphcache_mapreduce_parents updated: defaultdict(<cyfunction <lambda> at 0xb1f81e6c>, {'2c49f1424d675552d9e7323a3eef6206': [u'None', u'expansion', u'None'], '45b800affe042d5d9a4228427680a935': [u'Chennai', u'None'], 'fdc633a5e1dea73592deb7e3bbbe3aea': [u'Chennai', u'None'], 'dd10336563a65a645a42bb416a6ebec6': [u'None', u'area', u'None'], 'a8f48eba5bb66d59263f478b93779a2c': [u'metropolitan', u'None'], '9f1808799460fd7b2da9ab51bd7b6775': [u'None', u'area', u'None'], '4b7e9f2659636820e82592ed034512f9': [u'Chennai', u'Madras'], '44b9adf04881710b0a7c81b0a22b1209': [u'Chennai', u'None'], 'e9301955882d67edfb275156ef73113c': [u'metropolitan', u'None'], '552934a698e1bcf880132a2bd5996d11': [u'None', u'area', u'None'], '063da2002ba149bb4025d1e1fcfb49f5': [u'None', u'area', u'None'], 'a31cc044ea8d13e6b1bf4e98768e44a5': [u'None', u'area', u'None'], 'b1318a4c6d13196fb45da6102d193223': [u'None', u'area', u'None', u'special'], 'ff4fcba188cd7bb550ed88e9ee5dc6f1': [u'Chennai', u'Madras', u'None'], '57466dae2c092869867908c5c54e241c': [u'metropolitan', u'None'], 'ed43ebbafa0c6204a5916ca879d5bd26': [u'None', u'area'], 'e9da57cf07c9f8d232e2c9c1a07d1a0a': [u'None', u'area', u'culture', u'None'], '3a2fbf91abebcac17538118b2e02315d': [u'metropolitan', u'None', u'western'], 'c65d3beca4dc2d6f37377a842accc0cd': [u'None', u'expansion', u'None', u'function'], '3cd540871242471e0d89bea4eabc06ea': [u'None', u'expansion', u'None'], '40603e72c50afb5b6be8a7ff1684c966': [u'Chennai', u'None', u'Madras'], '4208c80be8e0c0d285fafd73cd5bd9a6': [u'metropolitan', u'None'], 'b7b50c706678d48359a2ac685d535b33': [u'metropolitan', u'None'], 'f2e69333b98cfc98f544ee3a5717b7c4': [u'Chennai', u'None'], '39c21ff4448a2910600584a0d49f93e8': [u'metropolitan', u'None'], '926a71600b58a41448b179d8665fd5df': [u'None', u'expansion', u'None'], 'e6ebeac0f1cb14fbd7b903291fcc6a8f': [u'metropolitan', u'None'], '25439f8325592e4ecd8b06f5f799b57a': [u'None', u'expansion', u'None'], 'd7b9ba5125de58e77ad31543f2c54034': [u'None', u'area', u'None']})
asfer_pickle_string_dump(): picklef.write(): region
16/03/25 13:55:12 INFO SparkContext: Running Spark version 1.5.2
16/03/25 13:55:12 INFO SecurityManager: Changing view acls to: root
16/03/25 13:55:12 INFO SecurityManager: Changing modify acls to: root
16/03/25 13:55:12 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/25 13:55:12 INFO Slf4jLogger: Slf4jLogger started
16/03/25 13:55:12 INFO Remoting: Starting remoting
16/03/25 13:55:12 INFO Utils: Successfully started service 'sparkDriver' on port 55878.
16/03/25 13:55:12 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:55878]
16/03/25 13:55:12 INFO SparkEnv: Registering MapOutputTracker
16/03/25 13:55:12 INFO SparkEnv: Registering BlockManagerMaster
16/03/25 13:55:12 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-fa51163d-64a0-46c5-915c-0710ccb47d9c
16/03/25 13:55:12 INFO MemoryStore: MemoryStore started with capacity 541.3 MB
16/03/25 13:55:12 INFO HttpFileServer: HTTP File server directory is /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/httpd-d35c86a4-a003-4491-bddd-583d55bae79b
16/03/25 13:55:12 INFO HttpServer: Starting HTTP Server
16/03/25 13:55:12 INFO Utils: Successfully started service 'HTTP file server' on port 58877.
16/03/25 13:55:12 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/25 13:55:12 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/25 13:55:12 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/25 13:55:12 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/userFiles-c367db63-45cf-4bbb-8869-17a3770c22e4/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:55:12 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458894312544
16/03/25 13:55:12 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/25 13:55:12 INFO Executor: Starting executor ID driver on host localhost
16/03/25 13:55:12 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56223.
16/03/25 13:55:12 INFO NettyBlockTransferService: Server created on 56223
16/03/25 13:55:12 INFO BlockManagerMaster: Trying to register BlockManager
16/03/25 13:55:12 INFO BlockManagerMasterEndpoint: Registering block manager localhost:56223 with 541.3 MB RAM, BlockManagerId(driver, localhost, 56223)
16/03/25 13:55:12 INFO BlockManagerMaster: Registered BlockManager
16/03/25 13:55:12 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:55:12 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:55:12 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:55:12 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:55:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/25 13:55:12 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/25 13:55:12 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:55:12 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=567646617
16/03/25 13:55:12 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 541.3 MB)
16/03/25 13:55:12 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=567646617
16/03/25 13:55:12 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 541.3 MB)
16/03/25 13:55:12 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:56223 (size: 4.1 KB, free: 541.3 MB)
16/03/25 13:55:12 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/25 13:55:12 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:55:12 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/25 13:55:12 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2559 bytes)
16/03/25 13:55:12 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2554 bytes)
16/03/25 13:55:12 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/25 13:55:12 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458894312544
16/03/25 13:55:12 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/25 13:55:12 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/userFiles-c367db63-45cf-4bbb-8869-17a3770c22e4/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:55:12 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/25 13:55:12 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/25 13:55:12 INFO MemoryStore: ensureFreeSpace(286) called with curMem=10732, maxMem=567646617
16/03/25 13:55:12 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 286.0 B, free 541.3 MB)
16/03/25 13:55:12 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:56223 (size: 286.0 B, free: 541.3 MB)
16/03/25 13:55:12 INFO MemoryStore: ensureFreeSpace(291) called with curMem=11018, maxMem=567646617
16/03/25 13:55:12 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 291.0 B, free 541.3 MB)
16/03/25 13:55:12 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:56223 (size: 291.0 B, free: 541.3 MB)
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: archbishop
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'a', u'of', u'highest', u'bishop', u'rank'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: sum
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'a', u'of', u'money', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: expressed
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'to', u'expression', u'give'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: geographical
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'science', u'or', u'to', u'of', u'relating', u'the', u'geography'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: boundary
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'a', u'limits', u'area', u'determining', u'an', u'of', u'line', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: Tamil
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'a', u'and', u'people', u'of', u'Sri', u'southern', u'member', u'India', u'mixed', u'Dravidian', u'the', u'Lanka', u'Caucasian'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: Nadu
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: function
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'mathematical', u'domain', u'set', u'associated', u'is', u'an', u'relation', u'another', u'given', u')', u'(', u'mathematics', u'function', u'that', u'such', u'with', u'a', u'of', u'element', u'range', u'each', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: product
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'commodities', u'offered', u'sale', u'for'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: terms
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'status', u'people', u'relations', u'to', u'groups', u'between', u'respect', u'the', u'with', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: equivalent
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'a', u'force', u'significance', u'to', u'measure', u'equal', u'value', u'effect', u'person', u'another', u'in', u'thing', u'or', u'etc'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: Bay
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'a', u'smaller', u'shoreline', u'gulf', u'of', u'larger', u'cove', u'but', u'an', u'indentation', u'than'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: western
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'a', u'and', u'about', u'United', u'development', u'of', u'life', u'period', u'States', u'exploration', u'western', u'in', u'during', u'the', u'film'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: particular
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'a', u'about', u')', u'(', u'some', u'general', u'to', u'as', u'part', u'opposed', u'fact'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: Bengal
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'a', u'whose', u'and', u'Bangladesh', u'eastern', u'region', u'India', u'part', u'western', u'in', u'included', u'now', u'is'])
mapFunction_Parents(): adding to parents: syn =  Synset('bengal.n.01') ; keyword:  region  in syndef_tokens= set([u'a', u'whose', u'and', u'Bangladesh', u'eastern', u'region', u'India', u'part', u'western', u'in', u'included', u'now', u'is'])
mapFunction_Parents(): returns= [u'Bengal']
reduceFunction_Parents(): returns= ['None', u'Bengal']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: Orthodox
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'pertaining', u'Judaism', u'characteristic', u'to', u'of', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'Bengal']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: region
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'extended', u'of', u'something', u'spatial', u'the', u'location'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'Bengal']
16/03/25 13:55:21 INFO PythonRunner: Times: total = 8895, boot = 461, init = 382, finish = 8052
16/03/25 13:55:21 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/25 13:55:21 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8990 ms on localhost (1/2)
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: area
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  region  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: expansion
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'a', u'function', u'product', u'terms', u'of', u'sum', u'expressed', u'as', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: serving
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'a', u'food', u'of', u'drink', u'meal', u'an', u'as', u'individual', u'taken', u'part', u'or', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: formerly
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'a', u';', u'time', u'at', u'previous'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: people
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'group', u')', u'(', u'men', u'children', u'or', u'collectively', u'beings', u'human', u'of', u'plural', u'any', u'women'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: Christianity
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'a', u'and', u'monotheistic', u'based', u'embodied', u'on', u'New', u'of', u'in', u'system', u'Jesus', u'as', u'practices', u'role', u'emphasizing', u'teachings', u'Testament', u'Old', u'the', u'beliefs', u'savior'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: culture
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'a', u'and', u'particular', u'society', u'place', u'at', u'time'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: indefinite
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'or', u'stated', u'defined', u'clearly', u'not', u'vague'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: bishop
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'and', u'the', u'spiritual', u'Christ', u'twelve', u'some', u'authority', u'in', u'Christian', u'ministers', u'member', u'to', u'churches', u';', u'administrative', u'be', u'Apostles', u'appointed', u'a', u'oversee', u'of', u'priests', u'or', u'considered', u'clergy', u'senior', u'successors', u'having'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: special
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'a', u'and', u'temporary', u'offering', u'that', u')', u'(', u'price', u'featured', u'at', u'in', u'usually', u'is', u'reduced', u'special', u'advertising'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: geography
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'and', u'climate', u'topography', u"'s", u'responses', u'people', u'of', u'study', u'surface', u'includes', u'to', u'soil', u'earth', u'the', u';', u'vegetation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: city
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'a', u'and', u'districts', u'several', u'urban', u'may', u'populated', u'large', u'area', u'independent', u'densely', u';', u'include', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: given
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'for', u'that', u'is', u'an', u'assumption', u'taken', u'granted'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: Madras
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'a', u'on', u';', u'Madras', u'formerly', u')', u'of', u'India', u'Bay', u'state', u'Andhra', u'(', u'in', u'the', u'Bengal', u'Pradesh', u'southeastern', u'south'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): region
mapFunction_Parents(): keyword: region ; prevleveltokens: Eastern
mapFunction_Parents(): keyword= region ; syndef_tokens= set([u'east', u'situated', u'in', u'the', u'toward', u'or', u'lying'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
16/03/25 13:55:22 INFO PythonRunner: Times: total = 9308, boot = 465, init = 390, finish = 8453
16/03/25 13:55:22 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/25 13:55:22 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 9.397 s
16/03/25 13:55:22 INFO DAGScheduler: looking for newly runnable stages
16/03/25 13:55:22 INFO DAGScheduler: running: Set()
16/03/25 13:55:22 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/25 13:55:22 INFO DAGScheduler: failed: Set()
16/03/25 13:55:22 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/25 13:55:22 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which is now runnable
16/03/25 13:55:22 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11309, maxMem=567646617
16/03/25 13:55:22 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 541.3 MB)
16/03/25 13:55:22 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16293, maxMem=567646617
16/03/25 13:55:22 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9395 ms on localhost (2/2)
16/03/25 13:55:22 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/25 13:55:22 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 541.3 MB)
16/03/25 13:55:22 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:56223 (size: 3.0 KB, free: 541.3 MB)
16/03/25 13:55:22 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/25 13:55:22 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:55:22 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/25 13:55:22 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:55:22 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:55:22 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/25 13:55:22 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/25 13:55:22 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:55:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/25 13:55:22 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:55:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/25 13:55:22 INFO PythonRunner: Times: total = 9, boot = -146, init = 154, finish = 1
16/03/25 13:55:22 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1293 bytes result sent to driver
reduceFunction_Parents(): returns= ['None', u'area', 'None', u'Bengal']
16/03/25 13:55:22 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 86 ms on localhost (1/2)
16/03/25 13:55:22 INFO PythonRunner: Times: total = 308, boot = 307, init = 0, finish = 1
16/03/25 13:55:22 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/25 13:55:22 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.319 s
16/03/25 13:55:22 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 9.741603 s
16/03/25 13:55:22 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 319 ms on localhost (2/2)
16/03/25 13:55:22 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/25 13:55:22 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:55:22 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:55:22 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:55:22 INFO DAGScheduler: Parents of final stage: List()
16/03/25 13:55:22 INFO DAGScheduler: Missing parents: List()
16/03/25 13:55:22 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:55:22 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19348, maxMem=567646617
16/03/25 13:55:22 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 541.3 MB)
16/03/25 13:55:22 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25164, maxMem=567646617
16/03/25 13:55:22 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 541.3 MB)
16/03/25 13:55:22 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:56223 (size: 3.3 KB, free: 541.3 MB)
16/03/25 13:55:22 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/25 13:55:22 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:55:22 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/25 13:55:22 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/25 13:55:22 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2374 bytes)
16/03/25 13:55:22 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/25 13:55:22 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/25 13:55:22 INFO PythonRunner: Times: total = 54, boot = -170, init = 224, finish = 0
16/03/25 13:55:22 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/25 13:55:22 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 69 ms on localhost (1/2)
16/03/25 13:55:22 INFO PythonRunner: Times: total = 145, boot = 145, init = 0, finish = 0
16/03/25 13:55:22 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1361 bytes result sent to driver
16/03/25 13:55:22 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 159 ms on localhost (2/2)
16/03/25 13:55:22 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/25 13:55:22 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.153 s
16/03/25 13:55:22 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 0.179281 s
16/03/25 13:55:22 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/25 13:55:22 INFO DAGScheduler: Stopping DAGScheduler
16/03/25 13:55:22 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/25 13:55:22 INFO MemoryStore: MemoryStore cleared
16/03/25 13:55:22 INFO BlockManager: BlockManager stopped
16/03/25 13:55:22 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/25 13:55:22 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/25 13:55:22 INFO SparkContext: Successfully stopped SparkContext
16/03/25 13:55:22 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/25 13:55:22 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/25 13:55:22 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
graphcache_mapreduce_parents updated: defaultdict(<cyfunction <lambda> at 0xb1f81e6c>, {'2c49f1424d675552d9e7323a3eef6206': [u'None', u'expansion', u'None'], '45b800affe042d5d9a4228427680a935': [u'Chennai', u'None'], 'fdc633a5e1dea73592deb7e3bbbe3aea': [u'Chennai', u'None'], 'dd10336563a65a645a42bb416a6ebec6': [u'None', u'area', u'None'], 'a8f48eba5bb66d59263f478b93779a2c': [u'metropolitan', u'None'], '9f1808799460fd7b2da9ab51bd7b6775': [u'None', u'area', u'None'], '4b7e9f2659636820e82592ed034512f9': [u'Chennai', u'Madras'], '44b9adf04881710b0a7c81b0a22b1209': [u'Chennai', u'None'], '1d1c5d8e5b55f6916d7d9218c4a0fe34': [u'None', u'area', u'None', u'Bengal'], 'e9301955882d67edfb275156ef73113c': [u'metropolitan', u'None'], '552934a698e1bcf880132a2bd5996d11': [u'None', u'area', u'None'], '063da2002ba149bb4025d1e1fcfb49f5': [u'None', u'area', u'None'], 'a31cc044ea8d13e6b1bf4e98768e44a5': [u'None', u'area', u'None'], 'b1318a4c6d13196fb45da6102d193223': [u'None', u'area', u'None', u'special'], 'ff4fcba188cd7bb550ed88e9ee5dc6f1': [u'Chennai', u'Madras', u'None'], '57466dae2c092869867908c5c54e241c': [u'metropolitan', u'None'], 'ed43ebbafa0c6204a5916ca879d5bd26': [u'None', u'area'], 'e9da57cf07c9f8d232e2c9c1a07d1a0a': [u'None', u'area', u'culture', u'None'], '3a2fbf91abebcac17538118b2e02315d': [u'metropolitan', u'None', u'western'], 'c65d3beca4dc2d6f37377a842accc0cd': [u'None', u'expansion', u'None', u'function'], '3cd540871242471e0d89bea4eabc06ea': [u'None', u'expansion', u'None'], '40603e72c50afb5b6be8a7ff1684c966': [u'Chennai', u'None', u'Madras'], '4208c80be8e0c0d285fafd73cd5bd9a6': [u'metropolitan', u'None'], 'b7b50c706678d48359a2ac685d535b33': [u'metropolitan', u'None'], 'f2e69333b98cfc98f544ee3a5717b7c4': [u'Chennai', u'None'], '39c21ff4448a2910600584a0d49f93e8': [u'metropolitan', u'None'], '926a71600b58a41448b179d8665fd5df': [u'None', u'expansion', u'None'], 'e6ebeac0f1cb14fbd7b903291fcc6a8f': [u'metropolitan', u'None'], '25439f8325592e4ecd8b06f5f799b57a': [u'None', u'expansion', u'None'], 'd7b9ba5125de58e77ad31543f2c54034': [u'None', u'area', u'None']})
asfer_pickle_string_dump(): picklef.write(): title
16/03/25 13:55:23 INFO SparkContext: Running Spark version 1.5.2
16/03/25 13:55:23 INFO SecurityManager: Changing view acls to: root
16/03/25 13:55:23 INFO SecurityManager: Changing modify acls to: root
16/03/25 13:55:23 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/25 13:55:23 INFO Slf4jLogger: Slf4jLogger started
16/03/25 13:55:23 INFO Remoting: Starting remoting
16/03/25 13:55:23 INFO Utils: Successfully started service 'sparkDriver' on port 54043.
16/03/25 13:55:23 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:54043]
16/03/25 13:55:23 INFO SparkEnv: Registering MapOutputTracker
16/03/25 13:55:23 INFO SparkEnv: Registering BlockManagerMaster
16/03/25 13:55:23 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-b26e5386-1e2f-4298-b1a0-57cc80454918
16/03/25 13:55:23 INFO MemoryStore: MemoryStore started with capacity 541.3 MB
16/03/25 13:55:23 INFO HttpFileServer: HTTP File server directory is /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/httpd-cf79fb13-74f2-4439-9e6e-657a44c6c3bb
16/03/25 13:55:23 INFO HttpServer: Starting HTTP Server
16/03/25 13:55:23 INFO Utils: Successfully started service 'HTTP file server' on port 53575.
16/03/25 13:55:23 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/25 13:55:23 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/25 13:55:23 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/25 13:55:23 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/userFiles-51717a48-8227-4867-a1fd-ddaa730899fe/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:55:23 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458894323925
16/03/25 13:55:23 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/25 13:55:23 INFO Executor: Starting executor ID driver on host localhost
16/03/25 13:55:23 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34039.
16/03/25 13:55:23 INFO NettyBlockTransferService: Server created on 34039
16/03/25 13:55:23 INFO BlockManagerMaster: Trying to register BlockManager
16/03/25 13:55:23 INFO BlockManagerMasterEndpoint: Registering block manager localhost:34039 with 541.3 MB RAM, BlockManagerId(driver, localhost, 34039)
16/03/25 13:55:23 INFO BlockManagerMaster: Registered BlockManager
16/03/25 13:55:24 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:55:24 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:55:24 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:55:24 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:55:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/25 13:55:24 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/25 13:55:24 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:55:24 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=567646617
16/03/25 13:55:24 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 541.3 MB)
16/03/25 13:55:24 INFO MemoryStore: ensureFreeSpace(4155) called with curMem=6576, maxMem=567646617
16/03/25 13:55:24 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 541.3 MB)
16/03/25 13:55:24 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:34039 (size: 4.1 KB, free: 541.3 MB)
16/03/25 13:55:24 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/25 13:55:24 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:55:24 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/25 13:55:24 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2559 bytes)
16/03/25 13:55:24 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2583 bytes)
16/03/25 13:55:24 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/25 13:55:24 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458894323925
16/03/25 13:55:24 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/25 13:55:24 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/userFiles-51717a48-8227-4867-a1fd-ddaa730899fe/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:55:24 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/25 13:55:24 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/25 13:55:24 INFO MemoryStore: ensureFreeSpace(314) called with curMem=10731, maxMem=567646617
16/03/25 13:55:24 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 314.0 B, free 541.3 MB)
16/03/25 13:55:24 INFO MemoryStore: ensureFreeSpace(286) called with curMem=11045, maxMem=567646617
16/03/25 13:55:24 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:34039 (size: 314.0 B, free: 541.3 MB)
16/03/25 13:55:24 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 286.0 B, free 541.3 MB)
16/03/25 13:55:24 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:34039 (size: 286.0 B, free: 541.3 MB)
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: Chennai
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: archbishop
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'a', u'of', u'highest', u'bishop', u'rank'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: metropolitan
titlemapFunction_Parents(): keyword= title ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])

mapFunction_Parents(): keyword: title ; prevleveltokens: sum
mapFunction_Parents(): adding to parents: syn =  Synset('metropolitan.n.01') ; keyword:  title  in syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= [u'metropolitan']
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: area
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region'mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'a', u'of', u'money', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
, u'some'asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: expressed
, u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: expansion
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'a', u'function', u'product', u'terms', u'of', u'sum', u'expressed', u'as', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: serving
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'to', u'expression', u'give'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: geographical
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'science', u'or', u'to', u'of', u'relating', u'the', u'geography'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: boundary
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'a', u'food', u'of', u'drink', u'meal', u'an', u'as', u'individual', u'taken', u'part', u'or', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: formerly
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'a', u';', u'time', u'at', u'previous'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: people
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'a', u'limits', u'area', u'determining', u'an', u'of', u'line', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: Tamil
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'a', u'and', u'people', u'of', u'Sri', u'southern', u'member', u'India', u'mixed', u'Dravidian', u'the', u'Lanka', u'Caucasian'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: Nadu
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: function
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'group', u')', u'(', u'men', u'children', u'or', u'collectively', u'beings', u'human', u'of', u'plural', u'any', u'women'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: Christianity
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'a', u'and', u'monotheistic', u'based', u'embodied', u'on', u'New', u'of', u'in', u'system', u'Jesus', u'as', u'practices', u'role', u'emphasizing', u'teachings', u'Testament', u'Old', u'the', u'beliefs', u'savior'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: culture
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'mathematical', u'domain', u'set', u'associated', u'is', u'an', u'relation', u'another', u'given', u')', u'(', u'mathematics', u'function', u'that', u'such', u'with', u'a', u'of', u'element', u'range', u'each', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: product
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'a', u'and', u'particular', u'society', u'place', u'at', u'time'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: indefinite
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'or', u'stated', u'defined', u'clearly', u'not', u'vague'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: bishop
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'and', u'the', u'spiritual', u'Christ', u'twelve', u'some', u'authority', u'in', u'Christian', u'ministers', u'member', u'to', u'churches', u';', u'administrative', u'be', u'Apostles', u'appointed', u'a', u'oversee', u'of', u'priests', u'or', u'considered', u'clergy', u'senior', u'successors', u'having'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: special
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'commodities', u'offered', u'sale', u'for'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: terms
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'a', u'and', u'temporary', u'offering', u'that', u')', u'(', u'price', u'featured', u'at', u'in', u'usually', u'is', u'reduced', u'special', u'advertising'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: geography
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'and', u'climate', u'topography', u"'s", u'responses', u'people', u'of', u'study', u'surface', u'includes', u'to', u'soil', u'earth', u'the', u';', u'vegetation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: city
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'status', u'people', u'relations', u'to', u'groups', u'between', u'respect', u'the', u'with', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: equivalent
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'a', u'force', u'significance', u'to', u'measure', u'equal', u'value', u'effect', u'person', u'another', u'in', u'thing', u'or', u'etc'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: Bay
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'a', u'and', u'districts', u'several', u'urban', u'may', u'populated', u'large', u'area', u'independent', u'densely', u';', u'include', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: given
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'a', u'smaller', u'shoreline', u'gulf', u'of', u'larger', u'cove', u'but', u'an', u'indentation', u'than'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: western
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'a', u'and', u'about', u'United', u'development', u'of', u'life', u'period', u'States', u'exploration', u'western', u'in', u'during', u'the', u'film'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: particular
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'a', u'about', u')', u'(', u'some', u'general', u'to', u'as', u'part', u'opposed', u'fact'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: Bengal
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'a', u'whose', u'and', u'Bangladesh', u'eastern', u'region', u'India', u'part', u'western', u'in', u'included', u'now', u'is'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: Orthodox
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'pertaining', u'Judaism', u'characteristic', u'to', u'of', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: region
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'extended', u'of', u'something', u'spatial', u'the', u'location'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: title
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'for', u'that', u'is', u'an', u'assumption', u'taken', u'granted'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: Madras
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'a', u'on', u';', u'Madras', u'formerly', u')', u'of', u'India', u'Bay', u'state', u'Andhra', u'(', u'in', u'the', u'Bengal', u'Pradesh', u'southeastern', u'south'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): title
mapFunction_Parents(): keyword: title ; prevleveltokens: Eastern
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'east', u'situated', u'in', u'the', u'toward', u'or', u'lying'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
mapFunction_Parents(): keyword= title ; syndef_tokens= set([u'a', u'statute', u'give', u'that', u'may', u'of', u'the', u'bill', u'brief', u'heading', u'deals', u'matters', u'names', u'it', u';', u'summary', u'with', u'or', u'legislative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/25 13:55:33 INFO PythonRunner: Times: total = 9034, boot = 480, init = 435, finish = 8119
16/03/25 13:55:33 INFO PythonRunner: Times: total = 9041, boot = 480, init = 506, finish = 8055
16/03/25 13:55:33 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/25 13:55:33 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/25 13:55:33 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 9141 ms on localhost (1/2)
16/03/25 13:55:33 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9150 ms on localhost (2/2)
16/03/25 13:55:33 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/25 13:55:33 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 9.154 s
16/03/25 13:55:33 INFO DAGScheduler: looking for newly runnable stages
16/03/25 13:55:33 INFO DAGScheduler: running: Set()
16/03/25 13:55:33 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/25 13:55:33 INFO DAGScheduler: failed: Set()
16/03/25 13:55:33 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/25 13:55:33 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which is now runnable
16/03/25 13:55:33 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11331, maxMem=567646617
16/03/25 13:55:33 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 541.3 MB)
16/03/25 13:55:33 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16315, maxMem=567646617
16/03/25 13:55:33 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 541.3 MB)
16/03/25 13:55:33 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:34039 (size: 3.0 KB, free: 541.3 MB)
16/03/25 13:55:33 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/25 13:55:33 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:55:33 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/25 13:55:33 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:55:33 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:55:33 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/25 13:55:33 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/25 13:55:33 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:55:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
16/03/25 13:55:33 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:55:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
reduceFunction_Parents(): returns= [u'metropolitan', 'None']
16/03/25 13:55:33 INFO PythonRunner: Times: total = 204, boot = 203, init = 1, finish = 0
16/03/25 13:55:33 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1280 bytes result sent to driver
16/03/25 13:55:33 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 231 ms on localhost (1/2)
16/03/25 13:55:33 INFO PythonRunner: Times: total = 275, boot = 274, init = 1, finish = 0
16/03/25 13:55:33 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/25 13:55:33 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.300 s
16/03/25 13:55:33 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 9.681556 s
16/03/25 13:55:33 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 300 ms on localhost (2/2)
16/03/25 13:55:33 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/25 13:55:33 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:55:33 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:55:33 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:55:33 INFO DAGScheduler: Parents of final stage: List()
16/03/25 13:55:33 INFO DAGScheduler: Missing parents: List()
16/03/25 13:55:33 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:55:33 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19370, maxMem=567646617
16/03/25 13:55:33 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 541.3 MB)
16/03/25 13:55:33 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25186, maxMem=567646617
16/03/25 13:55:33 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 541.3 MB)
16/03/25 13:55:33 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:34039 (size: 3.3 KB, free: 541.3 MB)
16/03/25 13:55:33 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/25 13:55:33 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:55:33 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/25 13:55:33 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/25 13:55:33 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2361 bytes)
16/03/25 13:55:33 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/25 13:55:33 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/25 13:55:33 INFO PythonRunner: Times: total = 56, boot = 55, init = 1, finish = 0
16/03/25 13:55:33 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/25 13:55:33 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 68 ms on localhost (1/2)
16/03/25 13:55:34 INFO PythonRunner: Times: total = 244, boot = 243, init = 1, finish = 0
16/03/25 13:55:34 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1345 bytes result sent to driver
16/03/25 13:55:34 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 259 ms on localhost (2/2)
16/03/25 13:55:34 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/25 13:55:34 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.260 s
16/03/25 13:55:34 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 0.287911 s
16/03/25 13:55:34 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/25 13:55:34 INFO DAGScheduler: Stopping DAGScheduler
16/03/25 13:55:34 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/25 13:55:34 INFO MemoryStore: MemoryStore cleared
16/03/25 13:55:34 INFO BlockManager: BlockManager stopped
16/03/25 13:55:34 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/25 13:55:34 INFO SparkContext: Successfully stopped SparkContext
16/03/25 13:55:34 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/25 13:55:34 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/25 13:55:34 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/25 13:55:34 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
graphcache_mapreduce_parents updated: defaultdict(<cyfunction <lambda> at 0xb1f81e6c>, {'2c49f1424d675552d9e7323a3eef6206': [u'None', u'expansion', u'None'], '45b800affe042d5d9a4228427680a935': [u'Chennai', u'None'], 'fdc633a5e1dea73592deb7e3bbbe3aea': [u'Chennai', u'None'], 'dd10336563a65a645a42bb416a6ebec6': [u'None', u'area', u'None'], '98acf8f6223b3758ff4a9dc22afb0e3b': [u'metropolitan', u'None'], 'a8f48eba5bb66d59263f478b93779a2c': [u'metropolitan', u'None'], '9f1808799460fd7b2da9ab51bd7b6775': [u'None', u'area', u'None'], '4b7e9f2659636820e82592ed034512f9': [u'Chennai', u'Madras'], '44b9adf04881710b0a7c81b0a22b1209': [u'Chennai', u'None'], '1d1c5d8e5b55f6916d7d9218c4a0fe34': [u'None', u'area', u'None', u'Bengal'], 'e9301955882d67edfb275156ef73113c': [u'metropolitan', u'None'], '552934a698e1bcf880132a2bd5996d11': [u'None', u'area', u'None'], '063da2002ba149bb4025d1e1fcfb49f5': [u'None', u'area', u'None'], 'a31cc044ea8d13e6b1bf4e98768e44a5': [u'None', u'area', u'None'], 'b1318a4c6d13196fb45da6102d193223': [u'None', u'area', u'None', u'special'], 'ff4fcba188cd7bb550ed88e9ee5dc6f1': [u'Chennai', u'Madras', u'None'], '57466dae2c092869867908c5c54e241c': [u'metropolitan', u'None'], 'ed43ebbafa0c6204a5916ca879d5bd26': [u'None', u'area'], 'e9da57cf07c9f8d232e2c9c1a07d1a0a': [u'None', u'area', u'culture', u'None'], '3a2fbf91abebcac17538118b2e02315d': [u'metropolitan', u'None', u'western'], 'c65d3beca4dc2d6f37377a842accc0cd': [u'None', u'expansion', u'None', u'function'], '3cd540871242471e0d89bea4eabc06ea': [u'None', u'expansion', u'None'], '40603e72c50afb5b6be8a7ff1684c966': [u'Chennai', u'None', u'Madras'], '4208c80be8e0c0d285fafd73cd5bd9a6': [u'metropolitan', u'None'], 'b7b50c706678d48359a2ac685d535b33': [u'metropolitan', u'None'], 'f2e69333b98cfc98f544ee3a5717b7c4': [u'Chennai', u'None'], '39c21ff4448a2910600584a0d49f93e8': [u'metropolitan', u'None'], '926a71600b58a41448b179d8665fd5df': [u'None', u'expansion', u'None'], 'e6ebeac0f1cb14fbd7b903291fcc6a8f': [u'metropolitan', u'None'], '25439f8325592e4ecd8b06f5f799b57a': [u'None', u'expansion', u'None'], 'd7b9ba5125de58e77ad31543f2c54034': [u'None', u'area', u'None']})
asfer_pickle_string_dump(): picklef.write(): patriarch
16/03/25 13:55:35 INFO SparkContext: Running Spark version 1.5.2
16/03/25 13:55:35 INFO SecurityManager: Changing view acls to: root
16/03/25 13:55:35 INFO SecurityManager: Changing modify acls to: root
16/03/25 13:55:35 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/25 13:55:35 INFO Slf4jLogger: Slf4jLogger started
16/03/25 13:55:35 INFO Remoting: Starting remoting
16/03/25 13:55:35 INFO Utils: Successfully started service 'sparkDriver' on port 46116.
16/03/25 13:55:35 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:46116]
16/03/25 13:55:35 INFO SparkEnv: Registering MapOutputTracker
16/03/25 13:55:35 INFO SparkEnv: Registering BlockManagerMaster
16/03/25 13:55:35 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-a1374cd8-61e5-4b2f-8fe3-943c446cd50b
16/03/25 13:55:35 INFO MemoryStore: MemoryStore started with capacity 534.6 MB
16/03/25 13:55:35 INFO HttpFileServer: HTTP File server directory is /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/httpd-e2d8039b-ca48-4635-ba94-c4a30561610c
16/03/25 13:55:35 INFO HttpServer: Starting HTTP Server
16/03/25 13:55:35 INFO Utils: Successfully started service 'HTTP file server' on port 37953.
16/03/25 13:55:35 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/25 13:55:35 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/25 13:55:35 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/25 13:55:35 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/userFiles-2980c206-1073-4d56-9ddc-c959dcd1d080/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:55:35 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458894335416
16/03/25 13:55:35 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/25 13:55:35 INFO Executor: Starting executor ID driver on host localhost
16/03/25 13:55:35 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33046.
16/03/25 13:55:35 INFO NettyBlockTransferService: Server created on 33046
16/03/25 13:55:35 INFO BlockManagerMaster: Trying to register BlockManager
16/03/25 13:55:35 INFO BlockManagerMasterEndpoint: Registering block manager localhost:33046 with 534.6 MB RAM, BlockManagerId(driver, localhost, 33046)
16/03/25 13:55:35 INFO BlockManagerMaster: Registered BlockManager
16/03/25 13:55:35 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:55:35 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:55:35 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:55:35 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:55:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/25 13:55:35 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/25 13:55:35 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:55:35 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=560568729
16/03/25 13:55:35 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 534.6 MB)
16/03/25 13:55:35 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=560568729
16/03/25 13:55:35 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 534.6 MB)
16/03/25 13:55:35 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:33046 (size: 4.1 KB, free: 534.6 MB)
16/03/25 13:55:35 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/25 13:55:35 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:55:35 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/25 13:55:35 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2576 bytes)
16/03/25 13:55:35 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2565 bytes)
16/03/25 13:55:35 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/25 13:55:35 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458894335416
16/03/25 13:55:35 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/25 13:55:35 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/userFiles-2980c206-1073-4d56-9ddc-c959dcd1d080/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:55:35 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/25 13:55:35 INFO MemoryStore: ensureFreeSpace(301) called with curMem=10732, maxMem=560568729
16/03/25 13:55:35 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 301.0 B, free 534.6 MB)
16/03/25 13:55:35 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:33046 (size: 301.0 B, free: 534.6 MB)
16/03/25 13:55:35 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/25 13:55:35 INFO MemoryStore: ensureFreeSpace(295) called with curMem=11033, maxMem=560568729
16/03/25 13:55:35 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 295.0 B, free 534.6 MB)
16/03/25 13:55:35 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:33046 (size: 295.0 B, free: 534.6 MB)
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: sum
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): adding to parents: syn =  Synset('metropolitan.n.01') ; keyword:  patriarch  in syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= [u'metropolitan']
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: area
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: expansion
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u'function', u'product', u'terms', u'of', u'sum', u'expressed', u'as', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: serving
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u'food', u'of', u'drink', u'meal', u'an', u'as', u'individual', u'taken', u'part', u'or', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: formerly
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u';', u'time', u'at', u'previous'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: people
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'group', u')', u'(', u'men', u'children', u'or', u'collectively', u'beings', u'human', u'of', u'plural', u'any', u'women'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: Christianity
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u'and', u'monotheistic', u'based', u'embodied', u'on', u'New', u'of', u'in', u'system', u'Jesus', u'as', u'practices', u'role', u'emphasizing', u'teachings', u'Testament', u'Old', u'the', u'beliefs', u'savior'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: culture
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u'and', u'particular', u'society', u'place', u'at', u'time'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: indefinite
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'or', u'stated', u'defined', u'clearly', u'not', u'vague'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: bishop
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'and', u'the', u'spiritual', u'Christ', u'twelve', u'some', u'authority', u'in', u'Christian', u'ministers', u'member', u'to', u'churches', u';', u'administrative', u'be', u'Apostles', u'appointed', u'a', u'oversee', u'of', u'priests', u'or', u'considered', u'clergy', u'senior', u'successors', u'having'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: special
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u'and', u'temporary', u'offering', u'that', u')', u'(', u'price', u'featured', u'at', u'in', u'usually', u'is', u'reduced', u'special', u'advertising'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: geography
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'and', u'climate', u'topography', u"'s", u'responses', u'people', u'of', u'study', u'surface', u'includes', u'to', u'soil', u'earth', u'the', u';', u'vegetation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: city
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u'and', u'districts', u'several', u'urban', u'may', u'populated', u'large', u'area', u'independent', u'densely', u';', u'include', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: given
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u'of', u'money', u'quantity'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: expressed
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'to', u'expression', u'give'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: geographical
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'science', u'or', u'to', u'of', u'relating', u'the', u'geography'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: boundary
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u'limits', u'area', u'determining', u'an', u'of', u'line', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: Tamil
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u'and', u'people', u'of', u'Sri', u'southern', u'member', u'India', u'mixed', u'Dravidian', u'the', u'Lanka', u'Caucasian'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: Nadu
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: function
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'mathematical', u'domain', u'set', u'associated', u'is', u'an', u'relation', u'another', u'given', u')', u'(', u'mathematics', u'function', u'that', u'such', u'with', u'a', u'of', u'element', u'range', u'each', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: product
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'commodities', u'offered', u'sale', u'for'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: terms
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'for', u'that', u'is', u'an', mapFunction_Parents(): keyword=u'assumption' patriarch ; syndef_tokens= set([u'status', u'people', u'relations', u'to', u'groups', u'between', u'respect', u'the', u'with', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: equivalent
, u'taken', u'granted'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: Madras
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u'force', u'significance', u'to', u'measure', u'equal', u'value', u'effect', u'person', u'another', u'in', u'thing', u'or', u'etc'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: Bay
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u'on', u';', u'Madras', u'formerly', u')', u'of', u'India', u'Bay', u'state', mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u'smaller', u'shoreline', u'gulf', u'of', u'larger', u'cove', u'but', u'an', u'indentation', u'than'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: western
u'Andhra', u'(', u'in', u'the', u'Bengal', u'Pradesh', u'southeastern', u'south'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: Eastern
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'east', u'situated', u'in', u'the', u'toward', u'or', u'lying'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword:mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u'and', u'about', u'United', u'development', u'of', u'life', u'period', u'States', u'exploration', u'western', u'in', u'during', u'the', u'film'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: particular
 patriarch ; prevleveltokens: archbishop
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u'of', u'highest', u'bishop', u'rank'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u'about', u')', u'(', u'some', u'general', u'to', u'as', u'part', u'opposed', u'fact'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: Bengal
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u'whose', u'and', u'Bangladesh', u'eastern', u'region', u'India', u'part', u'western', u'in', u'included', u'now', u'is'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: Orthodox
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'pertaining', u'Judaism', u'characteristic', u'to', u'of', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: region
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'extended', u'of', u'something', u'spatial', u'the', u'location'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: title
16/03/25 13:55:44 INFO PythonRunner: Times: total = 8910, boot = 474, init = 428, finish = 8008
16/03/25 13:55:44 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/25 13:55:44 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9002 ms on localhost (1/2)
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u'statute', u'give', u'that', u'may', u'of', u'the', u'bill', u'brief', u'heading', u'deals', u'matters', u'names', u'it', u';', u'summary', u'with', u'or', u'legislative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): patriarch
mapFunction_Parents(): keyword: patriarch ; prevleveltokens: patriarch
mapFunction_Parents(): keyword= patriarch ; syndef_tokens= set([u'a', u'and', u'older', u'is', u'who', u'rank', u'yourself', u'in', u'higher', u'than', u'man'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/25 13:55:44 INFO PythonRunner: Times: total = 8961, boot = 492, init = 392, finish = 8077
16/03/25 13:55:44 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/25 13:55:44 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 9056 ms on localhost (2/2)
16/03/25 13:55:44 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 9.068 s
16/03/25 13:55:44 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/25 13:55:44 INFO DAGScheduler: looking for newly runnable stages
16/03/25 13:55:44 INFO DAGScheduler: running: Set()
16/03/25 13:55:44 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/25 13:55:44 INFO DAGScheduler: failed: Set()
16/03/25 13:55:44 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/25 13:55:44 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which is now runnable
16/03/25 13:55:44 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11328, maxMem=560568729
16/03/25 13:55:44 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 534.6 MB)
16/03/25 13:55:44 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16312, maxMem=560568729
16/03/25 13:55:44 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 534.6 MB)
16/03/25 13:55:44 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:33046 (size: 3.0 KB, free: 534.6 MB)
16/03/25 13:55:44 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/25 13:55:44 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:55:44 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/25 13:55:44 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:55:44 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:55:44 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/25 13:55:44 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:55:44 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/25 13:55:44 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:55:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/25 13:55:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
reduceFunction_Parents(): returns= [u'metropolitan', 'None']
16/03/25 13:55:44 INFO PythonRunner: Times: total = 223, boot = 220, init = 1, finish = 2
16/03/25 13:55:44 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1280 bytes result sent to driver
16/03/25 13:55:44 INFO PythonRunner: Times: total = 225, boot = 224, init = 0, finish = 1
16/03/25 13:55:44 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/25 13:55:44 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 244 ms on localhost (1/2)
16/03/25 13:55:44 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 263 ms on localhost (2/2)
16/03/25 13:55:44 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/25 13:55:44 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.255 s
16/03/25 13:55:44 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 9.375110 s
16/03/25 13:55:45 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:55:45 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:55:45 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:55:45 INFO DAGScheduler: Parents of final stage: List()
16/03/25 13:55:45 INFO DAGScheduler: Missing parents: List()
16/03/25 13:55:45 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:55:45 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19367, maxMem=560568729
16/03/25 13:55:45 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 534.6 MB)
16/03/25 13:55:45 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25183, maxMem=560568729
16/03/25 13:55:45 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 534.6 MB)
16/03/25 13:55:45 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:33046 (size: 3.3 KB, free: 534.6 MB)
16/03/25 13:55:45 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/25 13:55:45 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:55:45 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/25 13:55:45 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/25 13:55:45 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2361 bytes)
16/03/25 13:55:45 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/25 13:55:45 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/25 13:55:45 INFO PythonRunner: Times: total = 173, boot = 173, init = 0, finish = 0
16/03/25 13:55:45 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/25 13:55:45 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 184 ms on localhost (1/2)
16/03/25 13:55:45 INFO PythonRunner: Times: total = 198, boot = 197, init = 1, finish = 0
16/03/25 13:55:45 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1345 bytes result sent to driver
16/03/25 13:55:45 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 224 ms on localhost (2/2)
16/03/25 13:55:45 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/25 13:55:45 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.226 s
16/03/25 13:55:45 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 0.258859 s
16/03/25 13:55:45 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/25 13:55:45 INFO DAGScheduler: Stopping DAGScheduler
16/03/25 13:55:45 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/25 13:55:45 INFO MemoryStore: MemoryStore cleared
16/03/25 13:55:45 INFO BlockManager: BlockManager stopped
16/03/25 13:55:45 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/25 13:55:45 INFO SparkContext: Successfully stopped SparkContext
16/03/25 13:55:45 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/25 13:55:45 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/25 13:55:45 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
graphcache_mapreduce_parents updated: defaultdict(<cyfunction <lambda> at 0xb1f81e6c>, {'c9e46d6d893b45343d5c7e9c6ec9851b': [u'metropolitan', u'None'], '2c49f1424d675552d9e7323a3eef6206': [u'None', u'expansion', u'None'], '45b800affe042d5d9a4228427680a935': [u'Chennai', u'None'], 'fdc633a5e1dea73592deb7e3bbbe3aea': [u'Chennai', u'None'], 'dd10336563a65a645a42bb416a6ebec6': [u'None', u'area', u'None'], '98acf8f6223b3758ff4a9dc22afb0e3b': [u'metropolitan', u'None'], 'a8f48eba5bb66d59263f478b93779a2c': [u'metropolitan', u'None'], '9f1808799460fd7b2da9ab51bd7b6775': [u'None', u'area', u'None'], '4b7e9f2659636820e82592ed034512f9': [u'Chennai', u'Madras'], '44b9adf04881710b0a7c81b0a22b1209': [u'Chennai', u'None'], '1d1c5d8e5b55f6916d7d9218c4a0fe34': [u'None', u'area', u'None', u'Bengal'], 'e9301955882d67edfb275156ef73113c': [u'metropolitan', u'None'], '552934a698e1bcf880132a2bd5996d11': [u'None', u'area', u'None'], '063da2002ba149bb4025d1e1fcfb49f5': [u'None', u'area', u'None'], 'a31cc044ea8d13e6b1bf4e98768e44a5': [u'None', u'area', u'None'], 'b1318a4c6d13196fb45da6102d193223': [u'None', u'area', u'None', u'special'], 'ff4fcba188cd7bb550ed88e9ee5dc6f1': [u'Chennai', u'Madras', u'None'], '57466dae2c092869867908c5c54e241c': [u'metropolitan', u'None'], 'ed43ebbafa0c6204a5916ca879d5bd26': [u'None', u'area'], 'e9da57cf07c9f8d232e2c9c1a07d1a0a': [u'None', u'area', u'culture', u'None'], '3a2fbf91abebcac17538118b2e02315d': [u'metropolitan', u'None', u'western'], 'c65d3beca4dc2d6f37377a842accc0cd': [u'None', u'expansion', u'None', u'function'], '3cd540871242471e0d89bea4eabc06ea': [u'None', u'expansion', u'None'], '40603e72c50afb5b6be8a7ff1684c966': [u'Chennai', u'None', u'Madras'], '4208c80be8e0c0d285fafd73cd5bd9a6': [u'metropolitan', u'None'], 'b7b50c706678d48359a2ac685d535b33': [u'metropolitan', u'None'], 'f2e69333b98cfc98f544ee3a5717b7c4': [u'Chennai', u'None'], '39c21ff4448a2910600584a0d49f93e8': [u'metropolitan', u'None'], '926a71600b58a41448b179d8665fd5df': [u'None', u'expansion', u'None'], 'e6ebeac0f1cb14fbd7b903291fcc6a8f': [u'metropolitan', u'None'], '25439f8325592e4ecd8b06f5f799b57a': [u'None', u'expansion', u'None'], 'd7b9ba5125de58e77ad31543f2c54034': [u'None', u'area', u'None']})
asfer_pickle_string_dump(): picklef.write(): Church
16/03/25 13:55:46 INFO SparkContext: Running Spark version 1.5.2
16/03/25 13:55:46 INFO SecurityManager: Changing view acls to: root
16/03/25 13:55:46 INFO SecurityManager: Changing modify acls to: root
16/03/25 13:55:46 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/25 13:55:46 INFO Slf4jLogger: Slf4jLogger started
16/03/25 13:55:46 INFO Remoting: Starting remoting
16/03/25 13:55:46 INFO Utils: Successfully started service 'sparkDriver' on port 42513.
16/03/25 13:55:46 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:42513]
16/03/25 13:55:46 INFO SparkEnv: Registering MapOutputTracker
16/03/25 13:55:46 INFO SparkEnv: Registering BlockManagerMaster
16/03/25 13:55:46 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-454cddf9-0b6b-446f-8830-802a6fe9f7c1
16/03/25 13:55:46 INFO MemoryStore: MemoryStore started with capacity 534.6 MB
16/03/25 13:55:46 INFO HttpFileServer: HTTP File server directory is /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/httpd-77dc7d31-69d6-4a04-9338-d9bf3128fbdc
16/03/25 13:55:46 INFO HttpServer: Starting HTTP Server
16/03/25 13:55:46 INFO Utils: Successfully started service 'HTTP file server' on port 34451.
16/03/25 13:55:46 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/25 13:55:46 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/25 13:55:46 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/25 13:55:46 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/userFiles-0e161365-aad8-410b-9883-e24dcc26b6d5/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:55:46 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458894346526
16/03/25 13:55:46 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/25 13:55:46 INFO Executor: Starting executor ID driver on host localhost
16/03/25 13:55:46 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51618.
16/03/25 13:55:46 INFO NettyBlockTransferService: Server created on 51618
16/03/25 13:55:46 INFO BlockManagerMaster: Trying to register BlockManager
16/03/25 13:55:46 INFO BlockManagerMasterEndpoint: Registering block manager localhost:51618 with 534.6 MB RAM, BlockManagerId(driver, localhost, 51618)
16/03/25 13:55:46 INFO BlockManagerMaster: Registered BlockManager
16/03/25 13:55:46 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:55:46 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:55:46 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:55:46 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:55:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/25 13:55:46 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/25 13:55:46 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:55:46 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=560568729
16/03/25 13:55:46 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 534.6 MB)
16/03/25 13:55:46 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=560568729
16/03/25 13:55:46 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 534.6 MB)
16/03/25 13:55:46 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:51618 (size: 4.1 KB, free: 534.6 MB)
16/03/25 13:55:46 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/25 13:55:46 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:55:46 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/25 13:55:46 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2576 bytes)
16/03/25 13:55:46 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2595 bytes)
16/03/25 13:55:46 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/25 13:55:46 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458894346526
16/03/25 13:55:46 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/25 13:55:46 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/userFiles-0e161365-aad8-410b-9883-e24dcc26b6d5/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:55:46 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/25 13:55:46 INFO MemoryStore: ensureFreeSpace(301) called with curMem=10732, maxMem=560568729
16/03/25 13:55:46 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 301.0 B, free 534.6 MB)
16/03/25 13:55:46 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:51618 (size: 301.0 B, free: 534.6 MB)
16/03/25 13:55:46 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/25 13:55:46 INFO MemoryStore: ensureFreeSpace(322) called with curMem=11033, maxMem=560568729
16/03/25 13:55:46 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 322.0 B, free 534.6 MB)
16/03/25 13:55:46 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:51618 (size: 322.0 B, free: 534.6 MB)
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: sum
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u'of', u'money', u'quantity'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: expressed
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'to', u'expression', u'give'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: geographical
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'science', u'or', u'to', u'of', u'relating', u'the', u'geography'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: boundary
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u'limits', u'area', u'determining', u'an', u'of', u'line', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: Tamil
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u'and', u'people', u'of', u'Sri', u'southern', u'member', u'India', u'mixed', u'Dravidian', u'the', u'Lanka', u'Caucasian'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: Nadu
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: function
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'mathematical', u'domain', u'set', u'associated', u'is', u'an', u'relation', u'another', u'given', u')', u'(', u'mathematics', u'function', u'that', u'such', u'with', u'a', u'of', u'element', u'range', u'each', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: product
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'commodities', u'offered', u'sale', u'for'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: terms
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'status', u'people', u'relations', u'to', u'groups', u'between', u'respect', u'the', u'with', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: equivalent
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u'force', u'significance', u'to', u'measure', u'equal', u'value', u'effect', u'person', u'another', u'in', u'thing', u'or', u'etc'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: Bay
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u'smaller', u'shoreline', u'gulf', u'of', u'larger', u'cove', u'but', u'an', u'indentation', u'than'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: western
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u'and', u'about', u'United', u'development', u'of', u'life', u'period', u'States', u'exploration', u'western', u'in', u'during', u'the', u'film'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: particular
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u'about', u')', u'(', u'some', u'general', u'to', u'as', u'part', u'opposed', u'fact'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: Bengal
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u'whose', u'and', u'Bangladesh', u'eastern', u'region', u'India', u'part', u'western', u'in', u'included', u'now', u'is'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: Orthodox
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'pertaining', u'Judaism', u'characteristic', u'to', u'of', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: region
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'extended', u'of', u'something', u'spatial', u'the', u'location'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: title
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u'statute', u'give', u'that', u'may', u'of', u'the', u'bill', u'brief', u'heading', u'deals', u'matters', u'names', u'it', u';', u'summary', u'with', u'or', u'legislative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: patriarch
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u'and', u'older', u'is', u'who', u'rank', u'yourself', u'in', u'higher', u'than', u'man'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: Church
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'and', u'own', u'have', u'of', u'who', u'one', u'forms', u'their', u'groups', u'the', u'worship', u'beliefs', u'Christians'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/25 13:55:55 INFO PythonRunner: Times: total = 8528, boot = 451, init = 378, finish = 7699
16/03/25 13:55:55 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/25 13:55:55 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8613 ms on localhost (1/2)
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): adding to parents: syn =  Synset('metropolitan.n.01') ; keyword:  Church  in syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= [u'metropolitan']
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: area
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: expansion
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u'function', u'product', u'terms', u'of', u'sum', u'expressed', u'as', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: serving
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u'food', u'of', u'drink', u'meal', u'an', u'as', u'individual', u'taken', u'part', u'or', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: formerly
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u';', u'time', u'at', u'previous'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: people
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'group', u')', u'(', u'men', u'children', u'or', u'collectively', u'beings', u'human', u'of', u'plural', u'any', u'women'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: Christianity
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u'and', u'monotheistic', u'based', u'embodied', u'on', u'New', u'of', u'in', u'system', u'Jesus', u'as', u'practices', u'role', u'emphasizing', u'teachings', u'Testament', u'Old', u'the', u'beliefs', u'savior'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: culture
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u'and', u'particular', u'society', u'place', u'at', u'time'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: indefinite
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'or', u'stated', u'defined', u'clearly', u'not', u'vague'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: bishop
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'and', u'the', u'spiritual', u'Christ', u'twelve', u'some', u'authority', u'in', u'Christian', u'ministers', u'member', u'to', u'churches', u';', u'administrative', u'be', u'Apostles', u'appointed', u'a', u'oversee', u'of', u'priests', u'or', u'considered', u'clergy', u'senior', u'successors', u'having'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: special
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u'and', u'temporary', u'offering', u'that', u')', u'(', u'price', u'featured', u'at', u'in', u'usually', u'is', u'reduced', u'special', u'advertising'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: geography
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'and', u'climate', u'topography', u"'s", u'responses', u'people', u'of', u'study', u'surface', u'includes', u'to', u'soil', u'earth', u'the', u';', u'vegetation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: city
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u'and', u'districts', u'several', u'urban', u'may', u'populated', u'large', u'area', u'independent', u'densely', u';', u'include', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: given
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'for', u'that', u'is', u'an', u'assumption', u'taken', u'granted'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: Madras
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u'on', u';', u'Madras', u'formerly', u')', u'of', u'India', u'Bay', u'state', u'Andhra', u'(', u'in', u'the', u'Bengal', u'Pradesh', u'southeastern', u'south'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: Eastern
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'east', u'situated', u'in', u'the', u'toward', u'or', u'lying'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): Church
mapFunction_Parents(): keyword: Church ; prevleveltokens: archbishop
mapFunction_Parents(): keyword= Church ; syndef_tokens= set([u'a', u'of', u'highest', u'bishop', u'rank'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
16/03/25 13:55:55 INFO PythonRunner: Times: total = 8898, boot = 458, init = 392, finish = 8048
16/03/25 13:55:55 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/25 13:55:55 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8961 ms on localhost (2/2)
16/03/25 13:55:55 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/25 13:55:55 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 8.956 s
16/03/25 13:55:55 INFO DAGScheduler: looking for newly runnable stages
16/03/25 13:55:55 INFO DAGScheduler: running: Set()
16/03/25 13:55:55 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/25 13:55:55 INFO DAGScheduler: failed: Set()
16/03/25 13:55:55 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/25 13:55:55 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which is now runnable
16/03/25 13:55:55 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11355, maxMem=560568729
16/03/25 13:55:55 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 534.6 MB)
16/03/25 13:55:55 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16339, maxMem=560568729
16/03/25 13:55:55 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 534.6 MB)
16/03/25 13:55:55 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:51618 (size: 3.0 KB, free: 534.6 MB)
16/03/25 13:55:55 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/25 13:55:55 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:55:55 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/25 13:55:55 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:55:55 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:55:55 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/25 13:55:55 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/25 13:55:55 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:55:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
16/03/25 13:55:55 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:55:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
16/03/25 13:55:55 INFO PythonRunner: Times: total = 20, boot = -174, init = 193, finish = 1
16/03/25 13:55:55 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/25 13:55:55 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 56 ms on localhost (1/2)
reduceFunction_Parents(): returns= [u'metropolitan', 'None']
16/03/25 13:55:56 INFO PythonRunner: Times: total = 238, boot = 237, init = 0, finish = 1
16/03/25 13:55:56 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1280 bytes result sent to driver
16/03/25 13:55:56 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 256 ms on localhost (2/2)
16/03/25 13:55:56 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/25 13:55:56 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.241 s
16/03/25 13:55:56 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 9.249432 s
16/03/25 13:55:56 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:55:56 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:55:56 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:55:56 INFO DAGScheduler: Parents of final stage: List()
16/03/25 13:55:56 INFO DAGScheduler: Missing parents: List()
16/03/25 13:55:56 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:55:56 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19394, maxMem=560568729
16/03/25 13:55:56 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 534.6 MB)
16/03/25 13:55:56 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25210, maxMem=560568729
16/03/25 13:55:56 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 534.6 MB)
16/03/25 13:55:56 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:51618 (size: 3.3 KB, free: 534.6 MB)
16/03/25 13:55:56 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/25 13:55:56 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:55:56 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/25 13:55:56 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/25 13:55:56 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2361 bytes)
16/03/25 13:55:56 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/25 13:55:56 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/25 13:55:56 INFO PythonRunner: Times: total = 76, boot = -207, init = 283, finish = 0
16/03/25 13:55:56 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/25 13:55:56 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 92 ms on localhost (1/2)
16/03/25 13:55:56 INFO PythonRunner: Times: total = 74, boot = 74, init = 0, finish = 0
16/03/25 13:55:56 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1345 bytes result sent to driver
16/03/25 13:55:56 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 99 ms on localhost (2/2)
16/03/25 13:55:56 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/25 13:55:56 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.101 s
16/03/25 13:55:56 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 0.131550 s
16/03/25 13:55:56 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/25 13:55:56 INFO DAGScheduler: Stopping DAGScheduler
16/03/25 13:55:56 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/25 13:55:56 INFO MemoryStore: MemoryStore cleared
16/03/25 13:55:56 INFO BlockManager: BlockManager stopped
16/03/25 13:55:56 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/25 13:55:56 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/25 13:55:56 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/25 13:55:56 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/25 13:55:56 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/03/25 13:55:56 INFO SparkContext: Successfully stopped SparkContext
graphcache_mapreduce_parents updated: defaultdict(<cyfunction <lambda> at 0xb1f81e6c>, {'c9e46d6d893b45343d5c7e9c6ec9851b': [u'metropolitan', u'None'], '2c49f1424d675552d9e7323a3eef6206': [u'None', u'expansion', u'None'], '45b800affe042d5d9a4228427680a935': [u'Chennai', u'None'], 'fdc633a5e1dea73592deb7e3bbbe3aea': [u'Chennai', u'None'], 'dd10336563a65a645a42bb416a6ebec6': [u'None', u'area', u'None'], '98acf8f6223b3758ff4a9dc22afb0e3b': [u'metropolitan', u'None'], 'a8f48eba5bb66d59263f478b93779a2c': [u'metropolitan', u'None'], '9f1808799460fd7b2da9ab51bd7b6775': [u'None', u'area', u'None'], '4b7e9f2659636820e82592ed034512f9': [u'Chennai', u'Madras'], '44b9adf04881710b0a7c81b0a22b1209': [u'Chennai', u'None'], '1d1c5d8e5b55f6916d7d9218c4a0fe34': [u'None', u'area', u'None', u'Bengal'], 'e9301955882d67edfb275156ef73113c': [u'metropolitan', u'None'], '552934a698e1bcf880132a2bd5996d11': [u'None', u'area', u'None'], '063da2002ba149bb4025d1e1fcfb49f5': [u'None', u'area', u'None'], 'a31cc044ea8d13e6b1bf4e98768e44a5': [u'None', u'area', u'None'], 'b1318a4c6d13196fb45da6102d193223': [u'None', u'area', u'None', u'special'], 'ff4fcba188cd7bb550ed88e9ee5dc6f1': [u'Chennai', u'Madras', u'None'], '57466dae2c092869867908c5c54e241c': [u'metropolitan', u'None'], 'ed43ebbafa0c6204a5916ca879d5bd26': [u'None', u'area'], 'e9da57cf07c9f8d232e2c9c1a07d1a0a': [u'None', u'area', u'culture', u'None'], '3a2fbf91abebcac17538118b2e02315d': [u'metropolitan', u'None', u'western'], 'c65d3beca4dc2d6f37377a842accc0cd': [u'None', u'expansion', u'None', u'function'], '3cd540871242471e0d89bea4eabc06ea': [u'None', u'expansion', u'None'], '40603e72c50afb5b6be8a7ff1684c966': [u'Chennai', u'None', u'Madras'], '4208c80be8e0c0d285fafd73cd5bd9a6': [u'metropolitan', u'None'], 'b7b50c706678d48359a2ac685d535b33': [u'metropolitan', u'None'], 'ed457e104ac489b5ec0bf242d39416e3': [u'metropolitan', u'None'], 'f2e69333b98cfc98f544ee3a5717b7c4': [u'Chennai', u'None'], '39c21ff4448a2910600584a0d49f93e8': [u'metropolitan', u'None'], '926a71600b58a41448b179d8665fd5df': [u'None', u'expansion', u'None'], 'e6ebeac0f1cb14fbd7b903291fcc6a8f': [u'metropolitan', u'None'], '25439f8325592e4ecd8b06f5f799b57a': [u'None', u'expansion', u'None'], 'd7b9ba5125de58e77ad31543f2c54034': [u'None', u'area', u'None']})
asfer_pickle_string_dump(): picklef.write(): usually
16/03/25 13:55:57 INFO SparkContext: Running Spark version 1.5.2
16/03/25 13:55:57 INFO SecurityManager: Changing view acls to: root
16/03/25 13:55:57 INFO SecurityManager: Changing modify acls to: root
16/03/25 13:55:57 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/25 13:55:57 INFO Slf4jLogger: Slf4jLogger started
16/03/25 13:55:57 INFO Remoting: Starting remoting
16/03/25 13:55:57 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:45911]
16/03/25 13:55:57 INFO Utils: Successfully started service 'sparkDriver' on port 45911.
16/03/25 13:55:57 INFO SparkEnv: Registering MapOutputTracker
16/03/25 13:55:57 INFO SparkEnv: Registering BlockManagerMaster
16/03/25 13:55:57 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-28aaa2b4-c7f2-4114-865a-4e483dfe43d4
16/03/25 13:55:57 INFO MemoryStore: MemoryStore started with capacity 534.6 MB
16/03/25 13:55:57 INFO HttpFileServer: HTTP File server directory is /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/httpd-d6afa462-caf7-4543-9595-161f3468369c
16/03/25 13:55:57 INFO HttpServer: Starting HTTP Server
16/03/25 13:55:57 INFO Utils: Successfully started service 'HTTP file server' on port 43398.
16/03/25 13:55:57 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/25 13:55:57 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/25 13:55:57 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/25 13:55:57 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/userFiles-22866501-22f5-469d-8fa8-e55c5806f517/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:55:57 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458894357668
16/03/25 13:55:57 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/25 13:55:57 INFO Executor: Starting executor ID driver on host localhost
16/03/25 13:55:57 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59769.
16/03/25 13:55:57 INFO NettyBlockTransferService: Server created on 59769
16/03/25 13:55:57 INFO BlockManagerMaster: Trying to register BlockManager
16/03/25 13:55:57 INFO BlockManagerMasterEndpoint: Registering block manager localhost:59769 with 534.6 MB RAM, BlockManagerId(driver, localhost, 59769)
16/03/25 13:55:57 INFO BlockManagerMaster: Registered BlockManager
16/03/25 13:55:57 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:55:57 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:55:57 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:55:57 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:55:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/25 13:55:57 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/25 13:55:57 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:55:57 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=560568729
16/03/25 13:55:57 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 534.6 MB)
16/03/25 13:55:57 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=560568729
16/03/25 13:55:57 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 534.6 MB)
16/03/25 13:55:57 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:59769 (size: 4.1 KB, free: 534.6 MB)
16/03/25 13:55:57 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/25 13:55:57 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:55:57 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/25 13:55:57 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2586 bytes)
16/03/25 13:55:57 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2582 bytes)
16/03/25 13:55:57 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/25 13:55:57 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458894357668
16/03/25 13:55:57 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/25 13:55:57 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/userFiles-22866501-22f5-469d-8fa8-e55c5806f517/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:55:57 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/25 13:55:57 INFO MemoryStore: ensureFreeSpace(316) called with curMem=10732, maxMem=560568729
16/03/25 13:55:57 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 316.0 B, free 534.6 MB)
16/03/25 13:55:57 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:59769 (size: 316.0 B, free: 534.6 MB)
16/03/25 13:55:57 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/25 13:55:57 INFO MemoryStore: ensureFreeSpace(307) called with curMem=11048, maxMem=560568729
16/03/25 13:55:57 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 307.0 B, free 534.6 MB)
16/03/25 13:55:57 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:59769 (size: 307.0 B, free: 534.6 MB)
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: expressed
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'to', u'expression', u'give'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: geographical
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'science', u'or', u'to', u'of', u'relating', u'the', u'geography'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: boundary
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'limits', u'area', u'determining', u'an', u'of', u'line', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: Tamil
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'and', u'people', u'of', u'Sri', u'southern', u'member', u'India', u'mixed', u'Dravidian', u'the', u'Lanka', u'Caucasian'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: Nadu
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: function
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'mathematical', u'domain', u'set', u'associated', u'is', u'an', u'relation', u'another', u'given', u')', u'(', u'mathematics', u'function', u'that', u'such', u'with', u'a', u'of', u'element', u'range', u'each', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: product
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'commodities', u'offered', u'sale', u'for'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: terms
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'status', u'people', u'relations', u'to', u'groups', u'between', u'respect', u'the', u'with', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: metropolitan

asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: equivalent
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: area
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'force', u'significance', u'to', u'measure', u'equal', u'value', u'effect', u'person', u'another', u'in', u'thing', u'or', u'etc'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['NonmapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')'e, u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01')' ; keyword:  usually  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: expansion
]
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: Bay
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'function', u'product', u'terms', u'of', u'sum', u'expressed', u'as', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: serving
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'smaller', u'shoreline', u'gulf', u'of', u'larger', u'cove', u'but', u'an', u'indentation', u'than'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: western
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'and', u'about', u'United', u'development', u'of', u'life', u'period', u'States', u'exploration', u'western', u'in', u'during', u'the', u'film'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: particular
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'food', u'of', u'drink', u'meal', u'an', u'as', u'individual', u'taken', u'part', u'or', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: formerly
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u';', u'time', u'at', u'previous'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: people
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'about', u')', u'(', u'some', u'general', u'to', u'as', u'part', u'opposed', u'fact'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'group', u')', u'(', u'men', u'children', u'or', u'collectively', u'beings', u'human', u'of', u'plural', u'any', u'women'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: Christianity
; prevleveltokens: Bengal
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'whose', u'and', u'Bangladesh', mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'and', u'monotheistic', u'based', u'embodied', u'on', u'New', u'of', u'in', u'system', u'Jesus', u'as', u'practices', u'role', u'emphasizing', u'teachings', u'Testament', u'Old', u'the', u'beliefs', u'savior'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: culture
u'eastern', u'region', u'India', u'part', u'western', u'in', u'included', u'now', u'is'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: Orthodox
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'and', u'particular', u'society', u'place', u'at', u'time'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: indefinite
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'pertaining', u'Judaism', u'characteristic', u'to', u'of', u'or'])
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'or', u'stated', u'defined', u'clearly', u'not', u'vague'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: bishop
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usuallymapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'and', u'the', u'spiritual', u'Christ', u'twelve', u'some', u'authority', u'in', u'Christian', u'ministers', u'member', u'to', u'churches', u';', u'administrative', u'be', u'Apostles', u'appointed', u'a', u'oversee', u'of', u'priests', u'or', u'considered', u'clergy', u'senior', u'successors', u'having'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: special
 ; prevleveltokens: region
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'extended', u'of', u'something', u'spatial', u'the', u'location'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: title
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'and', u'temporary', u'offering', u'that', u')', u'(', u'price', u'featured', u'at', u'in', u'usually', u'is', u'reduced', u'special', u'advertising'])
mapFunction_Parents(): adding to parents: syn =  Synset('special.n.01') ; keyword:  usually  in syndef_tokens= set([u'a', u'and', u'temporary', u'offering', u'that', u')', u'(', u'price', u'featured', u'at', u'in', u'usually', u'is', u'reduced', u'special', u'advertising'])
mapFunction_Parents(): returns= [u'special']
reduceFunction_Parents(): returns= ['None', u'area', u'special']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: geography
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'and', u'climate', u'topography', u"'s", u'responses', u'people', u'of', u'study', u'surface', u'includes', u'to', u'soil', u'earth', u'the', u';', u'vegetation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area', u'special']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: city
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'statute', u'give', u'that', u'may', u'of', u'the', u'bill', u'brief', u'heading', u'deals', u'matters', u'names', u'it', u';', u'summary', u'with', u'or', u'legislative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: patriarch
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'and', u'districts', u'several', u'urban', u'may', u'populated', mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'and', u'older', u'is', u'who', u'rank', u'yourself', u'in', u'higher', u'than', u'man'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: Church
u'large', u'area', u'independent', u'densely', u';', u'include', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area', u'special']
asfer_pickle_string_load(): picklef.readlines():mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'and', u'own', u'have', u'of', u'who', u'one', u'forms', u'their', u'groups', u'the', u'worship', u'beliefs', u'Christians'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: usually
 usually
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'normal', u'conditions', u'under'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
mapFunction_Parents(): keyword: usually ; prevleveltokens: given
16/03/25 13:56:06 INFO PythonRunner: Times: total = 8898, boot = 552, init = 432, finish = 7914
16/03/25 13:56:06 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'for', u'that', u'is', u'an', u'assumption', u'taken', u'granted'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area', u'special']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: Madras
16/03/25 13:56:06 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 9007 ms on localhost (1/2)
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'on', u';', u'Madras', u'formerly', u')', u'of', u'India', u'Bay', u'state', u'Andhra', u'(', u'in', u'the', u'Bengal', u'Pradesh', u'southeastern', u'south'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area', u'special']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: Eastern
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'east', u'situated', u'in', u'the', u'toward', u'or', u'lying'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area', u'special']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: archbishop
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'of', u'highest', u'bishop', u'rank'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area', u'special']
asfer_pickle_string_load(): picklef.readlines(): usually
mapFunction_Parents(): keyword: usually ; prevleveltokens: sum
mapFunction_Parents(): keyword= usually ; syndef_tokens= set([u'a', u'of', u'money', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area', u'special']
16/03/25 13:56:06 INFO PythonRunner: Times: total = 8975, boot = 561, init = 515, finish = 7899
16/03/25 13:56:06 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/25 13:56:06 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 9.091 s
16/03/25 13:56:06 INFO DAGScheduler: looking for newly runnable stages
16/03/25 13:56:06 INFO DAGScheduler: running: Set()
16/03/25 13:56:06 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/25 13:56:06 INFO DAGScheduler: failed: Set()
16/03/25 13:56:06 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/25 13:56:06 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which is now runnable
16/03/25 13:56:06 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11355, maxMem=560568729
16/03/25 13:56:06 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 534.6 MB)
16/03/25 13:56:06 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16339, maxMem=560568729
16/03/25 13:56:06 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 534.6 MB)
16/03/25 13:56:06 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9089 ms on localhost (2/2)
16/03/25 13:56:06 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/25 13:56:06 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:59769 (size: 3.0 KB, free: 534.6 MB)
16/03/25 13:56:06 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/25 13:56:06 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:56:06 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/25 13:56:06 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:56:06 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:56:06 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/25 13:56:06 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/25 13:56:06 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:56:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/25 13:56:06 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:56:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
reduceFunction_Parents(): returns= ['None', u'area', u'special', 'None']
16/03/25 13:56:07 INFO PythonRunner: Times: total = 195, boot = 194, init = 0, finish = 1
16/03/25 13:56:07 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1294 bytes result sent to driver
16/03/25 13:56:07 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 224 ms on localhost (1/2)
16/03/25 13:56:07 INFO PythonRunner: Times: total = 328, boot = 327, init = 0, finish = 1
16/03/25 13:56:07 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/25 13:56:07 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 353 ms on localhost (2/2)
16/03/25 13:56:07 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.347 s
16/03/25 13:56:07 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/25 13:56:07 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 9.480386 s
16/03/25 13:56:07 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:56:07 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:56:07 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:56:07 INFO DAGScheduler: Parents of final stage: List()
16/03/25 13:56:07 INFO DAGScheduler: Missing parents: List()
16/03/25 13:56:07 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:56:07 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19394, maxMem=560568729
16/03/25 13:56:07 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 534.6 MB)
16/03/25 13:56:07 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25210, maxMem=560568729
16/03/25 13:56:07 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 534.6 MB)
16/03/25 13:56:07 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:59769 (size: 3.3 KB, free: 534.6 MB)
16/03/25 13:56:07 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/25 13:56:07 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:56:07 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/25 13:56:07 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/25 13:56:07 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2375 bytes)
16/03/25 13:56:07 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/25 13:56:07 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/25 13:56:07 INFO PythonRunner: Times: total = 20, boot = -30, init = 50, finish = 0
16/03/25 13:56:07 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/25 13:56:07 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 58 ms on localhost (1/2)
16/03/25 13:56:07 INFO PythonRunner: Times: total = 168, boot = 168, init = 0, finish = 0
16/03/25 13:56:07 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1362 bytes result sent to driver
16/03/25 13:56:07 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 177 ms on localhost (2/2)
16/03/25 13:56:07 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/25 13:56:07 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.180 s
16/03/25 13:56:07 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 0.216225 s
16/03/25 13:56:07 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/25 13:56:07 INFO DAGScheduler: Stopping DAGScheduler
16/03/25 13:56:07 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/25 13:56:07 INFO MemoryStore: MemoryStore cleared
16/03/25 13:56:07 INFO BlockManager: BlockManager stopped
16/03/25 13:56:07 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/25 13:56:07 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/25 13:56:07 INFO SparkContext: Successfully stopped SparkContext
16/03/25 13:56:07 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/25 13:56:07 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/25 13:56:07 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
graphcache_mapreduce_parents updated: defaultdict(<cyfunction <lambda> at 0xb1f81e6c>, {'c9e46d6d893b45343d5c7e9c6ec9851b': [u'metropolitan', u'None'], '2c49f1424d675552d9e7323a3eef6206': [u'None', u'expansion', u'None'], '45b800affe042d5d9a4228427680a935': [u'Chennai', u'None'], 'fdc633a5e1dea73592deb7e3bbbe3aea': [u'Chennai', u'None'], 'dd10336563a65a645a42bb416a6ebec6': [u'None', u'area', u'None'], '98acf8f6223b3758ff4a9dc22afb0e3b': [u'metropolitan', u'None'], 'a8f48eba5bb66d59263f478b93779a2c': [u'metropolitan', u'None'], '9f1808799460fd7b2da9ab51bd7b6775': [u'None', u'area', u'None'], '4b7e9f2659636820e82592ed034512f9': [u'Chennai', u'Madras'], '44b9adf04881710b0a7c81b0a22b1209': [u'Chennai', u'None'], '1d1c5d8e5b55f6916d7d9218c4a0fe34': [u'None', u'area', u'None', u'Bengal'], 'e9301955882d67edfb275156ef73113c': [u'metropolitan', u'None'], '552934a698e1bcf880132a2bd5996d11': [u'None', u'area', u'None'], '063da2002ba149bb4025d1e1fcfb49f5': [u'None', u'area', u'None'], 'a31cc044ea8d13e6b1bf4e98768e44a5': [u'None', u'area', u'None'], 'b1318a4c6d13196fb45da6102d193223': [u'None', u'area', u'None', u'special'], 'ff4fcba188cd7bb550ed88e9ee5dc6f1': [u'Chennai', u'Madras', u'None'], '57466dae2c092869867908c5c54e241c': [u'metropolitan', u'None'], '3c28f836cfdab5d2af70e9fd66287ad9': [u'None', u'area', u'special', u'None'], 'ed43ebbafa0c6204a5916ca879d5bd26': [u'None', u'area'], 'e9da57cf07c9f8d232e2c9c1a07d1a0a': [u'None', u'area', u'culture', u'None'], '3a2fbf91abebcac17538118b2e02315d': [u'metropolitan', u'None', u'western'], 'c65d3beca4dc2d6f37377a842accc0cd': [u'None', u'expansion', u'None', u'function'], '3cd540871242471e0d89bea4eabc06ea': [u'None', u'expansion', u'None'], '40603e72c50afb5b6be8a7ff1684c966': [u'Chennai', u'None', u'Madras'], '4208c80be8e0c0d285fafd73cd5bd9a6': [u'metropolitan', u'None'], 'b7b50c706678d48359a2ac685d535b33': [u'metropolitan', u'None'], 'ed457e104ac489b5ec0bf242d39416e3': [u'metropolitan', u'None'], 'f2e69333b98cfc98f544ee3a5717b7c4': [u'Chennai', u'None'], '39c21ff4448a2910600584a0d49f93e8': [u'metropolitan', u'None'], '926a71600b58a41448b179d8665fd5df': [u'None', u'expansion', u'None'], 'e6ebeac0f1cb14fbd7b903291fcc6a8f': [u'metropolitan', u'None'], '25439f8325592e4ecd8b06f5f799b57a': [u'None', u'expansion', u'None'], 'd7b9ba5125de58e77ad31543f2c54034': [u'None', u'area', u'None']})
asfer_pickle_string_dump(): picklef.write(): position
16/03/25 13:56:08 INFO SparkContext: Running Spark version 1.5.2
16/03/25 13:56:08 INFO SecurityManager: Changing view acls to: root
16/03/25 13:56:08 INFO SecurityManager: Changing modify acls to: root
16/03/25 13:56:08 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/25 13:56:08 INFO Slf4jLogger: Slf4jLogger started
16/03/25 13:56:08 INFO Remoting: Starting remoting
16/03/25 13:56:08 INFO Utils: Successfully started service 'sparkDriver' on port 60993.
16/03/25 13:56:08 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:60993]
16/03/25 13:56:08 INFO SparkEnv: Registering MapOutputTracker
16/03/25 13:56:08 INFO SparkEnv: Registering BlockManagerMaster
16/03/25 13:56:08 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-be66b412-3268-4c51-8dae-d272b3dd24b6
16/03/25 13:56:08 INFO MemoryStore: MemoryStore started with capacity 534.6 MB
16/03/25 13:56:08 INFO HttpFileServer: HTTP File server directory is /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/httpd-e6726cee-bdc1-4e15-8397-caaebd2f9cee
16/03/25 13:56:08 INFO HttpServer: Starting HTTP Server
16/03/25 13:56:08 INFO Utils: Successfully started service 'HTTP file server' on port 38283.
16/03/25 13:56:08 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/25 13:56:08 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/25 13:56:08 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/25 13:56:08 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/userFiles-c1710991-c9fa-4c0e-83f1-7fa4a1924d54/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:56:08 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458894368871
16/03/25 13:56:08 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/25 13:56:08 INFO Executor: Starting executor ID driver on host localhost
16/03/25 13:56:08 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60562.
16/03/25 13:56:08 INFO NettyBlockTransferService: Server created on 60562
16/03/25 13:56:08 INFO BlockManagerMaster: Trying to register BlockManager
16/03/25 13:56:08 INFO BlockManagerMasterEndpoint: Registering block manager localhost:60562 with 534.6 MB RAM, BlockManagerId(driver, localhost, 60562)
16/03/25 13:56:08 INFO BlockManagerMaster: Registered BlockManager
16/03/25 13:56:09 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:56:09 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:56:09 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:56:09 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:56:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/25 13:56:09 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/25 13:56:09 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:56:09 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=560568729
16/03/25 13:56:09 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 534.6 MB)
16/03/25 13:56:09 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=560568729
16/03/25 13:56:09 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 534.6 MB)
16/03/25 13:56:09 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:60562 (size: 4.1 KB, free: 534.6 MB)
16/03/25 13:56:09 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/25 13:56:09 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:56:09 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/25 13:56:09 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2586 bytes)
16/03/25 13:56:09 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2614 bytes)
16/03/25 13:56:09 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/25 13:56:09 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458894368871
16/03/25 13:56:09 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/25 13:56:09 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/userFiles-c1710991-c9fa-4c0e-83f1-7fa4a1924d54/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:56:09 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/25 13:56:09 INFO MemoryStore: ensureFreeSpace(307) called with curMem=10732, maxMem=560568729
16/03/25 13:56:09 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 307.0 B, free 534.6 MB)
16/03/25 13:56:09 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/25 13:56:09 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:60562 (size: 307.0 B, free: 534.6 MB)
16/03/25 13:56:09 INFO MemoryStore: ensureFreeSpace(342) called with curMem=11039, maxMem=560568729
16/03/25 13:56:09 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 342.0 B, free 534.6 MB)
16/03/25 13:56:09 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:60562 (size: 342.0 B, free: 534.6 MB)
asfer_pickle_string_load(): picklef.readlines(): asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: expressed
position
mapFunction_Parents(): keyword: position ; prevleveltokens: Chennai
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): adding to parents: syn =  Synset('metropolitan.n.01') ; keyword:  position  in syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= [u'metropolitan']
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: area
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: expansion
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'function', u'product', u'terms', u'of', u'sum', u'expressed', u'as', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: serving
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'food', u'of', u'drink', u'meal', u'an', u'as', u'individual', u'taken', u'part', u'or', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: formerly
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u';', u'time', u'at', u'previous'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: people
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'group', u')', u'(', u'men', u'children', u'or', u'collectively', u'beings', u'human', u'of', u'plural', u'any', u'women'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: Christianity
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'monotheistic', u'based', u'embodied', u'on', u'New', u'of', u'in', u'system', u'Jesus', u'as', u'practices', u'role', u'emphasizing', u'teachings', u'Testament', u'Old', u'the', u'beliefs', u'savior'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: culture
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'particular', u'society', u'place', u'at', u'time'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: indefinite
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'or', u'stated', u'defined', u'clearly', u'not', u'vague'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: bishop
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'and', u'the', u'spiritual', u'Christ', u'twelve', u'some', u'authority', u'in', u'Christian', u'ministers', u'member', u'to', u'churches', u';', u'administrative', u'be', u'Apostles', u'appointed', u'a', u'oversee', u'of', u'priests', u'or', u'considered', u'clergy', u'senior', u'successors', u'having'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: special
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'temporary', u'offering', u'that', u')', u'(', u'price', u'featured', u'at', u'in', u'usually', u'is', u'reduced', u'special', u'advertising'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: geography
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'and', u'climate', u'topography', u"'s", u'responses', u'people', u'of', u'study', u'surface', u'includes', u'to', u'soil', u'earth', u'the', u';', u'vegetation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: city
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'districts', u'several', u'urban', u'may', u'populated', u'large', u'area', u'independent', u'densely', u';', u'include', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: given
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'for', u'that', u'is', u'an', u'assumption', u'taken', u'granted'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: Madras
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'on', u';', u'Madras', u'formerly', u')', u'of', u'India', u'Bay', u'state', u'Andhra', u'(', u'in', u'the', u'Bengal', u'Pradesh', u'southeastern', u'south'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: Eastern
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'east', u'situated', u'in', u'the', u'toward', u'or', u'lying'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: archbishop
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'of', u'highest', u'bishop', u'rank'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: sum
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'of', u'money', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= [u'metropolitan']
16/03/25 13:56:17 INFO PythonRunner: Times: total = 8559, boot = 529, init = 381, finish = 7649
16/03/25 13:56:17 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/25 13:56:17 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8639 ms on localhost (1/2)
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'to', u'expression', u'give'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: geographical
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'science', u'or', u'to', u'of', u'relating', u'the', u'geography'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: boundary
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'limits', u'area', u'determining', u'an', u'of', u'line', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: Tamil
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'people', u'of', u'Sri', u'southern', u'member', u'India', u'mixed', u'Dravidian', u'the', u'Lanka', u'Caucasian'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: Nadu
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: function
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'mathematical', u'domain', u'set', u'associated', u'is', u'an', u'relation', u'another', u'given', u')', u'(', u'mathematics', u'function', u'that', u'such', u'with', u'a', u'of', u'element', u'range', u'each', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: product
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'commodities', u'offered', u'sale', u'for'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: terms
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'status', u'people', u'relations', u'to', u'groups', u'between', u'respect', u'the', u'with', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: equivalent
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'force', u'significance', u'to', u'measure', u'equal', u'value', u'effect', u'person', u'another', u'in', u'thing', u'or', u'etc'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: Bay
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'smaller', u'shoreline', u'gulf', u'of', u'larger', u'cove', u'but', u'an', u'indentation', u'than'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: western
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'about', u'United', u'development', u'of', u'life', u'period', u'States', u'exploration', u'western', u'in', u'during', u'the', u'film'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: particular
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'about', u')', u'(', u'some', u'general', u'to', u'as', u'part', u'opposed', u'fact'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: Bengal
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'whose', u'and', u'Bangladesh', u'eastern', u'region', u'India', u'part', u'western', u'in', u'included', u'now', u'is'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: Orthodox
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'pertaining', u'Judaism', u'characteristic', u'to', u'of', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: region
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'extended', u'of', u'something', u'spatial', u'the', u'location'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: title
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'statute', u'give', u'that', u'may', u'of', u'the', u'bill', u'brief', u'heading', u'deals', u'matters', u'names', u'it', u';', u'summary', u'with', u'or', u'legislative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: patriarch
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'a', u'and', u'older', u'is', u'who', u'rank', u'yourself', u'in', u'higher', u'than', u'man'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: Church
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'and', u'own', u'have', u'of', u'who', u'one', u'forms', u'their', u'groups', u'the', u'worship', u'beliefs', u'Christians'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: usually
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'normal', u'conditions', u'under'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): position
mapFunction_Parents(): keyword: position ; prevleveltokens: position
mapFunction_Parents(): keyword= position ; syndef_tokens= set([u'space', u'of', u'portion', u'something', u'particular', u'the', u'occupied', u'by'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/25 13:56:17 INFO PythonRunner: Times: total = 8898, boot = 527, init = 390, finish = 7981
16/03/25 13:56:17 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/25 13:56:17 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8962 ms on localhost (2/2)
16/03/25 13:56:17 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/25 13:56:17 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 8.964 s
16/03/25 13:56:17 INFO DAGScheduler: looking for newly runnable stages
16/03/25 13:56:17 INFO DAGScheduler: running: Set()
16/03/25 13:56:17 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/25 13:56:17 INFO DAGScheduler: failed: Set()
16/03/25 13:56:17 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/25 13:56:17 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which is now runnable
16/03/25 13:56:17 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11381, maxMem=560568729
16/03/25 13:56:17 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 534.6 MB)
16/03/25 13:56:18 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16365, maxMem=560568729
16/03/25 13:56:18 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 534.6 MB)
16/03/25 13:56:18 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:60562 (size: 3.0 KB, free: 534.6 MB)
16/03/25 13:56:18 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/25 13:56:18 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:56:18 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/25 13:56:18 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:56:18 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:56:18 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/25 13:56:18 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:56:18 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/25 13:56:18 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:56:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/25 13:56:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
reduceFunction_Parents(): returns= [u'metropolitan', 'None']
16/03/25 13:56:18 INFO PythonRunner: Times: total = 34, boot = -149, init = 183, finish = 0
16/03/25 13:56:18 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1280 bytes result sent to driver
16/03/25 13:56:18 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 125 ms on localhost (1/2)
16/03/25 13:56:18 INFO PythonRunner: Times: total = 280, boot = 279, init = 1, finish = 0
16/03/25 13:56:18 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/25 13:56:18 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.295 s
16/03/25 13:56:18 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 9.309744 s
16/03/25 13:56:18 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 317 ms on localhost (2/2)
16/03/25 13:56:18 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/25 13:56:18 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:56:18 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:56:18 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:56:18 INFO DAGScheduler: Parents of final stage: List()
16/03/25 13:56:18 INFO DAGScheduler: Missing parents: List()
16/03/25 13:56:18 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:56:18 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19420, maxMem=560568729
16/03/25 13:56:18 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 534.6 MB)
16/03/25 13:56:18 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25236, maxMem=560568729
16/03/25 13:56:18 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 534.6 MB)
16/03/25 13:56:18 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:60562 (size: 3.3 KB, free: 534.6 MB)
16/03/25 13:56:18 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/25 13:56:18 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:56:18 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/25 13:56:18 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/25 13:56:18 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2361 bytes)
16/03/25 13:56:18 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/25 13:56:18 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/25 13:56:18 INFO PythonRunner: Times: total = 51, boot = -115, init = 166, finish = 0
16/03/25 13:56:18 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/25 13:56:18 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 63 ms on localhost (1/2)
16/03/25 13:56:18 INFO PythonRunner: Times: total = 87, boot = 87, init = 0, finish = 0
16/03/25 13:56:18 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1345 bytes result sent to driver
16/03/25 13:56:18 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 112 ms on localhost (2/2)
16/03/25 13:56:18 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/25 13:56:18 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.107 s
16/03/25 13:56:18 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 0.140016 s
16/03/25 13:56:18 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/25 13:56:18 INFO DAGScheduler: Stopping DAGScheduler
16/03/25 13:56:18 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/25 13:56:18 INFO MemoryStore: MemoryStore cleared
16/03/25 13:56:18 INFO BlockManager: BlockManager stopped
16/03/25 13:56:18 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/25 13:56:18 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/25 13:56:18 INFO SparkContext: Successfully stopped SparkContext
16/03/25 13:56:18 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/25 13:56:18 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/25 13:56:18 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
graphcache_mapreduce_parents updated: defaultdict(<cyfunction <lambda> at 0xb1f81e6c>, {'c9e46d6d893b45343d5c7e9c6ec9851b': [u'metropolitan', u'None'], '2c49f1424d675552d9e7323a3eef6206': [u'None', u'expansion', u'None'], '45b800affe042d5d9a4228427680a935': [u'Chennai', u'None'], 'fdc633a5e1dea73592deb7e3bbbe3aea': [u'Chennai', u'None'], 'dd10336563a65a645a42bb416a6ebec6': [u'None', u'area', u'None'], '98acf8f6223b3758ff4a9dc22afb0e3b': [u'metropolitan', u'None'], 'a8f48eba5bb66d59263f478b93779a2c': [u'metropolitan', u'None'], '9f1808799460fd7b2da9ab51bd7b6775': [u'None', u'area', u'None'], '4503bafd06fb20136c689c645a03eefa': [u'metropolitan', u'None'], '4b7e9f2659636820e82592ed034512f9': [u'Chennai', u'Madras'], '44b9adf04881710b0a7c81b0a22b1209': [u'Chennai', u'None'], '1d1c5d8e5b55f6916d7d9218c4a0fe34': [u'None', u'area', u'None', u'Bengal'], 'e9301955882d67edfb275156ef73113c': [u'metropolitan', u'None'], '552934a698e1bcf880132a2bd5996d11': [u'None', u'area', u'None'], '063da2002ba149bb4025d1e1fcfb49f5': [u'None', u'area', u'None'], 'a31cc044ea8d13e6b1bf4e98768e44a5': [u'None', u'area', u'None'], 'b1318a4c6d13196fb45da6102d193223': [u'None', u'area', u'None', u'special'], 'ff4fcba188cd7bb550ed88e9ee5dc6f1': [u'Chennai', u'Madras', u'None'], '57466dae2c092869867908c5c54e241c': [u'metropolitan', u'None'], '3c28f836cfdab5d2af70e9fd66287ad9': [u'None', u'area', u'special', u'None'], 'ed43ebbafa0c6204a5916ca879d5bd26': [u'None', u'area'], 'e9da57cf07c9f8d232e2c9c1a07d1a0a': [u'None', u'area', u'culture', u'None'], '3a2fbf91abebcac17538118b2e02315d': [u'metropolitan', u'None', u'western'], 'c65d3beca4dc2d6f37377a842accc0cd': [u'None', u'expansion', u'None', u'function'], '3cd540871242471e0d89bea4eabc06ea': [u'None', u'expansion', u'None'], '40603e72c50afb5b6be8a7ff1684c966': [u'Chennai', u'None', u'Madras'], '4208c80be8e0c0d285fafd73cd5bd9a6': [u'metropolitan', u'None'], 'b7b50c706678d48359a2ac685d535b33': [u'metropolitan', u'None'], 'ed457e104ac489b5ec0bf242d39416e3': [u'metropolitan', u'None'], 'f2e69333b98cfc98f544ee3a5717b7c4': [u'Chennai', u'None'], '39c21ff4448a2910600584a0d49f93e8': [u'metropolitan', u'None'], '926a71600b58a41448b179d8665fd5df': [u'None', u'expansion', u'None'], 'e6ebeac0f1cb14fbd7b903291fcc6a8f': [u'metropolitan', u'None'], '25439f8325592e4ecd8b06f5f799b57a': [u'None', u'expansion', u'None'], 'd7b9ba5125de58e77ad31543f2c54034': [u'None', u'area', u'None']})
asfer_pickle_string_dump(): picklef.write(): distinguished
16/03/25 13:56:19 INFO SparkContext: Running Spark version 1.5.2
16/03/25 13:56:19 INFO SecurityManager: Changing view acls to: root
16/03/25 13:56:19 INFO SecurityManager: Changing modify acls to: root
16/03/25 13:56:19 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/25 13:56:19 INFO Slf4jLogger: Slf4jLogger started
16/03/25 13:56:19 INFO Remoting: Starting remoting
16/03/25 13:56:19 INFO Utils: Successfully started service 'sparkDriver' on port 41794.
16/03/25 13:56:19 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:41794]
16/03/25 13:56:19 INFO SparkEnv: Registering MapOutputTracker
16/03/25 13:56:19 INFO SparkEnv: Registering BlockManagerMaster
16/03/25 13:56:19 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-492f5de3-805b-4b6c-af84-ccdebb4794db
16/03/25 13:56:19 INFO MemoryStore: MemoryStore started with capacity 534.6 MB
16/03/25 13:56:19 INFO HttpFileServer: HTTP File server directory is /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/httpd-ae466142-234b-44bd-acf6-2396592dcf4c
16/03/25 13:56:19 INFO HttpServer: Starting HTTP Server
16/03/25 13:56:19 INFO Utils: Successfully started service 'HTTP file server' on port 51974.
16/03/25 13:56:19 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/25 13:56:19 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/25 13:56:19 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/25 13:56:19 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/userFiles-49c3adae-1e26-47be-955c-844976624c37/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:56:19 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458894379814
16/03/25 13:56:19 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/25 13:56:19 INFO Executor: Starting executor ID driver on host localhost
16/03/25 13:56:19 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38717.
16/03/25 13:56:19 INFO NettyBlockTransferService: Server created on 38717
16/03/25 13:56:19 INFO BlockManagerMaster: Trying to register BlockManager
16/03/25 13:56:19 INFO BlockManagerMasterEndpoint: Registering block manager localhost:38717 with 534.6 MB RAM, BlockManagerId(driver, localhost, 38717)
16/03/25 13:56:19 INFO BlockManagerMaster: Registered BlockManager
16/03/25 13:56:19 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:56:19 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:56:19 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:56:19 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:56:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/25 13:56:19 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/25 13:56:19 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:56:19 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=560568729
16/03/25 13:56:19 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 534.6 MB)
16/03/25 13:56:19 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=560568729
16/03/25 13:56:19 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 534.6 MB)
16/03/25 13:56:19 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:38717 (size: 4.1 KB, free: 534.6 MB)
16/03/25 13:56:19 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/25 13:56:19 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:56:19 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/25 13:56:19 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2602 bytes)
16/03/25 13:56:19 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2601 bytes)
16/03/25 13:56:20 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/25 13:56:20 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/25 13:56:20 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458894379814
16/03/25 13:56:20 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/userFiles-49c3adae-1e26-47be-955c-844976624c37/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:56:20 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/25 13:56:20 INFO MemoryStore: ensureFreeSpace(321) called with curMem=10732, maxMem=560568729
16/03/25 13:56:20 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 321.0 B, free 534.6 MB)
16/03/25 13:56:20 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/25 13:56:20 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:38717 (size: 321.0 B, free: 534.6 MB)
16/03/25 13:56:20 INFO MemoryStore: ensureFreeSpace(323) called with curMem=11053, maxMem=560568729
16/03/25 13:56:20 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 323.0 B, free 534.6 MB)
16/03/25 13:56:20 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:38717 (size: 323.0 B, free: 534.6 MB)
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: Chennai
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: geographical
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: area
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  distinguished  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: expansion
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u'function', u'product', u'terms', u'of', u'sum', u'expressed', u'as', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: serving
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u'food', u'of', u'drink', u'meal', u'an', u'as', u'individual', u'taken', u'part', u'or', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: formerly
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u';', u'time', u'at', u'previous'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: people
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'group', u')', u'(', u'men', u'children', u'or', u'collectively', u'beings', u'human', u'of', u'plural', u'any', u'women'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: Christianity
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u'and', u'monotheistic', u'based', u'embodied', u'on', u'New', u'of', u'in', u'system', u'Jesus', u'as', u'practices', u'role', u'emphasizing', u'teachings', u'Testament', u'Old', u'the', u'beliefs', u'savior'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: culture
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u'and', u'particular', u'society', u'place', u'at', u'time'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: indefinite
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'or', u'stated', u'defined', u'clearly', u'not', u'vague'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: bishop
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'and', u'the', u'spiritual', u'Christ', u'twelve', u'some', u'authority', u'in', u'Christian', u'ministers', u'member', u'to', u'churches', u';', u'administrative', u'be', u'Apostles', u'appointed', u'a', u'oversee', u'of', u'priests', u'or', u'considered', u'clergy', u'senior', u'successors', u'having'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: special
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u'and', u'temporary', u'offering', u'that', u')', u'(', u'price', u'featured', u'at', u'in', u'usually', u'is', u'reduced', u'special', u'advertising'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: geography
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'and', u'climate', u'topography', u"'s", u'responses', u'people', u'of', u'study', u'surface', u'includes', u'to', u'soil', u'earth', u'the', u';', u'vegetation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: city
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u'and', u'districts', u'several', u'urban', u'may', u'populated', u'large', u'area', u'independent', u'densely', u';', u'include', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: given
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'for', u'that', u'is', u'an', u'assumption', u'taken', u'granted'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: Madras
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u'on', u';', u'Madras', u'formerly', u')', u'of', u'India', u'Bay', u'state', u'Andhra', u'(', u'in', u'the', u'Bengal', u'Pradesh', u'southeastern', u'south'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: Eastern
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'east', u'situated', u'in', u'the', u'toward', u'or', u'lying'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: archbishop
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u'of', u'highest', u'bishop', u'rank'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: sum
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'science', u'or', u'to', u'of', u'relating', u'the', u'geography'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: boundary
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u'of', u'money', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: expressed
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u'limits', u'area', u'determining', u'an', u'of', u'line', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: Tamil
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u'and', u'people', u'of', u'Sri', u'southern', u'member', u'India', u'mixed', u'Dravidian', u'the', u'Lanka', u'Caucasian'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: Nadu
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: function
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'to', u'expression', u'give'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'mathematical', u'domain', u'set', u'associated', u'is', u'an', u'relation', u'another', u'given', u')', u'(', u'mathematics', u'function', u'that', u'such', u'with', u'a', u'of', u'element', u'range', u'each', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: product
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'commodities', u'offered', u'sale', u'for'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: terms
16/03/25 13:56:29 INFO PythonRunner: Times: total = 8939, boot = 459, init = 375, finish = 8105
16/03/25 13:56:29 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'status', u'people', u'relations', u'to', u'groups', u'between', u'respect', u'the', u'with', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: equivalent
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u'force', u'significance', u'to', u'measure', u'equal', u'value', u'effect', u'person', u'another', u'in', u'thing', u'or', u'etc'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: Bay
16/03/25 13:56:29 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9223 ms on localhost (1/2)
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u'smaller', u'shoreline', u'gulf', u'of', u'larger', u'cove', u'but', u'an', u'indentation', u'than'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: western
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u'and', u'about', u'United', u'development', u'of', u'life', u'period', u'States', u'exploration', u'western', u'in', u'during', u'the', u'film'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: particular
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u'about', u')', u'(', u'some', u'general', u'to', u'as', u'part', u'opposed', u'fact'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: Bengal
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u'whose', u'and', u'Bangladesh', u'eastern', u'region', u'India', u'part', u'western', u'in', u'included', u'now', u'is'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: Orthodox
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'pertaining', u'Judaism', u'characteristic', u'to', u'of', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: region
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'extended', u'of', u'something', u'spatial', u'the', u'location'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: title
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u'statute', u'give', u'that', u'may', u'of', u'the', u'bill', u'brief', u'heading', u'deals', u'matters', u'names', u'it', u';', u'summary', u'with', u'or', u'legislative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: patriarch
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'a', u'and', u'older', u'is', u'who', u'rank', u'yourself', u'in', u'higher', u'than', u'man'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: Church
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'and', u'own', u'have', u'of', u'who', u'one', u'forms', u'their', u'groups', u'the', u'worship', u'beliefs', u'Christians'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: usually
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'normal', u'conditions', u'under'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: position
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'space', u'of', u'portion', u'something', u'particular', u'the', u'occupied', u'by'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): distinguished
mapFunction_Parents(): keyword: distinguished ; prevleveltokens: distinguished
mapFunction_Parents(): keyword= distinguished ; syndef_tokens= set([u'as', u'different', u'mark'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/25 13:56:29 INFO PythonRunner: Times: total = 9151, boot = 480, init = 452, finish = 8219
16/03/25 13:56:29 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/25 13:56:29 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 9.433 s
16/03/25 13:56:29 INFO DAGScheduler: looking for newly runnable stages
16/03/25 13:56:29 INFO DAGScheduler: running: Set()
16/03/25 13:56:29 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/25 13:56:29 INFO DAGScheduler: failed: Set()
16/03/25 13:56:29 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/25 13:56:29 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which is now runnable
16/03/25 13:56:29 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11376, maxMem=560568729
16/03/25 13:56:29 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 534.6 MB)
16/03/25 13:56:29 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 9431 ms on localhost (2/2)
16/03/25 13:56:29 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/25 13:56:29 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16360, maxMem=560568729
16/03/25 13:56:29 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 534.6 MB)
16/03/25 13:56:29 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:38717 (size: 3.0 KB, free: 534.6 MB)
16/03/25 13:56:29 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/25 13:56:29 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:56:29 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/25 13:56:29 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:56:29 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:56:29 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/25 13:56:29 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/25 13:56:29 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:56:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/03/25 13:56:29 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:56:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
16/03/25 13:56:29 INFO PythonRunner: Times: total = 143, boot = 142, init = 0, finish = 1
16/03/25 13:56:29 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/25 13:56:29 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 160 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'area', 'None']
16/03/25 13:56:29 INFO PythonRunner: Times: total = 211, boot = 209, init = 1, finish = 1
16/03/25 13:56:29 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1280 bytes result sent to driver
16/03/25 13:56:29 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.232 s
16/03/25 13:56:29 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 9.702773 s
16/03/25 13:56:29 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 231 ms on localhost (2/2)
16/03/25 13:56:29 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/25 13:56:29 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:56:29 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:56:29 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:56:29 INFO DAGScheduler: Parents of final stage: List()
16/03/25 13:56:29 INFO DAGScheduler: Missing parents: List()
16/03/25 13:56:29 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:56:29 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19415, maxMem=560568729
16/03/25 13:56:29 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 534.6 MB)
16/03/25 13:56:29 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25231, maxMem=560568729
16/03/25 13:56:29 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 534.6 MB)
16/03/25 13:56:29 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:38717 (size: 3.3 KB, free: 534.6 MB)
16/03/25 13:56:29 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/25 13:56:29 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:56:29 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/25 13:56:29 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/25 13:56:29 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2361 bytes)
16/03/25 13:56:29 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/25 13:56:29 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/25 13:56:29 INFO PythonRunner: Times: total = 138, boot = 138, init = 0, finish = 0
16/03/25 13:56:29 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/25 13:56:29 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 145 ms on localhost (1/2)
16/03/25 13:56:30 INFO PythonRunner: Times: total = 194, boot = 193, init = 1, finish = 0
16/03/25 13:56:30 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1348 bytes result sent to driver
16/03/25 13:56:30 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 207 ms on localhost (2/2)
16/03/25 13:56:30 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/25 13:56:30 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.208 s
16/03/25 13:56:30 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 0.227577 s
16/03/25 13:56:30 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/25 13:56:30 INFO DAGScheduler: Stopping DAGScheduler
16/03/25 13:56:30 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/25 13:56:30 INFO MemoryStore: MemoryStore cleared
16/03/25 13:56:30 INFO BlockManager: BlockManager stopped
16/03/25 13:56:30 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/25 13:56:30 INFO SparkContext: Successfully stopped SparkContext
16/03/25 13:56:30 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/25 13:56:30 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/25 13:56:30 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/25 13:56:30 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
graphcache_mapreduce_parents updated: defaultdict(<cyfunction <lambda> at 0xb1f81e6c>, {'c9e46d6d893b45343d5c7e9c6ec9851b': [u'metropolitan', u'None'], '2c49f1424d675552d9e7323a3eef6206': [u'None', u'expansion', u'None'], '45b800affe042d5d9a4228427680a935': [u'Chennai', u'None'], 'fdc633a5e1dea73592deb7e3bbbe3aea': [u'Chennai', u'None'], 'dd10336563a65a645a42bb416a6ebec6': [u'None', u'area', u'None'], '98acf8f6223b3758ff4a9dc22afb0e3b': [u'metropolitan', u'None'], 'a8f48eba5bb66d59263f478b93779a2c': [u'metropolitan', u'None'], '9f1808799460fd7b2da9ab51bd7b6775': [u'None', u'area', u'None'], '4503bafd06fb20136c689c645a03eefa': [u'metropolitan', u'None'], '4b7e9f2659636820e82592ed034512f9': [u'Chennai', u'Madras'], '44b9adf04881710b0a7c81b0a22b1209': [u'Chennai', u'None'], '1d1c5d8e5b55f6916d7d9218c4a0fe34': [u'None', u'area', u'None', u'Bengal'], 'e9301955882d67edfb275156ef73113c': [u'metropolitan', u'None'], '552934a698e1bcf880132a2bd5996d11': [u'None', u'area', u'None'], '063da2002ba149bb4025d1e1fcfb49f5': [u'None', u'area', u'None'], 'a31cc044ea8d13e6b1bf4e98768e44a5': [u'None', u'area', u'None'], 'b1318a4c6d13196fb45da6102d193223': [u'None', u'area', u'None', u'special'], 'ff4fcba188cd7bb550ed88e9ee5dc6f1': [u'Chennai', u'Madras', u'None'], '57466dae2c092869867908c5c54e241c': [u'metropolitan', u'None'], '3c28f836cfdab5d2af70e9fd66287ad9': [u'None', u'area', u'special', u'None'], 'ed43ebbafa0c6204a5916ca879d5bd26': [u'None', u'area'], 'e9da57cf07c9f8d232e2c9c1a07d1a0a': [u'None', u'area', u'culture', u'None'], '3a2fbf91abebcac17538118b2e02315d': [u'metropolitan', u'None', u'western'], 'c65d3beca4dc2d6f37377a842accc0cd': [u'None', u'expansion', u'None', u'function'], '3cd540871242471e0d89bea4eabc06ea': [u'None', u'expansion', u'None'], '40603e72c50afb5b6be8a7ff1684c966': [u'Chennai', u'None', u'Madras'], '4208c80be8e0c0d285fafd73cd5bd9a6': [u'metropolitan', u'None'], 'b7b50c706678d48359a2ac685d535b33': [u'metropolitan', u'None'], 'ed457e104ac489b5ec0bf242d39416e3': [u'metropolitan', u'None'], 'c251e6e2e2631354c71580629bbab1b4': [u'None', u'area', u'None'], 'f2e69333b98cfc98f544ee3a5717b7c4': [u'Chennai', u'None'], '39c21ff4448a2910600584a0d49f93e8': [u'metropolitan', u'None'], '926a71600b58a41448b179d8665fd5df': [u'None', u'expansion', u'None'], 'e6ebeac0f1cb14fbd7b903291fcc6a8f': [u'metropolitan', u'None'], '25439f8325592e4ecd8b06f5f799b57a': [u'None', u'expansion', u'None'], 'd7b9ba5125de58e77ad31543f2c54034': [u'None', u'area', u'None']})
asfer_pickle_string_dump(): picklef.write(): purpose
16/03/25 13:56:31 INFO SparkContext: Running Spark version 1.5.2
16/03/25 13:56:31 INFO SecurityManager: Changing view acls to: root
16/03/25 13:56:31 INFO SecurityManager: Changing modify acls to: root
16/03/25 13:56:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/25 13:56:31 INFO Slf4jLogger: Slf4jLogger started
16/03/25 13:56:31 INFO Remoting: Starting remoting
16/03/25 13:56:31 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:46472]
16/03/25 13:56:31 INFO Utils: Successfully started service 'sparkDriver' on port 46472.
16/03/25 13:56:31 INFO SparkEnv: Registering MapOutputTracker
16/03/25 13:56:31 INFO SparkEnv: Registering BlockManagerMaster
16/03/25 13:56:31 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-59d49408-420f-4907-aab5-cf9f232101ec
16/03/25 13:56:31 INFO MemoryStore: MemoryStore started with capacity 537.7 MB
16/03/25 13:56:31 INFO HttpFileServer: HTTP File server directory is /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/httpd-1185480c-f9ab-4674-a534-392980109f06
16/03/25 13:56:31 INFO HttpServer: Starting HTTP Server
16/03/25 13:56:31 INFO Utils: Successfully started service 'HTTP file server' on port 34970.
16/03/25 13:56:31 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/25 13:56:31 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/25 13:56:31 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/25 13:56:31 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/userFiles-8b8e8b0f-553f-463a-abbd-987bbcb59575/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:56:31 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458894391250
16/03/25 13:56:31 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/25 13:56:31 INFO Executor: Starting executor ID driver on host localhost
16/03/25 13:56:31 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59171.
16/03/25 13:56:31 INFO NettyBlockTransferService: Server created on 59171
16/03/25 13:56:31 INFO BlockManagerMaster: Trying to register BlockManager
16/03/25 13:56:31 INFO BlockManagerMasterEndpoint: Registering block manager localhost:59171 with 537.7 MB RAM, BlockManagerId(driver, localhost, 59171)
16/03/25 13:56:31 INFO BlockManagerMaster: Registered BlockManager
16/03/25 13:56:31 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:56:31 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:56:31 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:56:31 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:56:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/25 13:56:31 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/25 13:56:31 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:56:31 INFO MemoryStore: ensureFreeSpace(6576) called with curMem=0, maxMem=563824558
16/03/25 13:56:31 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 537.7 MB)
16/03/25 13:56:31 INFO MemoryStore: ensureFreeSpace(4156) called with curMem=6576, maxMem=563824558
16/03/25 13:56:31 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 537.7 MB)
16/03/25 13:56:31 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:59171 (size: 4.1 KB, free: 537.7 MB)
16/03/25 13:56:31 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/25 13:56:31 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:56:31 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/25 13:56:31 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2602 bytes)
16/03/25 13:56:31 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2632 bytes)
16/03/25 13:56:31 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/25 13:56:31 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458894391250
16/03/25 13:56:31 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/25 13:56:31 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/userFiles-8b8e8b0f-553f-463a-abbd-987bbcb59575/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:56:31 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/25 13:56:31 INFO MemoryStore: ensureFreeSpace(348) called with curMem=10732, maxMem=563824558
16/03/25 13:56:31 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 348.0 B, free 537.7 MB)
16/03/25 13:56:31 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:59171 (size: 348.0 B, free: 537.7 MB)
16/03/25 13:56:31 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/25 13:56:31 INFO MemoryStore: ensureFreeSpace(321) called with curMem=11080, maxMem=563824558
16/03/25 13:56:31 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 321.0 B, free 537.7 MB)
16/03/25 13:56:31 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:59171 (size: 321.0 B, free: 537.7 MB)
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: Chennai
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: geographical
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'city', u'Madras', u'formerly', u'on', u'of', u'Bay', u'in', u'the', u'Bengal', u'Tamil', u';', u'Nadu'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: metropolitan
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'and', u'given', u'position', u'in', u'Eastern', u'this', u'archbishop', u'is', u'Orthodox', u'patriarch', u'bishop', u';', u'to', u'equivalent', u'western', u'Church', u'title', u'the', u'Christianity', u'between'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: area
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): adding to parents: syn =  Synset('area.n.01') ; keyword:  purpose  in syndef_tokens= set([u'a', u'by', u'serving', u'people', u'geography', u'of', u'region', u'some', u')', u'distinguished', u'culture', u'(', u'geographical', u'particular', u'usually', u'boundary', u'indefinite', u'its', u'or', u'special', u'purpose'])
mapFunction_Parents(): returns= [u'area']
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: expansion
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'function', u'product', u'terms', u'of', u'sum', u'expressed', u'as', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: serving
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'food', u'of', u'drink', u'meal', u'an', u'as', u'individual', u'taken', u'part', u'or', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: formerly
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u';', u'time', u'at', u'previous'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: people
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'group', u')', u'(', u'men', u'children', u'or', u'collectively', u'beings', u'human', u'of', u'plural', u'any', u'women'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: Christianity
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'and', u'monotheistic', u'based', u'embodied', u'on', u'New', u'of', u'in', u'system', u'Jesus', u'as', u'practices', u'role', u'emphasizing', u'teachings', u'Testament', u'Old', u'the', u'beliefs', u'savior'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: culture
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'and', u'particular', u'society', u'place', u'at', u'time'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: indefinite
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'or', u'stated', u'defined', u'clearly', u'not', u'vague'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: bishop
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'and', u'the', u'spiritual', u'Christ', u'twelve', u'some', u'authority', u'in', u'Christian', u'ministers', u'member', u'to', u'churches', u';', u'administrative', u'be', u'Apostles', u'appointed', u'a', u'oversee', u'of', u'priests', u'or', u'considered', u'clergy', u'senior', u'successors', u'having'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: special
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'and', u'temporary', u'offering', u'that', u')', u'(', u'price', u'featured', u'at', u'in', u'usually', u'is', u'reduced', u'special', u'advertising'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: geography
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'and', u'climate', u'topography', u"'s", u'responses', u'people', u'of', u'study', u'surface', u'includes', u'to', u'soil', u'earth', u'the', u';', u'vegetation'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: city
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'and', u'districts', u'several', u'urban', u'may', u'populated', u'large', u'area', u'independent', u'densely', u';', u'include', u'administrative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: given
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'for', u'that', u'is', u'an', u'assumption', u'taken', u'granted'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: Madras
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'on', u';', u'Madras', u'formerly', u')', u'of', u'India', u'Bay', u'state', u'Andhra', u'(', u'in', u'the', u'Bengal', u'Pradesh', u'southeastern', u'south'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: Eastern
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'science', u'or', u'to', u'of', u'relating', u'the', u'geography'])
mapFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: boundary
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'east', u'situated', u'in', u'the', u'toward', u'or', u'lying'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: archbishop
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'of', u'highest', u'bishop', u'rank'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: sum
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'limits', u'area', u'determining', u'an', u'of', u'line', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= []
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: Tamil
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'and', u'people', u'of', u'Sri', u'southern', u'member', u'India', u'mixed', u'Dravidian', u'the', u'Lanka', u'Caucasian'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: Nadu
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: function
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'of', u'money', u'quantity'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: expressed
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'mathematical', u'domain', u'set', u'associated', u'is', u'an', u'relation', u'another', u'given', u')', u'(', u'mathematics', u'function', u'that', u'such', u'with', u'a', u'of', u'element', u'range', u'each', u'the'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: product
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'to', u'expression', u'give'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None', u'area']
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'commodities', u'offered', u'sale', u'for'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: terms
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'status', u'people', u'relations', u'to', u'groups', u'between', u'respect', u'the', u'with', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: equivalent
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'force', u'significance', u'to', u'measure', u'equal', u'value', u'effect', u'person', u'another', u'in', u'thing', u'or', u'etc'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: Bay
16/03/25 13:56:40 INFO PythonRunner: Times: total = 8801, boot = 464, init = 403, finish = 7934
16/03/25 13:56:40 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'smaller', u'shoreline', u'gulf', u'of', u'larger', u'cove', u'but', u'an', u'indentation', u'than'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: western
16/03/25 13:56:40 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8942 ms on localhost (1/2)
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'and', u'about', u'United', u'development', u'of', u'life', u'period', u'States', u'exploration', u'western', u'in', u'during', u'the', u'film'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: particular
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'about', u')', u'(', u'some', u'general', u'to', u'as', u'part', u'opposed', u'fact'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: Bengal
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'whose', u'and', u'Bangladesh', u'eastern', u'region', u'India', u'part', u'western', u'in', u'included', u'now', u'is'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: Orthodox
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'pertaining', u'Judaism', u'characteristic', u'to', u'of', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: region
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'extended', u'of', u'something', u'spatial', u'the', u'location'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: title
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'statute', u'give', u'that', u'may', u'of', u'the', u'bill', u'brief', u'heading', u'deals', u'matters', u'names', u'it', u';', u'summary', u'with', u'or', u'legislative'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: patriarch
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'a', u'and', u'older', u'is', u'who', u'rank', u'yourself', u'in', u'higher', u'than', u'man'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: Church
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'and', u'own', u'have', u'of', u'who', u'one', u'forms', u'their', u'groups', u'the', u'worship', u'beliefs', u'Christians'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: usually
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'normal', u'conditions', u'under'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: position
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'space', u'of', u'portion', u'something', u'particular', u'the', u'occupied', u'by'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: distinguished
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'as', u'different', u'mark'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
asfer_pickle_string_load(): picklef.readlines(): purpose
mapFunction_Parents(): keyword: purpose ; prevleveltokens: purpose
mapFunction_Parents(): keyword= purpose ; syndef_tokens= set([u'your', u'an', u'intended', u'that', u'is', u'actions', u'anticipated', u'planned', u'outcome', u'guides', u'or'])
mapFunction_Parents(): returns= []
reduceFunction_Parents(): returns= ['None']
16/03/25 13:56:40 INFO PythonRunner: Times: total = 9014, boot = 468, init = 469, finish = 8077
16/03/25 13:56:40 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/25 13:56:40 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 9139 ms on localhost (2/2)
16/03/25 13:56:40 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/25 13:56:40 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 9.126 s
16/03/25 13:56:40 INFO DAGScheduler: looking for newly runnable stages
16/03/25 13:56:40 INFO DAGScheduler: running: Set()
16/03/25 13:56:40 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/25 13:56:40 INFO DAGScheduler: failed: Set()
16/03/25 13:56:40 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/25 13:56:40 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which is now runnable
16/03/25 13:56:40 INFO MemoryStore: ensureFreeSpace(4984) called with curMem=11401, maxMem=563824558
16/03/25 13:56:40 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 537.7 MB)
16/03/25 13:56:40 INFO MemoryStore: ensureFreeSpace(3055) called with curMem=16385, maxMem=563824558
16/03/25 13:56:40 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 537.7 MB)
16/03/25 13:56:40 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:59171 (size: 3.0 KB, free: 537.7 MB)
16/03/25 13:56:40 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/25 13:56:40 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:56:40 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/25 13:56:40 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:56:40 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:56:40 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/25 13:56:40 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/25 13:56:40 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:56:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
16/03/25 13:56:40 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:56:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
16/03/25 13:56:40 INFO PythonRunner: Times: total = 42, boot = 10, init = 32, finish = 0
16/03/25 13:56:40 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/25 13:56:40 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 62 ms on localhost (1/2)
reduceFunction_Parents(): returns= ['None', u'area', 'None']
16/03/25 13:56:40 INFO PythonRunner: Times: total = 195, boot = 194, init = 0, finish = 1
16/03/25 13:56:40 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1280 bytes result sent to driver
16/03/25 13:56:40 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.221 s
16/03/25 13:56:40 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 9.415513 s
16/03/25 13:56:40 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 218 ms on localhost (2/2)
16/03/25 13:56:40 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/25 13:56:40 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213
16/03/25 13:56:40 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) with 2 output partitions
16/03/25 13:56:40 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:56:40 INFO DAGScheduler: Parents of final stage: List()
16/03/25 13:56:40 INFO DAGScheduler: Missing parents: List()
16/03/25 13:56:40 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213), which has no missing parents
16/03/25 13:56:40 INFO MemoryStore: ensureFreeSpace(5816) called with curMem=19440, maxMem=563824558
16/03/25 13:56:40 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 537.7 MB)
16/03/25 13:56:40 INFO MemoryStore: ensureFreeSpace(3376) called with curMem=25256, maxMem=563824558
16/03/25 13:56:40 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 537.7 MB)
16/03/25 13:56:41 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:59171 (size: 3.3 KB, free: 537.7 MB)
16/03/25 13:56:41 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/25 13:56:41 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213)
16/03/25 13:56:41 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/25 13:56:41 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/25 13:56:41 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2361 bytes)
16/03/25 13:56:41 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/25 13:56:41 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/25 13:56:41 INFO PythonRunner: Times: total = 69, boot = 22, init = 47, finish = 0
16/03/25 13:56:41 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/25 13:56:41 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 83 ms on localhost (1/2)
16/03/25 13:56:41 INFO PythonRunner: Times: total = 220, boot = 220, init = 0, finish = 0
16/03/25 13:56:41 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1348 bytes result sent to driver
16/03/25 13:56:41 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 237 ms on localhost (2/2)
16/03/25 13:56:41 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/25 13:56:41 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213) finished in 0.236 s
16/03/25 13:56:41 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:213, took 0.271998 s
16/03/25 13:56:41 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/25 13:56:41 INFO DAGScheduler: Stopping DAGScheduler
16/03/25 13:56:41 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/25 13:56:41 INFO MemoryStore: MemoryStore cleared
16/03/25 13:56:41 INFO BlockManager: BlockManager stopped
16/03/25 13:56:41 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/25 13:56:41 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/25 13:56:41 INFO SparkContext: Successfully stopped SparkContext
16/03/25 13:56:41 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/25 13:56:41 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/25 13:56:41 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
graphcache_mapreduce_parents updated: defaultdict(<cyfunction <lambda> at 0xb1f81e6c>, {'c9e46d6d893b45343d5c7e9c6ec9851b': [u'metropolitan', u'None'], '2c49f1424d675552d9e7323a3eef6206': [u'None', u'expansion', u'None'], '45b800affe042d5d9a4228427680a935': [u'Chennai', u'None'], 'fdc633a5e1dea73592deb7e3bbbe3aea': [u'Chennai', u'None'], 'dd10336563a65a645a42bb416a6ebec6': [u'None', u'area', u'None'], '98acf8f6223b3758ff4a9dc22afb0e3b': [u'metropolitan', u'None'], 'a8f48eba5bb66d59263f478b93779a2c': [u'metropolitan', u'None'], '9f1808799460fd7b2da9ab51bd7b6775': [u'None', u'area', u'None'], '4503bafd06fb20136c689c645a03eefa': [u'metropolitan', u'None'], '4b7e9f2659636820e82592ed034512f9': [u'Chennai', u'Madras'], '44b9adf04881710b0a7c81b0a22b1209': [u'Chennai', u'None'], '1d1c5d8e5b55f6916d7d9218c4a0fe34': [u'None', u'area', u'None', u'Bengal'], 'e9301955882d67edfb275156ef73113c': [u'metropolitan', u'None'], '552934a698e1bcf880132a2bd5996d11': [u'None', u'area', u'None'], '063da2002ba149bb4025d1e1fcfb49f5': [u'None', u'area', u'None'], 'a31cc044ea8d13e6b1bf4e98768e44a5': [u'None', u'area', u'None'], 'b1318a4c6d13196fb45da6102d193223': [u'None', u'area', u'None', u'special'], 'ff4fcba188cd7bb550ed88e9ee5dc6f1': [u'Chennai', u'Madras', u'None'], '57466dae2c092869867908c5c54e241c': [u'metropolitan', u'None'], '3c28f836cfdab5d2af70e9fd66287ad9': [u'None', u'area', u'special', u'None'], 'ed43ebbafa0c6204a5916ca879d5bd26': [u'None', u'area'], 'e9da57cf07c9f8d232e2c9c1a07d1a0a': [u'None', u'area', u'culture', u'None'], '3a2fbf91abebcac17538118b2e02315d': [u'metropolitan', u'None', u'western'], 'c65d3beca4dc2d6f37377a842accc0cd': [u'None', u'expansion', u'None', u'function'], '3cd540871242471e0d89bea4eabc06ea': [u'None', u'expansion', u'None'], '40603e72c50afb5b6be8a7ff1684c966': [u'Chennai', u'None', u'Madras'], '4208c80be8e0c0d285fafd73cd5bd9a6': [u'metropolitan', u'None'], 'b7b50c706678d48359a2ac685d535b33': [u'metropolitan', u'None'], 'ed457e104ac489b5ec0bf242d39416e3': [u'metropolitan', u'None'], '625feaadbb337eeb25fb2203afc35e5a': [u'None', u'area', u'None'], 'c251e6e2e2631354c71580629bbab1b4': [u'None', u'area', u'None'], 'f2e69333b98cfc98f544ee3a5717b7c4': [u'Chennai', u'None'], '39c21ff4448a2910600584a0d49f93e8': [u'metropolitan', u'None'], '926a71600b58a41448b179d8665fd5df': [u'None', u'expansion', u'None'], 'e6ebeac0f1cb14fbd7b903291fcc6a8f': [u'metropolitan', u'None'], '25439f8325592e4ecd8b06f5f799b57a': [u'None', u'expansion', u'None'], 'd7b9ba5125de58e77ad31543f2c54034': [u'None', u'area', u'None']})
InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:freqterms1= [u'serving', u'formerly', u'people', u'Christianity', u'culture', u'indefinite', u'bishop', u'special', u'geography', u'city', u'given', u'Madras', u'Eastern', u'archbishop', u'sum', u'expressed', u'geographical', u'boundary', u'Tamil', u'Nadu', u'function', u'product', u'terms', u'equivalent', u'Bay', u'western', u'particular', u'Bengal', u'Orthodox', u'region', u'title', u'patriarch', u'Church', u'usually', u'position', u'distinguished', u'purpose']
16/03/25 13:56:42 INFO SparkContext: Running Spark version 1.5.2
16/03/25 13:56:42 INFO SecurityManager: Changing view acls to: root
16/03/25 13:56:42 INFO SecurityManager: Changing modify acls to: root
16/03/25 13:56:42 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/03/25 13:56:42 INFO Slf4jLogger: Slf4jLogger started
16/03/25 13:56:42 INFO Remoting: Starting remoting
16/03/25 13:56:42 INFO Utils: Successfully started service 'sparkDriver' on port 37038.
16/03/25 13:56:42 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@localhost:37038]
16/03/25 13:56:42 INFO SparkEnv: Registering MapOutputTracker
16/03/25 13:56:42 INFO SparkEnv: Registering BlockManagerMaster
16/03/25 13:56:42 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-6ac79f4a-2d76-4626-9a57-3e291001115b
16/03/25 13:56:42 INFO MemoryStore: MemoryStore started with capacity 537.7 MB
16/03/25 13:56:42 INFO HttpFileServer: HTTP File server directory is /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/httpd-32d47cfb-6855-4cd0-918d-0b529496cfdf
16/03/25 13:56:42 INFO HttpServer: Starting HTTP Server
16/03/25 13:56:42 INFO Utils: Successfully started service 'HTTP file server' on port 35777.
16/03/25 13:56:42 INFO SparkEnv: Registering OutputCommitCoordinator
16/03/25 13:56:42 INFO Utils: Successfully started service 'SparkUI' on port 4040.
16/03/25 13:56:42 INFO SparkUI: Started SparkUI at http://localhost:4040
16/03/25 13:56:42 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py to /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/userFiles-cd7a2523-7b32-4501-a593-09e1fdcfff34/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:56:42 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458894402520
16/03/25 13:56:42 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
16/03/25 13:56:42 INFO Executor: Starting executor ID driver on host localhost
16/03/25 13:56:42 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35916.
16/03/25 13:56:42 INFO NettyBlockTransferService: Server created on 35916
16/03/25 13:56:42 INFO BlockManagerMaster: Trying to register BlockManager
16/03/25 13:56:42 INFO BlockManagerMasterEndpoint: Registering block manager localhost:35916 with 537.7 MB RAM, BlockManagerId(driver, localhost, 35916)
16/03/25 13:56:42 INFO BlockManagerMaster: Registered BlockManager
Spark_MapReduce(): wordsatthislevel: [u'serving', u'formerly', u'people', u'Christianity', u'culture', u'indefinite', u'bishop', u'special', u'geography', u'city', u'given', u'Madras', u'Eastern', u'archbishop', u'sum', u'expressed', u'geographical', u'boundary', u'Tamil', u'Nadu', u'function', u'product', u'terms', u'equivalent', u'Bay', u'western', u'particular', u'Bengal', u'Orthodox', u'region', u'title', u'patriarch', u'Church', u'usually', u'position', u'distinguished', u'purpose']
16/03/25 13:56:42 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:236
16/03/25 13:56:42 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:236)
16/03/25 13:56:42 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:236) with 2 output partitions
16/03/25 13:56:42 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:236)
16/03/25 13:56:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/03/25 13:56:42 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/03/25 13:56:42 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:236), which has no missing parents
16/03/25 13:56:42 INFO MemoryStore: ensureFreeSpace(6560) called with curMem=0, maxMem=563824558
16/03/25 13:56:42 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 537.7 MB)
16/03/25 13:56:42 INFO MemoryStore: ensureFreeSpace(4147) called with curMem=6560, maxMem=563824558
16/03/25 13:56:42 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 537.7 MB)
16/03/25 13:56:42 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:35916 (size: 4.0 KB, free: 537.7 MB)
16/03/25 13:56:42 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
16/03/25 13:56:42 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:236)
16/03/25 13:56:42 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/03/25 13:56:42 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2576 bytes)
16/03/25 13:56:42 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2598 bytes)
16/03/25 13:56:42 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/03/25 13:56:42 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py with timestamp 1458894402520
16/03/25 13:56:42 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/03/25 13:56:42 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py has been previously copied to /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/userFiles-cd7a2523-7b32-4501-a593-09e1fdcfff34/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py
16/03/25 13:56:42 INFO CacheManager: Partition rdd_0_0 not found, computing it
16/03/25 13:56:42 INFO CacheManager: Partition rdd_0_1 not found, computing it
16/03/25 13:56:42 INFO MemoryStore: ensureFreeSpace(318) called with curMem=10707, maxMem=563824558
16/03/25 13:56:42 INFO MemoryStore: Block rdd_0_1 stored as bytes in memory (estimated size 318.0 B, free 537.7 MB)
16/03/25 13:56:42 INFO BlockManagerInfo: Added rdd_0_1 in memory on localhost:35916 (size: 318.0 B, free: 537.7 MB)
16/03/25 13:56:42 INFO MemoryStore: ensureFreeSpace(301) called with curMem=11025, maxMem=563824558
16/03/25 13:56:42 INFO MemoryStore: Block rdd_0_0 stored as bytes in memory (estimated size 301.0 B, free 537.7 MB)
16/03/25 13:56:42 INFO BlockManagerInfo: Added rdd_0_0 in memory on localhost:35916 (size: 301.0 B, free: 537.7 MB)
mapFunction(): freqterms1:mapFunction(): freqterms1: Tamil
 serving
mapFunction(): freqterms1: formerly
mapFunction(): freqterms1: people
mapFunction(): freqterms1: Christianity
mapFunction(): freqterms1: culture
mapFunction(): freqterms1: indefinite
mapFunction(): freqterms1: bishop
mapFunction(): freqterms1: special
mapFunction(): freqterms1: geography
mapFunction(): freqterms1: city
mapFunction(): freqterms1: given
mapFunction(): freqterms1: Madras
mapFunction(): freqterms1: Eastern
mapFunction(): freqterms1: archbishop
mapFunction(): freqterms1: sum
mapFunction(): freqterms1: expressed
mapFunction(): freqterms1: geographical
mapFunction(): freqterms1: boundary
16/03/25 13:56:51 INFO PythonRunner: Times: total = 8551, boot = 484, init = 398, finish = 7669
16/03/25 13:56:51 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
16/03/25 13:56:51 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8670 ms on localhost (1/2)
mapFunction(): freqterms1: Nadu
mapFunction(): freqterms1: function
mapFunction(): freqterms1: product
mapFunction(): freqterms1: terms
mapFunction(): freqterms1: equivalent
mapFunction(): freqterms1: Bay
mapFunction(): freqterms1: western
mapFunction(): freqterms1: particular
mapFunction(): freqterms1: Bengal
mapFunction(): freqterms1: Orthodox
mapFunction(): freqterms1: region
mapFunction(): freqterms1: title
mapFunction(): freqterms1: patriarch
mapFunction(): freqterms1: Church
mapFunction(): freqterms1: usually
mapFunction(): freqterms1: position
mapFunction(): freqterms1: distinguished
mapFunction(): freqterms1: purpose
16/03/25 13:56:51 INFO PythonRunner: Times: total = 8888, boot = 483, init = 390, finish = 8015
16/03/25 13:56:51 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1803 bytes result sent to driver
16/03/25 13:56:51 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:236) finished in 8.988 s
16/03/25 13:56:51 INFO DAGScheduler: looking for newly runnable stages
16/03/25 13:56:51 INFO DAGScheduler: running: Set()
16/03/25 13:56:51 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/03/25 13:56:51 INFO DAGScheduler: failed: Set()
16/03/25 13:56:51 INFO DAGScheduler: Missing parents for ResultStage 1: List()
16/03/25 13:56:51 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:236), which is now runnable
16/03/25 13:56:51 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8995 ms on localhost (2/2)
16/03/25 13:56:51 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/03/25 13:56:51 INFO MemoryStore: ensureFreeSpace(4976) called with curMem=11326, maxMem=563824558
16/03/25 13:56:51 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 537.7 MB)
16/03/25 13:56:51 INFO MemoryStore: ensureFreeSpace(3047) called with curMem=16302, maxMem=563824558
16/03/25 13:56:51 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 537.7 MB)
16/03/25 13:56:51 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:35916 (size: 3.0 KB, free: 537.7 MB)
16/03/25 13:56:51 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/25 13:56:51 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:236)
16/03/25 13:56:51 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/03/25 13:56:51 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:56:51 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2137 bytes)
16/03/25 13:56:51 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/03/25 13:56:51 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:56:51 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/03/25 13:56:51 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/03/25 13:56:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/03/25 13:56:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
16/03/25 13:56:51 INFO PythonRunner: Times: total = 48, boot = -164, init = 210, finish = 2
16/03/25 13:56:51 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 4550 bytes result sent to driver
16/03/25 13:56:51 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 77 ms on localhost (1/2)
16/03/25 13:56:51 INFO PythonRunner: Times: total = 241, boot = 240, init = 1, finish = 0
16/03/25 13:56:51 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1213 bytes result sent to driver
16/03/25 13:56:51 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:236) finished in 0.246 s
16/03/25 13:56:51 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:236, took 9.290659 s
16/03/25 13:56:51 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 261 ms on localhost (2/2)
16/03/25 13:56:51 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/03/25 13:56:52 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:236
16/03/25 13:56:52 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:236) with 2 output partitions
16/03/25 13:56:52 INFO DAGScheduler: Final stage: ResultStage 2(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:236)
16/03/25 13:56:52 INFO DAGScheduler: Parents of final stage: List()
16/03/25 13:56:52 INFO DAGScheduler: Missing parents: List()
16/03/25 13:56:52 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:236), which has no missing parents
16/03/25 13:56:52 INFO MemoryStore: ensureFreeSpace(5872) called with curMem=19349, maxMem=563824558
16/03/25 13:56:52 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 537.7 MB)
16/03/25 13:56:52 INFO MemoryStore: ensureFreeSpace(3417) called with curMem=25221, maxMem=563824558
16/03/25 13:56:52 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 537.7 MB)
16/03/25 13:56:52 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:35916 (size: 3.3 KB, free: 537.7 MB)
16/03/25 13:56:52 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
16/03/25 13:56:52 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:236)
16/03/25 13:56:52 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
16/03/25 13:56:52 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2307 bytes)
16/03/25 13:56:52 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 5541 bytes)
16/03/25 13:56:52 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
16/03/25 13:56:52 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
16/03/25 13:56:52 INFO PythonRunner: Times: total = 109, boot = -30, init = 139, finish = 0
16/03/25 13:56:52 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 963 bytes result sent to driver
16/03/25 13:56:52 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 121 ms on localhost (1/2)
16/03/25 13:56:52 INFO PythonRunner: Times: total = 166, boot = 165, init = 1, finish = 0
16/03/25 13:56:52 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 4852 bytes result sent to driver
16/03/25 13:56:52 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 199 ms on localhost (2/2)
16/03/25 13:56:52 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
16/03/25 13:56:52 INFO DAGScheduler: ResultStage 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:236) finished in 0.192 s
16/03/25 13:56:52 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/InterviewAlgorithm/InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:236, took 0.214023 s
graphcache_mapreduce updated: defaultdict(<cyfunction <lambda> at 0xb1f81bcc>, {'70d7d53d7ab05e91c9f0c0600910ca35': Row(tokensatthislevel=[u'city', u'Tamil', u'Nadu', u'Bay', u'Bengal', u'formerly', u'Madras', u'Eastern', u'Orthodox', u'Church', u'title', u'given', u'position', u'bishop', u'patriarch', u'equivalent', u'archbishop', u'western', u'Christianity', u'particular', u'geographical', u'region', u'indefinite', u'boundary', u'usually', u'serving', u'special', u'purpose', u'distinguished', u'people', u'culture', u'geography', u'function', u'expressed', u'sum', u'product', u'terms']), '410bbddf7a28d78bd61df79edc29c2bb': Row(tokensatthislevel=[u'individual', u'quantity', u'food', u'drink', u'taken', u'part', u'meal', u'previous', u'time', u'plural', u'group', u'human', u'beings', u'men', u'women', u'children', u'collectively', u'monotheistic', u'system', u'beliefs', u'practices', u'based', u'Old', u'Testament', u'teachings', u'Jesus', u'embodied', u'New', u'Testament', u'emphasizing', u'role', u'Jesus', u'savior', u'particular', u'society', u'particular', u'time', u'place', u'vague', u'clearly', u'defined', u'stated', u'senior', u'member', u'Christian', u'clergy', u'spiritual', u'administrative', u'authority', u'appointed', u'Christian', u'churches', u'oversee', u'priests', u'ministers', u'considered', u'churches', u'successors', u'twelve', u'Apostles', u'Christ', u'special', u'offering', u'usually', u'temporary', u'reduced', u'price', u'featured', u'advertising', u'study', u'earth', u'surface', u'includes', u'people', u'responses', u'topography', u'climate', u'soil', u'vegetation', u'large', u'densely', u'populated', u'urban', u'area', u'include', u'several', u'independent', u'administrative', u'districts', u'assumption', u'taken', u'granted', u'state', u'southeastern', u'India', u'Bay', u'Bengal', u'south', u'Andhra', u'Pradesh', u'formerly', u'Madras', u'lying', u'toward', u'situated', u'east', u'bishop', u'highest', u'rank', u'quantity', u'money', u'give', u'expression', u'relating', u'science', u'geography', u'line', u'determining', u'limits', u'area', u'member', u'mixed', u'Dravidian', u'Caucasian', u'people', u'southern', u'India', u'Sri', u'Lanka', u'mathematics', u'mathematical', u'relation', u'element', u'given', u'set', u'domain', u'function', u'associated', u'element', u'another', u'set', u'range', u'function', u'commodities', u'offered', u'sale', u'status', u'respect', u'relations', u'people', u'groups', u'person', u'thing', u'equal', u'another', u'value', u'measure', u'force', u'effect', u'significance', u'etc', u'indentation', u'shoreline', u'larger', u'cove', u'smaller', u'gulf', u'film', u'life', u'western', u'United', u'States', u'period', u'exploration', u'development', u'fact', u'part', u'opposed', u'general', u'region', u'whose', u'eastern', u'part', u'Bangladesh', u'whose', u'western', u'part', u'included', u'India', u'pertaining', u'characteristic', u'Judaism', u'extended', u'spatial', u'location', u'something', u'heading', u'names', u'statute', u'legislative', u'bill', u'give', u'brief', u'summary', u'matters', u'deals', u'man', u'older', u'higher', u'rank', u'one', u'groups', u'Christians', u'beliefs', u'forms', u'worship', u'normal', u'conditions', u'particular', u'portion', u'space', u'occupied', u'something', u'mark', u'different', u'anticipated', u'outcome', u'intended', u'guides', u'planned', u'actions'])})
16/03/25 13:56:52 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
16/03/25 13:56:52 INFO DAGScheduler: Stopping DAGScheduler
16/03/25 13:56:52 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/03/25 13:56:52 INFO MemoryStore: MemoryStore cleared
16/03/25 13:56:52 INFO BlockManager: BlockManager stopped
16/03/25 13:56:52 INFO BlockManagerMaster: BlockManagerMaster stopped
16/03/25 13:56:52 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/03/25 13:56:52 INFO SparkContext: Successfully stopped SparkContext
16/03/25 13:56:52 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/03/25 13:56:52 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/03/25 13:56:52 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
InterviewAlgorithmWithIntrinisicMerit_Crawl_Visual_Spark.py:tokensofthislevel: [u'individual', u'quantity', u'food', u'drink', u'taken', u'part', u'meal', u'previous', u'time', u'plural', u'group', u'human', u'beings', u'men', u'women', u'children', u'collectively', u'monotheistic', u'system', u'beliefs', u'practices', u'based', u'Old', u'Testament', u'teachings', u'Jesus', u'embodied', u'New', u'Testament', u'emphasizing', u'role', u'Jesus', u'savior', u'particular', u'society', u'particular', u'time', u'place', u'vague', u'clearly', u'defined', u'stated', u'senior', u'member', u'Christian', u'clergy', u'spiritual', u'administrative', u'authority', u'appointed', u'Christian', u'churches', u'oversee', u'priests', u'ministers', u'considered', u'churches', u'successors', u'twelve', u'Apostles', u'Christ', u'special', u'offering', u'usually', u'temporary', u'reduced', u'price', u'featured', u'advertising', u'study', u'earth', u'surface', u'includes', u'people', u'responses', u'topography', u'climate', u'soil', u'vegetation', u'large', u'densely', u'populated', u'urban', u'area', u'include', u'several', u'independent', u'administrative', u'districts', u'assumption', u'taken', u'granted', u'state', u'southeastern', u'India', u'Bay', u'Bengal', u'south', u'Andhra', u'Pradesh', u'formerly', u'Madras', u'lying', u'toward', u'situated', u'east', u'bishop', u'highest', u'rank', u'quantity', u'money', u'give', u'expression', u'relating', u'science', u'geography', u'line', u'determining', u'limits', u'area', u'member', u'mixed', u'Dravidian', u'Caucasian', u'people', u'southern', u'India', u'Sri', u'Lanka', u'mathematics', u'mathematical', u'relation', u'element', u'given', u'set', u'domain', u'function', u'associated', u'element', u'another', u'set', u'range', u'function', u'commodities', u'offered', u'sale', u'status', u'respect', u'relations', u'people', u'groups', u'person', u'thing', u'equal', u'another', u'value', u'measure', u'force', u'effect', u'significance', u'etc', u'indentation', u'shoreline', u'larger', u'cove', u'smaller', u'gulf', u'film', u'life', u'western', u'United', u'States', u'period', u'exploration', u'development', u'fact', u'part', u'opposed', u'general', u'region', u'whose', u'eastern', u'part', u'Bangladesh', u'whose', u'western', u'part', u'included', u'India', u'pertaining', u'characteristic', u'Judaism', u'extended', u'spatial', u'location', u'something', u'heading', u'names', u'statute', u'legislative', u'bill', u'give', u'brief', u'summary', u'matters', u'deals', u'man', u'older', u'higher', u'rank', u'one', u'groups', u'Christians', u'beliefs', u'forms', u'worship', u'normal', u'conditions', u'particular', u'portion', u'space', u'occupied', u'something', u'mark', u'different', u'anticipated', u'outcome', u'intended', u'guides', u'planned', u'actions']
prevlevelsynsets: [Synset('helping.n.01'), Synset('once.r.01'), Synset('people.n.01'), Synset('christianity.n.01'), Synset('culture.n.01'), Synset('indefinite.a.01'), Synset('bishop.n.01'), Synset('special.n.01'), Synset('geography.n.01'), Synset('city.n.01'), Synset('given.n.01'), Synset('tamil_nadu.n.01'), Synset('eastern.s.01'), Synset('archbishop.n.01'), Synset('sum.n.01'), Synset('express.n.01'), Synset('geographic.a.01'), Synset('boundary.n.01'), Synset('tamil.n.01'), Synset('function.n.01'), Synset('merchandise.n.01'), Synset('footing.n.01'), Synset('equivalent.n.01'), Synset('bay.n.01'), Synset('western.n.01'), Synset('particular.n.01'), Synset('bengal.n.01'), Synset('orthodox.a.01'), Synset('region.n.01'), Synset('title.n.01'), Synset('patriarch.n.01'), Synset('church.n.01'), Synset('normally.r.01'), Synset('position.n.01'), Synset('distinguish.v.01'), Synset('purpose.n.01')]
defaultdict(<type 'list'>, {u'serving': [u'None', u'area'], u'Madras': [u'Chennai', u'None', u'Madras'], u'people': [u'None', u'area', u'None'], u'Christianity': [u'metropolitan', u'None'], u'culture': [u'None', u'area', u'None'], u'indefinite': [u'None', u'area', u'None'], u'bishop': [u'metropolitan', u'None'], u'special': [u'None', u'area', u'None', u'special'], u'geography': [u'None', u'area', u'None'], u'city': [u'Chennai', u'None'], u'given': [u'metropolitan', u'None'], u'position': [u'metropolitan', u'None'], u'formerly': [u'Chennai', u'None'], u'Eastern': [u'metropolitan', u'None'], u'archbishop': [u'metropolitan', u'None'], u'sum': [u'None', u'expansion', u'None'], u'expressed': [u'None', u'expansion', u'None'], u'geographical': [u'None', u'area', u'None'], u'boundary': [u'None', u'area', u'None'], u'Tamil': [u'Chennai', u'None'], u'Nadu': [u'Chennai', u'None'], u'function': [u'None', u'expansion', u'None', u'function'], u'product': [u'None', u'expansion', u'None'], u'terms': [u'None', u'expansion', u'None'], u'equivalent': [u'metropolitan', u'None'], u'Bay': [u'Chennai', u'Madras'], u'western': [u'metropolitan', u'None', u'western'], u'particular': [u'None', u'area', u'culture', u'None'], u'Bengal': [u'Chennai', u'Madras', u'None'], u'region': [u'None', u'area', u'None', u'Bengal'], u'Orthodox': [u'metropolitan', u'None'], u'patriarch': [u'metropolitan', u'None'], u'Church': [u'metropolitan', u'None'], u'usually': [u'None', u'area', u'special', u'None'], u'title': [u'metropolitan', u'None'], u'distinguished': [u'None', u'area', u'None'], u'purpose': [u'None', u'area', u'None']})
ksynset= Synset('helping.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('helping.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('tamil_nadu.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('tamil_nadu.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('tamil_nadu.n.01')
lsynset= Synset('tamil_nadu.n.01')
ksynset= Synset('people.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('people.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('people.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('christianity.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('christianity.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('culture.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('culture.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('culture.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('indefinite.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('indefinite.a.01')
lsynset= Synset('area.n.01')
ksynset= Synset('indefinite.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('bishop.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('bishop.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('special.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('special.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('special.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('special.n.01')
lsynset= Synset('special.n.01')
ksynset= Synset('geography.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('geography.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('geography.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('city.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('city.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('given.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('given.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('position.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('position.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('once.r.03')
lsynset= Synset('chennai.n.01')
ksynset= Synset('once.r.03')
lsynset= Synset('none.n.01')
ksynset= Synset('eastern.s.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('eastern.s.01')
lsynset= Synset('none.n.01')
ksynset= Synset('archbishop.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('archbishop.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('sum.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('sum.n.01')
lsynset= Synset('expansion.n.01')
ksynset= Synset('sum.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('express.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('express.v.01')
lsynset= Synset('expansion.n.01')
ksynset= Synset('express.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('geographic.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('geographic.a.01')
lsynset= Synset('area.n.01')
ksynset= Synset('geographic.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('boundary.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('boundary.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('boundary.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('tamil.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('tamil.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('function.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('function.n.01')
lsynset= Synset('expansion.n.01')
ksynset= Synset('function.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('function.n.01')
lsynset= Synset('function.n.01')
ksynset= Synset('merchandise.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('merchandise.n.01')
lsynset= Synset('expansion.n.01')
ksynset= Synset('merchandise.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('footing.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('footing.n.01')
lsynset= Synset('expansion.n.01')
ksynset= Synset('footing.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('equivalent.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('equivalent.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('bay.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('bay.n.01')
lsynset= Synset('tamil_nadu.n.01')
ksynset= Synset('western.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('western.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('western.n.01')
lsynset= Synset('western.n.01')
ksynset= Synset('particular.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('particular.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('particular.n.01')
lsynset= Synset('culture.n.01')
ksynset= Synset('particular.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('bengal.n.01')
lsynset= Synset('chennai.n.01')
ksynset= Synset('bengal.n.01')
lsynset= Synset('tamil_nadu.n.01')
ksynset= Synset('bengal.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('region.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('region.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('region.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('region.n.01')
lsynset= Synset('bengal.n.01')
ksynset= Synset('orthodox.a.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('orthodox.a.01')
lsynset= Synset('none.n.01')
ksynset= Synset('patriarch.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('patriarch.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('church.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('church.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('normally.r.01')
lsynset= Synset('none.n.01')
ksynset= Synset('normally.r.01')
lsynset= Synset('area.n.01')
ksynset= Synset('normally.r.01')
lsynset= Synset('special.n.01')
ksynset= Synset('normally.r.01')
lsynset= Synset('none.n.01')
ksynset= Synset('title.n.01')
lsynset= Synset('metropolitan.n.01')
ksynset= Synset('title.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('distinguish.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('distinguish.v.01')
lsynset= Synset('area.n.01')
ksynset= Synset('distinguish.v.01')
lsynset= Synset('none.n.01')
ksynset= Synset('purpose.n.01')
lsynset= Synset('none.n.01')
ksynset= Synset('purpose.n.01')
lsynset= Synset('area.n.01')
ksynset= Synset('purpose.n.01')
lsynset= Synset('none.n.01')
Core number (sorted) : [(u'area', 13), (u'metropolitan', 12), (u'Chennai', 7), (u'Madras', 5), (u'expansion', 5), (u'Bengal', 5), (u'culture', 4), (u'special', 4), (u'Bay', 4), (u'particular', 4), (u'region', 4), (u'usually', 4), (u'serving', 2), (u'people', 2), (u'Christianity', 2), (u'indefinite', 2), (u'bishop', 2), (u'geography', 2), (u'city', 2), (u'given', 2), (u'archbishop', 2), (u'sum', 2), (u'expressed', 2), (u'geographical', 2), (u'boundary', 2), (u'Tamil', 2), (u'Nadu', 2), (u'function', 2), (u'product', 2), (u'terms', 2), (u'equivalent', 2), (u'western', 2), (u'Orthodox', 2), (u'title', 2), (u'patriarch', 2), (u'Eastern', 2), (u'formerly', 2), (u'Church', 2), (u'position', 2), (u'distinguished', 2), (u'purpose', 2), (u'None', 0)]
=============================================================================================================
Unsupervised Classification based on top percentile Core numbers of the definition graph(subgraph of WordNet)
=============================================================================================================
This document belongs to class: area ,core number= 13
This document belongs to class: metropolitan ,core number= 12
This document belongs to class: Chennai ,core number= 7
This document belongs to class: Madras ,core number= 5
This document belongs to class: expansion ,core number= 5
This document belongs to class: Bengal ,core number= 5
max_core_number 13
===================================================================
Page Rank of the vertices of RGO Definition Graph
===================================================================
[(u'metropolitan', 0.14711476124956654), (u'area', 0.1324330177438469), (u'Chennai', 0.070218911144783), (u'expansion', 0.06896076372844066), (u'Bengal', 0.029161228094978266), (u'Madras', 0.029112804827554094), (u'culture', 0.021398752531447705), (u'special', 0.021398752531447705), (u'particular', 0.021398752531447705), (u'usually', 0.021398752531447705), (u'region', 0.02056663085554685), (u'Bay', 0.020420410259860057), (u'product', 0.015369451142525727), (u'sum', 0.015369451142525727), (u'expressed', 0.015369451142525727), (u'function', 0.015369451142525727), (u'terms', 0.015369451142525727), (u'Christianity', 0.014066884517173625), (u'bishop', 0.014066884517173625), (u'given', 0.014066884517173625), (u'archbishop', 0.014066884517173625), (u'equivalent', 0.014066884517173625), (u'position', 0.014066884517173625), (u'western', 0.014066884517173625), (u'Orthodox', 0.014066884517173625), (u'patriarch', 0.014066884517173625), (u'Eastern', 0.014066884517173625), (u'Church', 0.014066884517173625), (u'title', 0.014066884517173625), (u'serving', 0.01230428277059196), (u'people', 0.01230428277059196), (u'indefinite', 0.01230428277059196), (u'geography', 0.01230428277059196), (u'geographical', 0.01230428277059196), (u'boundary', 0.01230428277059196), (u'distinguished', 0.01230428277059196), (u'purpose', 0.01230428277059196), (u'city', 0.012171782350039574), (u'Tamil', 0.012171782350039574), (u'Nadu', 0.012171782350039574), (u'formerly', 0.012171782350039574), (u'None', 0.003645200486026732)]
==========================================================================================================
Alternative Quantitative Intrinsic Merit  - connectivity of RGO Definition Graph - Mengers Theorem
==========================================================================================================
0
==========================================================================================================
Alternative Quantitative Intrinsic Merit  - Maxflow-Mincut of RGO Definition Graph - Minimum Edge Cut
==========================================================================================================
==========================================================================================================
Alternative Quantitative Intrinsic Merit  - Maxflow-Mincut of RGO Definition Graph - Stoer-Wagner
==========================================================================================================
16/03/25 13:58:16 INFO ShutdownHookManager: Shutdown hook called
16/03/25 13:58:16 INFO ShutdownHookManager: Deleting directory /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/pyspark-9e15124e-ae82-4bd0-a1a5-b0e50ba5a8e9
16/03/25 13:58:16 INFO ShutdownHookManager: Deleting directory /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/pyspark-09aa751f-d6f2-487c-9407-c2ff3101e309
16/03/25 13:58:16 INFO ShutdownHookManager: Deleting directory /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/pyspark-96127591-f693-41e5-9f66-fbb860d4cf7e
16/03/25 13:58:16 INFO ShutdownHookManager: Deleting directory /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/pyspark-9675da3f-191b-4dc5-b87b-a75660a17436
16/03/25 13:58:16 INFO ShutdownHookManager: Deleting directory /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/pyspark-aa3f6cdf-d339-48e0-9ab5-04613f21072f
16/03/25 13:58:16 INFO ShutdownHookManager: Deleting directory /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/pyspark-8e477ffa-b700-49b2-a0cd-4483f0bea6fd
16/03/25 13:58:16 INFO ShutdownHookManager: Deleting directory /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/pyspark-66ea5d41-26a8-4202-8649-989cef345d51
16/03/25 13:58:16 INFO ShutdownHookManager: Deleting directory /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/pyspark-f9697a5a-7de2-4b08-94f3-6e285e90ce98
16/03/25 13:58:16 INFO ShutdownHookManager: Deleting directory /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/pyspark-a5d62727-0fd1-4afa-bd79-ded5b1e9127b
16/03/25 13:58:16 INFO ShutdownHookManager: Deleting directory /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/pyspark-f145aefe-fe7c-4219-b6d3-6454e464d700
16/03/25 13:58:16 INFO ShutdownHookManager: Deleting directory /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/pyspark-2c332a20-de72-425f-ba98-1884eb4a4cc7
16/03/25 13:58:16 INFO ShutdownHookManager: Deleting directory /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/pyspark-fb12b348-3a08-4b43-aff2-6a270934da2a
16/03/25 13:58:16 INFO ShutdownHookManager: Deleting directory /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/pyspark-099e7c22-9bb9-4237-9366-5776ecb747fd
16/03/25 13:58:16 INFO ShutdownHookManager: Deleting directory /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/pyspark-cc43251a-23b5-465c-a1af-d3dec6f8ea6d
16/03/25 13:58:16 INFO ShutdownHookManager: Deleting directory /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/pyspark-e552a130-56c3-404f-b077-32e605c37caa
16/03/25 13:58:16 INFO ShutdownHookManager: Deleting directory /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/pyspark-c3b8e149-2aac-4dc9-b1d2-360c7439f43a
16/03/25 13:58:16 INFO ShutdownHookManager: Deleting directory /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/pyspark-d8115ab8-1cce-4e7e-b745-65675bbdfb8c
16/03/25 13:58:16 INFO ShutdownHookManager: Deleting directory /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/pyspark-4e410ff6-0d22-421f-86c0-16ae86843b7c
16/03/25 13:58:16 INFO ShutdownHookManager: Deleting directory /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/pyspark-dd9b8492-eae0-4a60-a6bd-b39e70b6c89a
16/03/25 13:58:16 INFO ShutdownHookManager: Deleting directory /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/pyspark-1e14419a-ad83-47f3-8bb9-899563f4da22
16/03/25 13:58:16 INFO ShutdownHookManager: Deleting directory /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/pyspark-a091d2bf-6a9e-4c22-a178-df0190710fad
16/03/25 13:58:16 INFO ShutdownHookManager: Deleting directory /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/pyspark-dd510b59-a6e8-4ce4-a610-0a9d66d190a7
16/03/25 13:58:16 INFO ShutdownHookManager: Deleting directory /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/pyspark-81d974b8-29e1-4a39-ae47-46019a2ac859
16/03/25 13:58:16 INFO ShutdownHookManager: Deleting directory /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/pyspark-4cc609e7-a310-4c45-89ce-b0b66688f744
16/03/25 13:58:16 INFO ShutdownHookManager: Deleting directory /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/pyspark-f75afdc9-ce50-48af-b56b-fb394ce1d630
16/03/25 13:58:16 INFO ShutdownHookManager: Deleting directory /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/pyspark-12eb0fc3-c60d-4122-885e-a4150ad27357
16/03/25 13:58:16 INFO ShutdownHookManager: Deleting directory /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/pyspark-876e087d-e5a8-4e42-864f-47d1d46866e2
16/03/25 13:58:16 INFO ShutdownHookManager: Deleting directory /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/pyspark-8afca771-bc47-41bf-bb15-ccc80d28b098
16/03/25 13:58:16 INFO ShutdownHookManager: Deleting directory /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/pyspark-904cc3cc-4708-456d-b9dc-df53d293e020
16/03/25 13:58:16 INFO ShutdownHookManager: Deleting directory /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/pyspark-7faf6cf8-b020-4c9a-956e-80a4e9410d92
16/03/25 13:58:16 INFO ShutdownHookManager: Deleting directory /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b/pyspark-e2801d94-9035-4f40-a4e5-ccc294eac71a
16/03/25 13:58:16 INFO ShutdownHookManager: Deleting directory /tmp/spark-da95d86b-284d-4ac0-b77a-cdec962fb79b

