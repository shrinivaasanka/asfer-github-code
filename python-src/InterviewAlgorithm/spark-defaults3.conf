# References:
#1. https://gist.github.com/oza/a4ce3737335a80e1c18c
#2. Netflix Spark - http://events.linuxfoundation.org/sites/events/files/slides/Netflix%20Integrating%20Spark%20at%20Petabyte%20Scale.pdf
#3. HP Spark Reference Big Data Architecture - http://www8.hp.com/h20195/V2/getpdf.aspx/4AA6-2682ENW.pdf

# Example:
# spark.master                     spark://master:7077
#spark.eventLog.enabled           true
#spark.eventLog.dir               file:///home/shrinivaasanka/SparkEventLogs
# spark.serializer                 org.apache.spark.serializer.KryoSerializer
# spark.driver.memory              5g
# spark.executor.extraJavaOptions  -XX:+PrintGCDetails -Dkey=value -Dnumbers="one two three"
spark.executor.extraJavaOptions  -d64 -server -XX:+AggressiveOpts -XX:+UseLargePages
spark.serializer                   org.apache.spark.serializer.KryoSerializer
spark.shuffle.manager              SORT
spark.shuffle.consolidateFiles     true
spark.shuffle.spill                true
spark.shuffle.memoryFraction       0.85
spark.storage.memoryFraction       0.65
spark.shuffle.spill.compress       true
spark.shuffle.compress             true
spark.shuffle.service.enabled      true
spark.dynamicAllocation.enabled    true
spark.kryoserializer.buffer.max    2000 

spark.driver.memory              8g
spark.executor.memory            8g
spark.executor.cores	         4
spark.cores.max                  4
spark.python.worker.memory       8g
spark.python.worker.reuse        true
spark.task.cpus                  4

spark.default.parallelism        4
spark.executor.instances	 10

spark.dynamicAllocation.enabled 	true
spark.dynamicAllocation.executorIdleTimeout 	5
spark.dynamicAllocation.initialExecutors 	4
spark.dynamicAllocation.maxExecutors 	200
spark.dynamicAllocation.minExecutors 	4
spark.dynamicAllocation.schedulerBacklogTimeout 	5
spark.dynamicAllocation.sustainedSchedulerBacklogTimeout 	5
spark.dynamicAllocation.cachedExecutorIdleTimeout 	900
spark.network.timeout 1000
spark.network.timeoutInterval 1000
spark.storage.blockManagerSlaveTimeoutMs 10000
spark.executor.heartbeatInterval 1000 
spark.sql.execution.arrow.pyspark.enabled true

