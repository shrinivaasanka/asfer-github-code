*** Introductory Examples for the NLTK Book ***
Loading text1, ..., text9 and sent1, ..., sent9
Type the name of the text or sentence to view it.
Type: 'texts()' or 'sents()' to list the materials.
text1: Moby Dick by Herman Melville 1851
text2: Sense and Sensibility by Jane Austen 1811
text3: The Book of Genesis
text4: Inaugural Address Corpus
text5: Chat Corpus
text6: Monty Python and the Holy Grail
text7: Wall Street Journal
text8: Personals Corpus
text9: The Man Who Was Thursday by G . K . Chesterton 1908
================================================================
Question: Where is the Valley of Kings?
2
defaultdict(<class 'list'>, {'land': ['valley'], 'contains': ['valley'], 'kingdom': ['king'], 'long': ['valley'], 'ruler': ['king'], 'usually': ['valley'], 'river': ['valley'], 'male': ['king'], 'sovereign': ['king'], 'depression': ['valley'], 'surface': ['valley']})
('definitiongraph networkx edges:', OutEdgeView([('land', 'valley'), ('valley', 'land'), ('valley', 'contains'), ('valley', 'long'), ('valley', 'usually'), ('valley', 'river'), ('valley', 'depression'), ('valley', 'surface'), ('contains', 'valley'), ('kingdom', 'king'), ('king', 'kingdom'), ('king', 'ruler'), ('king', 'male'), ('king', 'sovereign'), ('long', 'valley'), ('ruler', 'king'), ('usually', 'valley'), ('river', 'valley'), ('male', 'king'), ('sovereign', 'king'), ('depression', 'valley'), ('surface', 'valley')]))
('Core number (sorted) :', [('land', 2), ('valley', 2), ('contains', 2), ('kingdom', 2), ('king', 2), ('long', 2), ('ruler', 2), ('usually', 2), ('river', 2), ('male', 2), ('sovereign', 2), ('depression', 2), ('surface', 2)])
=============================================================================================================
Unsupervised Classification based on top percentile Core numbers of the definition graph(subgraph of WordNet)
=============================================================================================================
('This document belongs to class:', 'land', ',core number=', 2)
('This document belongs to class:', 'valley', ',core number=', 2)
('This document belongs to class:', 'contains', ',core number=', 2)
('This document belongs to class:', 'kingdom', ',core number=', 2)
('This document belongs to class:', 'king', ',core number=', 2)
('This document belongs to class:', 'long', ',core number=', 2)
('This document belongs to class:', 'ruler', ',core number=', 2)
('This document belongs to class:', 'usually', ',core number=', 2)
('\tmax_core_number', 2)
===================================================================
Betweenness Centrality of Recursive Gloss Overlap graph vertices
===================================================================
[('valley', 0.3181818181818182), ('king', 0.09090909090909091), ('land', 0.0), ('contains', 0.0), ('kingdom', 0.0), ('long', 0.0), ('ruler', 0.0), ('usually', 0.0), ('river', 0.0), ('male', 0.0), ('sovereign', 0.0), ('depression', 0.0), ('surface', 0.0)]
===================================================================
Closeness Centrality of Recursive Gloss Overlap graph vertices
===================================================================
[('valley', 0.5833333333333334), ('king', 0.3333333333333333), ('land', 0.3141025641025641), ('contains', 0.3141025641025641), ('long', 0.3141025641025641), ('usually', 0.3141025641025641), ('river', 0.3141025641025641), ('depression', 0.3141025641025641), ('surface', 0.3141025641025641), ('kingdom', 0.19047619047619047), ('ruler', 0.19047619047619047), ('male', 0.19047619047619047), ('sovereign', 0.19047619047619047)]
===================================================================
Degree Centrality of Recursive Gloss Overlap graph vertices
===================================================================
[('valley', 1.1666666666666665), ('king', 0.6666666666666666), ('land', 0.16666666666666666), ('contains', 0.16666666666666666), ('kingdom', 0.16666666666666666), ('long', 0.16666666666666666), ('ruler', 0.16666666666666666), ('usually', 0.16666666666666666), ('river', 0.16666666666666666), ('male', 0.16666666666666666), ('sovereign', 0.16666666666666666), ('depression', 0.16666666666666666), ('surface', 0.16666666666666666)]
===================================================================
Page Rank of the vertices of RGO Definition Graph (a form of Eigenvector Centrality)
===================================================================
[('valley', 0.2889795326042667), ('king', 0.18295130476367186), ('kingdom', 0.05041601996292819), ('ruler', 0.05041601996292819), ('male', 0.05041601996292819), ('sovereign', 0.05041601996292819), ('land', 0.0466292975400498), ('contains', 0.0466292975400498), ('long', 0.0466292975400498), ('usually', 0.0466292975400498), ('river', 0.0466292975400498), ('depression', 0.0466292975400498), ('surface', 0.0466292975400498)]
Question Textgraph: ([('land', 2), ('valley', 2), ('contains', 2), ('kingdom', 2), ('king', 2), ('long', 2), ('ruler', 2), ('usually', 2), ('river', 2), ('male', 2), ('sovereign', 2), ('depression', 2), ('surface', 2)], [('valley', 0.2889795326042667), ('king', 0.18295130476367186), ('kingdom', 0.05041601996292819), ('ruler', 0.05041601996292819), ('male', 0.05041601996292819), ('sovereign', 0.05041601996292819), ('land', 0.0466292975400498), ('contains', 0.0466292975400498), ('long', 0.0466292975400498), ('usually', 0.0466292975400498), ('river', 0.0466292975400498), ('depression', 0.0466292975400498), ('surface', 0.0466292975400498)])
Init of ConceptNet Client
wikipedia search result: Valley of the Kings
Exception
2
defaultdict(<class 'list'>, {'land': ['valley'], 'contains': ['valley'], 'kingdom': ['king'], 'long': ['valley'], 'ruler': ['king'], 'usually': ['valley'], 'river': ['valley'], 'male': ['king'], 'sovereign': ['king'], 'depression': ['valley'], 'surface': ['valley']})
('definitiongraph networkx edges:', OutEdgeView([('land', 'valley'), ('valley', 'land'), ('valley', 'contains'), ('valley', 'long'), ('valley', 'usually'), ('valley', 'river'), ('valley', 'depression'), ('valley', 'surface'), ('contains', 'valley'), ('kingdom', 'king'), ('king', 'kingdom'), ('king', 'ruler'), ('king', 'male'), ('king', 'sovereign'), ('long', 'valley'), ('ruler', 'king'), ('usually', 'valley'), ('river', 'valley'), ('male', 'king'), ('sovereign', 'king'), ('depression', 'valley'), ('surface', 'valley')]))
('Core number (sorted) :', [('land', 2), ('valley', 2), ('contains', 2), ('kingdom', 2), ('king', 2), ('long', 2), ('ruler', 2), ('usually', 2), ('river', 2), ('male', 2), ('sovereign', 2), ('depression', 2), ('surface', 2)])
=============================================================================================================
Unsupervised Classification based on top percentile Core numbers of the definition graph(subgraph of WordNet)
=============================================================================================================
('This document belongs to class:', 'land', ',core number=', 2)
('This document belongs to class:', 'valley', ',core number=', 2)
('This document belongs to class:', 'contains', ',core number=', 2)
('This document belongs to class:', 'kingdom', ',core number=', 2)
('This document belongs to class:', 'king', ',core number=', 2)
('This document belongs to class:', 'long', ',core number=', 2)
('This document belongs to class:', 'ruler', ',core number=', 2)
('This document belongs to class:', 'usually', ',core number=', 2)
('\tmax_core_number', 2)
===================================================================
Betweenness Centrality of Recursive Gloss Overlap graph vertices
===================================================================
[('valley', 0.3181818181818182), ('king', 0.09090909090909091), ('land', 0.0), ('contains', 0.0), ('kingdom', 0.0), ('long', 0.0), ('ruler', 0.0), ('usually', 0.0), ('river', 0.0), ('male', 0.0), ('sovereign', 0.0), ('depression', 0.0), ('surface', 0.0)]
===================================================================
Closeness Centrality of Recursive Gloss Overlap graph vertices
===================================================================
[('valley', 0.5833333333333334), ('king', 0.3333333333333333), ('land', 0.3141025641025641), ('contains', 0.3141025641025641), ('long', 0.3141025641025641), ('usually', 0.3141025641025641), ('river', 0.3141025641025641), ('depression', 0.3141025641025641), ('surface', 0.3141025641025641), ('kingdom', 0.19047619047619047), ('ruler', 0.19047619047619047), ('male', 0.19047619047619047), ('sovereign', 0.19047619047619047)]
===================================================================
Degree Centrality of Recursive Gloss Overlap graph vertices
===================================================================
[('valley', 1.1666666666666665), ('king', 0.6666666666666666), ('land', 0.16666666666666666), ('contains', 0.16666666666666666), ('kingdom', 0.16666666666666666), ('long', 0.16666666666666666), ('ruler', 0.16666666666666666), ('usually', 0.16666666666666666), ('river', 0.16666666666666666), ('male', 0.16666666666666666), ('sovereign', 0.16666666666666666), ('depression', 0.16666666666666666), ('surface', 0.16666666666666666)]
===================================================================
Page Rank of the vertices of RGO Definition Graph (a form of Eigenvector Centrality)
===================================================================
[('valley', 0.2889795326042667), ('king', 0.18295130476367186), ('kingdom', 0.05041601996292819), ('ruler', 0.05041601996292819), ('male', 0.05041601996292819), ('sovereign', 0.05041601996292819), ('land', 0.0466292975400498), ('contains', 0.0466292975400498), ('long', 0.0466292975400498), ('usually', 0.0466292975400498), ('river', 0.0466292975400498), ('depression', 0.0466292975400498), ('surface', 0.0466292975400498)]
2
RecursiveGlossOverlapGraph(): textgraph =  [('land', 'valley'), ('valley', 'land'), ('valley', 'contains'), ('valley', 'long'), ('valley', 'usually'), ('valley', 'river'), ('valley', 'depression'), ('valley', 'surface'), ('contains', 'valley'), ('kingdom', 'king'), ('king', 'kingdom'), ('king', 'ruler'), ('king', 'male'), ('king', 'sovereign'), ('long', 'valley'), ('ruler', 'king'), ('usually', 'valley'), ('river', 'valley'), ('male', 'king'), ('sovereign', 'king'), ('depression', 'valley'), ('surface', 'valley')]
Answer Textgraph  1 : ([('land', 2), ('valley', 2), ('contains', 2), ('kingdom', 2), ('king', 2), ('long', 2), ('ruler', 2), ('usually', 2), ('river', 2), ('male', 2), ('sovereign', 2), ('depression', 2), ('surface', 2)], [('valley', 0.2889795326042667), ('king', 0.18295130476367186), ('kingdom', 0.05041601996292819), ('ruler', 0.05041601996292819), ('male', 0.05041601996292819), ('sovereign', 0.05041601996292819), ('land', 0.0466292975400498), ('contains', 0.0466292975400498), ('long', 0.0466292975400498), ('usually', 0.0466292975400498), ('river', 0.0466292975400498), ('depression', 0.0466292975400498), ('surface', 0.0466292975400498)])
Attention from Definition Graph: [[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]]
Attention slice from Definition Graph: [[0.5, 0.5, 0.5], [0.07142857142857142, 0.07142857142857142, 0.07142857142857142], [0.5, 0.5, 0.5]]
weights: [1, 2, 3]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  1.012
LinearPerceptronGradient() weight update iteration: deltaw =  [0.12000000000000002, 0.13200000000000003, 0.33799999999999997]
weights: [1.012, 2, 3]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  2.0132
LinearPerceptronGradient() weight update iteration: deltaw =  [0.12000000000000002, 0.13200000000000003, 0.33799999999999997]
weights: [1.012, 2.0132, 3]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  3.0338
LinearPerceptronGradient() weight update iteration: deltaw =  [0.12000000000000002, 0.13200000000000003, 0.33799999999999997]
weights updated after Gradient :  [1.012, 2.0132, 3.0338]
converged: True
weights: [0.1, 0.3, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.07142857142857142, 0.07142857142857142, 0.07142857142857142]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  0.11537142857142858
LinearPerceptronGradient() weight update iteration: deltaw =  [0.15371428571428575, 0.16680000000000003, 0.18191428571428575]
weights: [0.11537142857142858, 0.3, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.07142857142857142, 0.07142857142857142, 0.07142857142857142]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  0.31668
LinearPerceptronGradient() weight update iteration: deltaw =  [0.15371428571428575, 0.16680000000000003, 0.18191428571428575]
weights: [0.11537142857142858, 0.31668, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.07142857142857142, 0.07142857142857142, 0.07142857142857142]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  0.5181914285714285
LinearPerceptronGradient() weight update iteration: deltaw =  [0.15371428571428575, 0.16680000000000003, 0.18191428571428575]
weights updated after Gradient :  [0.11537142857142858, 0.31668, 0.5181914285714285]
converged: True
weights: [3, 4, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  3.02
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights: [3.02, 4, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  4.038
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights: [3.02, 4.038, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  5.187
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights updated after Gradient :  [3.02, 4.038, 5.187]
converged: True
Learnt Query Weights: [[1.012, 2.0132, 3.0338], [0.11537142857142858, 0.31668, 0.5181914285714285], [3.02, 4.038, 5.187]]
weights: [4, 5, 6]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  4.024
LinearPerceptronGradient() weight update iteration: deltaw =  [0.24000000000000005, 0.504, 2.636]
weights: [4.024, 5, 6]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  5.0504
LinearPerceptronGradient() weight update iteration: deltaw =  [0.24000000000000005, 0.504, 2.636]
weights: [4.024, 5.0504, 6]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  6.2636
LinearPerceptronGradient() weight update iteration: deltaw =  [0.24000000000000005, 0.504, 2.636]
weights updated after Gradient :  [4.024, 5.0504, 6.2636]
converged: True
weights: [0.1, 0.3, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.07142857142857142, 0.07142857142857142, 0.07142857142857142]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  0.11537142857142858
LinearPerceptronGradient() weight update iteration: deltaw =  [0.15371428571428575, 0.16680000000000003, 0.18191428571428575]
weights: [0.11537142857142858, 0.3, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.07142857142857142, 0.07142857142857142, 0.07142857142857142]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  0.31668
LinearPerceptronGradient() weight update iteration: deltaw =  [0.15371428571428575, 0.16680000000000003, 0.18191428571428575]
weights: [0.11537142857142858, 0.31668, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.07142857142857142, 0.07142857142857142, 0.07142857142857142]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  0.5181914285714285
LinearPerceptronGradient() weight update iteration: deltaw =  [0.15371428571428575, 0.16680000000000003, 0.18191428571428575]
weights updated after Gradient :  [0.11537142857142858, 0.31668, 0.5181914285714285]
converged: True
weights: [3, 4, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  3.02
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights: [3.02, 4, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  4.038
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights: [3.02, 4.038, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  5.187
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights updated after Gradient :  [3.02, 4.038, 5.187]
converged: True
Learnt Key Weights: [[4.024, 5.0504, 6.2636], [0.11537142857142858, 0.31668, 0.5181914285714285], [3.02, 4.038, 5.187]]
weights: [7, 8, 9]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  7.036
LinearPerceptronGradient() weight update iteration: deltaw =  [0.36, 0.876, 4.934]
weights: [7.036, 8, 9]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  8.0876
LinearPerceptronGradient() weight update iteration: deltaw =  [0.36, 0.876, 4.934]
weights: [7.036, 8.0876, 9]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  9.4934
LinearPerceptronGradient() weight update iteration: deltaw =  [0.36, 0.876, 4.934]
weights updated after Gradient :  [7.036, 8.0876, 9.4934]
converged: True
weights: [0.1, 0.3, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.07142857142857142, 0.07142857142857142, 0.07142857142857142]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  0.11537142857142858
LinearPerceptronGradient() weight update iteration: deltaw =  [0.15371428571428575, 0.16680000000000003, 0.18191428571428575]
weights: [0.11537142857142858, 0.3, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.07142857142857142, 0.07142857142857142, 0.07142857142857142]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  0.31668
LinearPerceptronGradient() weight update iteration: deltaw =  [0.15371428571428575, 0.16680000000000003, 0.18191428571428575]
weights: [0.11537142857142858, 0.31668, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.07142857142857142, 0.07142857142857142, 0.07142857142857142]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  0.5181914285714285
LinearPerceptronGradient() weight update iteration: deltaw =  [0.15371428571428575, 0.16680000000000003, 0.18191428571428575]
weights updated after Gradient :  [0.11537142857142858, 0.31668, 0.5181914285714285]
converged: True
weights: [3, 4, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  3.02
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights: [3.02, 4, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  4.038
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights: [3.02, 4.038, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  5.187
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights updated after Gradient :  [3.02, 4.038, 5.187]
converged: True
Learnt Values Weights: [[7.036, 8.0876, 9.4934], [0.11537142857142858, 0.31668, 0.5181914285714285], [3.02, 4.038, 5.187]]
Query weight for textgraph edge ( land , land ): 1.012
Key weight for textgraph edge ( land , land ): 4.024
Value weight for textgraph edge ( land , land ): 7.036
Query weight for textgraph edge ( land , valley ): 2.0132
Key weight for textgraph edge ( land , valley ): 5.0504
Value weight for textgraph edge ( land , valley ): 8.0876
Query weight for textgraph edge ( land , contains ): 3.0338
Key weight for textgraph edge ( land , contains ): 6.2636
Value weight for textgraph edge ( land , contains ): 9.4934
Query weight for textgraph edge ( valley , land ): 0.11537142857142858
Key weight for textgraph edge ( valley , land ): 0.11537142857142858
Value weight for textgraph edge ( valley , land ): 0.11537142857142858
Query weight for textgraph edge ( valley , valley ): 0.31668
Key weight for textgraph edge ( valley , valley ): 0.31668
Value weight for textgraph edge ( valley , valley ): 0.31668
Query weight for textgraph edge ( valley , contains ): 0.5181914285714285
Key weight for textgraph edge ( valley , contains ): 0.5181914285714285
Value weight for textgraph edge ( valley , contains ): 0.5181914285714285
Query weight for textgraph edge ( contains , land ): 3.02
Key weight for textgraph edge ( contains , land ): 3.02
Value weight for textgraph edge ( contains , land ): 3.02
Query weight for textgraph edge ( contains , valley ): 4.038
Key weight for textgraph edge ( contains , valley ): 4.038
Value weight for textgraph edge ( contains , valley ): 4.038
Query weight for textgraph edge ( contains , contains ): 5.187
Key weight for textgraph edge ( contains , contains ): 5.187
Value weight for textgraph edge ( contains , contains ): 5.187
wikipedia search result: List of burials in the Valley of the Kings
wikipedia search result summary: The following is a list of burials in the Valley of the Kings, in Thebes (modern Luxor, Egypt) and nearby areas.
The numbering system was established by John Gardner Wilkinson in 1821. Wilkinson numbered the 21 tombs known to him (some of which had been open since antiquity) according to their location, starting at the entrance to the valley and then moving south and east. Tombs that have been discovered since then have been allocated a sequential KV number (those in the Western Valley are known by the WV equivalent) in the order of their discovery.Since the mid 20th century, Egyptologists have used the acronym "KV" (standing for Kings' Valley) to designate tombs located in the Valley of the Kings. 


2
defaultdict(<class 'list'>, {'land': ['valley'], 'names': ['list'], 'grave': ['burial'], 'contains': ['valley'], 'array': ['list'], 'ruler': ['king'], 'usually': ['valley'], 'river': ['valley'], 'male': ['king'], 'surface': ['valley'], 'ordered': ['list'], 'kingdom': ['king'], 'placing': ['burial'], 'items': ['list'], 'long': ['valley'], 'ritual': ['burial'], 'corpse': ['burial'], 'containing': ['list'], 'topics': ['list'], 'sovereign': ['king'], 'depression': ['valley'], 'database': ['list']})
('definitiongraph networkx edges:', OutEdgeView([('land', 'valley'), ('valley', 'land'), ('valley', 'contains'), ('valley', 'usually'), ('valley', 'river'), ('valley', 'surface'), ('valley', 'long'), ('valley', 'depression'), ('names', 'list'), ('list', 'names'), ('list', 'array'), ('list', 'ordered'), ('list', 'items'), ('list', 'containing'), ('list', 'topics'), ('list', 'database'), ('grave', 'burial'), ('burial', 'grave'), ('burial', 'placing'), ('burial', 'ritual'), ('burial', 'corpse'), ('contains', 'valley'), ('array', 'list'), ('ruler', 'king'), ('king', 'ruler'), ('king', 'male'), ('king', 'kingdom'), ('king', 'sovereign'), ('usually', 'valley'), ('river', 'valley'), ('male', 'king'), ('surface', 'valley'), ('ordered', 'list'), ('kingdom', 'king'), ('placing', 'burial'), ('items', 'list'), ('long', 'valley'), ('ritual', 'burial'), ('corpse', 'burial'), ('containing', 'list'), ('topics', 'list'), ('sovereign', 'king'), ('depression', 'valley'), ('database', 'list')]))
('Core number (sorted) :', [('land', 2), ('valley', 2), ('names', 2), ('list', 2), ('grave', 2), ('burial', 2), ('contains', 2), ('array', 2), ('ruler', 2), ('king', 2), ('usually', 2), ('river', 2), ('male', 2), ('surface', 2), ('ordered', 2), ('kingdom', 2), ('placing', 2), ('items', 2), ('long', 2), ('ritual', 2), ('corpse', 2), ('containing', 2), ('topics', 2), ('sovereign', 2), ('depression', 2), ('database', 2)])
=============================================================================================================
Unsupervised Classification based on top percentile Core numbers of the definition graph(subgraph of WordNet)
=============================================================================================================
('This document belongs to class:', 'land', ',core number=', 2)
('This document belongs to class:', 'valley', ',core number=', 2)
('This document belongs to class:', 'names', ',core number=', 2)
('This document belongs to class:', 'list', ',core number=', 2)
('This document belongs to class:', 'grave', ',core number=', 2)
('This document belongs to class:', 'burial', ',core number=', 2)
('This document belongs to class:', 'contains', ',core number=', 2)
('This document belongs to class:', 'array', ',core number=', 2)
('This document belongs to class:', 'ruler', ',core number=', 2)
('This document belongs to class:', 'king', ',core number=', 2)
('This document belongs to class:', 'usually', ',core number=', 2)
('This document belongs to class:', 'river', ',core number=', 2)
('This document belongs to class:', 'male', ',core number=', 2)
('This document belongs to class:', 'surface', ',core number=', 2)
('\tmax_core_number', 2)
===================================================================
Betweenness Centrality of Recursive Gloss Overlap graph vertices
===================================================================
[('valley', 0.07), ('list', 0.07), ('burial', 0.02), ('king', 0.02), ('land', 0.0), ('names', 0.0), ('grave', 0.0), ('contains', 0.0), ('array', 0.0), ('ruler', 0.0), ('usually', 0.0), ('river', 0.0), ('male', 0.0), ('surface', 0.0), ('ordered', 0.0), ('kingdom', 0.0), ('placing', 0.0), ('items', 0.0), ('long', 0.0), ('ritual', 0.0), ('corpse', 0.0), ('containing', 0.0), ('topics', 0.0), ('sovereign', 0.0), ('depression', 0.0), ('database', 0.0)]
===================================================================
Closeness Centrality of Recursive Gloss Overlap graph vertices
===================================================================
[('valley', 0.28), ('list', 0.28), ('burial', 0.16), ('king', 0.16), ('land', 0.15076923076923077), ('names', 0.15076923076923077), ('contains', 0.15076923076923077), ('array', 0.15076923076923077), ('usually', 0.15076923076923077), ('river', 0.15076923076923077), ('surface', 0.15076923076923077), ('ordered', 0.15076923076923077), ('items', 0.15076923076923077), ('long', 0.15076923076923077), ('containing', 0.15076923076923077), ('topics', 0.15076923076923077), ('depression', 0.15076923076923077), ('database', 0.15076923076923077), ('grave', 0.09142857142857143), ('ruler', 0.09142857142857143), ('male', 0.09142857142857143), ('kingdom', 0.09142857142857143), ('placing', 0.09142857142857143), ('ritual', 0.09142857142857143), ('corpse', 0.09142857142857143), ('sovereign', 0.09142857142857143)]
===================================================================
Degree Centrality of Recursive Gloss Overlap graph vertices
===================================================================
[('valley', 0.56), ('list', 0.56), ('burial', 0.32), ('king', 0.32), ('land', 0.08), ('names', 0.08), ('grave', 0.08), ('contains', 0.08), ('array', 0.08), ('ruler', 0.08), ('usually', 0.08), ('river', 0.08), ('male', 0.08), ('surface', 0.08), ('ordered', 0.08), ('kingdom', 0.08), ('placing', 0.08), ('items', 0.08), ('long', 0.08), ('ritual', 0.08), ('corpse', 0.08), ('containing', 0.08), ('topics', 0.08), ('sovereign', 0.08), ('depression', 0.08), ('database', 0.08)]
===================================================================
Page Rank of the vertices of RGO Definition Graph (a form of Eigenvector Centrality)
===================================================================
[('valley', 0.1444926237063229), ('list', 0.1444926237063229), ('burial', 0.09147708108393071), ('king', 0.09147708108393071), ('grave', 0.025207652805940405), ('ruler', 0.025207652805940405), ('male', 0.025207652805940405), ('kingdom', 0.025207652805940405), ('placing', 0.025207652805940405), ('ritual', 0.025207652805940405), ('corpse', 0.025207652805940405), ('sovereign', 0.025207652805940405), ('land', 0.02331424056942639), ('names', 0.02331424056942639), ('contains', 0.02331424056942639), ('array', 0.02331424056942639), ('usually', 0.02331424056942639), ('river', 0.02331424056942639), ('surface', 0.02331424056942639), ('ordered', 0.02331424056942639), ('items', 0.02331424056942639), ('long', 0.02331424056942639), ('containing', 0.02331424056942639), ('topics', 0.02331424056942639), ('depression', 0.02331424056942639), ('database', 0.02331424056942639)]
2
RecursiveGlossOverlapGraph(): textgraph =  [('land', 'valley'), ('valley', 'land'), ('valley', 'contains'), ('valley', 'usually'), ('valley', 'river'), ('valley', 'surface'), ('valley', 'long'), ('valley', 'depression'), ('names', 'list'), ('list', 'names'), ('list', 'array'), ('list', 'ordered'), ('list', 'items'), ('list', 'containing'), ('list', 'topics'), ('list', 'database'), ('grave', 'burial'), ('burial', 'grave'), ('burial', 'placing'), ('burial', 'ritual'), ('burial', 'corpse'), ('contains', 'valley'), ('array', 'list'), ('ruler', 'king'), ('king', 'ruler'), ('king', 'male'), ('king', 'kingdom'), ('king', 'sovereign'), ('usually', 'valley'), ('river', 'valley'), ('male', 'king'), ('surface', 'valley'), ('ordered', 'list'), ('kingdom', 'king'), ('placing', 'burial'), ('items', 'list'), ('long', 'valley'), ('ritual', 'burial'), ('corpse', 'burial'), ('containing', 'list'), ('topics', 'list'), ('sovereign', 'king'), ('depression', 'valley'), ('database', 'list')]
Answer Textgraph  2 : ([('land', 2), ('valley', 2), ('names', 2), ('list', 2), ('grave', 2), ('burial', 2), ('contains', 2), ('array', 2), ('ruler', 2), ('king', 2), ('usually', 2), ('river', 2), ('male', 2), ('surface', 2), ('ordered', 2), ('kingdom', 2), ('placing', 2), ('items', 2), ('long', 2), ('ritual', 2), ('corpse', 2), ('containing', 2), ('topics', 2), ('sovereign', 2), ('depression', 2), ('database', 2)], [('valley', 0.1444926237063229), ('list', 0.1444926237063229), ('burial', 0.09147708108393071), ('king', 0.09147708108393071), ('grave', 0.025207652805940405), ('ruler', 0.025207652805940405), ('male', 0.025207652805940405), ('kingdom', 0.025207652805940405), ('placing', 0.025207652805940405), ('ritual', 0.025207652805940405), ('corpse', 0.025207652805940405), ('sovereign', 0.025207652805940405), ('land', 0.02331424056942639), ('names', 0.02331424056942639), ('contains', 0.02331424056942639), ('array', 0.02331424056942639), ('usually', 0.02331424056942639), ('river', 0.02331424056942639), ('surface', 0.02331424056942639), ('ordered', 0.02331424056942639), ('items', 0.02331424056942639), ('long', 0.02331424056942639), ('containing', 0.02331424056942639), ('topics', 0.02331424056942639), ('depression', 0.02331424056942639), ('database', 0.02331424056942639)])
Attention from Definition Graph: [[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]]
Attention slice from Definition Graph: [[0.5, 0.5, 0.5], [0.07142857142857142, 0.07142857142857142, 0.07142857142857142], [0.5, 0.5, 0.5]]
weights: [1, 2, 3]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  1.012
LinearPerceptronGradient() weight update iteration: deltaw =  [0.12000000000000002, 0.13200000000000003, 0.33799999999999997]
weights: [1.012, 2, 3]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  2.0132
LinearPerceptronGradient() weight update iteration: deltaw =  [0.12000000000000002, 0.13200000000000003, 0.33799999999999997]
weights: [1.012, 2.0132, 3]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  3.0338
LinearPerceptronGradient() weight update iteration: deltaw =  [0.12000000000000002, 0.13200000000000003, 0.33799999999999997]
weights updated after Gradient :  [1.012, 2.0132, 3.0338]
converged: True
weights: [0.1, 0.3, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.07142857142857142, 0.07142857142857142, 0.07142857142857142]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  0.11537142857142858
LinearPerceptronGradient() weight update iteration: deltaw =  [0.15371428571428575, 0.16680000000000003, 0.18191428571428575]
weights: [0.11537142857142858, 0.3, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.07142857142857142, 0.07142857142857142, 0.07142857142857142]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  0.31668
LinearPerceptronGradient() weight update iteration: deltaw =  [0.15371428571428575, 0.16680000000000003, 0.18191428571428575]
weights: [0.11537142857142858, 0.31668, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.07142857142857142, 0.07142857142857142, 0.07142857142857142]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  0.5181914285714285
LinearPerceptronGradient() weight update iteration: deltaw =  [0.15371428571428575, 0.16680000000000003, 0.18191428571428575]
weights updated after Gradient :  [0.11537142857142858, 0.31668, 0.5181914285714285]
converged: True
weights: [3, 4, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  3.02
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights: [3.02, 4, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  4.038
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights: [3.02, 4.038, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  5.187
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights updated after Gradient :  [3.02, 4.038, 5.187]
converged: True
Learnt Query Weights: [[1.012, 2.0132, 3.0338], [0.11537142857142858, 0.31668, 0.5181914285714285], [3.02, 4.038, 5.187]]
weights: [4, 5, 6]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  4.024
LinearPerceptronGradient() weight update iteration: deltaw =  [0.24000000000000005, 0.504, 2.636]
weights: [4.024, 5, 6]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  5.0504
LinearPerceptronGradient() weight update iteration: deltaw =  [0.24000000000000005, 0.504, 2.636]
weights: [4.024, 5.0504, 6]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  6.2636
LinearPerceptronGradient() weight update iteration: deltaw =  [0.24000000000000005, 0.504, 2.636]
weights updated after Gradient :  [4.024, 5.0504, 6.2636]
converged: True
weights: [0.1, 0.3, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.07142857142857142, 0.07142857142857142, 0.07142857142857142]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  0.11537142857142858
LinearPerceptronGradient() weight update iteration: deltaw =  [0.15371428571428575, 0.16680000000000003, 0.18191428571428575]
weights: [0.11537142857142858, 0.3, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.07142857142857142, 0.07142857142857142, 0.07142857142857142]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  0.31668
LinearPerceptronGradient() weight update iteration: deltaw =  [0.15371428571428575, 0.16680000000000003, 0.18191428571428575]
weights: [0.11537142857142858, 0.31668, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.07142857142857142, 0.07142857142857142, 0.07142857142857142]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  0.5181914285714285
LinearPerceptronGradient() weight update iteration: deltaw =  [0.15371428571428575, 0.16680000000000003, 0.18191428571428575]
weights updated after Gradient :  [0.11537142857142858, 0.31668, 0.5181914285714285]
converged: True
weights: [3, 4, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  3.02
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights: [3.02, 4, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  4.038
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights: [3.02, 4.038, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  5.187
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights updated after Gradient :  [3.02, 4.038, 5.187]
converged: True
Learnt Key Weights: [[4.024, 5.0504, 6.2636], [0.11537142857142858, 0.31668, 0.5181914285714285], [3.02, 4.038, 5.187]]
weights: [7, 8, 9]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  7.036
LinearPerceptronGradient() weight update iteration: deltaw =  [0.36, 0.876, 4.934]
weights: [7.036, 8, 9]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  8.0876
LinearPerceptronGradient() weight update iteration: deltaw =  [0.36, 0.876, 4.934]
weights: [7.036, 8.0876, 9]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  9.4934
LinearPerceptronGradient() weight update iteration: deltaw =  [0.36, 0.876, 4.934]
weights updated after Gradient :  [7.036, 8.0876, 9.4934]
converged: True
weights: [0.1, 0.3, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.07142857142857142, 0.07142857142857142, 0.07142857142857142]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  0.11537142857142858
LinearPerceptronGradient() weight update iteration: deltaw =  [0.15371428571428575, 0.16680000000000003, 0.18191428571428575]
weights: [0.11537142857142858, 0.3, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.07142857142857142, 0.07142857142857142, 0.07142857142857142]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  0.31668
LinearPerceptronGradient() weight update iteration: deltaw =  [0.15371428571428575, 0.16680000000000003, 0.18191428571428575]
weights: [0.11537142857142858, 0.31668, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.07142857142857142, 0.07142857142857142, 0.07142857142857142]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  0.5181914285714285
LinearPerceptronGradient() weight update iteration: deltaw =  [0.15371428571428575, 0.16680000000000003, 0.18191428571428575]
weights updated after Gradient :  [0.11537142857142858, 0.31668, 0.5181914285714285]
converged: True
weights: [3, 4, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  3.02
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights: [3.02, 4, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  4.038
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights: [3.02, 4.038, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  5.187
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights updated after Gradient :  [3.02, 4.038, 5.187]
converged: True
Learnt Values Weights: [[7.036, 8.0876, 9.4934], [0.11537142857142858, 0.31668, 0.5181914285714285], [3.02, 4.038, 5.187]]
Query weight for textgraph edge ( land , land ): 1.012
Key weight for textgraph edge ( land , land ): 4.024
Value weight for textgraph edge ( land , land ): 7.036
Query weight for textgraph edge ( land , valley ): 2.0132
Key weight for textgraph edge ( land , valley ): 5.0504
Value weight for textgraph edge ( land , valley ): 8.0876
Query weight for textgraph edge ( land , names ): 3.0338
Key weight for textgraph edge ( land , names ): 6.2636
Value weight for textgraph edge ( land , names ): 9.4934
Query weight for textgraph edge ( valley , land ): 0.11537142857142858
Key weight for textgraph edge ( valley , land ): 0.11537142857142858
Value weight for textgraph edge ( valley , land ): 0.11537142857142858
Query weight for textgraph edge ( valley , valley ): 0.31668
Key weight for textgraph edge ( valley , valley ): 0.31668
Value weight for textgraph edge ( valley , valley ): 0.31668
Query weight for textgraph edge ( valley , names ): 0.5181914285714285
Key weight for textgraph edge ( valley , names ): 0.5181914285714285
Value weight for textgraph edge ( valley , names ): 0.5181914285714285
Query weight for textgraph edge ( names , land ): 3.02
Key weight for textgraph edge ( names , land ): 3.02
Value weight for textgraph edge ( names , land ): 3.02
Query weight for textgraph edge ( names , valley ): 4.038
Key weight for textgraph edge ( names , valley ): 4.038
Value weight for textgraph edge ( names , valley ): 4.038
Query weight for textgraph edge ( names , names ): 5.187
Key weight for textgraph edge ( names , names ): 5.187
Value weight for textgraph edge ( names , names ): 5.187
wikipedia search result: Valley of the Kings (film)
wikipedia search result summary: Valley of the Kings is a 1954 American Technicolor adventure film made by Metro-Goldwyn-Mayer. It was written and directed by Robert Pirosh from a screenplay by Robert Pirosh and Karl Tunberg, "suggested by historical data" in the book Gods, Graves and Scholars by C. W. Ceram. The music was by Mikls Rzsa and the cinematography by Robert Surtees.
2
defaultdict(<class 'list'>, {'land': ['valley'], 'photograph': ['film'], 'something': ['film'], 'film': ['film'], 'contains': ['valley'], 'kingdom': ['king'], 'long': ['valley'], 'ruler': ['king'], 'usually': ['valley'], 'river': ['valley'], 'make': ['film'], 'male': ['king'], 'sovereign': ['king'], 'depression': ['valley'], 'surface': ['valley']})
('definitiongraph networkx edges:', OutEdgeView([('land', 'valley'), ('valley', 'land'), ('valley', 'contains'), ('valley', 'long'), ('valley', 'usually'), ('valley', 'river'), ('valley', 'depression'), ('valley', 'surface'), ('photograph', 'film'), ('film', 'photograph'), ('film', 'something'), ('film', 'film'), ('film', 'make'), ('something', 'film'), ('contains', 'valley'), ('kingdom', 'king'), ('king', 'kingdom'), ('king', 'ruler'), ('king', 'male'), ('king', 'sovereign'), ('long', 'valley'), ('ruler', 'king'), ('usually', 'valley'), ('river', 'valley'), ('make', 'film'), ('male', 'king'), ('sovereign', 'king'), ('depression', 'valley'), ('surface', 'valley')]))
('Core number (sorted) :', [('land', 2), ('valley', 2), ('photograph', 2), ('film', 2), ('something', 2), ('contains', 2), ('kingdom', 2), ('king', 2), ('long', 2), ('ruler', 2), ('usually', 2), ('river', 2), ('make', 2), ('male', 2), ('sovereign', 2), ('depression', 2), ('surface', 2)])
=============================================================================================================
Unsupervised Classification based on top percentile Core numbers of the definition graph(subgraph of WordNet)
=============================================================================================================
('This document belongs to class:', 'land', ',core number=', 2)
('This document belongs to class:', 'valley', ',core number=', 2)
('This document belongs to class:', 'photograph', ',core number=', 2)
('This document belongs to class:', 'film', ',core number=', 2)
('This document belongs to class:', 'something', ',core number=', 2)
('This document belongs to class:', 'contains', ',core number=', 2)
('This document belongs to class:', 'kingdom', ',core number=', 2)
('This document belongs to class:', 'king', ',core number=', 2)
('This document belongs to class:', 'long', ',core number=', 2)
('This document belongs to class:', 'ruler', ',core number=', 2)
('\tmax_core_number', 2)
===================================================================
Betweenness Centrality of Recursive Gloss Overlap graph vertices
===================================================================
[('valley', 0.175), ('king', 0.05), ('film', 0.025), ('land', 0.0), ('photograph', 0.0), ('something', 0.0), ('contains', 0.0), ('kingdom', 0.0), ('long', 0.0), ('ruler', 0.0), ('usually', 0.0), ('river', 0.0), ('make', 0.0), ('male', 0.0), ('sovereign', 0.0), ('depression', 0.0), ('surface', 0.0)]
===================================================================
Closeness Centrality of Recursive Gloss Overlap graph vertices
===================================================================
[('valley', 0.4375), ('king', 0.25), ('land', 0.23557692307692307), ('contains', 0.23557692307692307), ('long', 0.23557692307692307), ('usually', 0.23557692307692307), ('river', 0.23557692307692307), ('depression', 0.23557692307692307), ('surface', 0.23557692307692307), ('film', 0.1875), ('kingdom', 0.14285714285714285), ('ruler', 0.14285714285714285), ('male', 0.14285714285714285), ('sovereign', 0.14285714285714285), ('photograph', 0.11249999999999999), ('something', 0.11249999999999999), ('make', 0.11249999999999999)]
===================================================================
Degree Centrality of Recursive Gloss Overlap graph vertices
===================================================================
[('valley', 0.875), ('king', 0.5), ('film', 0.375), ('land', 0.125), ('photograph', 0.125), ('something', 0.125), ('contains', 0.125), ('kingdom', 0.125), ('long', 0.125), ('ruler', 0.125), ('usually', 0.125), ('river', 0.125), ('make', 0.125), ('male', 0.125), ('sovereign', 0.125), ('depression', 0.125), ('surface', 0.125)]
===================================================================
Page Rank of the vertices of RGO Definition Graph (a form of Eigenvector Centrality)
===================================================================
[('valley', 0.22098383259560087), ('king', 0.1399036810036828), ('film', 0.11287696380637677), ('photograph', 0.04080571794689403), ('something', 0.04080571794689403), ('make', 0.04080571794689403), ('kingdom', 0.038553491513785176), ('ruler', 0.038553491513785176), ('male', 0.038553491513785176), ('sovereign', 0.038553491513785176), ('land', 0.03565777181407382), ('contains', 0.03565777181407382), ('long', 0.03565777181407382), ('usually', 0.03565777181407382), ('river', 0.03565777181407382), ('depression', 0.03565777181407382), ('surface', 0.03565777181407382)]
2
RecursiveGlossOverlapGraph(): textgraph =  [('land', 'valley'), ('valley', 'land'), ('valley', 'contains'), ('valley', 'long'), ('valley', 'usually'), ('valley', 'river'), ('valley', 'depression'), ('valley', 'surface'), ('photograph', 'film'), ('film', 'photograph'), ('film', 'something'), ('film', 'film'), ('film', 'make'), ('something', 'film'), ('contains', 'valley'), ('kingdom', 'king'), ('king', 'kingdom'), ('king', 'ruler'), ('king', 'male'), ('king', 'sovereign'), ('long', 'valley'), ('ruler', 'king'), ('usually', 'valley'), ('river', 'valley'), ('make', 'film'), ('male', 'king'), ('sovereign', 'king'), ('depression', 'valley'), ('surface', 'valley')]
Answer Textgraph  3 : ([('land', 2), ('valley', 2), ('photograph', 2), ('film', 2), ('something', 2), ('contains', 2), ('kingdom', 2), ('king', 2), ('long', 2), ('ruler', 2), ('usually', 2), ('river', 2), ('make', 2), ('male', 2), ('sovereign', 2), ('depression', 2), ('surface', 2)], [('valley', 0.22098383259560087), ('king', 0.1399036810036828), ('film', 0.11287696380637677), ('photograph', 0.04080571794689403), ('something', 0.04080571794689403), ('make', 0.04080571794689403), ('kingdom', 0.038553491513785176), ('ruler', 0.038553491513785176), ('male', 0.038553491513785176), ('sovereign', 0.038553491513785176), ('land', 0.03565777181407382), ('contains', 0.03565777181407382), ('long', 0.03565777181407382), ('usually', 0.03565777181407382), ('river', 0.03565777181407382), ('depression', 0.03565777181407382), ('surface', 0.03565777181407382)])
Attention from Definition Graph: [[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]]
Attention slice from Definition Graph: [[0.5, 0.5, 0.5], [0.07142857142857142, 0.07142857142857142, 0.07142857142857142], [0.5, 0.5, 0.5]]
weights: [1, 2, 3]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  1.012
LinearPerceptronGradient() weight update iteration: deltaw =  [0.12000000000000002, 0.13200000000000003, 0.33799999999999997]
weights: [1.012, 2, 3]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  2.0132
LinearPerceptronGradient() weight update iteration: deltaw =  [0.12000000000000002, 0.13200000000000003, 0.33799999999999997]
weights: [1.012, 2.0132, 3]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  3.0338
LinearPerceptronGradient() weight update iteration: deltaw =  [0.12000000000000002, 0.13200000000000003, 0.33799999999999997]
weights updated after Gradient :  [1.012, 2.0132, 3.0338]
converged: True
weights: [0.1, 0.3, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.07142857142857142, 0.07142857142857142, 0.07142857142857142]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  0.11537142857142858
LinearPerceptronGradient() weight update iteration: deltaw =  [0.15371428571428575, 0.16680000000000003, 0.18191428571428575]
weights: [0.11537142857142858, 0.3, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.07142857142857142, 0.07142857142857142, 0.07142857142857142]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  0.31668
LinearPerceptronGradient() weight update iteration: deltaw =  [0.15371428571428575, 0.16680000000000003, 0.18191428571428575]
weights: [0.11537142857142858, 0.31668, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.07142857142857142, 0.07142857142857142, 0.07142857142857142]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  0.5181914285714285
LinearPerceptronGradient() weight update iteration: deltaw =  [0.15371428571428575, 0.16680000000000003, 0.18191428571428575]
weights updated after Gradient :  [0.11537142857142858, 0.31668, 0.5181914285714285]
converged: True
weights: [3, 4, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  3.02
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights: [3.02, 4, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  4.038
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights: [3.02, 4.038, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  5.187
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights updated after Gradient :  [3.02, 4.038, 5.187]
converged: True
Learnt Query Weights: [[1.012, 2.0132, 3.0338], [0.11537142857142858, 0.31668, 0.5181914285714285], [3.02, 4.038, 5.187]]
weights: [4, 5, 6]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  4.024
LinearPerceptronGradient() weight update iteration: deltaw =  [0.24000000000000005, 0.504, 2.636]
weights: [4.024, 5, 6]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  5.0504
LinearPerceptronGradient() weight update iteration: deltaw =  [0.24000000000000005, 0.504, 2.636]
weights: [4.024, 5.0504, 6]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  6.2636
LinearPerceptronGradient() weight update iteration: deltaw =  [0.24000000000000005, 0.504, 2.636]
weights updated after Gradient :  [4.024, 5.0504, 6.2636]
converged: True
weights: [0.1, 0.3, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.07142857142857142, 0.07142857142857142, 0.07142857142857142]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  0.11537142857142858
LinearPerceptronGradient() weight update iteration: deltaw =  [0.15371428571428575, 0.16680000000000003, 0.18191428571428575]
weights: [0.11537142857142858, 0.3, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.07142857142857142, 0.07142857142857142, 0.07142857142857142]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  0.31668
LinearPerceptronGradient() weight update iteration: deltaw =  [0.15371428571428575, 0.16680000000000003, 0.18191428571428575]
weights: [0.11537142857142858, 0.31668, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.07142857142857142, 0.07142857142857142, 0.07142857142857142]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  0.5181914285714285
LinearPerceptronGradient() weight update iteration: deltaw =  [0.15371428571428575, 0.16680000000000003, 0.18191428571428575]
weights updated after Gradient :  [0.11537142857142858, 0.31668, 0.5181914285714285]
converged: True
weights: [3, 4, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  3.02
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights: [3.02, 4, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  4.038
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights: [3.02, 4.038, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  5.187
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights updated after Gradient :  [3.02, 4.038, 5.187]
converged: True
Learnt Key Weights: [[4.024, 5.0504, 6.2636], [0.11537142857142858, 0.31668, 0.5181914285714285], [3.02, 4.038, 5.187]]
weights: [7, 8, 9]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  7.036
LinearPerceptronGradient() weight update iteration: deltaw =  [0.36, 0.876, 4.934]
weights: [7.036, 8, 9]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  8.0876
LinearPerceptronGradient() weight update iteration: deltaw =  [0.36, 0.876, 4.934]
weights: [7.036, 8.0876, 9]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  9.4934
LinearPerceptronGradient() weight update iteration: deltaw =  [0.36, 0.876, 4.934]
weights updated after Gradient :  [7.036, 8.0876, 9.4934]
converged: True
weights: [0.1, 0.3, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.07142857142857142, 0.07142857142857142, 0.07142857142857142]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  0.11537142857142858
LinearPerceptronGradient() weight update iteration: deltaw =  [0.15371428571428575, 0.16680000000000003, 0.18191428571428575]
weights: [0.11537142857142858, 0.3, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.07142857142857142, 0.07142857142857142, 0.07142857142857142]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  0.31668
LinearPerceptronGradient() weight update iteration: deltaw =  [0.15371428571428575, 0.16680000000000003, 0.18191428571428575]
weights: [0.11537142857142858, 0.31668, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.07142857142857142, 0.07142857142857142, 0.07142857142857142]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  0.5181914285714285
LinearPerceptronGradient() weight update iteration: deltaw =  [0.15371428571428575, 0.16680000000000003, 0.18191428571428575]
weights updated after Gradient :  [0.11537142857142858, 0.31668, 0.5181914285714285]
converged: True
weights: [3, 4, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  3.02
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights: [3.02, 4, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  4.038
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights: [3.02, 4.038, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  5.187
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights updated after Gradient :  [3.02, 4.038, 5.187]
converged: True
Learnt Values Weights: [[7.036, 8.0876, 9.4934], [0.11537142857142858, 0.31668, 0.5181914285714285], [3.02, 4.038, 5.187]]
Query weight for textgraph edge ( land , land ): 1.012
Key weight for textgraph edge ( land , land ): 4.024
Value weight for textgraph edge ( land , land ): 7.036
Query weight for textgraph edge ( land , valley ): 2.0132
Key weight for textgraph edge ( land , valley ): 5.0504
Value weight for textgraph edge ( land , valley ): 8.0876
Query weight for textgraph edge ( land , photograph ): 3.0338
Key weight for textgraph edge ( land , photograph ): 6.2636
Value weight for textgraph edge ( land , photograph ): 9.4934
Query weight for textgraph edge ( valley , land ): 0.11537142857142858
Key weight for textgraph edge ( valley , land ): 0.11537142857142858
Value weight for textgraph edge ( valley , land ): 0.11537142857142858
Query weight for textgraph edge ( valley , valley ): 0.31668
Key weight for textgraph edge ( valley , valley ): 0.31668
Value weight for textgraph edge ( valley , valley ): 0.31668
Query weight for textgraph edge ( valley , photograph ): 0.5181914285714285
Key weight for textgraph edge ( valley , photograph ): 0.5181914285714285
Value weight for textgraph edge ( valley , photograph ): 0.5181914285714285
Query weight for textgraph edge ( photograph , land ): 3.02
Key weight for textgraph edge ( photograph , land ): 3.02
Value weight for textgraph edge ( photograph , land ): 3.02
Query weight for textgraph edge ( photograph , valley ): 4.038
Key weight for textgraph edge ( photograph , valley ): 4.038
Value weight for textgraph edge ( photograph , valley ): 4.038
Query weight for textgraph edge ( photograph , photograph ): 5.187
Key weight for textgraph edge ( photograph , photograph ): 5.187
Value weight for textgraph edge ( photograph , photograph ): 5.187
wikipedia search result: Valley of the Queens
wikipedia search result summary: The Valley of the Queens (Arabic:   Wd al Malekt) is a site in Egypt, where the wives of pharaohs were buried in ancient times. It was known then as Ta-Set-Neferu, meaning "the place of beauty". It was most famous for being the burial site of many wives of Pharaohs. Pharaohs themselves were buried in the Valley of the Kings.Using the limits described by Christian Leblanc, the Valley of the Queens consists of the main wadi, which contains most of the tombs, along with the Valley of Prince Ahmose, the Valley of the Rope, the Valley of the Three Pits, and the Valley of the Dolmen. The main wadi contains 91 tombs and the subsidiary valleys add another 19 tombs. The burials in the subsidiary valleys all date to the 18th Dynasty.The reason for choosing the Valley of the Queens as a burial site is not known. The close proximity to the workers' village of Deir el-Medina and the Valley of the Kings may have been a factor. Another consideration could have been the existence of a sacred grotto dedicated to Hathor at the entrance of the Valley. This grotto may have been associated with rejuvenation of the dead.Along with the Valley of the Kings and nearby Thebes, the Valley of the Queens was inscribed on the UNESCO World Heritage List in 1979.
2
defaultdict(<class 'list'>, {'land': ['valley'], 'contains': ['valley'], 'borough': ['Queens'], 'long': ['valley'], 'City': ['Queens'], 'usually': ['valley'], 'river': ['valley'], 'New': ['Queens'], 'York': ['Queens'], 'depression': ['valley'], 'surface': ['valley']})
('definitiongraph networkx edges:', OutEdgeView([('land', 'valley'), ('valley', 'land'), ('valley', 'contains'), ('valley', 'long'), ('valley', 'usually'), ('valley', 'river'), ('valley', 'depression'), ('valley', 'surface'), ('contains', 'valley'), ('borough', 'Queens'), ('Queens', 'borough'), ('Queens', 'City'), ('Queens', 'New'), ('Queens', 'York'), ('long', 'valley'), ('City', 'Queens'), ('usually', 'valley'), ('river', 'valley'), ('New', 'Queens'), ('York', 'Queens'), ('depression', 'valley'), ('surface', 'valley')]))
('Core number (sorted) :', [('land', 2), ('valley', 2), ('contains', 2), ('borough', 2), ('Queens', 2), ('long', 2), ('City', 2), ('usually', 2), ('river', 2), ('New', 2), ('York', 2), ('depression', 2), ('surface', 2)])
=============================================================================================================
Unsupervised Classification based on top percentile Core numbers of the definition graph(subgraph of WordNet)
=============================================================================================================
('This document belongs to class:', 'land', ',core number=', 2)
('This document belongs to class:', 'valley', ',core number=', 2)
('This document belongs to class:', 'contains', ',core number=', 2)
('This document belongs to class:', 'borough', ',core number=', 2)
('This document belongs to class:', 'Queens', ',core number=', 2)
('This document belongs to class:', 'long', ',core number=', 2)
('This document belongs to class:', 'City', ',core number=', 2)
('This document belongs to class:', 'usually', ',core number=', 2)
('\tmax_core_number', 2)
===================================================================
Betweenness Centrality of Recursive Gloss Overlap graph vertices
===================================================================
[('valley', 0.3181818181818182), ('Queens', 0.09090909090909091), ('land', 0.0), ('contains', 0.0), ('borough', 0.0), ('long', 0.0), ('City', 0.0), ('usually', 0.0), ('river', 0.0), ('New', 0.0), ('York', 0.0), ('depression', 0.0), ('surface', 0.0)]
===================================================================
Closeness Centrality of Recursive Gloss Overlap graph vertices
===================================================================
[('valley', 0.5833333333333334), ('Queens', 0.3333333333333333), ('land', 0.3141025641025641), ('contains', 0.3141025641025641), ('long', 0.3141025641025641), ('usually', 0.3141025641025641), ('river', 0.3141025641025641), ('depression', 0.3141025641025641), ('surface', 0.3141025641025641), ('borough', 0.19047619047619047), ('City', 0.19047619047619047), ('New', 0.19047619047619047), ('York', 0.19047619047619047)]
===================================================================
Degree Centrality of Recursive Gloss Overlap graph vertices
===================================================================
[('valley', 1.1666666666666665), ('Queens', 0.6666666666666666), ('land', 0.16666666666666666), ('contains', 0.16666666666666666), ('borough', 0.16666666666666666), ('long', 0.16666666666666666), ('City', 0.16666666666666666), ('usually', 0.16666666666666666), ('river', 0.16666666666666666), ('New', 0.16666666666666666), ('York', 0.16666666666666666), ('depression', 0.16666666666666666), ('surface', 0.16666666666666666)]
===================================================================
Page Rank of the vertices of RGO Definition Graph (a form of Eigenvector Centrality)
===================================================================
[('valley', 0.2889795326042667), ('Queens', 0.18295130476367186), ('borough', 0.05041601996292819), ('City', 0.05041601996292819), ('New', 0.05041601996292819), ('York', 0.05041601996292819), ('land', 0.0466292975400498), ('contains', 0.0466292975400498), ('long', 0.0466292975400498), ('usually', 0.0466292975400498), ('river', 0.0466292975400498), ('depression', 0.0466292975400498), ('surface', 0.0466292975400498)]
2
RecursiveGlossOverlapGraph(): textgraph =  [('land', 'valley'), ('valley', 'land'), ('valley', 'contains'), ('valley', 'long'), ('valley', 'usually'), ('valley', 'river'), ('valley', 'depression'), ('valley', 'surface'), ('contains', 'valley'), ('borough', 'Queens'), ('Queens', 'borough'), ('Queens', 'City'), ('Queens', 'New'), ('Queens', 'York'), ('long', 'valley'), ('City', 'Queens'), ('usually', 'valley'), ('river', 'valley'), ('New', 'Queens'), ('York', 'Queens'), ('depression', 'valley'), ('surface', 'valley')]
Answer Textgraph  4 : ([('land', 2), ('valley', 2), ('contains', 2), ('borough', 2), ('Queens', 2), ('long', 2), ('City', 2), ('usually', 2), ('river', 2), ('New', 2), ('York', 2), ('depression', 2), ('surface', 2)], [('valley', 0.2889795326042667), ('Queens', 0.18295130476367186), ('borough', 0.05041601996292819), ('City', 0.05041601996292819), ('New', 0.05041601996292819), ('York', 0.05041601996292819), ('land', 0.0466292975400498), ('contains', 0.0466292975400498), ('long', 0.0466292975400498), ('usually', 0.0466292975400498), ('river', 0.0466292975400498), ('depression', 0.0466292975400498), ('surface', 0.0466292975400498)])
Attention from Definition Graph: [[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]]
Attention slice from Definition Graph: [[0.5, 0.5, 0.5], [0.07142857142857142, 0.07142857142857142, 0.07142857142857142], [0.5, 0.5, 0.5]]
weights: [1, 2, 3]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  1.012
LinearPerceptronGradient() weight update iteration: deltaw =  [0.12000000000000002, 0.13200000000000003, 0.33799999999999997]
weights: [1.012, 2, 3]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  2.0132
LinearPerceptronGradient() weight update iteration: deltaw =  [0.12000000000000002, 0.13200000000000003, 0.33799999999999997]
weights: [1.012, 2.0132, 3]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  3.0338
LinearPerceptronGradient() weight update iteration: deltaw =  [0.12000000000000002, 0.13200000000000003, 0.33799999999999997]
weights updated after Gradient :  [1.012, 2.0132, 3.0338]
converged: True
weights: [0.1, 0.3, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.07142857142857142, 0.07142857142857142, 0.07142857142857142]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  0.11537142857142858
LinearPerceptronGradient() weight update iteration: deltaw =  [0.15371428571428575, 0.16680000000000003, 0.18191428571428575]
weights: [0.11537142857142858, 0.3, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.07142857142857142, 0.07142857142857142, 0.07142857142857142]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  0.31668
LinearPerceptronGradient() weight update iteration: deltaw =  [0.15371428571428575, 0.16680000000000003, 0.18191428571428575]
weights: [0.11537142857142858, 0.31668, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.07142857142857142, 0.07142857142857142, 0.07142857142857142]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  0.5181914285714285
LinearPerceptronGradient() weight update iteration: deltaw =  [0.15371428571428575, 0.16680000000000003, 0.18191428571428575]
weights updated after Gradient :  [0.11537142857142858, 0.31668, 0.5181914285714285]
converged: True
weights: [3, 4, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  3.02
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights: [3.02, 4, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  4.038
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights: [3.02, 4.038, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  5.187
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights updated after Gradient :  [3.02, 4.038, 5.187]
converged: True
Learnt Query Weights: [[1.012, 2.0132, 3.0338], [0.11537142857142858, 0.31668, 0.5181914285714285], [3.02, 4.038, 5.187]]
weights: [4, 5, 6]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  4.024
LinearPerceptronGradient() weight update iteration: deltaw =  [0.24000000000000005, 0.504, 2.636]
weights: [4.024, 5, 6]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  5.0504
LinearPerceptronGradient() weight update iteration: deltaw =  [0.24000000000000005, 0.504, 2.636]
weights: [4.024, 5.0504, 6]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  6.2636
LinearPerceptronGradient() weight update iteration: deltaw =  [0.24000000000000005, 0.504, 2.636]
weights updated after Gradient :  [4.024, 5.0504, 6.2636]
converged: True
weights: [0.1, 0.3, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.07142857142857142, 0.07142857142857142, 0.07142857142857142]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  0.11537142857142858
LinearPerceptronGradient() weight update iteration: deltaw =  [0.15371428571428575, 0.16680000000000003, 0.18191428571428575]
weights: [0.11537142857142858, 0.3, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.07142857142857142, 0.07142857142857142, 0.07142857142857142]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  0.31668
LinearPerceptronGradient() weight update iteration: deltaw =  [0.15371428571428575, 0.16680000000000003, 0.18191428571428575]
weights: [0.11537142857142858, 0.31668, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.07142857142857142, 0.07142857142857142, 0.07142857142857142]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  0.5181914285714285
LinearPerceptronGradient() weight update iteration: deltaw =  [0.15371428571428575, 0.16680000000000003, 0.18191428571428575]
weights updated after Gradient :  [0.11537142857142858, 0.31668, 0.5181914285714285]
converged: True
weights: [3, 4, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  3.02
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights: [3.02, 4, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  4.038
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights: [3.02, 4.038, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  5.187
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights updated after Gradient :  [3.02, 4.038, 5.187]
converged: True
Learnt Key Weights: [[4.024, 5.0504, 6.2636], [0.11537142857142858, 0.31668, 0.5181914285714285], [3.02, 4.038, 5.187]]
weights: [7, 8, 9]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  7.036
LinearPerceptronGradient() weight update iteration: deltaw =  [0.36, 0.876, 4.934]
weights: [7.036, 8, 9]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  8.0876
LinearPerceptronGradient() weight update iteration: deltaw =  [0.36, 0.876, 4.934]
weights: [7.036, 8.0876, 9]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  9.4934
LinearPerceptronGradient() weight update iteration: deltaw =  [0.36, 0.876, 4.934]
weights updated after Gradient :  [7.036, 8.0876, 9.4934]
converged: True
weights: [0.1, 0.3, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.07142857142857142, 0.07142857142857142, 0.07142857142857142]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  0.11537142857142858
LinearPerceptronGradient() weight update iteration: deltaw =  [0.15371428571428575, 0.16680000000000003, 0.18191428571428575]
weights: [0.11537142857142858, 0.3, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.07142857142857142, 0.07142857142857142, 0.07142857142857142]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  0.31668
LinearPerceptronGradient() weight update iteration: deltaw =  [0.15371428571428575, 0.16680000000000003, 0.18191428571428575]
weights: [0.11537142857142858, 0.31668, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.07142857142857142, 0.07142857142857142, 0.07142857142857142]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  0.5181914285714285
LinearPerceptronGradient() weight update iteration: deltaw =  [0.15371428571428575, 0.16680000000000003, 0.18191428571428575]
weights updated after Gradient :  [0.11537142857142858, 0.31668, 0.5181914285714285]
converged: True
weights: [3, 4, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  3.02
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights: [3.02, 4, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  4.038
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights: [3.02, 4.038, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  5.187
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights updated after Gradient :  [3.02, 4.038, 5.187]
converged: True
Learnt Values Weights: [[7.036, 8.0876, 9.4934], [0.11537142857142858, 0.31668, 0.5181914285714285], [3.02, 4.038, 5.187]]
Query weight for textgraph edge ( land , land ): 1.012
Key weight for textgraph edge ( land , land ): 4.024
Value weight for textgraph edge ( land , land ): 7.036
Query weight for textgraph edge ( land , valley ): 2.0132
Key weight for textgraph edge ( land , valley ): 5.0504
Value weight for textgraph edge ( land , valley ): 8.0876
Query weight for textgraph edge ( land , contains ): 3.0338
Key weight for textgraph edge ( land , contains ): 6.2636
Value weight for textgraph edge ( land , contains ): 9.4934
Query weight for textgraph edge ( valley , land ): 0.11537142857142858
Key weight for textgraph edge ( valley , land ): 0.11537142857142858
Value weight for textgraph edge ( valley , land ): 0.11537142857142858
Query weight for textgraph edge ( valley , valley ): 0.31668
Key weight for textgraph edge ( valley , valley ): 0.31668
Value weight for textgraph edge ( valley , valley ): 0.31668
Query weight for textgraph edge ( valley , contains ): 0.5181914285714285
Key weight for textgraph edge ( valley , contains ): 0.5181914285714285
Value weight for textgraph edge ( valley , contains ): 0.5181914285714285
Query weight for textgraph edge ( contains , land ): 3.02
Key weight for textgraph edge ( contains , land ): 3.02
Value weight for textgraph edge ( contains , land ): 3.02
Query weight for textgraph edge ( contains , valley ): 4.038
Key weight for textgraph edge ( contains , valley ): 4.038
Value weight for textgraph edge ( contains , valley ): 4.038
Query weight for textgraph edge ( contains , contains ): 5.187
Key weight for textgraph edge ( contains , contains ): 5.187
Value weight for textgraph edge ( contains , contains ): 5.187
wikipedia search result: Valley of the Kings (Tibet)
Exception
2
defaultdict(<class 'list'>, {'land': ['valley'], 'region': ['Tibet'], 'contains': ['valley'], 'ruler': ['king'], 'usually': ['valley'], 'river': ['valley'], 'Peoples': ['Tibet'], 'male': ['king'], 'located': ['Tibet'], 'surface': ['valley'], 'China': ['Tibet'], 'kingdom': ['king'], 'Himalayas': ['Tibet'], 'long': ['valley'], 'Republic': ['Tibet'], 'autonomous': ['Tibet'], 'sovereign': ['king'], 'depression': ['valley']})
('definitiongraph networkx edges:', OutEdgeView([('land', 'valley'), ('valley', 'land'), ('valley', 'contains'), ('valley', 'usually'), ('valley', 'river'), ('valley', 'surface'), ('valley', 'long'), ('valley', 'depression'), ('region', 'Tibet'), ('Tibet', 'region'), ('Tibet', 'Peoples'), ('Tibet', 'located'), ('Tibet', 'China'), ('Tibet', 'Himalayas'), ('Tibet', 'Republic'), ('Tibet', 'autonomous'), ('contains', 'valley'), ('ruler', 'king'), ('king', 'ruler'), ('king', 'male'), ('king', 'kingdom'), ('king', 'sovereign'), ('usually', 'valley'), ('river', 'valley'), ('Peoples', 'Tibet'), ('male', 'king'), ('located', 'Tibet'), ('surface', 'valley'), ('China', 'Tibet'), ('kingdom', 'king'), ('Himalayas', 'Tibet'), ('long', 'valley'), ('Republic', 'Tibet'), ('autonomous', 'Tibet'), ('sovereign', 'king'), ('depression', 'valley')]))
('Core number (sorted) :', [('land', 2), ('valley', 2), ('region', 2), ('Tibet', 2), ('contains', 2), ('ruler', 2), ('king', 2), ('usually', 2), ('river', 2), ('Peoples', 2), ('male', 2), ('located', 2), ('surface', 2), ('China', 2), ('kingdom', 2), ('Himalayas', 2), ('long', 2), ('Republic', 2), ('autonomous', 2), ('sovereign', 2), ('depression', 2)])
=============================================================================================================
Unsupervised Classification based on top percentile Core numbers of the definition graph(subgraph of WordNet)
=============================================================================================================
('This document belongs to class:', 'land', ',core number=', 2)
('This document belongs to class:', 'valley', ',core number=', 2)
('This document belongs to class:', 'region', ',core number=', 2)
('This document belongs to class:', 'Tibet', ',core number=', 2)
('This document belongs to class:', 'contains', ',core number=', 2)
('This document belongs to class:', 'ruler', ',core number=', 2)
('This document belongs to class:', 'king', ',core number=', 2)
('This document belongs to class:', 'usually', ',core number=', 2)
('This document belongs to class:', 'river', ',core number=', 2)
('This document belongs to class:', 'Peoples', ',core number=', 2)
('This document belongs to class:', 'male', ',core number=', 2)
('This document belongs to class:', 'located', ',core number=', 2)
('\tmax_core_number', 2)
===================================================================
Betweenness Centrality of Recursive Gloss Overlap graph vertices
===================================================================
[('valley', 0.11052631578947368), ('Tibet', 0.11052631578947368), ('king', 0.031578947368421054), ('land', 0.0), ('region', 0.0), ('contains', 0.0), ('ruler', 0.0), ('usually', 0.0), ('river', 0.0), ('Peoples', 0.0), ('male', 0.0), ('located', 0.0), ('surface', 0.0), ('China', 0.0), ('kingdom', 0.0), ('Himalayas', 0.0), ('long', 0.0), ('Republic', 0.0), ('autonomous', 0.0), ('sovereign', 0.0), ('depression', 0.0)]
===================================================================
Closeness Centrality of Recursive Gloss Overlap graph vertices
===================================================================
[('valley', 0.35), ('Tibet', 0.35), ('king', 0.2), ('land', 0.18846153846153843), ('region', 0.18846153846153843), ('contains', 0.18846153846153843), ('usually', 0.18846153846153843), ('river', 0.18846153846153843), ('Peoples', 0.18846153846153843), ('located', 0.18846153846153843), ('surface', 0.18846153846153843), ('China', 0.18846153846153843), ('Himalayas', 0.18846153846153843), ('long', 0.18846153846153843), ('Republic', 0.18846153846153843), ('autonomous', 0.18846153846153843), ('depression', 0.18846153846153843), ('ruler', 0.11428571428571428), ('male', 0.11428571428571428), ('kingdom', 0.11428571428571428), ('sovereign', 0.11428571428571428)]
===================================================================
Degree Centrality of Recursive Gloss Overlap graph vertices
===================================================================
[('valley', 0.7000000000000001), ('Tibet', 0.7000000000000001), ('king', 0.4), ('land', 0.1), ('region', 0.1), ('contains', 0.1), ('ruler', 0.1), ('usually', 0.1), ('river', 0.1), ('Peoples', 0.1), ('male', 0.1), ('located', 0.1), ('surface', 0.1), ('China', 0.1), ('kingdom', 0.1), ('Himalayas', 0.1), ('long', 0.1), ('Republic', 0.1), ('autonomous', 0.1), ('sovereign', 0.1), ('depression', 0.1)]
===================================================================
Page Rank of the vertices of RGO Definition Graph (a form of Eigenvector Centrality)
===================================================================
[('valley', 0.1788949493487275), ('Tibet', 0.1788949493487275), ('king', 0.11325699848388751), ('ruler', 0.031209559902837636), ('male', 0.031209559902837636), ('kingdom', 0.031209559902837636), ('sovereign', 0.031209559902837636), ('land', 0.02886534737195049), ('region', 0.02886534737195049), ('contains', 0.02886534737195049), ('usually', 0.02886534737195049), ('river', 0.02886534737195049), ('Peoples', 0.02886534737195049), ('located', 0.02886534737195049), ('surface', 0.02886534737195049), ('China', 0.02886534737195049), ('Himalayas', 0.02886534737195049), ('long', 0.02886534737195049), ('Republic', 0.02886534737195049), ('autonomous', 0.02886534737195049), ('depression', 0.02886534737195049)]
2
RecursiveGlossOverlapGraph(): textgraph =  [('land', 'valley'), ('valley', 'land'), ('valley', 'contains'), ('valley', 'usually'), ('valley', 'river'), ('valley', 'surface'), ('valley', 'long'), ('valley', 'depression'), ('region', 'Tibet'), ('Tibet', 'region'), ('Tibet', 'Peoples'), ('Tibet', 'located'), ('Tibet', 'China'), ('Tibet', 'Himalayas'), ('Tibet', 'Republic'), ('Tibet', 'autonomous'), ('contains', 'valley'), ('ruler', 'king'), ('king', 'ruler'), ('king', 'male'), ('king', 'kingdom'), ('king', 'sovereign'), ('usually', 'valley'), ('river', 'valley'), ('Peoples', 'Tibet'), ('male', 'king'), ('located', 'Tibet'), ('surface', 'valley'), ('China', 'Tibet'), ('kingdom', 'king'), ('Himalayas', 'Tibet'), ('long', 'valley'), ('Republic', 'Tibet'), ('autonomous', 'Tibet'), ('sovereign', 'king'), ('depression', 'valley')]
Answer Textgraph  5 : ([('land', 2), ('valley', 2), ('region', 2), ('Tibet', 2), ('contains', 2), ('ruler', 2), ('king', 2), ('usually', 2), ('river', 2), ('Peoples', 2), ('male', 2), ('located', 2), ('surface', 2), ('China', 2), ('kingdom', 2), ('Himalayas', 2), ('long', 2), ('Republic', 2), ('autonomous', 2), ('sovereign', 2), ('depression', 2)], [('valley', 0.1788949493487275), ('Tibet', 0.1788949493487275), ('king', 0.11325699848388751), ('ruler', 0.031209559902837636), ('male', 0.031209559902837636), ('kingdom', 0.031209559902837636), ('sovereign', 0.031209559902837636), ('land', 0.02886534737195049), ('region', 0.02886534737195049), ('contains', 0.02886534737195049), ('usually', 0.02886534737195049), ('river', 0.02886534737195049), ('Peoples', 0.02886534737195049), ('located', 0.02886534737195049), ('surface', 0.02886534737195049), ('China', 0.02886534737195049), ('Himalayas', 0.02886534737195049), ('long', 0.02886534737195049), ('Republic', 0.02886534737195049), ('autonomous', 0.02886534737195049), ('depression', 0.02886534737195049)])
Attention from Definition Graph: [[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]]
Attention slice from Definition Graph: [[0.5, 0.5, 0.5], [0.07142857142857142, 0.07142857142857142, 0.07142857142857142], [0.5, 0.5, 0.5]]
weights: [1, 2, 3]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  1.012
LinearPerceptronGradient() weight update iteration: deltaw =  [0.12000000000000002, 0.13200000000000003, 0.33799999999999997]
weights: [1.012, 2, 3]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  2.0132
LinearPerceptronGradient() weight update iteration: deltaw =  [0.12000000000000002, 0.13200000000000003, 0.33799999999999997]
weights: [1.012, 2.0132, 3]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  3.0338
LinearPerceptronGradient() weight update iteration: deltaw =  [0.12000000000000002, 0.13200000000000003, 0.33799999999999997]
weights updated after Gradient :  [1.012, 2.0132, 3.0338]
converged: True
weights: [0.1, 0.3, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.07142857142857142, 0.07142857142857142, 0.07142857142857142]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  0.11537142857142858
LinearPerceptronGradient() weight update iteration: deltaw =  [0.15371428571428575, 0.16680000000000003, 0.18191428571428575]
weights: [0.11537142857142858, 0.3, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.07142857142857142, 0.07142857142857142, 0.07142857142857142]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  0.31668
LinearPerceptronGradient() weight update iteration: deltaw =  [0.15371428571428575, 0.16680000000000003, 0.18191428571428575]
weights: [0.11537142857142858, 0.31668, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.07142857142857142, 0.07142857142857142, 0.07142857142857142]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  0.5181914285714285
LinearPerceptronGradient() weight update iteration: deltaw =  [0.15371428571428575, 0.16680000000000003, 0.18191428571428575]
weights updated after Gradient :  [0.11537142857142858, 0.31668, 0.5181914285714285]
converged: True
weights: [3, 4, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  3.02
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights: [3.02, 4, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  4.038
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights: [3.02, 4.038, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  5.187
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights updated after Gradient :  [3.02, 4.038, 5.187]
converged: True
Learnt Query Weights: [[1.012, 2.0132, 3.0338], [0.11537142857142858, 0.31668, 0.5181914285714285], [3.02, 4.038, 5.187]]
weights: [4, 5, 6]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  4.024
LinearPerceptronGradient() weight update iteration: deltaw =  [0.24000000000000005, 0.504, 2.636]
weights: [4.024, 5, 6]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  5.0504
LinearPerceptronGradient() weight update iteration: deltaw =  [0.24000000000000005, 0.504, 2.636]
weights: [4.024, 5.0504, 6]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  6.2636
LinearPerceptronGradient() weight update iteration: deltaw =  [0.24000000000000005, 0.504, 2.636]
weights updated after Gradient :  [4.024, 5.0504, 6.2636]
converged: True
weights: [0.1, 0.3, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.07142857142857142, 0.07142857142857142, 0.07142857142857142]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  0.11537142857142858
LinearPerceptronGradient() weight update iteration: deltaw =  [0.15371428571428575, 0.16680000000000003, 0.18191428571428575]
weights: [0.11537142857142858, 0.3, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.07142857142857142, 0.07142857142857142, 0.07142857142857142]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  0.31668
LinearPerceptronGradient() weight update iteration: deltaw =  [0.15371428571428575, 0.16680000000000003, 0.18191428571428575]
weights: [0.11537142857142858, 0.31668, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.07142857142857142, 0.07142857142857142, 0.07142857142857142]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  0.5181914285714285
LinearPerceptronGradient() weight update iteration: deltaw =  [0.15371428571428575, 0.16680000000000003, 0.18191428571428575]
weights updated after Gradient :  [0.11537142857142858, 0.31668, 0.5181914285714285]
converged: True
weights: [3, 4, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  3.02
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights: [3.02, 4, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  4.038
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights: [3.02, 4.038, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  5.187
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights updated after Gradient :  [3.02, 4.038, 5.187]
converged: True
Learnt Key Weights: [[4.024, 5.0504, 6.2636], [0.11537142857142858, 0.31668, 0.5181914285714285], [3.02, 4.038, 5.187]]
weights: [7, 8, 9]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  7.036
LinearPerceptronGradient() weight update iteration: deltaw =  [0.36, 0.876, 4.934]
weights: [7.036, 8, 9]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  8.0876
LinearPerceptronGradient() weight update iteration: deltaw =  [0.36, 0.876, 4.934]
weights: [7.036, 8.0876, 9]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  9.4934
LinearPerceptronGradient() weight update iteration: deltaw =  [0.36, 0.876, 4.934]
weights updated after Gradient :  [7.036, 8.0876, 9.4934]
converged: True
weights: [0.1, 0.3, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.07142857142857142, 0.07142857142857142, 0.07142857142857142]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  0.11537142857142858
LinearPerceptronGradient() weight update iteration: deltaw =  [0.15371428571428575, 0.16680000000000003, 0.18191428571428575]
weights: [0.11537142857142858, 0.3, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.07142857142857142, 0.07142857142857142, 0.07142857142857142]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  0.31668
LinearPerceptronGradient() weight update iteration: deltaw =  [0.15371428571428575, 0.16680000000000003, 0.18191428571428575]
weights: [0.11537142857142858, 0.31668, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.07142857142857142, 0.07142857142857142, 0.07142857142857142]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  0.5181914285714285
LinearPerceptronGradient() weight update iteration: deltaw =  [0.15371428571428575, 0.16680000000000003, 0.18191428571428575]
weights updated after Gradient :  [0.11537142857142858, 0.31668, 0.5181914285714285]
converged: True
weights: [3, 4, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  3.02
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights: [3.02, 4, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  4.038
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights: [3.02, 4.038, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  5.187
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights updated after Gradient :  [3.02, 4.038, 5.187]
converged: True
Learnt Values Weights: [[7.036, 8.0876, 9.4934], [0.11537142857142858, 0.31668, 0.5181914285714285], [3.02, 4.038, 5.187]]
Query weight for textgraph edge ( land , land ): 1.012
Key weight for textgraph edge ( land , land ): 4.024
Value weight for textgraph edge ( land , land ): 7.036
Query weight for textgraph edge ( land , valley ): 2.0132
Key weight for textgraph edge ( land , valley ): 5.0504
Value weight for textgraph edge ( land , valley ): 8.0876
Query weight for textgraph edge ( land , region ): 3.0338
Key weight for textgraph edge ( land , region ): 6.2636
Value weight for textgraph edge ( land , region ): 9.4934
Query weight for textgraph edge ( valley , land ): 0.11537142857142858
Key weight for textgraph edge ( valley , land ): 0.11537142857142858
Value weight for textgraph edge ( valley , land ): 0.11537142857142858
Query weight for textgraph edge ( valley , valley ): 0.31668
Key weight for textgraph edge ( valley , valley ): 0.31668
Value weight for textgraph edge ( valley , valley ): 0.31668
Query weight for textgraph edge ( valley , region ): 0.5181914285714285
Key weight for textgraph edge ( valley , region ): 0.5181914285714285
Value weight for textgraph edge ( valley , region ): 0.5181914285714285
Query weight for textgraph edge ( region , land ): 3.02
Key weight for textgraph edge ( region , land ): 3.02
Value weight for textgraph edge ( region , land ): 3.02
Query weight for textgraph edge ( region , valley ): 4.038
Key weight for textgraph edge ( region , valley ): 4.038
Value weight for textgraph edge ( region , valley ): 4.038
Query weight for textgraph edge ( region , region ): 5.187
Key weight for textgraph edge ( region , region ): 5.187
Value weight for textgraph edge ( region , region ): 5.187
wikipedia search result: Kings Canyon National Park
wikipedia search result summary: Kings Canyon National Park is an American national park in the southern Sierra Nevada, in Fresno and Tulare Counties, California. Originally established in 1890 as General Grant National Park, the park was greatly expanded and renamed to Kings Canyon National Park on March 4, 1940. The park's namesake, Kings Canyon, is a rugged glacier-carved valley more than a mile (1,600 m) deep. Other natural features include multiple 14,000-foot (4,300 m) peaks, high mountain meadows, swift-flowing rivers, and some of the world's largest stands of giant sequoia trees. Kings Canyon is north of and contiguous with Sequoia National Park, and both parks are jointly administered by the National Park Service as the Sequoia and Kings Canyon National Parks.
The majority of the 461,901-acre (186,925 ha) park, drained by the Middle and South Forks of the Kings River and many smaller streams, is designated wilderness. Tourist facilities are concentrated in two areas: Grant Grove, home to General Grant (the second largest tree in the world, measured by trunk volume) and Cedar Grove, located in the heart of Kings Canyon. Overnight hiking is required to access most of the park's backcountry, or high country, which for much of the year is covered in deep snow. The combined Pacific Crest Trail/John Muir Trail, a backpacking route, traverses the entire length of the park from north to south.
General Grant National Park was initially created to protect a small area of giant sequoias from logging. Although John Muir's visits brought public attention to the huge wilderness area to the east, it took more than fifty years for the rest of Kings Canyon to be designated a national park. Environmental groups, park visitors and many local politicians wanted to see the area preserved; however, development interests wanted to build hydroelectric dams in the canyon. Even after President Franklin D. Roosevelt expanded the park in 1940, the fight continued until 1965, when the Cedar Grove and Tehipite Valley dam sites were finally annexed into the park.
As visitation rose postWorld War II, further debate took place over whether the park should be developed as a tourist resort, or retained as a more natural environment restricted to simpler recreation such as hiking and camping. Ultimately, the preservation lobby prevailed and today, the park has only limited services and lodgings despite its size. Due to this and the lack of road access to most of the park, Kings Canyon remains the least visited of the major Sierra parks, with just under 700,000 visitors in 2017 compared to 1.3 million visitors at Sequoia and over 4 million at Yosemite.
2
defaultdict(<class 'list'>, {'land': ['park'], 'little': ['canyon'], 'nation': ['national'], 'ravine': ['canyon'], 'allegiance': ['national'], 'property': ['park'], 'owes': ['national'], 'ruler': ['king'], 'large': ['park'], 'river': ['canyon'], 'male': ['king'], 'preserved': ['park'], 'rainfall': ['canyon'], 'person': ['national'], 'kingdom': ['king'], 'state': ['park'], 'natural': ['park'], 'formed': ['canyon'], 'public': ['park'], 'area': ['canyon', 'park'], 'sovereign': ['king']})
('definitiongraph networkx edges:', OutEdgeView([('land', 'park'), ('park', 'land'), ('park', 'property'), ('park', 'large'), ('park', 'preserved'), ('park', 'state'), ('park', 'natural'), ('park', 'public'), ('park', 'area'), ('little', 'canyon'), ('canyon', 'little'), ('canyon', 'ravine'), ('canyon', 'river'), ('canyon', 'rainfall'), ('canyon', 'formed'), ('canyon', 'area'), ('nation', 'national'), ('national', 'nation'), ('national', 'allegiance'), ('national', 'owes'), ('national', 'person'), ('ravine', 'canyon'), ('allegiance', 'national'), ('property', 'park'), ('owes', 'national'), ('ruler', 'king'), ('king', 'ruler'), ('king', 'male'), ('king', 'kingdom'), ('king', 'sovereign'), ('large', 'park'), ('river', 'canyon'), ('male', 'king'), ('preserved', 'park'), ('rainfall', 'canyon'), ('person', 'national'), ('kingdom', 'king'), ('state', 'park'), ('natural', 'park'), ('formed', 'canyon'), ('public', 'park'), ('area', 'canyon'), ('area', 'park'), ('sovereign', 'king')]))
('Core number (sorted) :', [('land', 2), ('park', 2), ('little', 2), ('canyon', 2), ('nation', 2), ('national', 2), ('ravine', 2), ('allegiance', 2), ('property', 2), ('owes', 2), ('ruler', 2), ('king', 2), ('large', 2), ('river', 2), ('male', 2), ('preserved', 2), ('rainfall', 2), ('person', 2), ('kingdom', 2), ('state', 2), ('natural', 2), ('formed', 2), ('public', 2), ('area', 2), ('sovereign', 2)])
=============================================================================================================
Unsupervised Classification based on top percentile Core numbers of the definition graph(subgraph of WordNet)
=============================================================================================================
('This document belongs to class:', 'land', ',core number=', 2)
('This document belongs to class:', 'park', ',core number=', 2)
('This document belongs to class:', 'little', ',core number=', 2)
('This document belongs to class:', 'canyon', ',core number=', 2)
('This document belongs to class:', 'nation', ',core number=', 2)
('This document belongs to class:', 'national', ',core number=', 2)
('This document belongs to class:', 'ravine', ',core number=', 2)
('This document belongs to class:', 'allegiance', ',core number=', 2)
('This document belongs to class:', 'property', ',core number=', 2)
('This document belongs to class:', 'owes', ',core number=', 2)
('This document belongs to class:', 'ruler', ',core number=', 2)
('This document belongs to class:', 'king', ',core number=', 2)
('This document belongs to class:', 'large', ',core number=', 2)
('This document belongs to class:', 'river', ',core number=', 2)
('\tmax_core_number', 2)
===================================================================
Betweenness Centrality of Recursive Gloss Overlap graph vertices
===================================================================
[('park', 0.2536231884057971), ('canyon', 0.19927536231884058), ('area', 0.17391304347826086), ('national', 0.021739130434782608), ('king', 0.021739130434782608), ('land', 0.0), ('little', 0.0), ('nation', 0.0), ('ravine', 0.0), ('allegiance', 0.0), ('property', 0.0), ('owes', 0.0), ('ruler', 0.0), ('large', 0.0), ('river', 0.0), ('male', 0.0), ('preserved', 0.0), ('rainfall', 0.0), ('person', 0.0), ('kingdom', 0.0), ('state', 0.0), ('natural', 0.0), ('formed', 0.0), ('public', 0.0), ('sovereign', 0.0)]
===================================================================
Closeness Centrality of Recursive Gloss Overlap graph vertices
===================================================================
[('park', 0.3266666666666667), ('area', 0.3141025641025641), ('canyon', 0.2816091954022989), ('land', 0.2149122807017544), ('property', 0.2149122807017544), ('large', 0.2149122807017544), ('preserved', 0.2149122807017544), ('state', 0.2149122807017544), ('natural', 0.2149122807017544), ('public', 0.2149122807017544), ('little', 0.19444444444444445), ('ravine', 0.19444444444444445), ('river', 0.19444444444444445), ('rainfall', 0.19444444444444445), ('formed', 0.19444444444444445), ('national', 0.16666666666666666), ('king', 0.16666666666666666), ('nation', 0.09523809523809523), ('allegiance', 0.09523809523809523), ('owes', 0.09523809523809523), ('ruler', 0.09523809523809523), ('male', 0.09523809523809523), ('person', 0.09523809523809523), ('kingdom', 0.09523809523809523), ('sovereign', 0.09523809523809523)]
===================================================================
Degree Centrality of Recursive Gloss Overlap graph vertices
===================================================================
[('park', 0.6666666666666666), ('canyon', 0.5), ('national', 0.3333333333333333), ('king', 0.3333333333333333), ('area', 0.16666666666666666), ('land', 0.08333333333333333), ('little', 0.08333333333333333), ('nation', 0.08333333333333333), ('ravine', 0.08333333333333333), ('allegiance', 0.08333333333333333), ('property', 0.08333333333333333), ('owes', 0.08333333333333333), ('ruler', 0.08333333333333333), ('large', 0.08333333333333333), ('river', 0.08333333333333333), ('male', 0.08333333333333333), ('preserved', 0.08333333333333333), ('rainfall', 0.08333333333333333), ('person', 0.08333333333333333), ('kingdom', 0.08333333333333333), ('state', 0.08333333333333333), ('natural', 0.08333333333333333), ('formed', 0.08333333333333333), ('public', 0.08333333333333333), ('sovereign', 0.08333333333333333)]
===================================================================
Page Rank of the vertices of RGO Definition Graph (a form of Eigenvector Centrality)
===================================================================
[('park', 0.159946399547332), ('canyon', 0.12221255496595394), ('national', 0.09513426032180526), ('king', 0.09513426032180526), ('area', 0.04030859795057581), ('nation', 0.026216434919548687), ('allegiance', 0.026216434919548687), ('owes', 0.026216434919548687), ('ruler', 0.026216434919548687), ('male', 0.026216434919548687), ('person', 0.026216434919548687), ('kingdom', 0.026216434919548687), ('sovereign', 0.026216434919548687), ('little', 0.023313869058946213), ('ravine', 0.023313869058946213), ('river', 0.023313869058946213), ('rainfall', 0.023313869058946213), ('formed', 0.023313869058946213), ('land', 0.022994728891629602), ('property', 0.022994728891629602), ('large', 0.022994728891629602), ('preserved', 0.022994728891629602), ('state', 0.022994728891629602), ('natural', 0.022994728891629602), ('public', 0.022994728891629602)]
2
RecursiveGlossOverlapGraph(): textgraph =  [('land', 'park'), ('park', 'land'), ('park', 'property'), ('park', 'large'), ('park', 'preserved'), ('park', 'state'), ('park', 'natural'), ('park', 'public'), ('park', 'area'), ('little', 'canyon'), ('canyon', 'little'), ('canyon', 'ravine'), ('canyon', 'river'), ('canyon', 'rainfall'), ('canyon', 'formed'), ('canyon', 'area'), ('nation', 'national'), ('national', 'nation'), ('national', 'allegiance'), ('national', 'owes'), ('national', 'person'), ('ravine', 'canyon'), ('allegiance', 'national'), ('property', 'park'), ('owes', 'national'), ('ruler', 'king'), ('king', 'ruler'), ('king', 'male'), ('king', 'kingdom'), ('king', 'sovereign'), ('large', 'park'), ('river', 'canyon'), ('male', 'king'), ('preserved', 'park'), ('rainfall', 'canyon'), ('person', 'national'), ('kingdom', 'king'), ('state', 'park'), ('natural', 'park'), ('formed', 'canyon'), ('public', 'park'), ('area', 'canyon'), ('area', 'park'), ('sovereign', 'king')]
Answer Textgraph  6 : ([('land', 2), ('park', 2), ('little', 2), ('canyon', 2), ('nation', 2), ('national', 2), ('ravine', 2), ('allegiance', 2), ('property', 2), ('owes', 2), ('ruler', 2), ('king', 2), ('large', 2), ('river', 2), ('male', 2), ('preserved', 2), ('rainfall', 2), ('person', 2), ('kingdom', 2), ('state', 2), ('natural', 2), ('formed', 2), ('public', 2), ('area', 2), ('sovereign', 2)], [('park', 0.159946399547332), ('canyon', 0.12221255496595394), ('national', 0.09513426032180526), ('king', 0.09513426032180526), ('area', 0.04030859795057581), ('nation', 0.026216434919548687), ('allegiance', 0.026216434919548687), ('owes', 0.026216434919548687), ('ruler', 0.026216434919548687), ('male', 0.026216434919548687), ('person', 0.026216434919548687), ('kingdom', 0.026216434919548687), ('sovereign', 0.026216434919548687), ('little', 0.023313869058946213), ('ravine', 0.023313869058946213), ('river', 0.023313869058946213), ('rainfall', 0.023313869058946213), ('formed', 0.023313869058946213), ('land', 0.022994728891629602), ('property', 0.022994728891629602), ('large', 0.022994728891629602), ('preserved', 0.022994728891629602), ('state', 0.022994728891629602), ('natural', 0.022994728891629602), ('public', 0.022994728891629602)])
Attention from Definition Graph: [[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.08333333333333333, 0.08333333333333333, 0.08333333333333333, 0.08333333333333333, 0.08333333333333333, 0.08333333333333333, 0.08333333333333333, 0.08333333333333333, 0.08333333333333333, 0.08333333333333333, 0.08333333333333333, 0.08333333333333333, 0.08333333333333333, 0.08333333333333333, 0.08333333333333333, 0.08333333333333333, 0.08333333333333333, 0.08333333333333333, 0.08333333333333333, 0.08333333333333333, 0.08333333333333333, 0.08333333333333333, 0.08333333333333333, 0.08333333333333333], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]]
Attention slice from Definition Graph: [[0.5, 0.5, 0.5], [0.0625, 0.0625, 0.0625], [0.5, 0.5, 0.5]]
weights: [1, 2, 3]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  1.012
LinearPerceptronGradient() weight update iteration: deltaw =  [0.12000000000000002, 0.13200000000000003, 0.33799999999999997]
weights: [1.012, 2, 3]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  2.0132
LinearPerceptronGradient() weight update iteration: deltaw =  [0.12000000000000002, 0.13200000000000003, 0.33799999999999997]
weights: [1.012, 2.0132, 3]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  3.0338
LinearPerceptronGradient() weight update iteration: deltaw =  [0.12000000000000002, 0.13200000000000003, 0.33799999999999997]
weights updated after Gradient :  [1.012, 2.0132, 3.0338]
converged: True
weights: [0.1, 0.3, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.0625, 0.0625, 0.0625]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  0.11555000000000001
LinearPerceptronGradient() weight update iteration: deltaw =  [0.15550000000000003, 0.17055000000000003, 0.19557500000000005]
weights: [0.11555000000000001, 0.3, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.0625, 0.0625, 0.0625]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  0.317055
LinearPerceptronGradient() weight update iteration: deltaw =  [0.15550000000000003, 0.17055000000000003, 0.19557500000000005]
weights: [0.11555000000000001, 0.317055, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.0625, 0.0625, 0.0625]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  0.5195575
LinearPerceptronGradient() weight update iteration: deltaw =  [0.15550000000000003, 0.17055000000000003, 0.19557500000000005]
weights updated after Gradient :  [0.11555000000000001, 0.317055, 0.5195575]
converged: True
weights: [3, 4, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  3.02
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights: [3.02, 4, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  4.038
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights: [3.02, 4.038, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  5.187
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights updated after Gradient :  [3.02, 4.038, 5.187]
converged: True
Learnt Query Weights: [[1.012, 2.0132, 3.0338], [0.11555000000000001, 0.317055, 0.5195575], [3.02, 4.038, 5.187]]
weights: [4, 5, 6]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  4.024
LinearPerceptronGradient() weight update iteration: deltaw =  [0.24000000000000005, 0.504, 2.636]
weights: [4.024, 5, 6]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  5.0504
LinearPerceptronGradient() weight update iteration: deltaw =  [0.24000000000000005, 0.504, 2.636]
weights: [4.024, 5.0504, 6]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  6.2636
LinearPerceptronGradient() weight update iteration: deltaw =  [0.24000000000000005, 0.504, 2.636]
weights updated after Gradient :  [4.024, 5.0504, 6.2636]
converged: True
weights: [0.1, 0.3, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.0625, 0.0625, 0.0625]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  0.11555000000000001
LinearPerceptronGradient() weight update iteration: deltaw =  [0.15550000000000003, 0.17055000000000003, 0.19557500000000005]
weights: [0.11555000000000001, 0.3, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.0625, 0.0625, 0.0625]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  0.317055
LinearPerceptronGradient() weight update iteration: deltaw =  [0.15550000000000003, 0.17055000000000003, 0.19557500000000005]
weights: [0.11555000000000001, 0.317055, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.0625, 0.0625, 0.0625]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  0.5195575
LinearPerceptronGradient() weight update iteration: deltaw =  [0.15550000000000003, 0.17055000000000003, 0.19557500000000005]
weights updated after Gradient :  [0.11555000000000001, 0.317055, 0.5195575]
converged: True
weights: [3, 4, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  3.02
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights: [3.02, 4, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  4.038
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights: [3.02, 4.038, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  5.187
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights updated after Gradient :  [3.02, 4.038, 5.187]
converged: True
Learnt Key Weights: [[4.024, 5.0504, 6.2636], [0.11555000000000001, 0.317055, 0.5195575], [3.02, 4.038, 5.187]]
weights: [7, 8, 9]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  7.036
LinearPerceptronGradient() weight update iteration: deltaw =  [0.36, 0.876, 4.934]
weights: [7.036, 8, 9]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  8.0876
LinearPerceptronGradient() weight update iteration: deltaw =  [0.36, 0.876, 4.934]
weights: [7.036, 8.0876, 9]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  9.4934
LinearPerceptronGradient() weight update iteration: deltaw =  [0.36, 0.876, 4.934]
weights updated after Gradient :  [7.036, 8.0876, 9.4934]
converged: True
weights: [0.1, 0.3, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.0625, 0.0625, 0.0625]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  0.11555000000000001
LinearPerceptronGradient() weight update iteration: deltaw =  [0.15550000000000003, 0.17055000000000003, 0.19557500000000005]
weights: [0.11555000000000001, 0.3, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.0625, 0.0625, 0.0625]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  0.317055
LinearPerceptronGradient() weight update iteration: deltaw =  [0.15550000000000003, 0.17055000000000003, 0.19557500000000005]
weights: [0.11555000000000001, 0.317055, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.0625, 0.0625, 0.0625]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  0.5195575
LinearPerceptronGradient() weight update iteration: deltaw =  [0.15550000000000003, 0.17055000000000003, 0.19557500000000005]
weights updated after Gradient :  [0.11555000000000001, 0.317055, 0.5195575]
converged: True
weights: [3, 4, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  3.02
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights: [3.02, 4, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  4.038
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights: [3.02, 4.038, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  5.187
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights updated after Gradient :  [3.02, 4.038, 5.187]
converged: True
Learnt Values Weights: [[7.036, 8.0876, 9.4934], [0.11555000000000001, 0.317055, 0.5195575], [3.02, 4.038, 5.187]]
Query weight for textgraph edge ( land , land ): 1.012
Key weight for textgraph edge ( land , land ): 4.024
Value weight for textgraph edge ( land , land ): 7.036
Query weight for textgraph edge ( land , park ): 2.0132
Key weight for textgraph edge ( land , park ): 5.0504
Value weight for textgraph edge ( land , park ): 8.0876
Query weight for textgraph edge ( land , little ): 3.0338
Key weight for textgraph edge ( land , little ): 6.2636
Value weight for textgraph edge ( land , little ): 9.4934
Query weight for textgraph edge ( park , land ): 0.11555000000000001
Key weight for textgraph edge ( park , land ): 0.11555000000000001
Value weight for textgraph edge ( park , land ): 0.11555000000000001
Query weight for textgraph edge ( park , park ): 0.317055
Key weight for textgraph edge ( park , park ): 0.317055
Value weight for textgraph edge ( park , park ): 0.317055
Query weight for textgraph edge ( park , little ): 0.5195575
Key weight for textgraph edge ( park , little ): 0.5195575
Value weight for textgraph edge ( park , little ): 0.5195575
Query weight for textgraph edge ( little , land ): 3.02
Key weight for textgraph edge ( little , land ): 3.02
Value weight for textgraph edge ( little , land ): 3.02
Query weight for textgraph edge ( little , park ): 4.038
Key weight for textgraph edge ( little , park ): 4.038
Value weight for textgraph edge ( little , park ): 4.038
Query weight for textgraph edge ( little , little ): 5.187
Key weight for textgraph edge ( little , little ): 5.187
Value weight for textgraph edge ( little , little ): 5.187
wikipedia search result: Valley of Hinnom (Gehenna)
wikipedia search result summary: The Valley of Hinnom (Hebrew:  , romanized: G en-Hnnm, lit.'Valley of the son of Hinnom') is a historic valley surrounding Ancient Jerusalem from the west and southwest. The valley is also known by the name Gehinnom ( G-Hnnm, lit.'Valley of Hinnom') an alternative Biblical Hebrew form which survived into Aramaic and has received various fundamental theological connotations, and by the Greek and Syriac transliteration Gehenna ( Genna/ Gihanna).The Valley of Hinnom is first mentioned in the Hebrew Bible as part of the border between the tribes of Judah and Benjamin (Joshua 15:8). During the late First Temple period, it was the site of the Tophet, where some of the kings of Judah had sacrificed their children by fire (Jeremiah 7:31). Thereafter, it was cursed by the biblical prophet Jeremiah (Jeremiah 19:26). In later Jewish rabbinic literature, Gehinnom became associated with divine punishment in Jewish Apocalypticism as the destination of the wicked. It is different from the more neutral term Sheol, the abode of the dead. The King James Version of the Bible translates both with the Anglo-Saxon word hell.
The Valley of Hinnom is the Modern Hebrew name for the valley surrounding the Old City of Jerusalem and the adjacent Mount Zion from the west and south. It meets and merges with the Kidron Valley, the other principal valley around the Old City, near the Pool of Siloam which lie to the southeastern corner of Ancient Jerusalem. It is also known as Wadi er-Rababi (Arabic:   "valley of the Rebab"). The northwestern part of the valley is now an urban park.
In Judaism, the term Gehinnom is used for the realm in which the wicked expiate their sins.
2
defaultdict(<class 'list'>, {'land': ['valley'], 'place': ['Gehenna'], 'contains': ['valley'], 'wicked': ['Gehenna'], 'long': ['valley'], 'punished': ['Gehenna'], 'usually': ['valley'], 'river': ['valley'], 'death': ['Gehenna'], 'depression': ['valley'], 'surface': ['valley']})
('definitiongraph networkx edges:', OutEdgeView([('land', 'valley'), ('valley', 'land'), ('valley', 'contains'), ('valley', 'long'), ('valley', 'usually'), ('valley', 'river'), ('valley', 'depression'), ('valley', 'surface'), ('place', 'Gehenna'), ('Gehenna', 'place'), ('Gehenna', 'wicked'), ('Gehenna', 'punished'), ('Gehenna', 'death'), ('contains', 'valley'), ('wicked', 'Gehenna'), ('long', 'valley'), ('punished', 'Gehenna'), ('usually', 'valley'), ('river', 'valley'), ('death', 'Gehenna'), ('depression', 'valley'), ('surface', 'valley')]))
('Core number (sorted) :', [('land', 2), ('valley', 2), ('place', 2), ('Gehenna', 2), ('contains', 2), ('wicked', 2), ('long', 2), ('punished', 2), ('usually', 2), ('river', 2), ('death', 2), ('depression', 2), ('surface', 2)])
=============================================================================================================
Unsupervised Classification based on top percentile Core numbers of the definition graph(subgraph of WordNet)
=============================================================================================================
('This document belongs to class:', 'land', ',core number=', 2)
('This document belongs to class:', 'valley', ',core number=', 2)
('This document belongs to class:', 'place', ',core number=', 2)
('This document belongs to class:', 'Gehenna', ',core number=', 2)
('This document belongs to class:', 'contains', ',core number=', 2)
('This document belongs to class:', 'wicked', ',core number=', 2)
('This document belongs to class:', 'long', ',core number=', 2)
('This document belongs to class:', 'punished', ',core number=', 2)
('\tmax_core_number', 2)
===================================================================
Betweenness Centrality of Recursive Gloss Overlap graph vertices
===================================================================
[('valley', 0.3181818181818182), ('Gehenna', 0.09090909090909091), ('land', 0.0), ('place', 0.0), ('contains', 0.0), ('wicked', 0.0), ('long', 0.0), ('punished', 0.0), ('usually', 0.0), ('river', 0.0), ('death', 0.0), ('depression', 0.0), ('surface', 0.0)]
===================================================================
Closeness Centrality of Recursive Gloss Overlap graph vertices
===================================================================
[('valley', 0.5833333333333334), ('Gehenna', 0.3333333333333333), ('land', 0.3141025641025641), ('contains', 0.3141025641025641), ('long', 0.3141025641025641), ('usually', 0.3141025641025641), ('river', 0.3141025641025641), ('depression', 0.3141025641025641), ('surface', 0.3141025641025641), ('place', 0.19047619047619047), ('wicked', 0.19047619047619047), ('punished', 0.19047619047619047), ('death', 0.19047619047619047)]
===================================================================
Degree Centrality of Recursive Gloss Overlap graph vertices
===================================================================
[('valley', 1.1666666666666665), ('Gehenna', 0.6666666666666666), ('land', 0.16666666666666666), ('place', 0.16666666666666666), ('contains', 0.16666666666666666), ('wicked', 0.16666666666666666), ('long', 0.16666666666666666), ('punished', 0.16666666666666666), ('usually', 0.16666666666666666), ('river', 0.16666666666666666), ('death', 0.16666666666666666), ('depression', 0.16666666666666666), ('surface', 0.16666666666666666)]
===================================================================
Page Rank of the vertices of RGO Definition Graph (a form of Eigenvector Centrality)
===================================================================
[('valley', 0.2889795326042667), ('Gehenna', 0.18295130476367186), ('place', 0.05041601996292819), ('wicked', 0.05041601996292819), ('punished', 0.05041601996292819), ('death', 0.05041601996292819), ('land', 0.0466292975400498), ('contains', 0.0466292975400498), ('long', 0.0466292975400498), ('usually', 0.0466292975400498), ('river', 0.0466292975400498), ('depression', 0.0466292975400498), ('surface', 0.0466292975400498)]
2
RecursiveGlossOverlapGraph(): textgraph =  [('land', 'valley'), ('valley', 'land'), ('valley', 'contains'), ('valley', 'long'), ('valley', 'usually'), ('valley', 'river'), ('valley', 'depression'), ('valley', 'surface'), ('place', 'Gehenna'), ('Gehenna', 'place'), ('Gehenna', 'wicked'), ('Gehenna', 'punished'), ('Gehenna', 'death'), ('contains', 'valley'), ('wicked', 'Gehenna'), ('long', 'valley'), ('punished', 'Gehenna'), ('usually', 'valley'), ('river', 'valley'), ('death', 'Gehenna'), ('depression', 'valley'), ('surface', 'valley')]
Answer Textgraph  7 : ([('land', 2), ('valley', 2), ('place', 2), ('Gehenna', 2), ('contains', 2), ('wicked', 2), ('long', 2), ('punished', 2), ('usually', 2), ('river', 2), ('death', 2), ('depression', 2), ('surface', 2)], [('valley', 0.2889795326042667), ('Gehenna', 0.18295130476367186), ('place', 0.05041601996292819), ('wicked', 0.05041601996292819), ('punished', 0.05041601996292819), ('death', 0.05041601996292819), ('land', 0.0466292975400498), ('contains', 0.0466292975400498), ('long', 0.0466292975400498), ('usually', 0.0466292975400498), ('river', 0.0466292975400498), ('depression', 0.0466292975400498), ('surface', 0.0466292975400498)])
Attention from Definition Graph: [[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]]
Attention slice from Definition Graph: [[0.5, 0.5, 0.5], [0.07142857142857142, 0.07142857142857142, 0.07142857142857142], [0.5, 0.5, 0.5]]
weights: [1, 2, 3]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  1.012
LinearPerceptronGradient() weight update iteration: deltaw =  [0.12000000000000002, 0.13200000000000003, 0.33799999999999997]
weights: [1.012, 2, 3]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  2.0132
LinearPerceptronGradient() weight update iteration: deltaw =  [0.12000000000000002, 0.13200000000000003, 0.33799999999999997]
weights: [1.012, 2.0132, 3]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  3.0338
LinearPerceptronGradient() weight update iteration: deltaw =  [0.12000000000000002, 0.13200000000000003, 0.33799999999999997]
weights updated after Gradient :  [1.012, 2.0132, 3.0338]
converged: True
weights: [0.1, 0.3, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.07142857142857142, 0.07142857142857142, 0.07142857142857142]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  0.11537142857142858
LinearPerceptronGradient() weight update iteration: deltaw =  [0.15371428571428575, 0.16680000000000003, 0.18191428571428575]
weights: [0.11537142857142858, 0.3, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.07142857142857142, 0.07142857142857142, 0.07142857142857142]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  0.31668
LinearPerceptronGradient() weight update iteration: deltaw =  [0.15371428571428575, 0.16680000000000003, 0.18191428571428575]
weights: [0.11537142857142858, 0.31668, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.07142857142857142, 0.07142857142857142, 0.07142857142857142]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  0.5181914285714285
LinearPerceptronGradient() weight update iteration: deltaw =  [0.15371428571428575, 0.16680000000000003, 0.18191428571428575]
weights updated after Gradient :  [0.11537142857142858, 0.31668, 0.5181914285714285]
converged: True
weights: [3, 4, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  3.02
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights: [3.02, 4, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  4.038
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights: [3.02, 4.038, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  5.187
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights updated after Gradient :  [3.02, 4.038, 5.187]
converged: True
Learnt Query Weights: [[1.012, 2.0132, 3.0338], [0.11537142857142858, 0.31668, 0.5181914285714285], [3.02, 4.038, 5.187]]
weights: [4, 5, 6]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  4.024
LinearPerceptronGradient() weight update iteration: deltaw =  [0.24000000000000005, 0.504, 2.636]
weights: [4.024, 5, 6]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  5.0504
LinearPerceptronGradient() weight update iteration: deltaw =  [0.24000000000000005, 0.504, 2.636]
weights: [4.024, 5.0504, 6]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  6.2636
LinearPerceptronGradient() weight update iteration: deltaw =  [0.24000000000000005, 0.504, 2.636]
weights updated after Gradient :  [4.024, 5.0504, 6.2636]
converged: True
weights: [0.1, 0.3, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.07142857142857142, 0.07142857142857142, 0.07142857142857142]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  0.11537142857142858
LinearPerceptronGradient() weight update iteration: deltaw =  [0.15371428571428575, 0.16680000000000003, 0.18191428571428575]
weights: [0.11537142857142858, 0.3, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.07142857142857142, 0.07142857142857142, 0.07142857142857142]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  0.31668
LinearPerceptronGradient() weight update iteration: deltaw =  [0.15371428571428575, 0.16680000000000003, 0.18191428571428575]
weights: [0.11537142857142858, 0.31668, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.07142857142857142, 0.07142857142857142, 0.07142857142857142]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  0.5181914285714285
LinearPerceptronGradient() weight update iteration: deltaw =  [0.15371428571428575, 0.16680000000000003, 0.18191428571428575]
weights updated after Gradient :  [0.11537142857142858, 0.31668, 0.5181914285714285]
converged: True
weights: [3, 4, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  3.02
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights: [3.02, 4, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  4.038
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights: [3.02, 4.038, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  5.187
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights updated after Gradient :  [3.02, 4.038, 5.187]
converged: True
Learnt Key Weights: [[4.024, 5.0504, 6.2636], [0.11537142857142858, 0.31668, 0.5181914285714285], [3.02, 4.038, 5.187]]
weights: [7, 8, 9]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  7.036
LinearPerceptronGradient() weight update iteration: deltaw =  [0.36, 0.876, 4.934]
weights: [7.036, 8, 9]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  8.0876
LinearPerceptronGradient() weight update iteration: deltaw =  [0.36, 0.876, 4.934]
weights: [7.036, 8.0876, 9]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  9.4934
LinearPerceptronGradient() weight update iteration: deltaw =  [0.36, 0.876, 4.934]
weights updated after Gradient :  [7.036, 8.0876, 9.4934]
converged: True
weights: [0.1, 0.3, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.07142857142857142, 0.07142857142857142, 0.07142857142857142]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  0.11537142857142858
LinearPerceptronGradient() weight update iteration: deltaw =  [0.15371428571428575, 0.16680000000000003, 0.18191428571428575]
weights: [0.11537142857142858, 0.3, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.07142857142857142, 0.07142857142857142, 0.07142857142857142]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  0.31668
LinearPerceptronGradient() weight update iteration: deltaw =  [0.15371428571428575, 0.16680000000000003, 0.18191428571428575]
weights: [0.11537142857142858, 0.31668, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.07142857142857142, 0.07142857142857142, 0.07142857142857142]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  0.5181914285714285
LinearPerceptronGradient() weight update iteration: deltaw =  [0.15371428571428575, 0.16680000000000003, 0.18191428571428575]
weights updated after Gradient :  [0.11537142857142858, 0.31668, 0.5181914285714285]
converged: True
weights: [3, 4, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  3.02
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights: [3.02, 4, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  4.038
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights: [3.02, 4.038, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  5.187
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights updated after Gradient :  [3.02, 4.038, 5.187]
converged: True
Learnt Values Weights: [[7.036, 8.0876, 9.4934], [0.11537142857142858, 0.31668, 0.5181914285714285], [3.02, 4.038, 5.187]]
Query weight for textgraph edge ( land , land ): 1.012
Key weight for textgraph edge ( land , land ): 4.024
Value weight for textgraph edge ( land , land ): 7.036
Query weight for textgraph edge ( land , valley ): 2.0132
Key weight for textgraph edge ( land , valley ): 5.0504
Value weight for textgraph edge ( land , valley ): 8.0876
Query weight for textgraph edge ( land , place ): 3.0338
Key weight for textgraph edge ( land , place ): 6.2636
Value weight for textgraph edge ( land , place ): 9.4934
Query weight for textgraph edge ( valley , land ): 0.11537142857142858
Key weight for textgraph edge ( valley , land ): 0.11537142857142858
Value weight for textgraph edge ( valley , land ): 0.11537142857142858
Query weight for textgraph edge ( valley , valley ): 0.31668
Key weight for textgraph edge ( valley , valley ): 0.31668
Value weight for textgraph edge ( valley , valley ): 0.31668
Query weight for textgraph edge ( valley , place ): 0.5181914285714285
Key weight for textgraph edge ( valley , place ): 0.5181914285714285
Value weight for textgraph edge ( valley , place ): 0.5181914285714285
Query weight for textgraph edge ( place , land ): 3.02
Key weight for textgraph edge ( place , land ): 3.02
Value weight for textgraph edge ( place , land ): 3.02
Query weight for textgraph edge ( place , valley ): 4.038
Key weight for textgraph edge ( place , valley ): 4.038
Value weight for textgraph edge ( place , valley ): 4.038
Query weight for textgraph edge ( place , place ): 5.187
Key weight for textgraph edge ( place , place ): 5.187
Value weight for textgraph edge ( place , place ): 5.187
wikipedia search result: Exploration of the Valley of the Kings
wikipedia search result summary: The area of the Valley of the Kings, in Luxor, Egypt, has been a major area of modern Egyptological exploration for the last two centuries. Before this, the area was a site for tourism in antiquity (especially during Roman times). This area illustrates the changes in the study of ancient Egypt. Starting as antiquity hunting, and ending as scientific excavation of the whole Theban Necropolis. Despite the exploration and investigation noted below, only eleven of the tombs have actually been completely recorded.
The Greek writers Strabo (1st century BC) and Diodorus Siculus (1st century AD) reported that the total number of Theban royal tombs was 47, which at the time, only 17 were believed to be undestroyed. Pausanias and other ancient writers remarked on the pipe-like corridors of the Valley, meaning the tombs.Others have also visited the valley in these times, many of the tombs have graffiti written by these ancient tourists. Jules Baillet located over 2100 Greek and Latin graffiti, along with a smaller number in Phoenician, Cypriot, Lycian, Coptic, and other languages. The majority of the ancient graffiti are found in KV9, which contains just under a thousand of them. The earliest positively dated graffiti dates to 278 BC.
2
defaultdict(<class 'list'>, {'discovery': ['exploration'], 'land': ['valley'], 'purpose': ['exploration'], 'surface': ['valley'], 'contains': ['valley'], 'kingdom': ['king'], 'travel': ['exploration'], 'long': ['valley'], 'ruler': ['king'], 'usually': ['valley'], 'river': ['valley'], 'male': ['king'], 'sovereign': ['king'], 'depression': ['valley']})
('definitiongraph networkx edges:', OutEdgeView([('discovery', 'exploration'), ('exploration', 'discovery'), ('exploration', 'purpose'), ('exploration', 'travel'), ('land', 'valley'), ('valley', 'land'), ('valley', 'surface'), ('valley', 'contains'), ('valley', 'long'), ('valley', 'usually'), ('valley', 'river'), ('valley', 'depression'), ('purpose', 'exploration'), ('surface', 'valley'), ('contains', 'valley'), ('kingdom', 'king'), ('king', 'kingdom'), ('king', 'ruler'), ('king', 'male'), ('king', 'sovereign'), ('travel', 'exploration'), ('long', 'valley'), ('ruler', 'king'), ('usually', 'valley'), ('river', 'valley'), ('male', 'king'), ('sovereign', 'king'), ('depression', 'valley')]))
('Core number (sorted) :', [('discovery', 2), ('exploration', 2), ('land', 2), ('valley', 2), ('purpose', 2), ('surface', 2), ('contains', 2), ('kingdom', 2), ('king', 2), ('travel', 2), ('long', 2), ('ruler', 2), ('usually', 2), ('river', 2), ('male', 2), ('sovereign', 2), ('depression', 2)])
=============================================================================================================
Unsupervised Classification based on top percentile Core numbers of the definition graph(subgraph of WordNet)
=============================================================================================================
('This document belongs to class:', 'discovery', ',core number=', 2)
('This document belongs to class:', 'exploration', ',core number=', 2)
('This document belongs to class:', 'land', ',core number=', 2)
('This document belongs to class:', 'valley', ',core number=', 2)
('This document belongs to class:', 'purpose', ',core number=', 2)
('This document belongs to class:', 'surface', ',core number=', 2)
('This document belongs to class:', 'contains', ',core number=', 2)
('This document belongs to class:', 'kingdom', ',core number=', 2)
('This document belongs to class:', 'king', ',core number=', 2)
('This document belongs to class:', 'travel', ',core number=', 2)
('\tmax_core_number', 2)
===================================================================
Betweenness Centrality of Recursive Gloss Overlap graph vertices
===================================================================
[('valley', 0.175), ('king', 0.05), ('exploration', 0.025), ('discovery', 0.0), ('land', 0.0), ('purpose', 0.0), ('surface', 0.0), ('contains', 0.0), ('kingdom', 0.0), ('travel', 0.0), ('long', 0.0), ('ruler', 0.0), ('usually', 0.0), ('river', 0.0), ('male', 0.0), ('sovereign', 0.0), ('depression', 0.0)]
===================================================================
Closeness Centrality of Recursive Gloss Overlap graph vertices
===================================================================
[('valley', 0.4375), ('king', 0.25), ('land', 0.23557692307692307), ('surface', 0.23557692307692307), ('contains', 0.23557692307692307), ('long', 0.23557692307692307), ('usually', 0.23557692307692307), ('river', 0.23557692307692307), ('depression', 0.23557692307692307), ('exploration', 0.1875), ('kingdom', 0.14285714285714285), ('ruler', 0.14285714285714285), ('male', 0.14285714285714285), ('sovereign', 0.14285714285714285), ('discovery', 0.11249999999999999), ('purpose', 0.11249999999999999), ('travel', 0.11249999999999999)]
===================================================================
Degree Centrality of Recursive Gloss Overlap graph vertices
===================================================================
[('valley', 0.875), ('king', 0.5), ('exploration', 0.375), ('discovery', 0.125), ('land', 0.125), ('purpose', 0.125), ('surface', 0.125), ('contains', 0.125), ('kingdom', 0.125), ('travel', 0.125), ('long', 0.125), ('ruler', 0.125), ('usually', 0.125), ('river', 0.125), ('male', 0.125), ('sovereign', 0.125), ('depression', 0.125)]
===================================================================
Page Rank of the vertices of RGO Definition Graph (a form of Eigenvector Centrality)
===================================================================
[('valley', 0.22098383259560087), ('king', 0.1399036810036828), ('exploration', 0.11287696380637677), ('discovery', 0.04080571794689403), ('purpose', 0.04080571794689403), ('travel', 0.04080571794689403), ('kingdom', 0.038553491513785176), ('ruler', 0.038553491513785176), ('male', 0.038553491513785176), ('sovereign', 0.038553491513785176), ('land', 0.03565777181407382), ('surface', 0.03565777181407382), ('contains', 0.03565777181407382), ('long', 0.03565777181407382), ('usually', 0.03565777181407382), ('river', 0.03565777181407382), ('depression', 0.03565777181407382)]
2
RecursiveGlossOverlapGraph(): textgraph =  [('discovery', 'exploration'), ('exploration', 'discovery'), ('exploration', 'purpose'), ('exploration', 'travel'), ('land', 'valley'), ('valley', 'land'), ('valley', 'surface'), ('valley', 'contains'), ('valley', 'long'), ('valley', 'usually'), ('valley', 'river'), ('valley', 'depression'), ('purpose', 'exploration'), ('surface', 'valley'), ('contains', 'valley'), ('kingdom', 'king'), ('king', 'kingdom'), ('king', 'ruler'), ('king', 'male'), ('king', 'sovereign'), ('travel', 'exploration'), ('long', 'valley'), ('ruler', 'king'), ('usually', 'valley'), ('river', 'valley'), ('male', 'king'), ('sovereign', 'king'), ('depression', 'valley')]
Answer Textgraph  8 : ([('discovery', 2), ('exploration', 2), ('land', 2), ('valley', 2), ('purpose', 2), ('surface', 2), ('contains', 2), ('kingdom', 2), ('king', 2), ('travel', 2), ('long', 2), ('ruler', 2), ('usually', 2), ('river', 2), ('male', 2), ('sovereign', 2), ('depression', 2)], [('valley', 0.22098383259560087), ('king', 0.1399036810036828), ('exploration', 0.11287696380637677), ('discovery', 0.04080571794689403), ('purpose', 0.04080571794689403), ('travel', 0.04080571794689403), ('kingdom', 0.038553491513785176), ('ruler', 0.038553491513785176), ('male', 0.038553491513785176), ('sovereign', 0.038553491513785176), ('land', 0.03565777181407382), ('surface', 0.03565777181407382), ('contains', 0.03565777181407382), ('long', 0.03565777181407382), ('usually', 0.03565777181407382), ('river', 0.03565777181407382), ('depression', 0.03565777181407382)])
Attention from Definition Graph: [[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142, 0.07142857142857142], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]]
Attention slice from Definition Graph: [[0.5, 0.5, 0.5], [0.16666666666666666, 0.16666666666666666, 0.16666666666666666], [0.5, 0.5, 0.5]]
weights: [1, 2, 3]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  1.012
LinearPerceptronGradient() weight update iteration: deltaw =  [0.12000000000000002, 0.13200000000000003, 0.33799999999999997]
weights: [1.012, 2, 3]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  2.0132
LinearPerceptronGradient() weight update iteration: deltaw =  [0.12000000000000002, 0.13200000000000003, 0.33799999999999997]
weights: [1.012, 2.0132, 3]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  3.0338
LinearPerceptronGradient() weight update iteration: deltaw =  [0.12000000000000002, 0.13200000000000003, 0.33799999999999997]
weights updated after Gradient :  [1.012, 2.0132, 3.0338]
converged: True
weights: [0.1, 0.3, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  0.11346666666666667
LinearPerceptronGradient() weight update iteration: deltaw =  [0.13466666666666668, 0.12680000000000002, 0.03620000000000004]
weights: [0.11346666666666667, 0.3, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  0.31268
LinearPerceptronGradient() weight update iteration: deltaw =  [0.13466666666666668, 0.12680000000000002, 0.03620000000000004]
weights: [0.11346666666666667, 0.31268, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  0.50362
LinearPerceptronGradient() weight update iteration: deltaw =  [0.13466666666666668, 0.12680000000000002, 0.03620000000000004]
weights updated after Gradient :  [0.11346666666666667, 0.31268, 0.50362]
converged: True
weights: [3, 4, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  3.02
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights: [3.02, 4, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  4.038
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights: [3.02, 4.038, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  5.187
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights updated after Gradient :  [3.02, 4.038, 5.187]
converged: True
Learnt Query Weights: [[1.012, 2.0132, 3.0338], [0.11346666666666667, 0.31268, 0.50362], [3.02, 4.038, 5.187]]
weights: [4, 5, 6]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  4.024
LinearPerceptronGradient() weight update iteration: deltaw =  [0.24000000000000005, 0.504, 2.636]
weights: [4.024, 5, 6]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  5.0504
LinearPerceptronGradient() weight update iteration: deltaw =  [0.24000000000000005, 0.504, 2.636]
weights: [4.024, 5.0504, 6]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  6.2636
LinearPerceptronGradient() weight update iteration: deltaw =  [0.24000000000000005, 0.504, 2.636]
weights updated after Gradient :  [4.024, 5.0504, 6.2636]
converged: True
weights: [0.1, 0.3, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  0.11346666666666667
LinearPerceptronGradient() weight update iteration: deltaw =  [0.13466666666666668, 0.12680000000000002, 0.03620000000000004]
weights: [0.11346666666666667, 0.3, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  0.31268
LinearPerceptronGradient() weight update iteration: deltaw =  [0.13466666666666668, 0.12680000000000002, 0.03620000000000004]
weights: [0.11346666666666667, 0.31268, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  0.50362
LinearPerceptronGradient() weight update iteration: deltaw =  [0.13466666666666668, 0.12680000000000002, 0.03620000000000004]
weights updated after Gradient :  [0.11346666666666667, 0.31268, 0.50362]
converged: True
weights: [3, 4, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  3.02
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights: [3.02, 4, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  4.038
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights: [3.02, 4.038, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  5.187
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights updated after Gradient :  [3.02, 4.038, 5.187]
converged: True
Learnt Key Weights: [[4.024, 5.0504, 6.2636], [0.11346666666666667, 0.31268, 0.50362], [3.02, 4.038, 5.187]]
weights: [7, 8, 9]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  7.036
LinearPerceptronGradient() weight update iteration: deltaw =  [0.36, 0.876, 4.934]
weights: [7.036, 8, 9]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  8.0876
LinearPerceptronGradient() weight update iteration: deltaw =  [0.36, 0.876, 4.934]
weights: [7.036, 8.0876, 9]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  9.4934
LinearPerceptronGradient() weight update iteration: deltaw =  [0.36, 0.876, 4.934]
weights updated after Gradient :  [7.036, 8.0876, 9.4934]
converged: True
weights: [0.1, 0.3, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  0.11346666666666667
LinearPerceptronGradient() weight update iteration: deltaw =  [0.13466666666666668, 0.12680000000000002, 0.03620000000000004]
weights: [0.11346666666666667, 0.3, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  0.31268
LinearPerceptronGradient() weight update iteration: deltaw =  [0.13466666666666668, 0.12680000000000002, 0.03620000000000004]
weights: [0.11346666666666667, 0.31268, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  0.50362
LinearPerceptronGradient() weight update iteration: deltaw =  [0.13466666666666668, 0.12680000000000002, 0.03620000000000004]
weights updated after Gradient :  [0.11346666666666667, 0.31268, 0.50362]
converged: True
weights: [3, 4, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  3.02
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights: [3.02, 4, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  4.038
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights: [3.02, 4.038, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  5.187
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights updated after Gradient :  [3.02, 4.038, 5.187]
converged: True
Learnt Values Weights: [[7.036, 8.0876, 9.4934], [0.11346666666666667, 0.31268, 0.50362], [3.02, 4.038, 5.187]]
Query weight for textgraph edge ( discovery , discovery ): 1.012
Key weight for textgraph edge ( discovery , discovery ): 4.024
Value weight for textgraph edge ( discovery , discovery ): 7.036
Query weight for textgraph edge ( discovery , exploration ): 2.0132
Key weight for textgraph edge ( discovery , exploration ): 5.0504
Value weight for textgraph edge ( discovery , exploration ): 8.0876
Query weight for textgraph edge ( discovery , land ): 3.0338
Key weight for textgraph edge ( discovery , land ): 6.2636
Value weight for textgraph edge ( discovery , land ): 9.4934
Query weight for textgraph edge ( exploration , discovery ): 0.11346666666666667
Key weight for textgraph edge ( exploration , discovery ): 0.11346666666666667
Value weight for textgraph edge ( exploration , discovery ): 0.11346666666666667
Query weight for textgraph edge ( exploration , exploration ): 0.31268
Key weight for textgraph edge ( exploration , exploration ): 0.31268
Value weight for textgraph edge ( exploration , exploration ): 0.31268
Query weight for textgraph edge ( exploration , land ): 0.50362
Key weight for textgraph edge ( exploration , land ): 0.50362
Value weight for textgraph edge ( exploration , land ): 0.50362
Query weight for textgraph edge ( land , discovery ): 3.02
Key weight for textgraph edge ( land , discovery ): 3.02
Value weight for textgraph edge ( land , discovery ): 3.02
Query weight for textgraph edge ( land , exploration ): 4.038
Key weight for textgraph edge ( land , exploration ): 4.038
Value weight for textgraph edge ( land , exploration ): 4.038
Query weight for textgraph edge ( land , land ): 5.187
Key weight for textgraph edge ( land , land ): 5.187
Value weight for textgraph edge ( land , land ): 5.187
wikipedia search result: Sacramento Kings
Exception
2
defaultdict(<class 'list'>, {'city': ['Sacramento'], 'northeast': ['Sacramento'], 'San': ['Sacramento'], 'ruler': ['king'], 'River': ['Sacramento'], 'Francisco': ['Sacramento'], 'capital': ['Sacramento'], 'male': ['king'], 'miles': ['Sacramento'], 'north': ['Sacramento'], 'kingdom': ['king'], 'central': ['Sacramento'], '75': ['Sacramento'], 'California': ['Sacramento'], 'Sacramento': ['Sacramento'], 'sovereign': ['king']})
('definitiongraph networkx edges:', OutEdgeView([('city', 'Sacramento'), ('Sacramento', 'city'), ('Sacramento', 'northeast'), ('Sacramento', 'San'), ('Sacramento', 'River'), ('Sacramento', 'Francisco'), ('Sacramento', 'capital'), ('Sacramento', 'miles'), ('Sacramento', 'north'), ('Sacramento', 'central'), ('Sacramento', '75'), ('Sacramento', 'California'), ('Sacramento', 'Sacramento'), ('northeast', 'Sacramento'), ('San', 'Sacramento'), ('ruler', 'king'), ('king', 'ruler'), ('king', 'male'), ('king', 'kingdom'), ('king', 'sovereign'), ('River', 'Sacramento'), ('Francisco', 'Sacramento'), ('capital', 'Sacramento'), ('male', 'king'), ('miles', 'Sacramento'), ('north', 'Sacramento'), ('kingdom', 'king'), ('central', 'Sacramento'), ('75', 'Sacramento'), ('California', 'Sacramento'), ('sovereign', 'king')]))
('Core number (sorted) :', [('city', 2), ('Sacramento', 2), ('northeast', 2), ('San', 2), ('ruler', 2), ('king', 2), ('River', 2), ('Francisco', 2), ('capital', 2), ('male', 2), ('miles', 2), ('north', 2), ('kingdom', 2), ('central', 2), ('75', 2), ('California', 2), ('sovereign', 2)])
=============================================================================================================
Unsupervised Classification based on top percentile Core numbers of the definition graph(subgraph of WordNet)
=============================================================================================================
('This document belongs to class:', 'city', ',core number=', 2)
('This document belongs to class:', 'Sacramento', ',core number=', 2)
('This document belongs to class:', 'northeast', ',core number=', 2)
('This document belongs to class:', 'San', ',core number=', 2)
('This document belongs to class:', 'ruler', ',core number=', 2)
('This document belongs to class:', 'king', ',core number=', 2)
('This document belongs to class:', 'River', ',core number=', 2)
('This document belongs to class:', 'Francisco', ',core number=', 2)
('This document belongs to class:', 'capital', ',core number=', 2)
('This document belongs to class:', 'male', ',core number=', 2)
('\tmax_core_number', 2)
===================================================================
Betweenness Centrality of Recursive Gloss Overlap graph vertices
===================================================================
[('Sacramento', 0.4583333333333333), ('king', 0.05), ('city', 0.0), ('northeast', 0.0), ('San', 0.0), ('ruler', 0.0), ('River', 0.0), ('Francisco', 0.0), ('capital', 0.0), ('male', 0.0), ('miles', 0.0), ('north', 0.0), ('kingdom', 0.0), ('central', 0.0), ('75', 0.0), ('California', 0.0), ('sovereign', 0.0)]
===================================================================
Closeness Centrality of Recursive Gloss Overlap graph vertices
===================================================================
[('Sacramento', 0.6875), ('city', 0.3601190476190476), ('northeast', 0.3601190476190476), ('San', 0.3601190476190476), ('River', 0.3601190476190476), ('Francisco', 0.3601190476190476), ('capital', 0.3601190476190476), ('miles', 0.3601190476190476), ('north', 0.3601190476190476), ('central', 0.3601190476190476), ('75', 0.3601190476190476), ('California', 0.3601190476190476), ('king', 0.25), ('ruler', 0.14285714285714285), ('male', 0.14285714285714285), ('kingdom', 0.14285714285714285), ('sovereign', 0.14285714285714285)]
===================================================================
Degree Centrality of Recursive Gloss Overlap graph vertices
===================================================================
[('Sacramento', 1.375), ('king', 0.5), ('city', 0.125), ('northeast', 0.125), ('San', 0.125), ('ruler', 0.125), ('River', 0.125), ('Francisco', 0.125), ('capital', 0.125), ('male', 0.125), ('miles', 0.125), ('north', 0.125), ('kingdom', 0.125), ('central', 0.125), ('75', 0.125), ('California', 0.125), ('sovereign', 0.125)]
===================================================================
Page Rank of the vertices of RGO Definition Graph (a form of Eigenvector Centrality)
===================================================================
[('Sacramento', 0.3290964332346634), ('king', 0.1399054005586343), ('ruler', 0.038553061625047305), ('male', 0.038553061625047305), ('kingdom', 0.038553061625047305), ('sovereign', 0.038553061625047305), ('city', 0.03425326542786483), ('northeast', 0.03425326542786483), ('San', 0.03425326542786483), ('River', 0.03425326542786483), ('Francisco', 0.03425326542786483), ('capital', 0.03425326542786483), ('miles', 0.03425326542786483), ('north', 0.03425326542786483), ('central', 0.03425326542786483), ('75', 0.03425326542786483), ('California', 0.03425326542786483)]
2
RecursiveGlossOverlapGraph(): textgraph =  [('city', 'Sacramento'), ('Sacramento', 'city'), ('Sacramento', 'northeast'), ('Sacramento', 'San'), ('Sacramento', 'River'), ('Sacramento', 'Francisco'), ('Sacramento', 'capital'), ('Sacramento', 'miles'), ('Sacramento', 'north'), ('Sacramento', 'central'), ('Sacramento', '75'), ('Sacramento', 'California'), ('Sacramento', 'Sacramento'), ('northeast', 'Sacramento'), ('San', 'Sacramento'), ('ruler', 'king'), ('king', 'ruler'), ('king', 'male'), ('king', 'kingdom'), ('king', 'sovereign'), ('River', 'Sacramento'), ('Francisco', 'Sacramento'), ('capital', 'Sacramento'), ('male', 'king'), ('miles', 'Sacramento'), ('north', 'Sacramento'), ('kingdom', 'king'), ('central', 'Sacramento'), ('75', 'Sacramento'), ('California', 'Sacramento'), ('sovereign', 'king')]
Answer Textgraph  9 : ([('city', 2), ('Sacramento', 2), ('northeast', 2), ('San', 2), ('ruler', 2), ('king', 2), ('River', 2), ('Francisco', 2), ('capital', 2), ('male', 2), ('miles', 2), ('north', 2), ('kingdom', 2), ('central', 2), ('75', 2), ('California', 2), ('sovereign', 2)], [('Sacramento', 0.3290964332346634), ('king', 0.1399054005586343), ('ruler', 0.038553061625047305), ('male', 0.038553061625047305), ('kingdom', 0.038553061625047305), ('sovereign', 0.038553061625047305), ('city', 0.03425326542786483), ('northeast', 0.03425326542786483), ('San', 0.03425326542786483), ('River', 0.03425326542786483), ('Francisco', 0.03425326542786483), ('capital', 0.03425326542786483), ('miles', 0.03425326542786483), ('north', 0.03425326542786483), ('central', 0.03425326542786483), ('75', 0.03425326542786483), ('California', 0.03425326542786483)])
Attention from Definition Graph: [[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.041666666666666664, 0.041666666666666664, 0.041666666666666664, 0.041666666666666664, 0.041666666666666664, 0.041666666666666664, 0.041666666666666664, 0.041666666666666664, 0.041666666666666664, 0.041666666666666664, 0.041666666666666664, 0.041666666666666664, 0.041666666666666664, 0.041666666666666664, 0.041666666666666664, 0.041666666666666664], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]]
Attention slice from Definition Graph: [[0.5, 0.5, 0.5], [0.041666666666666664, 0.041666666666666664, 0.041666666666666664], [0.5, 0.5, 0.5]]
weights: [1, 2, 3]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  1.012
LinearPerceptronGradient() weight update iteration: deltaw =  [0.12000000000000002, 0.13200000000000003, 0.33799999999999997]
weights: [1.012, 2, 3]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  2.0132
LinearPerceptronGradient() weight update iteration: deltaw =  [0.12000000000000002, 0.13200000000000003, 0.33799999999999997]
weights: [1.012, 2.0132, 3]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  3.0338
LinearPerceptronGradient() weight update iteration: deltaw =  [0.12000000000000002, 0.13200000000000003, 0.33799999999999997]
weights updated after Gradient :  [1.012, 2.0132, 3.0338]
converged: True
weights: [0.1, 0.3, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.041666666666666664, 0.041666666666666664, 0.041666666666666664]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  0.11596666666666668
LinearPerceptronGradient() weight update iteration: deltaw =  [0.1596666666666667, 0.17930000000000004, 0.22745000000000004]
weights: [0.11596666666666668, 0.3, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.041666666666666664, 0.041666666666666664, 0.041666666666666664]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  0.31793
LinearPerceptronGradient() weight update iteration: deltaw =  [0.1596666666666667, 0.17930000000000004, 0.22745000000000004]
weights: [0.11596666666666668, 0.31793, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.041666666666666664, 0.041666666666666664, 0.041666666666666664]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  0.522745
LinearPerceptronGradient() weight update iteration: deltaw =  [0.1596666666666667, 0.17930000000000004, 0.22745000000000004]
weights updated after Gradient :  [0.11596666666666668, 0.31793, 0.522745]
converged: True
weights: [3, 4, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  3.02
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights: [3.02, 4, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  4.038
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights: [3.02, 4.038, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  5.187
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights updated after Gradient :  [3.02, 4.038, 5.187]
converged: True
Learnt Query Weights: [[1.012, 2.0132, 3.0338], [0.11596666666666668, 0.31793, 0.522745], [3.02, 4.038, 5.187]]
weights: [4, 5, 6]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  4.024
LinearPerceptronGradient() weight update iteration: deltaw =  [0.24000000000000005, 0.504, 2.636]
weights: [4.024, 5, 6]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  5.0504
LinearPerceptronGradient() weight update iteration: deltaw =  [0.24000000000000005, 0.504, 2.636]
weights: [4.024, 5.0504, 6]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  6.2636
LinearPerceptronGradient() weight update iteration: deltaw =  [0.24000000000000005, 0.504, 2.636]
weights updated after Gradient :  [4.024, 5.0504, 6.2636]
converged: True
weights: [0.1, 0.3, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.041666666666666664, 0.041666666666666664, 0.041666666666666664]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  0.11596666666666668
LinearPerceptronGradient() weight update iteration: deltaw =  [0.1596666666666667, 0.17930000000000004, 0.22745000000000004]
weights: [0.11596666666666668, 0.3, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.041666666666666664, 0.041666666666666664, 0.041666666666666664]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  0.31793
LinearPerceptronGradient() weight update iteration: deltaw =  [0.1596666666666667, 0.17930000000000004, 0.22745000000000004]
weights: [0.11596666666666668, 0.31793, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.041666666666666664, 0.041666666666666664, 0.041666666666666664]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  0.522745
LinearPerceptronGradient() weight update iteration: deltaw =  [0.1596666666666667, 0.17930000000000004, 0.22745000000000004]
weights updated after Gradient :  [0.11596666666666668, 0.31793, 0.522745]
converged: True
weights: [3, 4, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  3.02
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights: [3.02, 4, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  4.038
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights: [3.02, 4.038, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  5.187
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights updated after Gradient :  [3.02, 4.038, 5.187]
converged: True
Learnt Key Weights: [[4.024, 5.0504, 6.2636], [0.11596666666666668, 0.31793, 0.522745], [3.02, 4.038, 5.187]]
weights: [7, 8, 9]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  7.036
LinearPerceptronGradient() weight update iteration: deltaw =  [0.36, 0.876, 4.934]
weights: [7.036, 8, 9]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  8.0876
LinearPerceptronGradient() weight update iteration: deltaw =  [0.36, 0.876, 4.934]
weights: [7.036, 8.0876, 9]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  9.4934
LinearPerceptronGradient() weight update iteration: deltaw =  [0.36, 0.876, 4.934]
weights updated after Gradient :  [7.036, 8.0876, 9.4934]
converged: True
weights: [0.1, 0.3, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.041666666666666664, 0.041666666666666664, 0.041666666666666664]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  0.11596666666666668
LinearPerceptronGradient() weight update iteration: deltaw =  [0.1596666666666667, 0.17930000000000004, 0.22745000000000004]
weights: [0.11596666666666668, 0.3, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.041666666666666664, 0.041666666666666664, 0.041666666666666664]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  0.31793
LinearPerceptronGradient() weight update iteration: deltaw =  [0.1596666666666667, 0.17930000000000004, 0.22745000000000004]
weights: [0.11596666666666668, 0.31793, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.041666666666666664, 0.041666666666666664, 0.041666666666666664]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  0.522745
LinearPerceptronGradient() weight update iteration: deltaw =  [0.1596666666666667, 0.17930000000000004, 0.22745000000000004]
weights updated after Gradient :  [0.11596666666666668, 0.31793, 0.522745]
converged: True
weights: [3, 4, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  3.02
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights: [3.02, 4, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  4.038
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights: [3.02, 4.038, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  5.187
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights updated after Gradient :  [3.02, 4.038, 5.187]
converged: True
Learnt Values Weights: [[7.036, 8.0876, 9.4934], [0.11596666666666668, 0.31793, 0.522745], [3.02, 4.038, 5.187]]
Query weight for textgraph edge ( city , city ): 1.012
Key weight for textgraph edge ( city , city ): 4.024
Value weight for textgraph edge ( city , city ): 7.036
Query weight for textgraph edge ( city , Sacramento ): 2.0132
Key weight for textgraph edge ( city , Sacramento ): 5.0504
Value weight for textgraph edge ( city , Sacramento ): 8.0876
Query weight for textgraph edge ( city , northeast ): 3.0338
Key weight for textgraph edge ( city , northeast ): 6.2636
Value weight for textgraph edge ( city , northeast ): 9.4934
Query weight for textgraph edge ( Sacramento , city ): 0.11596666666666668
Key weight for textgraph edge ( Sacramento , city ): 0.11596666666666668
Value weight for textgraph edge ( Sacramento , city ): 0.11596666666666668
Query weight for textgraph edge ( Sacramento , Sacramento ): 0.31793
Key weight for textgraph edge ( Sacramento , Sacramento ): 0.31793
Value weight for textgraph edge ( Sacramento , Sacramento ): 0.31793
Query weight for textgraph edge ( Sacramento , northeast ): 0.522745
Key weight for textgraph edge ( Sacramento , northeast ): 0.522745
Value weight for textgraph edge ( Sacramento , northeast ): 0.522745
Query weight for textgraph edge ( northeast , city ): 3.02
Key weight for textgraph edge ( northeast , city ): 3.02
Value weight for textgraph edge ( northeast , city ): 3.02
Query weight for textgraph edge ( northeast , Sacramento ): 4.038
Key weight for textgraph edge ( northeast , Sacramento ): 4.038
Value weight for textgraph edge ( northeast , Sacramento ): 4.038
Query weight for textgraph edge ( northeast , northeast ): 5.187
Key weight for textgraph edge ( northeast , northeast ): 5.187
Value weight for textgraph edge ( northeast , northeast ): 5.187
wikipedia search result: Honor of Kings
Exception
2
defaultdict(<class 'list'>, {'distinction': ['award'], 'signifying': ['award'], 'approval': ['award'], 'symbol': ['award'], 'kingdom': ['king'], 'ruler': ['king'], 'male': ['king'], 'tangible': ['award'], 'sovereign': ['king']})
('definitiongraph networkx edges:', OutEdgeView([('distinction', 'award'), ('award', 'distinction'), ('award', 'signifying'), ('award', 'approval'), ('award', 'symbol'), ('award', 'tangible'), ('signifying', 'award'), ('approval', 'award'), ('symbol', 'award'), ('kingdom', 'king'), ('king', 'kingdom'), ('king', 'ruler'), ('king', 'male'), ('king', 'sovereign'), ('ruler', 'king'), ('male', 'king'), ('tangible', 'award'), ('sovereign', 'king')]))
('Core number (sorted) :', [('distinction', 2), ('award', 2), ('signifying', 2), ('approval', 2), ('symbol', 2), ('kingdom', 2), ('king', 2), ('ruler', 2), ('male', 2), ('tangible', 2), ('sovereign', 2)])
=============================================================================================================
Unsupervised Classification based on top percentile Core numbers of the definition graph(subgraph of WordNet)
=============================================================================================================
('This document belongs to class:', 'distinction', ',core number=', 2)
('This document belongs to class:', 'award', ',core number=', 2)
('This document belongs to class:', 'signifying', ',core number=', 2)
('This document belongs to class:', 'approval', ',core number=', 2)
('This document belongs to class:', 'symbol', ',core number=', 2)
('This document belongs to class:', 'kingdom', ',core number=', 2)
('This document belongs to class:', 'king', ',core number=', 2)
('\tmax_core_number', 2)
===================================================================
Betweenness Centrality of Recursive Gloss Overlap graph vertices
===================================================================
[('award', 0.22222222222222224), ('king', 0.13333333333333333), ('distinction', 0.0), ('signifying', 0.0), ('approval', 0.0), ('symbol', 0.0), ('kingdom', 0.0), ('ruler', 0.0), ('male', 0.0), ('tangible', 0.0), ('sovereign', 0.0)]
===================================================================
Closeness Centrality of Recursive Gloss Overlap graph vertices
===================================================================
[('award', 0.5), ('king', 0.4), ('distinction', 0.2777777777777778), ('signifying', 0.2777777777777778), ('approval', 0.2777777777777778), ('symbol', 0.2777777777777778), ('tangible', 0.2777777777777778), ('kingdom', 0.22857142857142856), ('ruler', 0.22857142857142856), ('male', 0.22857142857142856), ('sovereign', 0.22857142857142856)]
===================================================================
Degree Centrality of Recursive Gloss Overlap graph vertices
===================================================================
[('award', 1.0), ('king', 0.8), ('distinction', 0.2), ('signifying', 0.2), ('approval', 0.2), ('symbol', 0.2), ('kingdom', 0.2), ('ruler', 0.2), ('male', 0.2), ('tangible', 0.2), ('sovereign', 0.2)]
===================================================================
Page Rank of the vertices of RGO Definition Graph (a form of Eigenvector Centrality)
===================================================================
[('award', 0.2579838741730587), ('king', 0.2162151783570667), ('kingdom', 0.05958256904709696), ('ruler', 0.05958256904709696), ('male', 0.05958256904709696), ('sovereign', 0.05958256904709696), ('distinction', 0.057494134256297375), ('signifying', 0.057494134256297375), ('approval', 0.057494134256297375), ('symbol', 0.057494134256297375), ('tangible', 0.057494134256297375)]
2
RecursiveGlossOverlapGraph(): textgraph =  [('distinction', 'award'), ('award', 'distinction'), ('award', 'signifying'), ('award', 'approval'), ('award', 'symbol'), ('award', 'tangible'), ('signifying', 'award'), ('approval', 'award'), ('symbol', 'award'), ('kingdom', 'king'), ('king', 'kingdom'), ('king', 'ruler'), ('king', 'male'), ('king', 'sovereign'), ('ruler', 'king'), ('male', 'king'), ('tangible', 'award'), ('sovereign', 'king')]
Answer Textgraph  10 : ([('distinction', 2), ('award', 2), ('signifying', 2), ('approval', 2), ('symbol', 2), ('kingdom', 2), ('king', 2), ('ruler', 2), ('male', 2), ('tangible', 2), ('sovereign', 2)], [('award', 0.2579838741730587), ('king', 0.2162151783570667), ('kingdom', 0.05958256904709696), ('ruler', 0.05958256904709696), ('male', 0.05958256904709696), ('sovereign', 0.05958256904709696), ('distinction', 0.057494134256297375), ('signifying', 0.057494134256297375), ('approval', 0.057494134256297375), ('symbol', 0.057494134256297375), ('tangible', 0.057494134256297375)])
Attention from Definition Graph: [[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]]
Attention slice from Definition Graph: [[0.5, 0.5, 0.5], [0.1, 0.1, 0.1], [0.5, 0.5, 0.5]]
weights: [1, 2, 3]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  1.012
LinearPerceptronGradient() weight update iteration: deltaw =  [0.12000000000000002, 0.13200000000000003, 0.33799999999999997]
weights: [1.012, 2, 3]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  2.0132
LinearPerceptronGradient() weight update iteration: deltaw =  [0.12000000000000002, 0.13200000000000003, 0.33799999999999997]
weights: [1.012, 2.0132, 3]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  3.0338
LinearPerceptronGradient() weight update iteration: deltaw =  [0.12000000000000002, 0.13200000000000003, 0.33799999999999997]
weights updated after Gradient :  [1.012, 2.0132, 3.0338]
converged: True
weights: [0.1, 0.3, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.1, 0.1, 0.1]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  0.11480000000000001
LinearPerceptronGradient() weight update iteration: deltaw =  [0.14800000000000002, 0.15480000000000002, 0.13820000000000002]
weights: [0.11480000000000001, 0.3, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.1, 0.1, 0.1]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  0.31548
LinearPerceptronGradient() weight update iteration: deltaw =  [0.14800000000000002, 0.15480000000000002, 0.13820000000000002]
weights: [0.11480000000000001, 0.31548, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.1, 0.1, 0.1]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  0.51382
LinearPerceptronGradient() weight update iteration: deltaw =  [0.14800000000000002, 0.15480000000000002, 0.13820000000000002]
weights updated after Gradient :  [0.11480000000000001, 0.31548, 0.51382]
converged: True
weights: [3, 4, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  3.02
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights: [3.02, 4, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  4.038
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights: [3.02, 4.038, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  5.187
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights updated after Gradient :  [3.02, 4.038, 5.187]
converged: True
Learnt Query Weights: [[1.012, 2.0132, 3.0338], [0.11480000000000001, 0.31548, 0.51382], [3.02, 4.038, 5.187]]
weights: [4, 5, 6]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  4.024
LinearPerceptronGradient() weight update iteration: deltaw =  [0.24000000000000005, 0.504, 2.636]
weights: [4.024, 5, 6]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  5.0504
LinearPerceptronGradient() weight update iteration: deltaw =  [0.24000000000000005, 0.504, 2.636]
weights: [4.024, 5.0504, 6]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  6.2636
LinearPerceptronGradient() weight update iteration: deltaw =  [0.24000000000000005, 0.504, 2.636]
weights updated after Gradient :  [4.024, 5.0504, 6.2636]
converged: True
weights: [0.1, 0.3, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.1, 0.1, 0.1]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  0.11480000000000001
LinearPerceptronGradient() weight update iteration: deltaw =  [0.14800000000000002, 0.15480000000000002, 0.13820000000000002]
weights: [0.11480000000000001, 0.3, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.1, 0.1, 0.1]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  0.31548
LinearPerceptronGradient() weight update iteration: deltaw =  [0.14800000000000002, 0.15480000000000002, 0.13820000000000002]
weights: [0.11480000000000001, 0.31548, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.1, 0.1, 0.1]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  0.51382
LinearPerceptronGradient() weight update iteration: deltaw =  [0.14800000000000002, 0.15480000000000002, 0.13820000000000002]
weights updated after Gradient :  [0.11480000000000001, 0.31548, 0.51382]
converged: True
weights: [3, 4, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  3.02
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights: [3.02, 4, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  4.038
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights: [3.02, 4.038, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  5.187
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights updated after Gradient :  [3.02, 4.038, 5.187]
converged: True
Learnt Key Weights: [[4.024, 5.0504, 6.2636], [0.11480000000000001, 0.31548, 0.51382], [3.02, 4.038, 5.187]]
weights: [7, 8, 9]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  7.036
LinearPerceptronGradient() weight update iteration: deltaw =  [0.36, 0.876, 4.934]
weights: [7.036, 8, 9]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  8.0876
LinearPerceptronGradient() weight update iteration: deltaw =  [0.36, 0.876, 4.934]
weights: [7.036, 8.0876, 9]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  9.4934
LinearPerceptronGradient() weight update iteration: deltaw =  [0.36, 0.876, 4.934]
weights updated after Gradient :  [7.036, 8.0876, 9.4934]
converged: True
weights: [0.1, 0.3, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.1, 0.1, 0.1]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  0.11480000000000001
LinearPerceptronGradient() weight update iteration: deltaw =  [0.14800000000000002, 0.15480000000000002, 0.13820000000000002]
weights: [0.11480000000000001, 0.3, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.1, 0.1, 0.1]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  0.31548
LinearPerceptronGradient() weight update iteration: deltaw =  [0.14800000000000002, 0.15480000000000002, 0.13820000000000002]
weights: [0.11480000000000001, 0.31548, 0.5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.1, 0.1, 0.1]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  0.51382
LinearPerceptronGradient() weight update iteration: deltaw =  [0.14800000000000002, 0.15480000000000002, 0.13820000000000002]
weights updated after Gradient :  [0.11480000000000001, 0.31548, 0.51382]
converged: True
weights: [3, 4, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 0 ] =  3.02
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights: [3.02, 4, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 1 ] =  4.038
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights: [3.02, 4.038, 5]
variables: [[0.1, 0.3, 0.5], [0.1, 0.1, 0.1], [0.2, 0.3, 0.5]]
outputs: [0.5, 0.5, 0.5]
LinearPerceptronGradient() weight update iteration: Ascending
LinearPerceptronGradient() weight update iteration: weights[ 2 ] =  5.187
LinearPerceptronGradient() weight update iteration: deltaw =  [0.2, 0.38, 1.87]
weights updated after Gradient :  [3.02, 4.038, 5.187]
converged: True
Learnt Values Weights: [[7.036, 8.0876, 9.4934], [0.11480000000000001, 0.31548, 0.51382], [3.02, 4.038, 5.187]]
Query weight for textgraph edge ( distinction , distinction ): 1.012
Key weight for textgraph edge ( distinction , distinction ): 4.024
Value weight for textgraph edge ( distinction , distinction ): 7.036
Query weight for textgraph edge ( distinction , award ): 2.0132
Key weight for textgraph edge ( distinction , award ): 5.0504
Value weight for textgraph edge ( distinction , award ): 8.0876
Query weight for textgraph edge ( distinction , signifying ): 3.0338
Key weight for textgraph edge ( distinction , signifying ): 6.2636
Value weight for textgraph edge ( distinction , signifying ): 9.4934
Query weight for textgraph edge ( award , distinction ): 0.11480000000000001
Key weight for textgraph edge ( award , distinction ): 0.11480000000000001
Value weight for textgraph edge ( award , distinction ): 0.11480000000000001
Query weight for textgraph edge ( award , award ): 0.31548
Key weight for textgraph edge ( award , award ): 0.31548
Value weight for textgraph edge ( award , award ): 0.31548
Query weight for textgraph edge ( award , signifying ): 0.51382
Key weight for textgraph edge ( award , signifying ): 0.51382
Value weight for textgraph edge ( award , signifying ): 0.51382
Query weight for textgraph edge ( signifying , distinction ): 3.02
Key weight for textgraph edge ( signifying , distinction ): 3.02
Value weight for textgraph edge ( signifying , distinction ): 3.02
Query weight for textgraph edge ( signifying , award ): 4.038
Key weight for textgraph edge ( signifying , award ): 4.038
Value weight for textgraph edge ( signifying , award ): 4.038
Query weight for textgraph edge ( signifying , signifying ): 5.187
Key weight for textgraph edge ( signifying , signifying ): 5.187
Value weight for textgraph edge ( signifying , signifying ): 5.187
