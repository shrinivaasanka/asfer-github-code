root@shrinivaasanka-Inspiron-1545:/home/shrinivaasanka/Krishna_iResearch_OpenSource/GitHub/asfer-github-code/python-src# /home/shrinivaasanka/spark-2.1.0-bin-hadoop2.7/bin/spark-submit DiscreteHyperbolicFactorizationUpperbound_TileSearch_Optimized.py 1071
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
18/03/21 16:09:21 WARN Utils: Your hostname, shrinivaasanka-Inspiron-1545 resolves to a loopback address: 127.0.1.1; using 192.168.122.1 instead (on interface virbr0)
18/03/21 16:09:21 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
18/03/21 16:09:24 INFO SparkContext: Running Spark version 2.1.0
18/03/21 16:09:24 WARN SparkContext: Support for Java 7 is deprecated as of Spark 2.0.0
18/03/21 16:09:25 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
18/03/21 16:09:25 WARN SparkConf: Detected deprecated memory fraction settings: [spark.shuffle.memoryFraction, spark.storage.memoryFraction]. As of Spark 1.6, execution and storage memory management are unified. All memory fractions used in the old model are now deprecated and no longer read. If you wish to use the old memory management, you may explicitly enable `spark.memory.useLegacyMode` (not recommended).
18/03/21 16:09:25 INFO SecurityManager: Changing view acls to: root
18/03/21 16:09:25 INFO SecurityManager: Changing modify acls to: root
18/03/21 16:09:25 INFO SecurityManager: Changing view acls groups to: 
18/03/21 16:09:25 INFO SecurityManager: Changing modify acls groups to: 
18/03/21 16:09:25 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
18/03/21 16:09:26 INFO Utils: Successfully started service 'sparkDriver' on port 59010.
18/03/21 16:09:26 INFO SparkEnv: Registering MapOutputTracker
18/03/21 16:09:27 INFO SparkEnv: Registering BlockManagerMaster
18/03/21 16:09:27 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
18/03/21 16:09:27 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
18/03/21 16:09:27 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-e62fefd1-b27f-452c-bfce-4061063c2571
18/03/21 16:09:27 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
18/03/21 16:09:27 INFO SparkEnv: Registering OutputCommitCoordinator
18/03/21 16:09:28 INFO Utils: Successfully started service 'SparkUI' on port 4040.
18/03/21 16:09:28 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.122.1:4040
18/03/21 16:09:28 INFO SparkContext: Added file file:/home/shrinivaasanka/Krishna_iResearch_OpenSource/GitHub/asfer-github-code/python-src/DiscreteHyperbolicFactorizationUpperbound_TileSearch_Optimized.py at file:/home/shrinivaasanka/Krishna_iResearch_OpenSource/GitHub/asfer-github-code/python-src/DiscreteHyperbolicFactorizationUpperbound_TileSearch_Optimized.py with timestamp 1521628768861
18/03/21 16:09:28 INFO Utils: Copying /home/shrinivaasanka/Krishna_iResearch_OpenSource/GitHub/asfer-github-code/python-src/DiscreteHyperbolicFactorizationUpperbound_TileSearch_Optimized.py to /tmp/spark-e3e0ac95-cc1e-49d6-8474-2b72021d8c07/userFiles-ba8e05fd-fa5e-4dfe-9720-fa73c27f86f1/DiscreteHyperbolicFactorizationUpperbound_TileSearch_Optimized.py
18/03/21 16:09:29 INFO Executor: Starting executor ID driver on host localhost
18/03/21 16:09:29 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45734.
18/03/21 16:09:29 INFO NettyBlockTransferService: Server created on 192.168.122.1:45734
18/03/21 16:09:29 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
18/03/21 16:09:29 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.122.1, 45734, None)
18/03/21 16:09:29 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.122.1:45734 with 912.3 MB RAM, BlockManagerId(driver, 192.168.122.1, 45734, None)
18/03/21 16:09:29 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.122.1, 45734, None)
18/03/21 16:09:29 INFO BlockManager: external shuffle service port = 7337
18/03/21 16:09:29 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.122.1, 45734, None)
18/03/21 16:09:30 INFO EventLoggingListener: Logging events to file:///home/shrinivaasanka/SparkEventLogs/local-1521628769029
=============================================================================================================
Hardy-Ramanujan Ray Shooting Queries - Approximate Factors of  1071  are:
=============================================================================================================
normal_order_n(loglogN) =  6
approximate_factor( 1 ) =  62.2220405785
approximate_factor( 2 ) =  42.0700175866
approximate_factor( 3 ) =  31.7261363439
approximate_factor( 4 ) =  23.8664862476
approximate_factor( 5 ) =  15.9402947168
=============================================================================================================
18/03/21 16:09:31 INFO SparkContext: Starting job: foreach at /home/shrinivaasanka/Krishna_iResearch_OpenSource/GitHub/asfer-github-code/python-src/DiscreteHyperbolicFactorizationUpperbound_TileSearch_Optimized.py:167
18/03/21 16:09:31 INFO DAGScheduler: Got job 0 (foreach at /home/shrinivaasanka/Krishna_iResearch_OpenSource/GitHub/asfer-github-code/python-src/DiscreteHyperbolicFactorizationUpperbound_TileSearch_Optimized.py:167) with 3 output partitions
18/03/21 16:09:31 INFO DAGScheduler: Final stage: ResultStage 0 (foreach at /home/shrinivaasanka/Krishna_iResearch_OpenSource/GitHub/asfer-github-code/python-src/DiscreteHyperbolicFactorizationUpperbound_TileSearch_Optimized.py:167)
18/03/21 16:09:31 INFO DAGScheduler: Parents of final stage: List()
18/03/21 16:09:31 INFO DAGScheduler: Missing parents: List()
18/03/21 16:09:31 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[1] at foreach at /home/shrinivaasanka/Krishna_iResearch_OpenSource/GitHub/asfer-github-code/python-src/DiscreteHyperbolicFactorizationUpperbound_TileSearch_Optimized.py:167), which has no missing parents
18/03/21 16:09:31 WARN SizeEstimator: Failed to check whether UseCompressedOops is set; assuming yes
18/03/21 16:09:31 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.4 KB, free 912.3 MB)
18/03/21 16:09:32 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 912.3 MB)
18/03/21 16:09:32 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.122.1:45734 (size: 4.1 KB, free: 912.3 MB)
18/03/21 16:09:32 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:996
18/03/21 16:09:32 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 0 (PythonRDD[1] at foreach at /home/shrinivaasanka/Krishna_iResearch_OpenSource/GitHub/asfer-github-code/python-src/DiscreteHyperbolicFactorizationUpperbound_TileSearch_Optimized.py:167)
18/03/21 16:09:32 INFO TaskSchedulerImpl: Adding task set 0.0 with 3 tasks
18/03/21 16:09:32 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 6208 bytes)
18/03/21 16:09:32 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
18/03/21 16:09:32 INFO Executor: Fetching file:/home/shrinivaasanka/Krishna_iResearch_OpenSource/GitHub/asfer-github-code/python-src/DiscreteHyperbolicFactorizationUpperbound_TileSearch_Optimized.py with timestamp 1521628768861
18/03/21 16:09:32 INFO Utils: /home/shrinivaasanka/Krishna_iResearch_OpenSource/GitHub/asfer-github-code/python-src/DiscreteHyperbolicFactorizationUpperbound_TileSearch_Optimized.py has been previously copied to /tmp/spark-e3e0ac95-cc1e-49d6-8474-2b72021d8c07/userFiles-ba8e05fd-fa5e-4dfe-9720-fa73c27f86f1/DiscreteHyperbolicFactorizationUpperbound_TileSearch_Optimized.py
=================================================
Factor is =  1
=================================================
=================================================
Factor is =  3
=================================================
=================================================
Factor is =  7
=================================================
=================================================
Factor is =  9
=================================================
=================================================
Factor is =  17
=================================================
=================================================
Factor is =  21
=================================================
=================================================
Factor is =  51
=================================================
=================================================
Factor is =  63
=================================================
=================================================
Factor is =  119
=================================================
=================================================
Factor is =  153
=================================================
18/03/21 16:09:33 INFO PythonRunner: Times: total = 662, boot = 640, init = 21, finish = 1
18/03/21 16:09:33 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1529 bytes result sent to driver
18/03/21 16:09:33 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 6208 bytes)
18/03/21 16:09:33 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
18/03/21 16:09:33 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1144 ms on localhost (executor driver) (1/3)
=================================================
Factor is =  357
=================================================
18/03/21 16:09:33 INFO PythonRunner: Times: total = 10, boot = 5, init = 4, finish = 1
18/03/21 16:09:33 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1529 bytes result sent to driver
18/03/21 16:09:33 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, localhost, executor driver, partition 2, PROCESS_LOCAL, 6208 bytes)
18/03/21 16:09:33 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
18/03/21 16:09:33 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 213 ms on localhost (executor driver) (2/3)
18/03/21 16:09:33 INFO PythonRunner: Times: total = 8, boot = 4, init = 3, finish = 1
18/03/21 16:09:33 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1529 bytes result sent to driver
18/03/21 16:09:33 INFO DAGScheduler: ResultStage 0 (foreach at /home/shrinivaasanka/Krishna_iResearch_OpenSource/GitHub/asfer-github-code/python-src/DiscreteHyperbolicFactorizationUpperbound_TileSearch_Optimized.py:167) finished in 1.484 s
18/03/21 16:09:33 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 197 ms on localhost (executor driver) (3/3)
18/03/21 16:09:33 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
18/03/21 16:09:33 INFO DAGScheduler: Job 0 finished: foreach at /home/shrinivaasanka/Krishna_iResearch_OpenSource/GitHub/asfer-github-code/python-src/DiscreteHyperbolicFactorizationUpperbound_TileSearch_Optimized.py:167, took 2.567916 s
18/03/21 16:09:33 INFO SparkContext: Invoking stop() from shutdown hook
18/03/21 16:09:33 INFO SparkUI: Stopped Spark web UI at http://192.168.122.1:4040
18/03/21 16:09:33 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
18/03/21 16:09:33 INFO MemoryStore: MemoryStore cleared
18/03/21 16:09:33 INFO BlockManager: BlockManager stopped
18/03/21 16:09:34 INFO BlockManagerMaster: BlockManagerMaster stopped
18/03/21 16:09:34 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
18/03/21 16:09:34 INFO SparkContext: Successfully stopped SparkContext
18/03/21 16:09:34 INFO ShutdownHookManager: Shutdown hook called
18/03/21 16:09:34 INFO ShutdownHookManager: Deleting directory /tmp/spark-e3e0ac95-cc1e-49d6-8474-2b72021d8c07
18/03/21 16:09:34 INFO ShutdownHookManager: Deleting directory /tmp/spark-e3e0ac95-cc1e-49d6-8474-2b72021d8c07/pyspark-9ca5e9ac-5553-4344-832a-fd2ec4c17e5e
