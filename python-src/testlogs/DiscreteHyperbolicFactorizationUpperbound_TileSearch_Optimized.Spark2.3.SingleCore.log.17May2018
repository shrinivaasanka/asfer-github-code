root@HCL:/media/Krishna_iResearch_/Krishna_iResearch_OpenSource/GitHub/asfer-github-code/python-src# /home/kashrinivaasan/spark-2.3.0-bin-hadoop2.7/bin/spark-submit DiscreteHyperbolicFactorizationUpperbound_TileSearch_Optimized.py 999999999 2> testlogs/DiscreteHyperbolicFactorizationUpperbound_TileSearch_Optimized.log.17May2018
2018-05-17 17:44:30 WARN  Utils:66 - Your hostname, HCL resolves to a loopback address: 127.0.1.1; using 192.168.1.116 instead (on interface usb0)
2018-05-17 17:44:30 WARN  Utils:66 - Set SPARK_LOCAL_IP if you need to bind to another address
2018-05-17 17:44:31 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-05-17 17:44:33 INFO  SparkContext:54 - Running Spark version 2.3.0
2018-05-17 17:44:33 INFO  SparkContext:54 - Submitted application: Spark_TileSearch_Optimized
2018-05-17 17:44:33 INFO  SecurityManager:54 - Changing view acls to: root
2018-05-17 17:44:33 INFO  SecurityManager:54 - Changing modify acls to: root
2018-05-17 17:44:33 INFO  SecurityManager:54 - Changing view acls groups to: 
2018-05-17 17:44:33 INFO  SecurityManager:54 - Changing modify acls groups to: 
2018-05-17 17:44:33 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
2018-05-17 17:44:34 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 38570.
2018-05-17 17:44:34 INFO  SparkEnv:54 - Registering MapOutputTracker
2018-05-17 17:44:34 INFO  SparkEnv:54 - Registering BlockManagerMaster
2018-05-17 17:44:34 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-05-17 17:44:34 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2018-05-17 17:44:34 INFO  DiskBlockManager:54 - Created local directory at /tmp/blockmgr-255a65a1-707f-458f-b6bf-a2fe240afbc6
2018-05-17 17:44:34 INFO  MemoryStore:54 - MemoryStore started with capacity 413.9 MB
2018-05-17 17:44:34 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2018-05-17 17:44:34 INFO  log:192 - Logging initialized @6201ms
2018-05-17 17:44:35 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2018-05-17 17:44:35 INFO  Server:414 - Started @6447ms
2018-05-17 17:44:35 INFO  AbstractConnector:278 - Started ServerConnector@1c632e8{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-05-17 17:44:35 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2018-05-17 17:44:35 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1dcc4e3{/jobs,null,AVAILABLE,@Spark}
2018-05-17 17:44:35 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a737fa{/jobs/json,null,AVAILABLE,@Spark}
2018-05-17 17:44:35 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f3c17{/jobs/job,null,AVAILABLE,@Spark}
2018-05-17 17:44:35 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@b88152{/jobs/job/json,null,AVAILABLE,@Spark}
2018-05-17 17:44:35 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1f77798{/stages,null,AVAILABLE,@Spark}
2018-05-17 17:44:35 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@351f35{/stages/json,null,AVAILABLE,@Spark}
2018-05-17 17:44:35 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1681190{/stages/stage,null,AVAILABLE,@Spark}
2018-05-17 17:44:35 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1e9258e{/stages/stage/json,null,AVAILABLE,@Spark}
2018-05-17 17:44:35 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6842b2{/stages/pool,null,AVAILABLE,@Spark}
2018-05-17 17:44:35 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@a1f907{/stages/pool/json,null,AVAILABLE,@Spark}
2018-05-17 17:44:35 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@12221ef{/storage,null,AVAILABLE,@Spark}
2018-05-17 17:44:35 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@13fb210{/storage/json,null,AVAILABLE,@Spark}
2018-05-17 17:44:35 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1f40557{/storage/rdd,null,AVAILABLE,@Spark}
2018-05-17 17:44:35 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4ca36f{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-05-17 17:44:35 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@69c310{/environment,null,AVAILABLE,@Spark}
2018-05-17 17:44:35 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@fa4bff{/environment/json,null,AVAILABLE,@Spark}
2018-05-17 17:44:35 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1f33a4a{/executors,null,AVAILABLE,@Spark}
2018-05-17 17:44:35 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@67be40{/executors/json,null,AVAILABLE,@Spark}
2018-05-17 17:44:35 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f69cdf{/executors/threadDump,null,AVAILABLE,@Spark}
2018-05-17 17:44:35 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@13864d{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-05-17 17:44:35 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@eec9af{/static,null,AVAILABLE,@Spark}
2018-05-17 17:44:35 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1c7c9e4{/,null,AVAILABLE,@Spark}
2018-05-17 17:44:35 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@13ac8d1{/api,null,AVAILABLE,@Spark}
2018-05-17 17:44:35 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f25308{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-05-17 17:44:35 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@112614c{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-05-17 17:44:35 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://192.168.1.116:4040
2018-05-17 17:44:36 INFO  SparkContext:54 - Added file file:/media/Krishna_iResearch_/Krishna_iResearch_OpenSource/GitHub/asfer-github-code/python-src/DiscreteHyperbolicFactorizationUpperbound_TileSearch_Optimized.py at file:/media/Krishna_iResearch_/Krishna_iResearch_OpenSource/GitHub/asfer-github-code/python-src/DiscreteHyperbolicFactorizationUpperbound_TileSearch_Optimized.py with timestamp 1526559276104
2018-05-17 17:44:36 INFO  Utils:54 - Copying /media/Krishna_iResearch_/Krishna_iResearch_OpenSource/GitHub/asfer-github-code/python-src/DiscreteHyperbolicFactorizationUpperbound_TileSearch_Optimized.py to /tmp/spark-ea6a1cf1-6816-4cc1-81a0-8b6e9ba35e94/userFiles-7ba0a1c2-8ecf-4657-96ea-a3f4ebac0d12/DiscreteHyperbolicFactorizationUpperbound_TileSearch_Optimized.py
2018-05-17 17:44:36 INFO  Executor:54 - Starting executor ID driver on host localhost
2018-05-17 17:44:36 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50885.
2018-05-17 17:44:36 INFO  NettyBlockTransferService:54 - Server created on 192.168.1.116:50885
2018-05-17 17:44:36 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-05-17 17:44:36 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 192.168.1.116, 50885, None)
2018-05-17 17:44:36 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 192.168.1.116:50885 with 413.9 MB RAM, BlockManagerId(driver, 192.168.1.116, 50885, None)
2018-05-17 17:44:36 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 192.168.1.116, 50885, None)
2018-05-17 17:44:36 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 192.168.1.116, 50885, None)
2018-05-17 17:44:37 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@cc6913{/metrics/json,null,AVAILABLE,@Spark}
=============================================================================================================
Hardy-Ramanujan Ray Shooting Queries - Approximate Factors of  999999999  are:
=============================================================================================================
normal_order_n(loglogN) =  9
approximate_factor( 1 ) =  75306.9133554
approximate_factor( 2 ) =  52415.3850023
approximate_factor( 3 ) =  41616.9144821
approximate_factor( 4 ) =  34520.7843021
approximate_factor( 5 ) =  28966.2164755
approximate_factor( 6 ) =  24027.1141293
approximate_factor( 7 ) =  19077.0039287
approximate_factor( 8 ) =  13277.8169854
=============================================================================================================
2018-05-17 17:44:38 INFO  SparkContext:54 - Starting job: foreach at /media/Krishna_iResearch_/Krishna_iResearch_OpenSource/GitHub/asfer-github-code/python-src/DiscreteHyperbolicFactorizationUpperbound_TileSearch_Optimized.py:167
2018-05-17 17:44:38 INFO  DAGScheduler:54 - Got job 0 (foreach at /media/Krishna_iResearch_/Krishna_iResearch_OpenSource/GitHub/asfer-github-code/python-src/DiscreteHyperbolicFactorizationUpperbound_TileSearch_Optimized.py:167) with 2 output partitions
2018-05-17 17:44:38 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (foreach at /media/Krishna_iResearch_/Krishna_iResearch_OpenSource/GitHub/asfer-github-code/python-src/DiscreteHyperbolicFactorizationUpperbound_TileSearch_Optimized.py:167)
2018-05-17 17:44:38 INFO  DAGScheduler:54 - Parents of final stage: List()
2018-05-17 17:44:38 INFO  DAGScheduler:54 - Missing parents: List()
2018-05-17 17:44:38 INFO  DAGScheduler:54 - Submitting ResultStage 0 (PythonRDD[1] at foreach at /media/Krishna_iResearch_/Krishna_iResearch_OpenSource/GitHub/asfer-github-code/python-src/DiscreteHyperbolicFactorizationUpperbound_TileSearch_Optimized.py:167), which has no missing parents
2018-05-17 17:44:38 WARN  SizeEstimator:66 - Failed to check whether UseCompressedOops is set; assuming yes
2018-05-17 17:44:38 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 6.5 KB, free 413.9 MB)
2018-05-17 17:44:39 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 413.9 MB)
2018-05-17 17:44:39 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 192.168.1.116:50885 (size: 4.1 KB, free: 413.9 MB)
2018-05-17 17:44:39 INFO  SparkContext:54 - Created broadcast 0 from broadcast at DAGScheduler.scala:1039
2018-05-17 17:44:39 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ResultStage 0 (PythonRDD[1] at foreach at /media/Krishna_iResearch_/Krishna_iResearch_OpenSource/GitHub/asfer-github-code/python-src/DiscreteHyperbolicFactorizationUpperbound_TileSearch_Optimized.py:167) (first 15 tasks are for partitions Vector(0, 1))
2018-05-17 17:44:39 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 2 tasks
2018-05-17 17:44:39 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7839 bytes)
2018-05-17 17:44:39 INFO  TaskSetManager:54 - Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 7839 bytes)
2018-05-17 17:44:39 INFO  Executor:54 - Running task 1.0 in stage 0.0 (TID 1)
2018-05-17 17:44:39 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2018-05-17 17:44:39 INFO  Executor:54 - Fetching file:/media/Krishna_iResearch_/Krishna_iResearch_OpenSource/GitHub/asfer-github-code/python-src/DiscreteHyperbolicFactorizationUpperbound_TileSearch_Optimized.py with timestamp 1526559276104
2018-05-17 17:44:39 INFO  Utils:54 - /media/Krishna_iResearch_/Krishna_iResearch_OpenSource/GitHub/asfer-github-code/python-src/DiscreteHyperbolicFactorizationUpperbound_TileSearch_Optimized.py has been previously copied to /tmp/spark-ea6a1cf1-6816-4cc1-81a0-8b6e9ba35e94/userFiles-7ba0a1c2-8ecf-4657-96ea-a3f4ebac0d12/DiscreteHyperbolicFactorizationUpperbound_TileSearch_Optimized.py
=================================================
Factor is =  1
=================================================
=================================================
Factor is =  3
=================================================
=================================================
Factor is =  9
=================================================
=================================================
Factor is =  27
=================================================
=================================================
Factor is =  37
=================================================
=================================================
Factor is =  81
=================================================
=================================================
Factor is =  111
=================================================
=================================================
Factor is =  333
=================================================
=================================================
Factor is =  999
=================================================
=================================================
Factor is =  2997
=================================================
=================================================
Factor is =  333667
=================================================
=================================================
Factor is =  1001001
=================================================
=================================================
Factor is =  3003003
=================================================
=================================================
Factor is =  9009009
=================================================
=================================================
Factor is =  12345679
=================================================
