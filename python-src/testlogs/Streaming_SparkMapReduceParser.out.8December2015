Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
15/12/08 14:50:34 INFO SparkContext: Running Spark version 1.5.2
15/12/08 14:50:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
15/12/08 14:50:37 WARN Utils: Your hostname, shrinivaasanka-Inspiron-1545 resolves to a loopback address: 127.0.1.1; using 14.99.224.131 instead (on interface ppp0)
15/12/08 14:50:37 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
15/12/08 14:50:37 INFO SecurityManager: Changing view acls to: root
15/12/08 14:50:37 INFO SecurityManager: Changing modify acls to: root
15/12/08 14:50:37 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
15/12/08 14:50:41 INFO Slf4jLogger: Slf4jLogger started
15/12/08 14:50:41 INFO Remoting: Starting remoting
15/12/08 14:50:43 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@14.99.224.131:37245]
15/12/08 14:50:43 INFO Utils: Successfully started service 'sparkDriver' on port 37245.
15/12/08 14:50:43 INFO SparkEnv: Registering MapOutputTracker
15/12/08 14:50:43 INFO SparkEnv: Registering BlockManagerMaster
15/12/08 14:50:43 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-49b50340-dabc-41c5-98ba-4fd36ba6ee24
15/12/08 14:50:43 INFO MemoryStore: MemoryStore started with capacity 530.0 MB
15/12/08 14:50:43 INFO HttpFileServer: HTTP File server directory is /tmp/spark-ff2b6c84-2229-4c95-8bb1-4de0dba361ac/httpd-e3d10585-a2b9-41d0-81cc-36d0b37fb831
15/12/08 14:50:43 INFO HttpServer: Starting HTTP Server
15/12/08 14:50:44 INFO Utils: Successfully started service 'HTTP file server' on port 55017.
15/12/08 14:50:44 INFO SparkEnv: Registering OutputCommitCoordinator
15/12/08 14:50:45 INFO Utils: Successfully started service 'SparkUI' on port 4040.
15/12/08 14:50:45 INFO SparkUI: Started SparkUI at http://14.99.224.131:4040
15/12/08 14:50:54 INFO Utils: Copying /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/Streaming_SparkMapReduceParser.py to /tmp/spark-ff2b6c84-2229-4c95-8bb1-4de0dba361ac/userFiles-0c4d52ca-aaad-4690-895e-aa5852264451/Streaming_SparkMapReduceParser.py
15/12/08 14:50:54 INFO SparkContext: Added file file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/Streaming_SparkMapReduceParser.py at file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/Streaming_SparkMapReduceParser.py with timestamp 1449566454254
15/12/08 14:50:54 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
15/12/08 14:50:54 INFO Executor: Starting executor ID driver on host localhost
15/12/08 14:50:55 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52852.
15/12/08 14:50:55 INFO NettyBlockTransferService: Server created on 52852
15/12/08 14:50:55 INFO BlockManagerMaster: Trying to register BlockManager
15/12/08 14:50:55 INFO BlockManagerMasterEndpoint: Registering block manager localhost:52852 with 530.0 MB RAM, BlockManagerId(driver, localhost, 52852)
15/12/08 14:50:55 INFO BlockManagerMaster: Registered BlockManager
15/12/08 14:50:57 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/Streaming_SparkMapReduceParser.py:49
15/12/08 14:50:57 INFO DAGScheduler: Registering RDD 2 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/Streaming_SparkMapReduceParser.py:48)
15/12/08 14:50:57 INFO DAGScheduler: Got job 0 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/Streaming_SparkMapReduceParser.py:49) with 2 output partitions
15/12/08 14:50:57 INFO DAGScheduler: Final stage: ResultStage 1(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/Streaming_SparkMapReduceParser.py:49)
15/12/08 14:50:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
15/12/08 14:50:57 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
15/12/08 14:50:58 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/Streaming_SparkMapReduceParser.py:48), which has no missing parents
15/12/08 14:50:58 WARN SizeEstimator: Failed to check whether UseCompressedOops is set; assuming yes
15/12/08 14:50:58 INFO MemoryStore: ensureFreeSpace(7552) called with curMem=0, maxMem=555755765
15/12/08 14:50:58 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 7.4 KB, free 530.0 MB)
15/12/08 14:50:58 INFO MemoryStore: ensureFreeSpace(4605) called with curMem=7552, maxMem=555755765
15/12/08 14:50:58 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.5 KB, free 530.0 MB)
15/12/08 14:50:58 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:52852 (size: 4.5 KB, free: 530.0 MB)
15/12/08 14:50:58 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
15/12/08 14:50:58 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[2] at reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/Streaming_SparkMapReduceParser.py:48)
15/12/08 14:50:58 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
15/12/08 14:50:58 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 4306 bytes)
15/12/08 14:50:58 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 3722 bytes)
15/12/08 14:50:58 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
15/12/08 14:50:58 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
15/12/08 14:50:58 INFO Executor: Fetching file:/media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/Streaming_SparkMapReduceParser.py with timestamp 1449566454254
15/12/08 14:50:59 INFO Utils: /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/Streaming_SparkMapReduceParser.py has been previously copied to /tmp/spark-ff2b6c84-2229-4c95-8bb1-4de0dba361ac/userFiles-0c4d52ca-aaad-4690-895e-aa5852264451/Streaming_SparkMapReduceParser.py
15/12/08 14:51:01 INFO PythonRunner: Times: total = 2260, boot = 2181, init = 39, finish = 40
15/12/08 14:51:01 INFO PythonRunner: Times: total = 2262, boot = 2176, init = 46, finish = 40
15/12/08 14:51:01 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1223 bytes result sent to driver
15/12/08 14:51:01 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1223 bytes result sent to driver
15/12/08 14:51:01 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 2825 ms on localhost (1/2)
15/12/08 14:51:01 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 2772 ms on localhost (2/2)
15/12/08 14:51:01 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
15/12/08 14:51:01 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/Streaming_SparkMapReduceParser.py:48) finished in 2.939 s
15/12/08 14:51:01 INFO DAGScheduler: looking for newly runnable stages
15/12/08 14:51:01 INFO DAGScheduler: running: Set()
15/12/08 14:51:01 INFO DAGScheduler: waiting: Set(ResultStage 1)
15/12/08 14:51:01 INFO DAGScheduler: failed: Set()
15/12/08 14:51:01 INFO DAGScheduler: Missing parents for ResultStage 1: List()
15/12/08 14:51:01 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/Streaming_SparkMapReduceParser.py:49), which is now runnable
15/12/08 14:51:02 INFO MemoryStore: ensureFreeSpace(5192) called with curMem=12157, maxMem=555755765
15/12/08 14:51:02 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 5.1 KB, free 530.0 MB)
15/12/08 14:51:02 INFO MemoryStore: ensureFreeSpace(3222) called with curMem=17349, maxMem=555755765
15/12/08 14:51:02 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.1 KB, free 530.0 MB)
15/12/08 14:51:02 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:52852 (size: 3.1 KB, free: 530.0 MB)
15/12/08 14:51:02 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
15/12/08 14:51:02 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/Streaming_SparkMapReduceParser.py:49)
15/12/08 14:51:02 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
15/12/08 14:51:02 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2092 bytes)
15/12/08 14:51:02 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2092 bytes)
15/12/08 14:51:02 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
15/12/08 14:51:02 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
15/12/08 14:51:02 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/12/08 14:51:02 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/12/08 14:51:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 25 ms
15/12/08 14:51:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 28 ms
15/12/08 14:51:02 INFO PythonRunner: Times: total = 18, boot = -876, init = 893, finish = 1
15/12/08 14:51:02 INFO PythonRunner: Times: total = 18, boot = -867, init = 884, finish = 1
15/12/08 14:51:02 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 2189 bytes result sent to driver
15/12/08 14:51:02 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 2157 bytes result sent to driver
15/12/08 14:51:02 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 161 ms on localhost (1/2)
15/12/08 14:51:02 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 175 ms on localhost (2/2)
15/12/08 14:51:02 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
15/12/08 14:51:02 INFO DAGScheduler: ResultStage 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/Streaming_SparkMapReduceParser.py:49) finished in 0.177 s
15/12/08 14:51:02 INFO DAGScheduler: Job 0 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/Streaming_SparkMapReduceParser.py:49, took 4.675695 s
Spark MapReduce results:
[('11210.97\n', 32), ('11176.07\n', 30), ('11324.80\n', 29), ('11253.24\n', 29), ('5\n', 7), ('4\n', 7), ('1253.24\n', 7), ('23\n', 7), ('54\n', 6), ('11279.65\n', 5), ('1176.07\n', 5), ('34\n', 4), ('2\n', 4), ('32\n', 4), ('3\n', 4), ('1324.80\n', 4), ('324.80\n', 4), ('43\n', 3), ('45\n', 3), ('1210.97\n', 3), ('176.07\n', 3), ('253.24\n', 3), ('232\n', 2), ('11294.94\n', 2), ('11209.77\n', 2), ('11151.34\n', 2), ('210.97\n', 2), ('73886.564728138\n', 1), ('73898.545566924\n', 1), ('3896.134840278\n', 1), ('3906.2\n', 1), ('11097.23\n', 1), ('3907.366003301\n', 1), ('898\n', 1), ('21\n', 1), ('73894.446086190\n', 1), ('dssdsdssdsd\n', 1), ('53\n', 1), ('3894.027858345\n', 1), ('73903.113948042\n', 1), ('3895.250597658\n', 1), ('67\n', 1), ('73887.832578763\n', 1), ('42\n', 1), ('36\n', 1), ('dskdsl\n', 1), ('sdsdsdssssssss\n', 1), ('3896.484495961\n', 1), ('gxhghxg\n', 1), ('2165270016\n', 1), ('33243\n', 1), ('iioeoiowo\n', 1), ('73904.118525642\n', 1), ('11030.23\n', 1), ('ssdsds\n', 1), ('3906.876790421\n', 1), ('73890.298873108\n', 1), ('435\n', 1), ('899.421295233\n', 1), ('11253.23\n', 1), ('3891.494155878\n', 1), ('3897.161606313\n', 1), ('11190.96\n', 1), ('\n', 1), ('65\n', 1), ('345\n', 1), ('43423\n', 1), ('6\n', 1), ('2292999936\n', 1), ('57\n', 1), ('901.236901477\n', 1), ('3900.765462846\n', 1), ('2292179968\n', 1), ('904.658246223\n', 1), ('24.80\n', 1), ('43343\n', 1), ('73888.225341230\n', 1), ('73901.619737376\n', 1), ('32323\n', 1), ('1\n', 1), ('73888.575435121\n', 1), ('902.450028066\n', 1), ('655\n', 1), ('3889.267531573\n', 1), ('jdsjdsk\n', 1), ('73890.025329227\n', 1), ('73891.807796805\n', 1), ('73905.474405902\n', 1), ('73893.053610028\n', 1), ('323\n', 1), ('898.722960509\n', 1), ('11076.02\n', 1), ('234\n', 1), ('2549619968\n', 1), ('dsdsds\n', 1), ('73885.399249226\n', 1), ('4324\n', 1), ('10.97\n', 1), ('3899.932742683\n', 1), ('78355224\n', 1), ('11258.28\n', 1), ('sasasaa\n', 1), ('11149.76\n', 1), ('92.551464300\n', 1)]
15/12/08 14:51:02 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/Streaming_SparkMapReduceParser.py:56
15/12/08 14:51:02 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 155 bytes
15/12/08 14:51:02 INFO DAGScheduler: Got job 1 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/Streaming_SparkMapReduceParser.py:56) with 2 output partitions
15/12/08 14:51:02 INFO DAGScheduler: Final stage: ResultStage 3(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/Streaming_SparkMapReduceParser.py:56)
15/12/08 14:51:02 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
15/12/08 14:51:02 INFO DAGScheduler: Missing parents: List()
15/12/08 14:51:02 INFO DAGScheduler: Submitting ResultStage 3 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/Streaming_SparkMapReduceParser.py:49), which has no missing parents
15/12/08 14:51:02 INFO MemoryStore: ensureFreeSpace(5192) called with curMem=20571, maxMem=555755765
15/12/08 14:51:02 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.1 KB, free 530.0 MB)
15/12/08 14:51:02 INFO MemoryStore: ensureFreeSpace(3222) called with curMem=25763, maxMem=555755765
15/12/08 14:51:02 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.1 KB, free 530.0 MB)
15/12/08 14:51:02 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:52852 (size: 3.1 KB, free: 530.0 MB)
15/12/08 14:51:02 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
15/12/08 14:51:02 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 3 (PythonRDD[5] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/Streaming_SparkMapReduceParser.py:49)
15/12/08 14:51:02 INFO TaskSchedulerImpl: Adding task set 3.0 with 2 tasks
15/12/08 14:51:02 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 4, localhost, PROCESS_LOCAL, 2092 bytes)
15/12/08 14:51:02 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 5, localhost, PROCESS_LOCAL, 2092 bytes)
15/12/08 14:51:02 INFO Executor: Running task 0.0 in stage 3.0 (TID 4)
15/12/08 14:51:02 INFO Executor: Running task 1.0 in stage 3.0 (TID 5)
15/12/08 14:51:02 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/12/08 14:51:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 13 ms
15/12/08 14:51:02 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/12/08 14:51:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
15/12/08 14:51:02 INFO PythonRunner: Times: total = 55, boot = -271, init = 325, finish = 1
15/12/08 14:51:02 INFO PythonRunner: Times: total = 55, boot = -308, init = 363, finish = 0
15/12/08 14:51:02 INFO Executor: Finished task 0.0 in stage 3.0 (TID 4). 2157 bytes result sent to driver
15/12/08 14:51:02 INFO Executor: Finished task 1.0 in stage 3.0 (TID 5). 2189 bytes result sent to driver
15/12/08 14:51:02 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 4) in 115 ms on localhost (1/2)
15/12/08 14:51:02 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 5) in 119 ms on localhost (2/2)
15/12/08 14:51:02 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
15/12/08 14:51:02 INFO DAGScheduler: ResultStage 3 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/Streaming_SparkMapReduceParser.py:56) finished in 0.123 s
15/12/08 14:51:02 INFO DAGScheduler: Job 1 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/Streaming_SparkMapReduceParser.py:56, took 0.245259 s
15/12/08 14:51:06 INFO SparkContext: Starting job: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/Streaming_SparkMapReduceParser.py:59
15/12/08 14:51:06 INFO DAGScheduler: Got job 2 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/Streaming_SparkMapReduceParser.py:59) with 2 output partitions
15/12/08 14:51:06 INFO DAGScheduler: Final stage: ResultStage 4(collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/Streaming_SparkMapReduceParser.py:59)
15/12/08 14:51:06 INFO DAGScheduler: Parents of final stage: List()
15/12/08 14:51:06 INFO DAGScheduler: Missing parents: List()
15/12/08 14:51:06 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/Streaming_SparkMapReduceParser.py:59), which has no missing parents
15/12/08 14:51:06 INFO MemoryStore: ensureFreeSpace(5728) called with curMem=28985, maxMem=555755765
15/12/08 14:51:06 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 5.6 KB, free 530.0 MB)
15/12/08 14:51:06 INFO MemoryStore: ensureFreeSpace(3328) called with curMem=34713, maxMem=555755765
15/12/08 14:51:06 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.3 KB, free 530.0 MB)
15/12/08 14:51:06 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:52852 (size: 3.3 KB, free: 530.0 MB)
15/12/08 14:51:06 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861
15/12/08 14:51:06 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[12] at collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/Streaming_SparkMapReduceParser.py:59)
15/12/08 14:51:06 INFO TaskSchedulerImpl: Adding task set 4.0 with 2 tasks
15/12/08 14:51:06 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, localhost, PROCESS_LOCAL, 3063 bytes)
15/12/08 14:51:06 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, localhost, PROCESS_LOCAL, 3171 bytes)
15/12/08 14:51:06 INFO Executor: Running task 0.0 in stage 4.0 (TID 6)
15/12/08 14:51:06 INFO Executor: Running task 1.0 in stage 4.0 (TID 7)
15/12/08 14:51:07 INFO PythonRunner: Times: total = 60, boot = -4201, init = 4261, finish = 0
15/12/08 14:51:07 INFO PythonRunner: Times: total = 53, boot = -4192, init = 4245, finish = 0
15/12/08 14:51:07 INFO Executor: Finished task 0.0 in stage 4.0 (TID 6). 4056 bytes result sent to driver
15/12/08 14:51:07 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 237 ms on localhost (1/2)
15/12/08 14:51:07 INFO Executor: Finished task 1.0 in stage 4.0 (TID 7). 4164 bytes result sent to driver
15/12/08 14:51:07 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 244 ms on localhost (2/2)
15/12/08 14:51:07 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
15/12/08 14:51:07 INFO DAGScheduler: ResultStage 4 (collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/Streaming_SparkMapReduceParser.py:59) finished in 0.242 s
15/12/08 14:51:07 INFO DAGScheduler: Job 2 finished: collect at /media/shrinivaasanka/0fc4d8a2-1c74-42b8-8099-9ef78d8c8ea2/home/kashrinivaasan/KrishnaiResearch_OpenSource/GitHub/asfer-github-code/python-src/Streaming_SparkMapReduceParser.py:59, took 0.269749 s
SparkSQL DataFrame query results:
{u'54\n': 6, u'73886.564728138\n': 1, u'34\n': 4, u'232\n': 2, u'73898.545566924\n': 1, u'3896.134840278\n': 1, u'3906.2\n': 1, u'11097.23\n': 1, u'3907.366003301\n': 1, u'898\n': 1, u'21\n': 1, u'73894.446086190\n': 1, u'dssdsdssdsd\n': 1, u'53\n': 1, u'3894.027858345\n': 1, u'5\n': 7, u'73903.113948042\n': 1, u'3895.250597658\n': 1, u'67\n': 1, u'73887.832578763\n': 1, u'42\n': 1, u'36\n': 1, u'11294.94\n': 2, u'dskdsl\n': 1, u'11279.65\n': 5, u'11209.77\n': 2, u'sdsdsdssssssss\n': 1, u'2\n': 4, u'3896.484495961\n': 1, u'gxhghxg\n': 1, u'2165270016\n': 1, u'43\n': 3, u'33243\n': 1, u'iioeoiowo\n': 1, u'73904.118525642\n': 1, u'11030.23\n': 1, u'32\n': 4, u'ssdsds\n': 1, u'11324.80\n': 29, u'11151.34\n': 2, u'3906.876790421\n': 1, u'73890.298873108\n': 1, u'435\n': 1, u'3\n': 4, u'11176.07\n': 30, u'899.421295233\n': 1, u'11253.23\n': 1, u'1324.80\n': 4, u'3891.494155878\n': 1, u'3897.161606313\n': 1, u'11190.96\n': 1, u'\n': 1, u'65\n': 1, u'345\n': 1, u'43423\n': 1, u'324.80\n': 4, u'6\n': 1, u'2292999936\n': 1, u'45\n': 3, u'11253.24\n': 29, u'57\n': 1, u'1210.97\n': 3, u'901.236901477\n': 1, u'3900.765462846\n': 1, u'2292179968\n': 1, u'904.658246223\n': 1, u'24.80\n': 1, u'43343\n': 1, u'73888.225341230\n': 1, u'73901.619737376\n': 1, u'32323\n': 1, u'176.07\n': 3, u'1\n': 1, u'73888.575435121\n': 1, u'902.450028066\n': 1, u'210.97\n': 2, u'655\n': 1, u'3889.267531573\n': 1, u'jdsjdsk\n': 1, u'73890.025329227\n': 1, u'73891.807796805\n': 1, u'253.24\n': 3, u'73905.474405902\n': 1, u'73893.053610028\n': 1, u'4\n': 7, u'323\n': 1, u'898.722960509\n': 1, u'11076.02\n': 1, u'234\n': 1, u'2549619968\n': 1, u'dsdsds\n': 1, u'1253.24\n': 7, u'11210.97\n': 32, u'73885.399249226\n': 1, u'4324\n': 1, u'10.97\n': 1, u'3899.932742683\n': 1, u'78355224\n': 1, u'11258.28\n': 1, u'23\n': 7, u'1176.07\n': 5, u'sasasaa\n': 1, u'11149.76\n': 1, u'92.551464300\n': 1}
Cardinality of Stream Dataset:
104
15/12/08 14:51:07 INFO SparkContext: Invoking stop() from shutdown hook
15/12/08 14:51:07 INFO SparkUI: Stopped Spark web UI at http://14.99.224.131:4040
15/12/08 14:51:07 INFO DAGScheduler: Stopping DAGScheduler
15/12/08 14:51:07 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
15/12/08 14:51:07 INFO MemoryStore: MemoryStore cleared
15/12/08 14:51:07 INFO BlockManager: BlockManager stopped
15/12/08 14:51:07 INFO BlockManagerMaster: BlockManagerMaster stopped
15/12/08 14:51:07 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
15/12/08 14:51:07 INFO SparkContext: Successfully stopped SparkContext
15/12/08 14:51:07 INFO ShutdownHookManager: Shutdown hook called
15/12/08 14:51:07 INFO ShutdownHookManager: Deleting directory /tmp/spark-ff2b6c84-2229-4c95-8bb1-4de0dba361ac
