Policy action index chosen by Monte Carlo: 2
State transition on observation : a
[6, 2]
Reward collected so far: 0.2
Policy action index chosen by Monte Carlo: 2
State transition on observation : h
[6, 2]
Reward collected so far: 0.4
Policy action index chosen by Monte Carlo: 4
State transition on observation : k
[5, 4]
Reward collected so far: 0.9
Policy action index chosen by Monte Carlo: 5
State transition on observation : a
[4, 1]
Reward collected so far: 1.7
Policy action index chosen by Monte Carlo: 5
State transition on observation : a
[4, 1]
Reward collected so far: 2.5
Policy action index chosen by Monte Carlo: 3
State transition on observation : h
[3, 6]
Reward collected so far: 3.4
Policy action index chosen by Monte Carlo: 4
State transition on observation : h
[5, 4]
Reward collected so far: 3.9
Policy action index chosen by Monte Carlo: 2
State transition on observation : k
[6, 2]
Reward collected so far: 4.1
Policy action index chosen by Monte Carlo: 4
State transition on observation : b
[5, 4]
Reward collected so far: 4.6
Policy action index chosen by Monte Carlo: 4
State transition on observation : l
[5, 4]
Reward collected so far: 5.1
Policy action index chosen by Monte Carlo: 3
State transition on observation : l
[3, 6]
Reward collected so far: 6.0
Policy action index chosen by Monte Carlo: 4
State transition on observation : a
[5, 4]
Reward collected so far: 6.5
Policy action index chosen by Monte Carlo: 3
State transition on observation : g
[3, 6]
Reward collected so far: 7.4


======================================================================================
Policy action index chosen by Monte Carlo: 3
State transition on observation : a
[3, 6]
Reward collected so far: 0.9
Policy action index chosen by Monte Carlo: 4
State transition on observation : h
[5, 4]
Reward collected so far: 1.4
Policy action index chosen by Monte Carlo: 3
State transition on observation : k
[3, 6]
Reward collected so far: 2.3
Policy action index chosen by Monte Carlo: 4
State transition on observation : a
[5, 4]
Reward collected so far: 2.8
Policy action index chosen by Monte Carlo: 2
State transition on observation : a
[6, 2]
Reward collected so far: 3.0
Policy action index chosen by Monte Carlo: 4
State transition on observation : h
[5, 4]
Reward collected so far: 3.5
Policy action index chosen by Monte Carlo: 1
State transition on observation : h
[0, 1]
Reward collected so far: 4.3
Policy action index chosen by Monte Carlo: 4
State transition on observation : k
[5, 4]
Reward collected so far: 4.8
Policy action index chosen by Monte Carlo: 2
State transition on observation : b
[6, 2]
Reward collected so far: 5.0
Policy action index chosen by Monte Carlo: 1
State transition on observation : l
[0, 1]
Reward collected so far: 5.8
Policy action index chosen by Monte Carlo: 5
State transition on observation : l
[4, 1]
Reward collected so far: 6.6
Policy action index chosen by Monte Carlo: 5
State transition on observation : a
[4, 1]
Reward collected so far: 7.4
Policy action index chosen by Monte Carlo: 1
State transition on observation : g
[0, 1]
Reward collected so far: 8.2

=========================================================================

Policy action index chosen by Monte Carlo: 4
State transition on observation : a
[5, 4]
Reward collected so far: 0.5
Policy action index chosen by Monte Carlo: 4
State transition on observation : h
[5, 4]
Reward collected so far: 1.0
Policy action index chosen by Monte Carlo: 5
State transition on observation : k
[4, 1]
Reward collected so far: 1.8
Policy action index chosen by Monte Carlo: 3
State transition on observation : a
[3, 6]
Reward collected so far: 2.7
Policy action index chosen by Monte Carlo: 2
State transition on observation : a
[6, 2]
Reward collected so far: 2.9
Policy action index chosen by Monte Carlo: 5
State transition on observation : h
[4, 1]
Reward collected so far: 3.7
Policy action index chosen by Monte Carlo: 4
State transition on observation : h
[5, 4]
Reward collected so far: 4.2
Policy action index chosen by Monte Carlo: 5
State transition on observation : k
[4, 1]
Reward collected so far: 5.0
Policy action index chosen by Monte Carlo: 6
State transition on observation : b
[1, 5]
Reward collected so far: 5.75
Policy action index chosen by Monte Carlo: 5
State transition on observation : l
[4, 1]
Reward collected so far: 6.55
Policy action index chosen by Monte Carlo: 6
State transition on observation : l
[1, 5]
Reward collected so far: 7.3
Policy action index chosen by Monte Carlo: 1
State transition on observation : a
[0, 1]
Reward collected so far: 8.1
Policy action index chosen by Monte Carlo: 1
State transition on observation : g
[0, 1]
Reward collected so far: 8.9
