#/***************************************************************************************
#ASFER - a ruleminer which gets rules specific to a query and executes them
#
#This program is free software: you can redistribute it and/or modify
#it under the terms of the GNU General Public License as published by
#the Free Software Foundation, either version 3 of the License, or
#(at your option) any later version.
#
#This program is distributed in the hope that it will be useful,
#but WITHOUT ANY WARRANTY; without even the implied warranty of
#MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#GNU General Public License for more details.
#
#You should have received a copy of the GNU General Public License
#along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
#---------------------------------------------------------------------------------------------------
#Copyright (C):
#Srinivasan Kannan (alias) Ka.Shrinivaasan (alias) Shrinivas Kannan
#Independent Open Source Developer, Researcher and Consultant
#Ph: 9003082186, 9791165980
#Open Source Products Profile(Krishna iResearch): http://sourceforge.net/users/ka_shrinivaasan
#Personal website(research): https://sites.google.com/site/kuja27/
#emails: ka.shrinivaasan@gmail.com, shrinivas.kannan@gmail.com, kashrinivaasan@live.com
#---------------------------------------------------------------------------------------------------
#*****************************************************************************************/

#autogenerated words.txt and words-frequency.txt needed for NaiveBayesClassifier
global filteredwordsinarticle

attrvalues=["Tornadoes","Hurricanes","Typhoon","Cyclone","Tsunami","Earthquakes","Temperature","Air","Earth","Water","Sky"]

def filterWordsInArticle(wordsinarticle):
	filteredwordsinarticle=[]
	for e in wordsinarticle:
		if e.find("~") == -1 and e.find(",") == -1 and e.find("&") == -1 and e.find("?") == -1 and e.find("%") == -1 and e.find(">") == -1 and e.find("<") == -1 and e != "-" and e.find("=") == -1 and e.find("[") == -1 and e.find("]") == -1 and e.find(".") == -1 and e.find(":") == -1 and e.find("{") == -1 and e.find("}") == -1 and e.find("(") == -1 and e.find(")") == -1 and e.find("|") == -1 and e.find("\"") == -1 and e in attrvalues:
			filteredwordsinarticle.append(e)
	return filteredwordsinarticle 

articlesdataset=open("articlesdataset.txt","r") #contains fullpath to the article files
articles=[]
for e in articlesdataset:
	articles.append(e.strip())

words=[]
articleid=1
wordstxt=open("words.txt","w")
wordfrequencytxt=open("word-frequency.txt","w")
while articleid <= len(articles):
	articlewordfrequency={}
	f=open(articles[articleid-1],"r")
	articlecontents=f.read()
	wordsinarticle=articlecontents.split()
	wordsinarticle=filterWordsInArticle(wordsinarticle)
	words=words+wordsinarticle
	setwordsinarticle=set(wordsinarticle)
	for e in setwordsinarticle:
		articlewordfrequency[e]=wordsinarticle.count(e)
	#print "Word frequency for article ", articleid, ":", wordfrequency
	for k,v in articlewordfrequency.items():
		wordstxt.write(k+"~"+str(articleid)+"~"+str(v)+"\n")
	articleid=articleid+1
wordfrequency={}
setwords=set(words)
for e in setwords:
	wordfrequency[e]=words.count(e)
for k,v in wordfrequency.items():
	wordfrequencytxt.write(k+"~"+str(v)+"\n")

#autogenerated training-set.txt , test-set.txt and topics.txt for NaiveBayes Classifier
trainingsettxt=open("training-set.txt","w")
testsettxt=open("test-set.txt","w")
topicstxt=open("topics.txt","w")

#following need to be updated based on the article dataset file above- mostly testset might have to be updated
trainingset=[1,2] #article id(s)
testset=[3,4,5]
topics=["Storms~1","Earthquakes~2"]
for e in trainingset:
	trainingsettxt.write(str(e)+"\n")
for e in testset:
	testsettxt.write(str(e)+"\n")
for e in topics:
	topicstxt.write(e+"\n")
 

#autogenerated decisiontree-attrvalues.txt  decisiontree-training.txt  decisiontree-test.txt  for DecisionTree Classifier
decisiontreeattrvaluestxt=open("decisiontree-attrvalues.txt","w")
decisiontreetrainingtxt=open("decisiontree-training.txt","w")
decisiontreetesttxt=open("decisiontree-test.txt","w")

#following need to be updated based on the article dataset file above- mostly testset might have to be updated
decisiontreeattrvalues=["Type1-Asteroids,Comets,Tornadoes,Hurricanes,Typhoon,Cyclone,Tsunami,Tremors,Temperature,nil-",
			"Type2-Asteroids,Comets,Tornadoes,Hurricanes,Typhoon,Cyclone,Tsunami,Tremors,Temperature,nil-",
			"Place1-Air,Earth,Water,Sky,nil-",
			"Place2-Air,Earth,Water,Sky,nil-",
			"Place3-Air,Earth,Water,Sky,nil-",
			"Class-Earthquakes,Storms,Celestial-"
]

decisiontreetraining=["Type1 Type2 Place1 Place2 Place3 Class",
			"nil Cyclone Earth Air Water Storms",
			"Tsunami Tremors Water Earth nil Earthquakes",
			"Asteroids nil Sky nil nil Celestial",
			"Comets nil Sky nil nil Celestial",
			"Hurricane nil Earth Air Water Storms",
			"Tornadoes nil Earth Air nil Storms",
			"Cyclone nil Earth Air Water Storms",
			"Tremors nil Earth nil nil Earthquakes",
			"Typhoon nil Earth Air Water Storms"
]

decisiontreetest=["Type1   Type2    Place1  Place2  Place3",
		"Tornadoes Hurricanes Air Water Earth" ,
		"Tremors  Tsunami nil Water  Earth" ,
		"Cyclone Temperature Earth Water Air" ,
		"Asteroids nil Sky nil nil",
		"Comets nil Sky nil nil"
]

for e in decisiontreeattrvalues:
	decisiontreeattrvaluestxt.write(e+"\n")
for e in decisiontreetraining:
	decisiontreetrainingtxt.write(e+"\n")
for e in decisiontreetest:
	decisiontreetesttxt.write(e+"\n")
